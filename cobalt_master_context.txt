PROJECT DIRECTORY STRUCTURE
================================================================================

cobalt/
configs/
    config.yaml
    prompts.yaml
    rules.yaml
    strategies.yaml
data/
    postgres/
        base/
            1/
            16384/
            4/
            5/
        global/
        pg_commit_ts/
        pg_dynshmem/
        pg_logical/
            mappings/
            snapshots/
        pg_multixact/
            members/
            offsets/
        pg_notify/
        pg_replslot/
        pg_serial/
        pg_snapshots/
        pg_stat/
        pg_stat_tmp/
        pg_subtrans/
        pg_tblspc/
        pg_twophase/
        pg_wal/
            archive_status/
        pg_xact/
dev_utils/
    brain_scan.py
    create_missing_tasks.py
    create_prd.py
    generate_constitution.py
    generate_context.py
    ingest_knowledge.py
    manage_vault.py
    reset_memory_table.py
    test_prompt.py
    update_board.py
    wipe_memory.py
docs/
    0 - Inbox/
        Briefing_2026-02-24.md
        Briefing_2026-02-25.md
        Morning_Briefing_2026-02-26.md
        Split_Brain_Summary.md
    0 - Projects/
        Cobalt/
            00 - Master Plan/
                ADR/
                    ADR-001 Hybrid Compute Strategy.md
                    ADR-002 Cobalt-Ion Distributed Protocol.md
                    ADR-003 Python-First Architecture.md
                    ADR-004 Zero Trust Security.md
                    ADR-005 Agentic RAG.md
                    ADR-006 Prime Directive and HITL.md
                    ADR-007 HITL Proposal Engine.md
                    ADR-008 JIT Secrets Vault.md
                    ADR-009 Headless Browser Strategy.md
                    ADR-010 Sovereign Split-Brain Architecture.md
                    ADR-011 Vector Librarian.md
                    ADR-012 Drone Polymorphism.md
                Developer Docs/
                    brain_base.md
                    brain_scan.md
                    briefing.md
                    browser.md
                    cli.md
                    config.md
                    cortex.md
                    create_missing_tasks.md
                    create_prd.md
                    deep_dive.md
                    engineering.md
                    filesystem.md
                    finance.md
                    generate_constitution.md
                    generate_context.md
                    knowledge.md
                    llm.md
                    main.md
                    mattermost.md
                    memory_base.md
                    memory_core.md
                    ops.md
                    orchestrator.md
                    persona.md
                    playbook.md
                    postgres.md
                    prompt.md
                    proposals.md
                    reset_memory_table.md
                    scheduler.md
                    scribe.md
                    search.md
                    second_day_play.md
                    strategy.md
                    tactical.md
                    test_script.md
                    tool_manager.md
                    update_board.md
                    vault.md
                    wipe_memory.md
                ARCHITECTURE_ASSESSMENT.md
            90 - Project Management/
                Requirements/
                    PRD-000 The Ironman Directive.md
                    PRD-001 Cobalt-Ion Tactical HUD.md
                    PRD-002 Mattermost HITL Proposal Engine.md
                    PRD-003 Zero Trust Docker Sandbox.md
                    PRD-004 Cortex LLM Switchboard Router.md
                    PRD-005 Voice Architecture.md
                    PRD-006 Dynamic Browser Automation.md
                    PRD-007 Sovereign Split-Brain Orchestration.md
                Sprints/
                    Sprint-2026-02-25 Zero Trust HITL Engine.md
                    Sprint_Agentic_Browser.md
                    Sprint_Hardening_Tech_Debt.md
                User Stories/
                    Story-001_Initial_Brainstorm.md
                Backlog.md
            Tasks/
                01 System Prep.md
                02 Architecture Setup.md
                03 Dependency Management.md
                04 Verification.md
                05 Hello World.md
                06 Core Config.md
                07 Memory System.md
                08 Persona Logic.md
                09 Interface Layer.md
                10 Tool Manager.md
                11 Prompt Engine.md
                12 Browser Capabilities.md
                13 Trading Engine.md
                14 Autonomous Loop.md
                15 Memory Interface.md
                16 Postgres Adapter.md
                17 Cortex Dispatcher.md
                18 Scribe Skill (Obsidian).md
                19 Scheduler & Cron.md
                20 Multi-Agent Orchestration.md
                21 (Morning Briefing).md
                22 Mac Studio Deployment.md
                23 Strategos Agent Setup.md
                24 Playbook Registry.md
                25 Strategy Interface.md
                26 Second Day Play Impl.md
                27 Backtest Engine.md
                28 Ops Medical Stub.md
                29 Privacy Guardrails.md
                30 Ion Core Architecture.md
                31 Cobalt-Ion Bridge.md
                32 HUD Widgets & Overlay.md
                33 Mattermost C2 Integration.md
                34 Automated Trade Journaling.md
                35 Untethering Tailscale VSCode.md
                36 Feature Proposal Engine.md
                37 Feature Docker Sandbox.md
                38 Refactor Switchboard Router.md
                39 Tool Playwright Browser.md
                40 Tool LastPass Integration.md
                41 Dynamic Persona Engine.md
                42 Orchestration State Machine.md
                43 Upgrade Playwright Browser Tool.md
            Cobalt Project Board.base
logs/
    agent_2026-02-22.log
    agent_2026-02-24.log
    agent_2026-02-25.log
    agent_2026-02-26.log
    agent_2026-02-27.log
    cobalt_agent_2026-02-15.log
    mattermost_session.log
src/
    cobalt_agent/
        brain/
            strategies/
                second_day_play.py
            base.py
            cortex.py
            engineering.py
            ops.py
            playbook.py
            strategy.py
            tactical.py
        core/
            orchestrator.py
            proposals.py
        interfaces/
            cli.py
            mattermost.py
        memory/
            base.py
            core.py
            postgres.py
        security/
            vault.py
        services/
            scheduler.py
        skills/
            productivity/
                briefing.py
                scribe.py
            research/
                deep_dive.py
        tools/
            aom.py
            browser.py
            filesystem.py
            finance.py
            knowledge.py
            maps.py
            search.py
            test_script.py
            tool_manager.py
        config.py
        llm.py
        main.py
        persona.py
        prompt.py
    cobalt_agent.egg-info/
        SOURCES.txt
        dependency_links.txt
        requires.txt
        top_level.txt
tests/
    conftest.py
    test_browser_actions.py
    test_browser_aom.py
    test_cortex.py
    test_llm.py
    test_orchestrator.py
    test_scheduler.py
    test_scribe.py
    test_strategies.py
    test_vault.py
README.md
cobalt_master_context.txt
docker-compose.yml
pyproject.toml

========================================
FILE: README.md
========================================



========================================
FILE: cobalt_master_context.txt
========================================



========================================
FILE: configs/config.yaml
========================================

# Project Cobalt Configuration File

system:
  debug_mode: true
  version: "0.5.0"
  obsidian_vault_path: /Users/cobalt/cobalt/docs

# 1. NETWORK TOPOLOGY (Hardware Abstraction)
network:
  nodes:
    cortex:
      role: primary_inference
      ip: "100.70.206.126"
      port: 11434
      protocol: http
    edge_mobile:
      role: client
      ip: localhost
      port: 8080
    edge_dev:
      role: hot_spare
      ip: localhost
      port: 8081
    station_trading:
      role: execution
      ip: localhost
      port: 8082

# 2. CREDENTIALS
keys:
  openai: "OPENAI_API_KEY"
  anthropic: "ANTHROPIC_API_KEY"
  gemini: "GEMINI_API_KEY"
  openrouter: "OPENROUTER_API_KEY"

# 3. UNIVERSAL MODEL REGISTRY (2026 Edition)
models:
  # --- LOCAL ---
  local_coder_32b:
    provider: "ollama"
    model_name: "qwen2.5-coder:32b"
    node_ref: "cortex"
    context: 32768
  local_strategist_r1:
    provider: "ollama"
    model_name: "deepseek-r1:70b"
    node_ref: "cortex"
    context: 16384
  local_bleeding_edge:
    provider: "ollama"
    model_name: "qwen3-coder-next"
    node_ref: "cortex"
    context: 65536

  # --- CLOUD BLEEDING EDGE ---
  cloud_gpt5_2:
    provider: "openai"
    model_name: "gpt-5.2" 
    env_key_ref: "openai"
  cloud_claude_4_6_opus:
    provider: "openrouter"
    model_name: "anthropic/claude-4.6-opus"
    env_key_ref: "openrouter"
  cloud_claude_4_6_sonnet:
    provider: "openrouter"
    model_name: "anthropic/claude-4.6-sonnet"
    env_key_ref: "openrouter"
  cloud_gemini_2_5_pro:
    provider: "gemini"
    model_name: "gemini-2.5-pro"
    env_key_ref: "gemini"
  cloud_gemini_2.5_flash:
    provider: "gemini"
    model_name: "gemini-2.5-flash"
    env_key_ref: "gemini"

# 4. ACTIVE SWITCHBOARD
active_profile:
  default: "local_bleeding_edge"
  coder: "local_bleeding_edge"
  architect: "local_bleeding_edge"
  strategist: "local_strategist_r1"
  researcher: "cloud_gemini_2_5_pro"
  fast_chat: "local_coder_32b"

mattermost:
  approval_channel: "cobalt-approvals"
  approval_team: "cobalt-bridge"

persona:
  name: "Cobalt"
  roles:
    - "Chief of Staff to Dejan"
    - "Principal Systems Architect"
    - "Zero-Trust Automation Engine"
  skills:
    - "Infrastructure and Workflow Automation"
    - "Zero-Trust Security Analysis"
    - "Documentation as Code (Obsidian Vault Integration)"
    - "Systematic Problem Solving and Triage"
  tone:
    - "Hyper-competent and authoritative"
    - "Analytical and unshakeable"
    - "Extremely concise (high signal, zero noise)"
    - "Professional (strictly avoid chatty filler, apologies, and sycophancy)"
  directives:
    - "PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework."
    - "PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization."
    - "ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands."
    - "DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented."
    - "BREVITY: Deliver answers directly. Eliminate introductory filler."
    - "FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions."
    - "TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only."

# COBALT ORGANIZATIONAL CHART
# Defines the active Departments and their mission statements.
departments:
  TACTICAL:
    description: "Capital Allocation, Trading Strategies, Market Data, Risk Management, 'Stocks in Play'."
    active: true
  INTEL:
    description: "Deep Research, News Briefings, Information Retrieval, Macro Analysis."
    active: true
  GROWTH:
    description: "Project Management, Skill Acquisition, Real Estate, Solar/Homestead Planning."
    active: true
  OPS:
    description: "Medical Admin (Billing/Coding), Journaling (Scribe), Scheduling."
    active: true
  ENGINEERING:
    description: "Writing new code, fixing tools, system upgrades."
    active: true
  DEFAULT:
    description: "General chat, web research, web browsing, article summarization. Use for queries that don't fit other domains."
    active: true

# 5. BROWSER CONFIGURATION
# Domain whitelist for Zero-Trust Browser Security
browser:
  allowed_domains:
    - "finviz.com"
    - "tradingview.com"
    - "sec.gov"
    - "example.com"


========================================
FILE: configs/prompts.yaml
========================================

# Cobalt Prompts Configuration
# Centralized storage for all LLM prompts (system and user templates)
# All prompts support dynamic variable injection via Python's .format() method

# === SYSTEM IDENTITY & CORE DIRECTIVES ===
system:
  core_identity: |
    You are {name}, an advanced AI agent with the following attributes:

    ROLES:
    {roles}

    SKILLS:
    {skills}

    COMMUNICATION STYLE:
    {tone}

    CORE DIRECTIVES:
    {directives}

    MISSION: Execute tasks with precision, leveraging your multidisciplinary expertise 
    to deliver optimal outcomes while adhering to core directives.

# === SCHEDULER PROMPTS ===
scheduler:
  morning_briefing: |
    You are an intraday daytrader. Summarize the US market for {today_str} using this preferred format:

    General Market Tone
    Mood:
    Internals:
    Economic / Macro Backdrop:
    Day-Trading implication:

    Key Pre-Market Movers (bullets or bearish ‚Äî ticker / % move pre-market/ reason / catalyst & long or short trade idea)
    For key pre-market movers filter and only consider if:
    Hard rules are pre-market price > $1, pre-market volume > 100K and one of the following (ATR > 0.4, RVOL > 4)
    Addition to that use any of the following filters (Average Daily Volume 14 days > 2M, gap outside -3% and +3%)

    (For each Ticker do following)
    Moving Ticker symbol (company name) +/- ~% pre-market
    Why:
    Catalyst:
    Opportunity (daytrader):
    Trade Idea:

    Lastly provide following summary: Bottom Line ‚Äî intraday trade plan

# === OPERATIONS PROMPTS ===
ops:
  system: |
    You are THE SCRIBE, Cobalt's Chief of Operations.
    Your job is to read data, format documentation cleanly, and maintain the Obsidian Vault.

    CRITICAL RULES:
    1. You are a documentation expert. Use pristine Markdown formatting.
    2. You do not write Python or application code. You write journals, summaries, and reports.
    3. YOU MUST USE THE EXACT SYNTAX BELOW TO CALL A TOOL. If you do not use the `ACTION:` prefix, the tool will fail.
       - CORRECT: ACTION: write_file {"filepath": "0 - Inbox/note.md", "content": "# Hello"}
       - INCORRECT: {"filepath": "0 - Inbox/note.md", "content": "# Hello"}
       - INCORRECT: ```json\n{"filepath": "0 - Inbox/note.md", "content": "# Hello"}\n```
    4. DO NOT roleplay. DO NOT say "I will create the note now." Just output the ACTION string.
    5. WAIT PROTOCOL: If you use the `write_file` tool and the System Observation says "Action paused. Proposal sent", YOU MUST STOP. Output a final conversational message saying "I have submitted the proposal for your approval." DO NOT try to write the file again.

    AVAILABLE TOOLS:
    - `read_file`: Reads a file. 
      Syntax: ACTION: read_file {"filepath": "docs/file.md"}

    - `list_directory`: Lists a folder. 
      Syntax: ACTION: list_directory {"directory_path": "0 - Inbox/"}

    - `write_file`: Modifies or creates a file. YOU MUST USE THIS TO PROPOSE CHANGES. 
      Syntax: ACTION: write_file {"filepath": "0 - Inbox/note.md", "content": "# Hello"}

# === ENGINEERING PROMPTS ===
engineering:
  system: |
    You are THE FORGE, Cobalt's Principal Systems Architect and Senior Software Engineer.
    Your job is to read, analyze, and write code.

    CRITICAL RULES:
    1. NEVER guess the contents of a file or directory.
    2. To modify or create a file, you MUST use the `write_file` tool. 
    3. YOU MUST USE THE EXACT SYNTAX BELOW TO CALL A TOOL. If you do not use the `ACTION:` prefix, the tool will fail.
       - CORRECT: ACTION: write_file {"filepath": "src/test.py", "content": "print('hello')"}
       - INCORRECT: {"filepath": "src/test.py", "content": "print('hello')"}
       - INCORRECT: ```json\n{"filepath": "src/test.py", "content": "print('hello')"}\n```
    4. DO NOT roleplay. DO NOT say "I will create the file now." Just output the ACTION string.
    5. WORKFLOW EFFICIENCY: If the user provides an exact filepath (e.g., "create a file at src/test.py"), DO NOT use `list_directory`. Execute `write_file` immediately to save context space.
    6. WAIT PROTOCOL: If you use the `write_file` tool and the System Observation says "Action paused. Proposal sent", YOU MUST STOP. Output a final conversational message saying "I have submitted the proposal for your approval." DO NOT try to write the file again.

    AVAILABLE TOOLS:
    - `read_file`: Reads a file. 
      Syntax: ACTION: read_file {"filepath": "src/main.py"}

    - `list_directory`: Lists a folder. 
      Syntax: ACTION: list_directory {"directory_path": "src/"}

    - `write_file`: Modifies or creates a file. YOU MUST USE THIS TO PROPOSE CHANGES. 
      Syntax: ACTION: write_file {"filepath": "src/test.py", "content": "print('hello')"}

# === PROPOSAL ENGINE PROMPTS ===
proposal:
  security_intercept: |
    [SECURITY PROTOCOL: PRIME DIRECTIVE]
    High-risk action detected: "{user_input}"
    
    You are the Chief of Staff. You are FORBIDDEN from executing this autonomously.
    Generate a JSON response explaining the risk.
    
    OUTPUT FORMAT:
    {{
      "action": "Summary of what was requested",
      "justification": "Why the user wants this",
      "risk_assessment": "Blunt warning about data loss or system instability"
    }}
    
    OUTPUT ONLY JSON. NO EXTRA TEXT.

# === ROUTING & CLASSIFICATION PROMPTS ===
routing:
  classify_domain: |
    You are the Chief of Staff (Cortex). Route this user request to the correct Department.
    
    USER REQUEST: "{user_input}"
    
    ACTIVE DEPARTMENTS:
    {options_text}
    - DEFAULT: General chat, web research, web browsing, article summarization. Use for queries that don't fit other domains.
    
    === STRICT ROUTING RULES (MUST FOLLOW) ===
    1. WEB RESEARCH / DEFAULT ROUTING:
       - If the user asks to browse a website, scrape a URL, summarize an article, or perform general web research, you MUST return 'DEFAULT'.
       - Examples: "What's the weather in Paris?", "Summarize this article", "Look up recent news", "Research X", "Browse Y"
    
    2. TACTICAL (TRADING ONLY - STRICTLY RESTRICTED):
       - ONLY return 'TACTICAL' if the user explicitly mentions trading, stocks, tickers, playbooks, or expected value (EV).
       - Valid examples: "What is the current AAPL trading at?", "TSLA stock price", "Show me playbooks", "Calculate EV for X"
       - Extract ONLY the ticker symbol (e.g. "NVDA", "AAPL") or "STRATEGY" as task_parameters
    
    3. INTEL (Research/News):
       - Use for: news, deep dives, current events (non-trading focused)
       - Extract the search topic as task_parameters
    
    4. OPS (Operations/Scribe):
       - Use for: logging, journaling, saving notes, medical billing
       - Extract relevant content as task_parameters
    
    5. ENGINEERING (CODE WORK - STRICTLY RESTRICTED):
       - ONLY return 'ENGINEERING' if the user explicitly asks to write, edit, or review code.
       - Examples: "Write a function", "Fix this bug", "Review my code", "Create a new tool"
    
    6. DEFAULT:
       - Use for: general conversation, greetings, system questions, or anything not matching the above
       - Return task_parameters: "chat"
    
    === EXAMPLES ===
    Input: "What is the current price of AAPL?"
    ‚Üí Domain: TACTICAL, Parameters: "AAPL"
    
    Input: "What is the price of TSLA?"
    ‚Üí Domain: TACTICAL, Parameters: "TSLA"
    
    Input: "Show me the strategies/playbooks"
    ‚Üí Domain: TACTICAL, Parameters: "STRATEGY"
    
    Input: "What is the expected value of X given Y?"
    ‚Üí Domain: TACTICAL, Parameters: "STRATEGY"
    
    Input: "Browse https://example.com and summarize it"
    ‚Üí Domain: DEFAULT, Parameters: "chat"
    
    Input: "Summarize this article about AI"
    ‚Üí Domain: DEFAULT, Parameters: "chat"
    
    Input: "Write a Python function to do X"
    ‚Üí Domain: ENGINEERING, Parameters: "Python function: X"
    
    Input: "Fix the routing bug in cortex.py"
    ‚Üí Domain: ENGINEERING, Parameters: "Fix routing bug in cortex.py"
    
    Input: "What's the weather like?"
    ‚Üí Domain: DEFAULT, Parameters: "chat"
    
    Input: "Hi, how are you?"
    ‚Üí Domain: DEFAULT, Parameters: "chat"
    
    === FINAL INSTRUCTION ===
    FOLLOW THESE RULES STRICTLY AND MUTUALLY EXCLUSIVELY:
    1. Web research/browser/URL/summary queries ‚Üí DEFAULT
    2. Trading/stocks/tickers/playbooks/EV ‚Üí TACTICAL
    3. Writing/editing/reviewing code ‚Üí ENGINEERING
    4. Everything else ‚Üí DEFAULT
    
    Return the decision structured correctly. DO NOT DEVIATE FROM THESE RULES.

# === ORCHESTRATOR PROMPTS ===
orchestrator:
  plan_execution: |
    You are the Orchestrator. Plan and execute complex multi-step tasks.
    Break down the request into logical steps and execute each one.

========================================
FILE: configs/rules.yaml
========================================

# Cobalt Trading Rules & Thresholds
# ROOT KEY: trading_rules (Distinguishes these from coding rules or behavioral rules)

trading_rules:
  momentum:
    rvol_alert_threshold: 3.0   # Trigger "MOMENTUM ALERT" if RVOL > 3.0
    rvol_strong_threshold: 1.5  # Consider it "strong volume" above this

  moving_averages:
    bullish_cross:
      fast: 10
      slow: 20
      logic: "rising" # Check if slopes are positive

  rsi:
    period: 20
    overbought: 80
    oversold: 20

  atr:
    period: 14
    expansion_multiplier: 5.0   # 5x ATR in 5 days = Parabolic
    extension_multiplier: 3.0   # 3x ATR = Extended

# Cortex Routing Rules
cortex_routing:
  orchestrator_keywords: ["engineering", "directory", "file", "codebase", "src/", "list the", "research", "summarize", "ops", "read", "write", "search", "prd"]
  high_risk_keywords: ["delete", "move", "remove", "format", "execute", "kill", "reorganize"]

========================================
FILE: configs/strategies.yaml
========================================

# COBALT STRATEGY PLAYBOOK
# Defines the specific setups, risk rules, and entry criteria for the Tactical Department.

strategies:
  second_day_play:
    name: "Second Day Play"
    active: true
    direction: "BOTH" # Long or Short
    description: "Continuation play for stocks with strong Day 1 momentum."
    
    # EXISTING FILTERS (Preserved)
    time_window:
      start: "09:30"
      end: "10:30" # "Trade trigger before 10:30 am EST"
    filters:
      min_atr: 1.0 # "Range of more than 1 ATR"
      day1_close_zone: 0.20 # "Upper 20% or lower 20%"
      max_gap: 0.33 # "Gap up of less than 1/3 of the range from day 1"
      min_rvol_day1: 1.5 # "Traded more than average RVOL"
      
      # COMPLEX VARIABLES (Optional)
      liquidity:
        min_average_daily_volume: 1000000
        min_price: 2.00
      correlation:
        check_sector: true
        check_spy: true

    execution:
      entry_trigger: "candle_close_above_prior_high"
      stop_buffer: 0.02 # "$0.02 below the low"
      target_multiplier: 2.0 # "Target twice the height of day 1 range"

    # NEW SCORING BLOCK (Added for Logic Lab & Ion)
    scoring:
      # The base score if all hard filters are met
      base_score: 50
      
      # Relative Volume (RVOL) Logic
      high_rvol_threshold: 3.0
      high_rvol_points: 10
      base_rvol_points: 10 # Points for just meeting min_rvol
      
      # Price Action Logic
      gap_up_points: 10
      
      # Ion (Real-Time) Modifiers - Instructions for the Windows HUD
      live_rvol_multiplier: 5.0
      spy_correlation_weight: 10.0
      resistance_penalty: -20.0
      time_decay_per_min: -0.5

  fashionably_late_scalp:
    name: "Fashionably Late Scalp"
    active: false
    direction: "BOTH"
    time_window:
      start: "10:00"
      end: "13:30" # Morning + Mid-Day
    filters:
      trend_indicator: "9EMA"
      baseline_indicator: "VWAP"
      min_volume_ratio: 1.0 # "Volume bars during convergence > divergence"
    execution:
      entry_trigger: "cross_9ema_vwap"
      stop_rule: "measured_move_third" # "1/3 distance from VWAP to Low"
      target_rule: "measured_move_1x" # "1 measured move above cross"

  second_chance_scalp:
    name: "Second Chance Scalp"
    active: false
    direction: "BOTH"
    time_window:
      start: "09:59"
      end: "16:00" # All day
    filters:
      pattern: "break_retest"
      volume_break: "high"
      volume_retest: "low" # "Low-volume retest"
    execution:
      entry_trigger: "candle_close_above_prior"
      stop_buffer: 0.02 # "$0.02 below turn candle"
      exit_strategy: "half_and_trail"

========================================
FILE: dev_utils/brain_scan.py
========================================

"""
Brain Scan v2 - Deep Diagnostic
Checks Schema, Content, and Embedding Health.
Uses centralized config from cobalt_agent.config.
"""
import sys
import os

# Ensure we can import cobalt_agent
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

from cobalt_agent.config import load_config

def scan():
    """
    Connect to database using centralized config and scan memory logs.
    Raises ValueError if critical database credentials are missing.
    """
    # Load config and extract database credentials
    config = load_config()
    
    # Validate required database credentials
    db_config = config.postgres
    required_fields = ["host", "db", "user", "password"]
    missing = [f for f in required_fields if getattr(db_config, f, None) is None]
    
    if missing:
        raise ValueError("Missing critical database environment variable(s): {}. Check .env".format(", ".join(missing)))
    
    conn_str = f"postgresql://{db_config.user}:{db_config.password}@{db_config.host}:5432/{db_config.db}"
    
    import psycopg
    with psycopg.connect(conn_str) as conn:
        print(f"üî¨ Scanning Database: {db_config.db}")
        
        # 1. GET TABLE INFO
        table_name = 'memory_logs'
        columns = conn.execute(f"""
            SELECT column_name, data_type 
            FROM information_schema.columns 
            WHERE table_name = '{table_name}';
        """).fetchall()
        
        print(f"\nüìã Schema for '{table_name}':")
        has_vector = False
        for col in columns:
            print(f"   - {col[0]} ({col[1]})")
            if 'vector' in col[1] or 'embedding' in col[0]:
                has_vector = True
        
        if not has_vector:
            print("\n‚ùå CRITICAL: No VECTOR column found! Semantic search is impossible.")
        
        # 2. CHECK CONTENT (Last 20 items)
        print(f"\nüìú Recent Memories (Last 20):")
        # We explicitly ask for embedding status
        query = f"""
            SELECT id, source, content, 
                   (embedding IS NOT NULL) as has_vector 
            FROM {table_name} 
            ORDER BY timestamp DESC LIMIT 20;
        """
        
        try:
            rows = conn.execute(query).fetchall()
        except Exception as e:
            # Fallback if 'embedding' column doesn't exist
            print(f"‚ö†Ô∏è Query failed (likely missing column): {e}")
            rows = conn.execute(f"SELECT id, source, content FROM {table_name} ORDER BY timestamp DESC LIMIT 20").fetchall()

        found_tsla = False
        for row in rows:
            id_val = row[0]
            source = row[1]
            content = row[2][:60].replace("\n", " ") # Truncate for display
            
            # Check vector status if we grabbed it
            vector_status = "‚úÖ" if (len(row) > 3 and row[3]) else "‚ùå NULL"
            
            print(f"   [{id_val}] {vector_status} | {source}: {content}...")
            
            if "TSLA" in content:
                found_tsla = True

        print("\n--- DIAGNOSIS ---")
        if not found_tsla:
            print("‚ùå 'TSLA' memory NOT FOUND in database. The Write failed.")
        else:
            print("‚úÖ 'TSLA' memory FOUND.")

if __name__ == "__main__":
    scan()

========================================
FILE: dev_utils/create_missing_tasks.py
========================================

"""
Cobalt Task Generator
Creates the missing Phase 4 (Ion) and Phase 5 (Ops) tasks on the Project Board.
"""
import os
import sys
import importlib.util
from datetime import datetime

# --- 1. ROBUST SCRIBE LOADER (The "Smoking Gun" Fix) ---
# This works because 'uv run' executes from the Project Root.
current_dir = os.getcwd()
scribe_path = os.path.join(current_dir, "cobalt_agent", "skills", "productivity", "scribe.py")

print(f"üîç Loading Scribe from: {scribe_path}")

try:
    if not os.path.exists(scribe_path):
        raise FileNotFoundError(f"File not found at {scribe_path}")

    # Load module directly by file path (bypassing package issues)
    spec = importlib.util.spec_from_file_location("scribe_module", scribe_path)
    scribe_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(scribe_module)
    
    Scribe = scribe_module.Scribe
    print("‚úÖ Scribe Class Loaded Successfully.")
except Exception as e:
    print(f"‚ùå Failed to load Scribe: {e}")
    sys.exit(1)

# Initialize
scribe = Scribe()
current_date = datetime.now().strftime("%Y-%m-%d")

# --- 2. DEFINE TASKS ---

tasks = {
    "30 Ion Core Architecture.md": f"""---
status: To Do
priority: P1 (High)
module: Interface
phase: 4 (Ion HUD)
complexity: L
tags: [cobalt, task, ion]
created: {current_date}
---

# 30 Ion Core Architecture

## Objective
Establish the foundational Python application for the **Windows HUD**.

## Requirements
* [ ] Create `ion_agent/` directory structure on Windows.
* [ ] Initialize a **PyQt6** application loop.
* [ ] Implement a **Transparent Overlay Window** (Click-through capable).
* [ ] Create a system tray icon for background management.
* [ ] Ensure it can run alongside TradeStation without stealing focus.

## Technical Notes
* Use `PyQt6.QtCore.Qt.WindowType.FramelessWindowHint`.
* Must handle high-DPI scaling (4K monitors).
""",

    "31 Cobalt-Ion Bridge.md": f"""---
status: To Do
priority: P0 (Critical)
module: Core
phase: 4 (Ion HUD)
complexity: M
tags: [cobalt, task, network]
created: {current_date}
---

# 31 Cobalt-Ion Bridge

## Objective
Create the low-latency communication link between **Cobalt (Mac)** and **Ion (Windows)**.

## Requirements
* [ ] Implement **ZeroMQ (ZMQ)** PUB/SUB pattern.
* [ ] **Publisher:** Cobalt (Mac) broadcasting strategy signals.
* [ ] **Subscriber:** Ion (Windows) listening for HUD updates.
* [ ] Define the JSON payload schema (Ticker, Action, Confidence, Price).
* [ ] Secure the connection over **Tailscale IP**.

## Technical Notes
* Latency target: < 50ms.
* Use `zmq.asyncio` for non-blocking I/O.
""",

    "32 HUD Widgets & Overlay.md": f"""---
status: To Do
priority: P1 (High)
module: Interface
phase: 4 (Ion HUD)
complexity: M
tags: [cobalt, task, ui]
created: {current_date}
---

# 32 HUD Widgets & Overlay

## Objective
Build the specific visual components that appear on the screen.

## Requirements
* [ ] **Confidence Gauge:** A visual bar/dial showing Model Confidence (0-100%).
* [ ] **Signal Box:** A "BUY/SELL" indicator that flashes on trigger.
* [ ] **Trade Log:** A small scrolling list of recent fills.
* [ ] **P&L Ticker:** Real-time session P&L display.

## Design
* "Dark Mode" aesthetic (Cyberpunk/High-Contrast).
* Green = Long, Red = Short.
""",

    "33 Mattermost C2 Integration.md": f"""---
status: To Do
priority: P1 (High)
module: Ops
phase: 5 (Ops)
complexity: M
tags: [cobalt, task, chat]
created: {current_date}
---

# 33 Mattermost C2 Integration

## Objective
Connect Cobalt to the "Red Phone" (Mattermost) for remote command and control.

## Requirements
* [ ] Create a Mattermost Bot Account ("Cobalt").
* [ ] Implement **Incoming Webhooks** for alerts (Trade Signals).
* [ ] Implement **Outgoing Webhooks** (or Slash Commands) for user commands.
* [ ] **Kill Switch:** Create a command `/cobalt stop` that halts all trading instantly.
* [ ] **Approval Flow:** Interactive buttons for "Approve Trade?" messages.
""",

    "34 Automated Trade Journaling.md": f"""---
status: To Do
priority: P2 (Normal)
module: Skills
phase: 5 (Ops)
complexity: S
tags: [cobalt, task, journaling]
created: {current_date}
---

# 34 Automated Trade Journaling

## Objective
Remove manual data entry by having Cobalt write its own trade logs.

## Requirements
* [ ] Capture execution details (Entry, Exit, Size, P&L).
* [ ] Capture "Why?" (The Strategy Logic snapshot at moment of trade).
* [ ] Format as a Markdown table.
* [ ] Append to the **Daily Note** in Obsidian via Scribe.

## Format
| Time | Ticker | Side | P&L | Strategy | Confidence |
|------|--------|------|-----|----------|------------|
"""
}

# --- 3. EXECUTE WRITE ---
print(f"üìù Creating {len(tasks)} missing tasks in '0 - Projects/Cobalt/Tasks'...")

target_folder = "0 - Projects/Cobalt/Tasks"

for filename, content in tasks.items():
    try:
        # Scribe.write_note(filename, content, folder)
        result = scribe.write_note(filename=filename, content=content, folder=target_folder)
        print(f"‚úÖ Created: {filename}")
    except Exception as e:
        print(f"‚ùå Failed: {filename} | Error: {e}")

print("\nüèÅ Board Updated. Run 'update_board.py' (or refresh Obsidian) to see changes.")

========================================
FILE: dev_utils/create_prd.py
========================================

"""
Cobalt Requirements Generator
Creates the PRD-001 based on the 'Strategic Pause' conversation.
"""
import os
import sys
import importlib.util
from datetime import datetime

# --- LOAD SCRIBE ---
current_dir = os.getcwd()
scribe_path = os.path.join(current_dir, "cobalt_agent", "skills", "productivity", "scribe.py")

try:
    if not os.path.exists(scribe_path):
        raise FileNotFoundError(f"File not found at {scribe_path}")
    
    spec = importlib.util.spec_from_file_location("scribe_module", scribe_path)
    scribe_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(scribe_module)
    Scribe = scribe_module.Scribe
    print("‚úÖ Scribe Class Loaded Successfully.")
except Exception as e:
    print(f"‚ùå Failed to load Scribe: {e}")
    sys.exit(1)

scribe = Scribe()
current_date = datetime.now().strftime("%Y-%m-%d")

# --- PRD CONTENT ---

prd_content = f"""---
status: Approved
priority: P0
module: Core
tags: [cobalt, requirements, prd, ion]
created: {current_date}
---

# PRD-001: Cobalt-Ion Tactical HUD

## 1. Executive Summary
**The Vision:** Build a "Co-Pilot" system for manual day trading.
**The Problem:** Professional trading requires processing dozens of variables (RVOL, Levels, Tape, News) in real-time. Humans are slow and emotional.
**The Solution:** A "Heads-Up Display" (HUD) that acts as a real-time **Confidence Gauge**. It calculates the mathematical "Expected Value" (EV) of a trade 10x/second, allowing the trader to execute with conviction.

## 2. Core Philosophy
1.  **Not an Auto-Trader:** The system NEVER executes trades autonomously. It observes, calculates, and suggests. The user pulls the trigger.
2.  **Distributed Brain:** * **Mac Studio (Cobalt):** The Strategist. Slow, deep thinking. Analysis of Context & Catalysts.
    * **Windows PC (Ion):** The Calculator. Fast, reactive math. Visualizing the HUD.
3.  **Python-First:** Both components run on Python (PyQt6 for Windows HUD) to ensure speed of development and shared logic.

## 3. User Stories

### Story A: The "Morning Briefing" (Context)
**As a** Trader,
**I want** Cobalt to scan the market for "In Play" stocks and identify the specific *Strategies* (from my Playbook) that apply to them (e.g., "NVDA is an Earnings Gap"),
**So that** I start the day with a curated list of opportunities, not just raw tickers.

### Story B: The "Formula Injection" (Handoff)
**As a** System Architect,
**I want** Cobalt to send a "Math Package" (JSON) to Ion containing the specific *Weights and Variables* for the day (e.g., "For NVDA, Gap Fill is +10 points, Resistance at $145 is -20 points"),
**So that** Ion can run the math locally without latency, acting as a "dumb calculator" for Cobalt's "smart rules."

### Story C: The "Tactical Engagement" (The HUD)
**As a** Trader executing a trade,
**I want** a visual Gauge (0-100) that updates in real-time based on Price, Volume, and Time,
**So that** I can intuitively see if the trade is degrading (Score dropping) or improving (Score rising) without doing mental math.
* *Example:* "I am long NVDA. Volume dries up -> Score drops 10 points -> Gauge turns Yellow -> I trim my position."

## 4. Functional Requirements

### 4.1 The Scoring Engine (Dynamic EV)
The Score (0-100) is calculated as:
$$ Score = Base + Fuel - Friction - Decay $$
* **Base:** Static score from the Daily Setup (e.g., "A+ Setup" = 60).
* **Fuel (Momentum):** Live modifiers (e.g., `RVOL > 2.0` adds +10).
* **Friction (Risk):** Proximity to Resistance (e.g., `Dist < $0.10` subtracts -20).
* **Decay (Time):** Penalty for stalling (e.g., `-1 point` per minute of chop).

### 4.2 The "Math Package" Protocol
Cobalt must send a JSON payload to Ion containing:
* `Ticker`: Symbol (e.g., "NVDA").
* `Strategies`: List of active setups (e.g., ["GapAndGo", "BellaFade"]).
* `Zones`: Key Price Levels (Entry, Stop, Target).
* `Coefficients`: The weights for the Scoring Engine.

### 4.3 The Multi-Strategy Capability
The system must support **Conflicting Strategies** simultaneously.
* *Scenario:* NVDA gaps up.
* *HUD State:* Ion displays *two* potential scores:
    1.  **Long Score:** For the "Gap & Go" breakout.
    2.  **Short Score:** For the "Extension Fade" reversal.

## 5. Technical Constraints
* **Language:** Python 3.11+.
* **GUI Framework:** PyQt6 (Windows) for transparent overlays.
* **Communication:** ZeroMQ (ZMQ) over Tailscale LAN.
* **Data Source:** TradeStation API (connected locally on Windows).
* **Latency Target:** < 50ms from Tick to HUD Update.

## 6. Future Extensibility
* **Discord Integration:** Manual scraping of trader sentiment to adjust "Base Scores."
* **Journaling:** Automated logging of *why* a score was high/low at the moment of execution.
"""

# --- EXECUTE ---
print("üìù Generating PRD-001 based on Strategic Conversation...")

try:
    folder = "0 - Projects/Cobalt/90 - Project Management/Requirements"
    filename = "PRD-001 Cobalt-Ion Tactical HUD.md"
    
    scribe.write_note(filename=filename, content=prd_content, folder=folder)
    print(f"‚úÖ Successfully Created: {folder}/{filename}")

except Exception as e:
    print(f"‚ùå Failed to create PRD: {e}")

========================================
FILE: dev_utils/generate_constitution.py
========================================

"""
Cobalt Constitution Generator (Master Version)
Contains:
1. Dashboard (The Root)
2. System Manifest (5 Depts, Coach Role, Hardware Stack)
3. Security Architecture (Zero Trust, Vault, JIT)
4. ADRs (Distributed Protocol, Python-First)
5. Project Management (Roadmap, Backlog)
"""
import os
import sys
import importlib.util
from datetime import datetime

# --- 1. ROBUST SCRIBE LOADER ---
current_dir = os.getcwd()
scribe_path = os.path.join(current_dir, "cobalt_agent", "skills", "productivity", "scribe.py")

try:
    if not os.path.exists(scribe_path):
        raise FileNotFoundError(f"File not found at {scribe_path}")
    
    spec = importlib.util.spec_from_file_location("scribe_module", scribe_path)
    scribe_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(scribe_module)
    Scribe = scribe_module.Scribe
    print("‚úÖ Scribe Class Loaded Successfully.")
except Exception as e:
    print(f"‚ùå Failed to load Scribe: {e}")
    sys.exit(1)

scribe = Scribe()
current_date = datetime.now().strftime("%Y-%m-%d")

# --- 2. FRONTMATTER DEFINITIONS ---

arch_frontmatter = f"""---
status: Done
priority: P0 (Critical)
module: Ops
phase: 1 (Foundation)
complexity: M
tags: [cobalt, architecture, documentation]
created: {current_date}
---
"""

pm_frontmatter = f"""---
status: In Progress
priority: P1 (High)
module: Ops
phase: 3 (Capabilities)
complexity: S
tags: [cobalt, planning, roadmap]
created: {current_date}
---
"""

dashboard_frontmatter = f"""---
status: In Progress
priority: P0 (Critical)
module: Core
phase: 1 (Foundation)
complexity: L
tags: [cobalt, root, dashboard]
created: {current_date}
---
"""

# --- 3. THE CONSTITUTION CONTENT ---

files_to_create = {
    
    # ---------------------------------------------------------
    # THE DASHBOARD (Updated with all ADRs)
    # ---------------------------------------------------------
    "0 - Projects/Cobalt/00 Cobalt Master Plan.md": f"""{dashboard_frontmatter}
# Cobalt Command Center

## 1. Strategy & Ops (Level 1)
* [[System Manifest]] - The Stack, Hierarchy, and Roles.
* [[Security Architecture]] - Zero Trust, JIT Access, and Kill-Switches.
* [[ADR-001 Cobalt-Ion Distributed Protocol]] - Architecture Decisions.
* [[ADR-002 Hybrid AI Compute]] - Local vs. Cloud Model Strategy.
* [[ADR-003 Python-First Architecture]] - Ion HUD Technology Stack.

## 2. Project Management (Level 2)
* [[Roadmap]] - The Strategic Phases (Q1/Q2 Goals).
* [[Backlog]] - Future ideas and holding pen.

## 3. Execution (Level 3)
![[Cobalt Project Board]]
""",

    # ---------------------------------------------------------
    # LEVEL 1: MASTER PLAN
    # ---------------------------------------------------------

    "0 - Projects/Cobalt/00 - Master Plan/System Manifest.md": f"""{arch_frontmatter}
# Cobalt System Manifest

## 1. The Vision
**Cobalt** is a distributed, semi-autonomous trading system acting as a "Chief of Staff."
**Dejan** is the CEO and final decision-maker.

## 2. The Hierarchy

### Level 1: The CEO (Dejan)
* **Role:** The Decision Maker.
* **Responsibilities:**
    * Setting Strategic Goals.
    * Final Approval on "High Risk" Actions.
    * Risk Control Override.

### Level 2: Cobalt (The Chief of Staff & Performance Coach)
* **Role:** The Brain & The Mirror.
* **Responsibilities:**
    * **Orchestration:** Directing the 5 Departments below.
    * **Coaching:** Reviewing Scribe's journals to provide psychological feedback.
    * **Gatekeeping:** Protecting the CEO from noise and emotional trading.
    * **Memory:** Maintaining the context of all projects and trades.

### Level 3: The Departments (The Workforce)
* **Strategos (Tactical)**
    * Market Analysis & Technical Indicators.
    * Quant Logic & Strategy Generation.
    * Pattern Recognition Engine.
* **Ion (Interface)**
    * Windows HUD Overlay (PyQt6).
    * TradeStation Execution Bridge.
    * Real-time Data Visualization.
* **Scribe (Ops)**
    * Documentation & Knowledge Management.
    * Automated Journaling & Logging.
    * Project Management (Kanban Updates).
* **Sentinel (Risk)**
    * Position Sizing Logic.
    * "Kill Switch" Enforcement.
    * Compliance & Privacy Guardrails.
* **Scout (Research)**
    * Data Gathering (FinanceTool).
    * Sentiment Analysis (News/Social).
    * Web Browsing & Due Diligence.

## 3. The Hardware Stack

* **The Brain (Mac Studio M2 Ultra)**
    * **Specs:** 96GB RAM, 2TB SSD.
    * **Role:** Central Compute Node.
    * **Workload:** Hosts DeepSeek-R1 (Local LLM), Postgres DB, and Core Logic.

* **The Engine (Windows Workstation)**
    * **Role:** Dedicated Execution Environment.
    * **Workload:** Runs TradeStation Platform and Ion Agent (HUD).
    * **Constraint:** Zero-latency link to Mac via Tailscale.

* **The Console (Lenovo X1 Carbon)**
    * **Role:** Primary Development Interface.
    * **Workload:** VSCode (Remote SSH), Task Management, Ops Control.
    * **Security:** Biometric Access required for code changes.

* **The Red Phone (Mobile iOS/Android)**
    * **Role:** Command & Control (C2).
    * **Workload:** Mattermost Alerts ("Trade Signal"), MFA "Kill Switch" Approvals.
    * **Access:** Emergency System Shutdown.

## 4. The Software Stack
* **Core Intelligence (Cobalt):**
    * **Language:** Python 3.11+
    * **Models:** DeepSeek-R1 (Thinking), OpenAI o3-mini (Speed), Gemini 1.5 Pro (Architect).
    * **Memory:** PostgreSQL (Vector + Relational), Obsidian (Markdown).

* **Departmental Stacks:**
    * **Strategos:** `pandas`, `numpy`, `ta-lib` (Technical Analysis).
    * **Ion:** `PyQt6` (GUI), `pyzmq` (Networking), `EasyLanguage` (TradeStation).
    * **Scribe:** `obsidian-api`, `jinja2` (Templating).
    * **Sentinel:** `pydantic` (Data Validation), `cryptography` (Security).
    * **Scout:** `playwright` (Browsing), `beautifulsoup4` (Scraping).
""",

    "0 - Projects/Cobalt/00 - Master Plan/Security Architecture.md": f"""{arch_frontmatter}
# Cobalt Security Architecture (Zero Trust)

## 1. Core Philosophy: "Assume Breach"
We operate under the assumption that the network is compromised. Trust is never granted implicitly based on location (LAN) or device ownership.
* **Verify Explicitly:** Always authenticate and authorize based on all available data points.
* **Use Least Privilege:** Limit user access with Just-In-Time and Just-Enough-Access (JIT/JEA).
* **Assume Breach:** Minimize blast radius and segment access.

## 2. Identity & Access Management (IAM)
* **The Identity Provider:** Tailscale is the root of trust for *Device Identity*.
* **MFA Protocol:** Critical actions (Trade > $X, System Config Changes) require out-of-band verification via Mattermost (Mobile).
* **Service-to-Service Auth:**
    * Components (e.g., Mac -> Windows) must authenticate via **mTLS** or **Signed JWTs**.
    * `Ion` will reject commands from `Cobalt` that are not cryptographically signed by `Sentinel`.

## 3. Secrets Management (The Vault)
* **No Hardcoded Keys:** API Keys (TradeStation, OpenAI) are NEVER stored in plain text code or environment variables.
* **The Cobalt Vault:**
    * Secrets are stored in an encrypted local keystore (AES-256).
    * **Injection:** Secrets are loaded into memory *only* at runtime process initialization.
    * **Rotation:** Keys are rotated regularly.

## 4. Just-In-Time (JIT) Execution
* **Standing Privileges:** `Ion` (The Executor) has **Read-Only** access to the broker by default.
* **The Token Flow:**
    1.  `Strategos` spots a trade.
    2.  `Sentinel` validates risk checks.
    3.  `Sentinel` issues a **One-Time Execution Token (OTET)**.
    4.  `Ion` uses the OTET to unlock the "Execute" function for *that specific trade only*.
    5.  Token expires immediately after execution or timeout (500ms).

## 5. Network Micro-Segmentation
* **The Airlock:**
    * `Scout` (Research/Web Scraper) is isolated in a "Dirty" VLAN/Container.
    * `Scout` CANNOT talk to `Ion` (Execution) or `Sentinel` (Risk).
    * `Scout` can only write to a sanitized "Drop Zone" in the Database.
* **Tailscale ACLs:**
    * **Mac Studio:** Can talk to Windows (Port 5555 Only).
    * **Windows:** Can talk to Mac Studio (Postgres Port Only).
    * **External:** All inbound traffic blocked.
""",

    # ---------------------------------------------------------
    # ADRs
    # ---------------------------------------------------------

    "0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-001 Cobalt-Ion Distributed Protocol.md": f"""{arch_frontmatter}
# ADR-001: The Cobalt-Ion Distributed Architecture
## Status: ACCEPTED
## Decision
We use a **Distributed Actor Model**:
* **Cobalt (Mac):** Generates the "Strategy Math" (Scoring Profile).
* **Ion (Windows):** Runs the "Math" 10x/sec against live data to paint the HUD.
* **Protocol:** JSON payloads over Tailscale LAN.
""",

    "0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-002 Hybrid AI Compute.md": f"""{arch_frontmatter}
# ADR-002: Hybrid AI Compute Strategy
## Status: ACCEPTED
## Decision
* **DeepSeek-R1 (Local 70B):** Used for "Morning Prep" and deep reasoning. Zero data leakage.
* **OpenAI o3-mini (Cloud):** Used for fast, non-sensitive pattern recognition during the day.
* **Gemini 1.5 Pro (Cloud):** Used as the System Architect and Code Generator (Massive Context).
""",

    "0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-003 Python-First Architecture.md": f"""{arch_frontmatter}
# ADR-003: Python-First Architecture
## Status: ACCEPTED
## Decision
We will use **Python (PyQt6)** for the Ion HUD.
* **Reasoning:** Modern Python is fast enough for human-speed trading (HUD updates). It simplifies the codebase (one language for Brain and HUD) and allows code sharing (Pydantic models).
""",

    # ---------------------------------------------------------
    # LEVEL 2: PROJECT MANAGEMENT
    # ---------------------------------------------------------

    "0 - Projects/Cobalt/90 - Project Management/Roadmap.md": f"""{pm_frontmatter}
# Cobalt Strategic Roadmap

## Phase 1: The Core (Completed) ‚úÖ
* Basic Agent Setup (Hello World).
* Configuration System (YAML).
* Logging & Tooling.

## Phase 2: The Brain (Completed) ‚úÖ
* Memory System (Postgres).
* Scribe Tool (Obsidian Integration).
* DeepSeek Local Model Integration.

## Phase 3: The Tactical Department (Active) üöß
* **Feature:** Data Feeds (FinanceTool).
* **Feature:** Strategy Playbook (YAML -> Python).
* **Feature:** Backtester (Validating Strategies).

## Phase 4: The Ion HUD (Next) üìÖ
* **Epic:** Build Python/PyQt Overlay for Windows.
* **Epic:** Establish Socket/ZMQ Link between Mac and Windows.
* **Epic:** Zero Trust Security Implementation (JIT/Vault).

## Phase 5: The Ops Department (Future) üîÆ
* **Epic:** Mattermost Chat Integration.
* **Epic:** Automated Journaling.
""",

    "0 - Projects/Cobalt/90 - Project Management/Backlog.md": f"""{pm_frontmatter}
# Cobalt Product Backlog
## Unscheduled Ideas
* [ ] Integrate Discord scraping for sentiment analysis.
* [ ] Build "Ion Voice" for audio alerts.
* [ ] Research "Mean Reversion" strategy implementation.
"""
}

# --- 4. EXECUTE WRITE ---

print("üìù Scribe initializing Cobalt Constitution...")

for full_path, content in files_to_create.items():
    try:
        # Resolve Folder/Filename
        path_str = str(full_path)
        last_slash = path_str.rfind("/")
        
        if last_slash == -1:
            print(f"‚ùå Invalid path format: {full_path}")
            continue
            
        folder = path_str[:last_slash]
        filename = path_str[last_slash+1:]
        
        # Write
        result = scribe.write_note(filename=filename, content=content, folder=folder)
        print(f"‚úÖ Generated: {full_path}")
        
    except Exception as e:
        print(f"‚ùå Failed: {full_path} | Error: {e}")

print("\nüèÅ Cobalt Constitution generated.")

========================================
FILE: dev_utils/generate_context.py
========================================

#!/usr/bin/env python3
"""
Script to generate a master context file for architectural review.
Generates cobalt_master_context.txt with directory tree and file contents.
"""

import os
from pathlib import Path

# Exclusions: files/dirs starting with . or __, plus venv and uv.lock
EXCLUDED_PREFIXES = ('.', '__')
EXCLUDED_NAMES = {'venv', 'uv.lock'}

# Inclusions: allowed file extensions
ALLOWED_EXTENSIONS = {'.py', '.md', '.yaml', '.yml', '.toml', '.log', '.txt', '.base'}


def is_excluded(path: Path, base: Path) -> bool:
    """Check if a path should be excluded based on naming rules."""
    rel_path = path.relative_to(base)
    
    # Check each component of the path
    for part in rel_path.parts:
        if part.startswith(EXCLUDED_PREFIXES) or part in EXCLUDED_NAMES:
            return True
    
    # Check for uv.lock file specifically
    if path.name == 'uv.lock':
        return True
    
    return False


def get_file_extension(file_path: Path) -> str:
    """Get the file extension."""
    return file_path.suffix.lower()


def should_process_file(file_path: Path) -> bool:
    """Check if a file should be processed based on its extension."""
    return get_file_extension(file_path) in ALLOWED_EXTENSIONS


def read_file_content(file_path: Path) -> str:
    """Read file content. For .log files, only read last 200 lines."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
            if get_file_extension(file_path) == '.log':
                # For log files, only read last 200 lines
                lines = f.readlines()
                return ''.join(lines[-200:])
            else:
                return f.read()
    except Exception as e:
        return f"[Error reading file: {e}]"


def generate_directory_tree(base_path: Path, indent: str = '') -> str:
    """Generate a text-based directory tree, respecting exclusions."""
    tree_lines = []
    tree_lines.append(f"{base_path.name}/")
    
    def walk_directory(path: Path, prefix: str):
        try:
            # Get all entries, sorted
            entries = sorted(path.iterdir(), key=lambda x: (x.is_file(), x.name))
            
            for entry in entries:
                rel_path = entry.relative_to(base_path)
                
                # Skip excluded paths
                if is_excluded(entry, base_path):
                    continue
                
                if entry.is_dir():
                    tree_lines.append(f"{prefix}{entry.name}/")
                    walk_directory(entry, prefix + "    ")
                else:
                    # Check if file should be processed
                    if should_process_file(entry):
                        tree_lines.append(f"{prefix}{entry.name}")
        except PermissionError:
            tree_lines.append(f"{prefix}[Permission denied]")
    
    walk_directory(base_path, '')
    return '\n'.join(tree_lines)


def collect_files(base_path: Path) -> list:
    """Collect all files that should be processed."""
    files = []
    
    for root, dirs, filenames in os.walk(base_path):
        root_path = Path(root)
        
        # Filter out excluded directories
        dirs[:] = [d for d in dirs if not is_excluded(root_path / d, base_path)]
        
        for filename in filenames:
            file_path = root_path / filename
            
            # Skip excluded paths
            if is_excluded(file_path, base_path):
                continue
            
            # Check if file should be processed
            if should_process_file(file_path):
                files.append(file_path)
    
    return sorted(files)


def main():
    base_path = Path.cwd()
    output_file = base_path / 'cobalt_master_context.txt'
    
    print(f"Generating context file for: {base_path}")
    
    # Generate directory tree
    print("Generating directory tree...")
    tree_content = generate_directory_tree(base_path)
    
    # Collect files to process
    print("Collecting files...")
    files = collect_files(base_path)
    print(f"Found {len(files)} files to process")
    
    # Write to output file
    print(f"Writing to {output_file}...")
    with open(output_file, 'w', encoding='utf-8') as out_f:
        # Write directory tree as first section
        out_f.write("PROJECT DIRECTORY STRUCTURE\n")
        out_f.write("=" * 80 + "\n\n")
        out_f.write(tree_content)
        
        # Process each file
        for file_path in files:
            rel_path = file_path.relative_to(base_path)
            print(f"Processing: {rel_path}")
            
            content = read_file_content(file_path)
            
            out_f.write(f"\n\n========================================\n")
            out_f.write(f"FILE: {rel_path}\n")
            out_f.write(f"========================================\n\n")
            out_f.write(content)
    
    print(f"\nContext file generated: {output_file}")
    print(f"Total files processed: {len(files)}")


if __name__ == '__main__':
    main()

========================================
FILE: dev_utils/ingest_knowledge.py
========================================

"""
Knowledge Ingestion Engine
Sweeps the codebase, config files, and docs, chunks them, and embeds them into the Postgres Vector DB.
"""
import os
import sys
from pathlib import Path
from loguru import logger

# Add src to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "src")))
from cobalt_agent.memory.postgres import PostgresMemory

def chunk_text(text: str, max_chars: int = 1500, overlap: int = 200) -> list[str]:
    """Splits text into overlapping chunks."""
    chunks = []
    start = 0
    text_len = len(text)
    
    while start < text_len:
        end = start + max_chars
        chunks.append(text[start:end])
        start += max_chars - overlap
    return chunks

def ingest_directory(db: PostgresMemory, base_dir: Path, extensions: list[str], source_type: str):
    logger.info(f"Scanning {base_dir} for {extensions}...")
    
    if not base_dir.exists():
        logger.warning(f"Directory {base_dir} does not exist. Skipping.")
        return

    files_processed = 0
    chunks_embedded = 0

    for ext in extensions:
        for file_path in base_dir.rglob(f"*{ext}"):
            # Skip hidden dirs and env
            if any(part.startswith('.') for part in file_path.parts) or 'venv' in file_path.parts:
                continue
                
            try:
                content = file_path.read_text(encoding='utf-8')
                if not content.strip():
                    continue
                    
                chunks = chunk_text(content)
                
                for chunk in chunks:
                    metadata = {
                        "filepath": str(file_path.relative_to(base_dir.parent)),
                        "type": source_type
                    }
                    # Add to vector DB
                    db.add_log(
                        message=chunk,
                        source=source_type,
                        data=metadata
                    )
                    chunks_embedded += 1
                files_processed += 1
                
            except Exception as e:
                logger.error(f"Failed to read {file_path}: {e}")

    logger.info(f"‚úÖ Finished {source_type}: Processed {files_processed} files into {chunks_embedded} vector chunks.")

def main():
    logger.info("üöÄ Starting Knowledge Ingestion Pipeline...")
    db = None
    try:
        with PostgresMemory() as db:
            project_root = Path(__file__).parent.parent

            # 1. Ingest Codebase
            ingest_directory(db, project_root / "src", [".py"], "python_code")
            
            # 2. Ingest Playbooks
            ingest_directory(db, project_root / "configs", [".yaml", ".yml"], "configuration")
            
            # 3. Ingest Obsidian Sandbox
            ingest_directory(db, project_root / "docs", [".md"], "obsidian_note")
            
            logger.info("üéâ Ingestion Complete. The Vector Librarian is ready.")
    except Exception as e:
        logger.exception(f"Database operation failed: {e}")
        return

if __name__ == "__main__":
    main()


========================================
FILE: dev_utils/manage_vault.py
========================================

import sys
import os
from pathlib import Path
from rich.console import Console
from rich.prompt import Prompt

# Add project root to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "src")))
from cobalt_agent.security.vault import VaultManager

console = Console()

def main():
    console.print("\n[bold blue]üõ°Ô∏è Cobalt Local Vault Manager[/bold blue]")
    vault = VaultManager()
    
    # Check if Master Key is in environment for ease of use during dev
    master_key = os.getenv("COBALT_MASTER_KEY")
    
    if not master_key:
        action = Prompt.ask("No COBALT_MASTER_KEY found in environment. Generate a new one?", choices=["y", "n"], default="y")
        if action == "y":
            new_key = vault.generate_master_key()
            console.print(f"\n[bold red]!!! CRITICAL: SAVE THIS KEY IN YOUR PASSWORD MANAGER !!![/bold red]")
            console.print(f"[bold green]export COBALT_MASTER_KEY='{new_key}'[/bold green]\n")
            console.print("Run this export command in your terminal, then run this script again.")
            return
        else:
            console.print("Exiting. You must set COBALT_MASTER_KEY to use the vault.")
            return

    if not vault.unlock(master_key):
        console.print("[red]Failed to unlock vault. Check your Master Key.[/red]")
        return
        
    while True:
        console.print("\n[bold cyan]--- Vault Menu ---[/bold cyan]")
        console.print("[1] List All Secret Names")
        console.print("[2] Retrieve a Secret")
        console.print("[3] Add/Update a Secret (String or JSON)")
        console.print("[4] Delete a Secret")
        console.print("[5] Exit and Lock Vault")
        
        choice = Prompt.ask("Choose an action", choices=["1", "2", "3", "4", "5"])
        
        if choice == "1":
            keys = vault.list_secrets()
            if keys:
                console.print("\n[bold green]Stored Keys:[/bold green]")
                for k in keys:
                    console.print(f" - {k}")
            else:
                console.print("[yellow]Vault is empty.[/yellow]")
                
        elif choice == "2":
            key_name = Prompt.ask("Enter Secret Name to retrieve")
            val = vault.get_secret(key_name)
            if val:
                console.print(f"\n[bold green]{key_name}:[/bold green]\n{val}")
            else:
                console.print(f"[red]Secret '{key_name}' not found.[/red]")
                
        elif choice == "3":
            key_name = Prompt.ask("Enter Secret Name (e.g., BROKER_CREDS)")
            console.print("[dim]Note: You can paste a flat string OR a JSON string like {\"url\":\"...\", \"user\":\"...\", \"pass\":\"...\"}[/dim]")
            secret_value = Prompt.ask("Enter Secret Value", password=True)
            if vault.set_secret(master_key, key_name, secret_value):
                console.print(f"[green]Successfully saved '{key_name}'[/green]")
                
        elif choice == "4":
            key_name = Prompt.ask("Enter Secret Name to delete")
            confirm = Prompt.ask(f"Are you sure you want to delete '{key_name}'?", choices=["y", "n"])
            if confirm == "y":
                if vault.delete_secret(master_key, key_name):
                    console.print(f"[green]Deleted '{key_name}'.[/green]")
                else:
                    console.print(f"[red]Failed to delete '{key_name}'.[/red]")
                    
        elif choice == "5":
            vault.lock()
            console.print("[bold blue]Vault locked. Goodbye.[/bold blue]")
            break

if __name__ == "__main__":
    main()

========================================
FILE: dev_utils/reset_memory_table.py
========================================

"""
Reset Memory Table
Drops and recreates memory_logs table for clean testing.
Uses centralized config from cobalt_agent.config.
"""
import sys
import os

# Ensure we can import cobalt_agent
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

from cobalt_agent.config import load_config

def reset_table():
    """
    Connect to database using centralized config and reset memory_logs table.
    Raises ValueError if critical database credentials are missing.
    """
    # Load config and extract database credentials
    config = load_config()
    
    # Validate required database credentials
    db_config = config.postgres
    required_fields = ["host", "db", "user", "password"]
    missing = [f for f in required_fields if getattr(db_config, f, None) is None]
    
    if missing:
        raise ValueError("Missing critical database environment variable(s): {}. Check .env".format(", ".join(missing)))
    
    conn_str = f"postgresql://{db_config.user}:{db_config.password}@{db_config.host}:5432/{db_config.db}"
    
    import psycopg
    with psycopg.connect(conn_str) as conn:
        print(f"üîÅ Resetting table in database: {db_config.db}")
        
        table_name = 'memory_logs'
        
        # Drop table if exists
        conn.execute(f"DROP TABLE IF EXISTS {table_name};")
        print(f"‚úÖ Dropped table: {table_name}")
        
        # Recreate table
        create_table_query = f"""
        CREATE TABLE {table_name} (
            id SERIAL PRIMARY KEY,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            source VARCHAR(255),
            content TEXT,
            embedding vector(768)
        );
        """
        conn.execute(create_table_query)
        print(f"‚úÖ Created table: {table_name}")

if __name__ == "__main__":
    reset_table()

========================================
FILE: dev_utils/test_prompt.py
========================================

print('Prompt engine found')

========================================
FILE: dev_utils/update_board.py
========================================

"""
Script to populate the Obsidian Project Board with Phase 4 & 5 tasks.
Uses the Scribe tool to ensure correct formatting.
"""
import sys
import os

# Add project root to path so we can import the cobalt_agent package
# This assumes dev_utils/ is one level deep in the project root
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from cobalt_agent.skills.productivity.scribe import Scribe

def create_task(id_num, title, priority, module, complexity, description):
    scribe = Scribe()
    # Format: "23 Strategos Agent Setup"
    filename = f"{id_num} {title}"
    
    # Frontmatter for your Kanban Board (Obsidian Canvas/Dataview compatible)
    content = f"""---
status: To Do
priority: {priority}
module: {module}
complexity: {complexity}
tags:
  - cobalt/task
created: 2026-02-10
---

# {title}

## Objective
{description}

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script
"""
    # Save to 0 - Inbox (You can drag them to your board later)
    result = scribe.write_note(filename, content, folder="0 - Inbox")
    print(result)

if __name__ == "__main__":
    print("üöÄ Generating Phase 4 & 5 Tasks...")
    
    # --- PHASE 4: TACTICAL (STRATEGOS) ---
    create_task("23", "Strategos Agent Setup", "P0", "Tactical", "M", 
                "Create the 'Strategos' class. This manages the Playbook and Risk, replacing the basic FinanceTool wrapper.")
    
    create_task("24", "Playbook Registry", "P1", "Tactical", "S", 
                "Create 'strategies.yaml' to define rules for Second Day Play and Fashionably Late Scalp.")
    
    create_task("25", "Strategy Interface", "P1", "Tactical", "M", 
                "Define the abstract Python class for a Strategy (check_entry, check_stop, calculate_probability).")
    
    create_task("26", "Second Day Play Impl", "P1", "Tactical", "L", 
                "Implement the specific logic from the SMB PDF: Day 1 Trend, Day 2 Open, RVOL checks.")
    
    create_task("27", "Backtest Engine", "P2", "Tactical", "XL", 
                "Create the engine that runs a Strategy against 90 days of historical minute-data.")

    # --- PHASE 5: OPS (STEWARD) ---
    create_task("28", "Ops Medical Stub", "P2", "Ops", "S", 
                "Create the Steward Agent shell to handle future medical billing tasks.")
    
    create_task("29", "Privacy Guardrails", "P0", "Ops", "M", 
                "Implement PII stripping to ensure no patient data ever hits the LLM.")

    print("\n‚úÖ Done! Check your Obsidian '0 - Inbox' folder.")

========================================
FILE: dev_utils/wipe_memory.py
========================================

"""
Wipe Memory Script (Smart Version)
Finds ANY table in the public schema and wipes it.
Uses centralized config from cobalt_agent.config.
"""
import sys
import os

# Ensure we can import cobalt_agent
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

from cobalt_agent.config import load_config

def wipe():
    """
    Connect to database using centralized config and wipe all memory tables.
    Raises ValueError if critical database credentials are missing.
    """
    # Load config and extract database credentials
    config = load_config()
    
    # Validate required database credentials
    db_config = config.postgres
    required_fields = ["host", "db", "user", "password"]
    missing = [f for f in required_fields if getattr(db_config, f, None) is None]
    
    if missing:
        raise ValueError("Missing critical database environment variable(s): {}. Check .env".format(", ".join(missing)))
    
    conn_str = f"postgresql://{db_config.user}:{db_config.password}@{db_config.host}:5432/{db_config.db}"
    
    import psycopg
    with psycopg.connect(conn_str, autocommit=True) as conn:
        # 1. Find the table name automatically
        res = conn.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public';
        """).fetchall()
        
        if not res:
            print("‚ö†Ô∏è  No tables found in 'public' schema. Database is truly empty.")
            return

        # 2. Loop through and wipe them
        for row in res:
            table_name = row[0]
            print(f"üßπ Wiping table: {table_name}...")
            conn.execute(f"TRUNCATE TABLE {table_name};")
        
        print("‚ú® All memory tables wiped clean.")

if __name__ == "__main__":
    wipe()

========================================
FILE: docker-compose.yml
========================================

services:
  db:
    profiles: ["core"]
    image: pgvector/pgvector:pg16
    container_name: cobalt_memory
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    restart: always
    networks:
      - cobalt_net

  pgadmin:
    image: dpage/pgadmin4
    container_name: cobalt_viewer
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD}
    ports:
      - "18080:80"
    restart: always
    networks:
      - cobalt_net
    depends_on:
      - db

  mattermost:
    profiles: ["core"]
    image: mattermost/mattermost-enterprise-edition:latest
    platform: linux/amd64
    ports:
      - "8065:8065"
    environment:
      MM_SQLSETTINGS_DRIVERNAME: postgres
      MM_SQLSETTINGS_DATASOURCE: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}?sslmode=disable&connect_timeout=10
    depends_on:
      - db
    volumes:
      - mattermost_config:/mattermost/config
      - mattermost_data:/mattermost/data
    restart: unless-stopped
    networks:
      - cobalt_net

networks:
  cobalt_net:
    driver: bridge

volumes:
  mattermost_config:
  mattermost_data:


========================================
FILE: docs/0 - Inbox/Briefing_2026-02-24.md
========================================

# üå§Ô∏è Morning Briefing: 2026-02-24
*Generated at: 08:00*

### üßê Executive Summary
Markets showed mixed sentiment amid mixed economic signals, with tech stocks rallying on AI breakthrough news while energy sector lagged due to falling crude prices. Investor caution persisted ahead of the Fed's upcoming meeting, balancing optimism over earnings season with concerns about persistent inflation. Overall mood leaned cautiously optimistic with increased volatility in mid-cap sectors.

### üìà Market Pulse
Bullish on tech and AI-related equities; Bearish on energy and utilities; Neutral on financials pending rate clarity.

### üì∞ Top Headlines
- Tech Giant Announces Breakthrough in On-Device AI Model Efficiency
- Crude Oil Prices Drop 4.2% Amid Record US Inventory Build
- Fed Chair Signals Patience on Rate Cuts Despite Inflation Cooling
- FDA Approves First Gene Therapy for Rare Blood Disorder
- Auto Sales Fall 3.1% in Q2, Reflecting Consumer Caution

### üí° Strategic Thought
> If AI-driven productivity gains are real and accelerating, why are valuations in the sector still pricing in near-perfect execution‚Äîwhat if the market underestimates execution risk over innovation hype?


========================================
FILE: docs/0 - Inbox/Briefing_2026-02-25.md
========================================

# üå§Ô∏è Morning Briefing: 2026-02-25
*Generated at: 08:00*

### üßê Executive Summary
Markets opened with cautious optimism amid mixed economic indicators, as inflation data slightly beat expectations while labor market remains resilient. Sentiment was buoyed by strong tech earnings but tempered by geopolitical tensions and Fed commentary reinforcing a higher-for-longer rate outlook. Investors shifted toward defensive sectors while tech and energy led gains.

### üìà Market Pulse
Bullish ‚Äî The S&P 500 closed near its daily high on strong volume, with the 50-day MA crossing above the 200-day MA (golden cross), and RSI stabilizing above 50. Support levels at 4,700 held firmly, and sector rotation shows increasing momentum in tech and industrials.

### üì∞ Top Headlines
- Fed Chair Powell Signals Rates May Stay High Through 2024 Amid Sticky Inflation
- Tech Earnings Beat Expectations: Apple and Microsoft Report Strong Quarterly Growth
- Oil Prices Surge 3% on Middle East Escalation and OPEC+ Production Cuts
- Labor Department Reports Unemployment Rate Holds at 3.7%, Wages Rise 4.1% YoY
- SEC Proposes New Rules on AI Disclosure for Public Companies

### üí° Strategic Thought
> If the Fed‚Äôs 'higher for longer' narrative is now fully priced in, are we witnessing the last golden cross before a potential Q4 correction‚Äîespecially if inflation data unexpectedly re-accelerates?


========================================
FILE: docs/0 - Inbox/Morning_Briefing_2026-02-26.md
========================================

### **Market Analysis: February 26, 2026**

**General Market Tone**

*   **Mood:** Apprehensive and risk-off. The market is digesting a key inflation print that came in hotter than anticipated, re-igniting fears of a "higher-for-longer" Fed stance. Expect selling pressure on high-duration assets, particularly in the tech and growth sectors.
*   **Internals:** Negative. Breadth is decidedly weak, with the NYSE TICK indicator holding below the zero line in pre-market. The VIX is spiking, up ~9% to over 18.50, indicating rising fear. We're seeing a clear rotation out of Technology (XLK) and Consumer Discretionary (XLY) and into more defensive sectors like Utilities (XLU) and Staples (XLP).
*   **Economic / Macro Backdrop:** The primary driver is this morning's 8:30 AM EST release of the Core PCE Price Index, the Fed's preferred inflation gauge. It came in at +0.5% MoM, versus the +0.3% consensus estimate. This upside surprise has sent Treasury yields surging, with the 10-year yield jumping 12 basis points to 4.18%. The market is now pricing out any near-term rate cut probabilities.
*   **Day-Trading Implication:** The path of least resistance is to the downside. The environment favors short-sellers. Long positions require a very strong, stock-specific catalyst to fight the broad market tide. Expect elevated volatility, especially at the open. Key support levels on SPY (~$530) and QQQ (~$455) will be critical tests early in the session.

---

### **Key Pre-Market Movers**

*   ** bearish ‚Äî SNOW (Snowflake Inc.) -18.2% pre-market**
    *   **Why:** Significant earnings and guidance miss. The company reported after the bell yesterday and missed revenue expectations while providing Q1 and full-year guidance that was substantially below analyst consensus. Management cited a sharp slowdown in consumption from key enterprise customers.
    *   **Catalyst:** Q4 2025 Earnings Report and Forward Guidance.
    *   **Opportunity (daytrader):** This is a clean, catalyst-driven momentum play to the downside. The weak guidance is a fundamental reason for institutions to sell, suggesting sustained pressure throughout the day. High pre-market volume (6.5M shares) confirms heavy interest.
    *   **Trade Idea:** Short. Look for an initial flush at the open. The ideal entry would be a weak bounce towards a key resistance level, such as the pre-market low or VWAP, for a short entry. Target psychological levels below. Stop-loss above the high of the opening 5-minute candle.

*   ** bullish ‚Äî VRTX (Vertex Pharmaceuticals) +12.5% pre-market**
    *   **Why:** Positive clinical trial results that exceeded expectations. The company announced its experimental drug for Alpha-1 Antitrypsin Deficiency (AATD) met its primary endpoint in a Phase 3 trial with a highly favorable safety and efficacy profile.
    *   **Catalyst:** Top-line Phase 3 Clinical Trial Data Press Release.
    *   **Opportunity (daytrader):** A powerful, stock-specific catalyst that can create a "stock in play" capable of ignoring the broader market's weakness. This is a story of fundamental value creation, attracting buyers who are not concerned with today's macro data.
    *   **Trade Idea:** Long. This is a gap-and-go candidate. Avoid chasing the initial spike at the open. Look for a controlled pullback and consolidation in the first 15-30 minutes. An ideal entry would be a dip-buy near the opening print or the formation of a bull flag, with a stop-loss set below the low of the day.

*   ** bearish ‚Äî PLTR (Palantir Technologies Inc.) -5.8% pre-market**
    *   **Why:** Sympathy move with the broader software/tech sector sell-off and a notable analyst downgrade. A major firm downgraded PLTR from "Buy" to "Hold," citing valuation concerns in the current rate environment and potential for slowing government contract growth.
    *   **Catalyst:** Analyst Downgrade and broad market weakness.
    *   **Opportunity (daytrader):** While not as powerful as an earnings miss, the combination of a specific negative catalyst (downgrade) and a hostile macro environment makes PLTR vulnerable. It's a high-beta name that will be sold aggressively in a risk-off tape.
    *   **Trade Idea:** Short. Watch for a break of pre-market lows after the open. If the broader market (QQQ) shows continued weakness, PLTR is likely to underperform. A short entry on a failure to reclaim VWAP would be a high-probability setup.

---

### **Bottom Line ‚Äî Intraday Trade Plan**

My primary bias is short. The hot PCE print has given sellers a clear mandate. The plan is to be aggressive on the short side, focusing on high-beta tech stocks that are breaking key technical levels or have a negative catalyst, like **SNOW** and **PLTR**. These are my A+ setups for the day.

For longs, the bar is extremely high. I will not take any long positions on general market weakness or "cheap" looking stocks. The only longs I will consider must have a powerful, idiosyncratic catalyst that insulates them from the macro selling pressure. **VRTX** is the only name on my long watchlist. I will wait for a clear pattern to emerge after the open before considering an entry.

Risk management is paramount today. With the VIX elevated, I will use slightly smaller position sizes to account for wider price swings. I will be patient for my entry points and will not chase stocks down at the open. The goal is to short weak pops into resistance and buy controlled dips on the single name showing true relative strength.

========================================
FILE: docs/0 - Inbox/Split_Brain_Summary.md
========================================

# Split-Brain Architecture Summary (PRD-007 Core Philosophy)

> *Note: PRD-007 appears to be a misreference; the retrieved document is PRD-001. This summary reflects the "Core Philosophy" section from PRD-001: Cobalt-Ion Tactical HUD.*

## Core Philosophy: The Sniper and Spotter Architecture

### 1. Not an Auto-Trader (With Exception)
- The system does **not** execute trades autonomously by default.
- Cobalt observes, calculates, and suggests. The user pulls the trigger.
- **Exception:** Ion *can* execute autonomously, but **only** when provided with a cryptographic **Just-In-Time (JIT)** execution token issued by the Human-in-the-Loop via the Mattermost Proposal Engine.

### 2. Distributed Brain

| Component | Role | Hardware | Language | Function |
|-----------|------|----------|----------|----------|
| **Cobalt** | **Spotter** | Mac Studio | Python | Slow, deep thinking: Context analysis, catalyst evaluation, risk modeling, and strategy generation |
| **Ion** | **Sniper** | Windows PC | Rust | Fast, reactive execution: real-time scoring, low-latency HUD rendering, and JIT-authorized trades |

### 3. Separation of Concerns

- **Cobalt (Spotter)**
  - High-level strategy formulation
  - Risk analysis & scenario modeling
  - Generation of the "Math Package" (JSON payload with strategy weights & variables)
  - Operates on macOS

- **Ion (Sniper)**
  - Real-time score computation (10x/second updates)
  - Visual HUD rendering
  - Latency-sensitive trade execution
  - Operates on Windows

### Key Design Principle
> **"The Spotter thinks; the Sniper acts ‚Äî but only when authorized."**

This architecture ensures human oversight remains paramount while maximizing responsiveness through specialized, distributed components.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-001 Hybrid Compute Strategy.md
========================================

---
title: "ADR-001 Hybrid Compute Strategy"
status: Active 
priority: P0
module: [Architecture]
phase: 1
complexity: M
tags: [cobalt, architecture, documentation, adr]
created: 2026-02-23
---

# ADR-001: Hybrid Compute Strategy

## Status: ACCEPTED

## Decision

We implement a **Hybrid Compute Strategy** with two distinct LLM paths:

### Dayshift (Fast Path)
- **Model**: Local 8B + Qwen 3 Coder
- **Use Cases**:
  - Chat interactions
  - Tool invocation routing
  - Simple queries
  - Real-time decision support
- **Characteristics**:
  - Low latency (< 2 seconds)
  - High throughput
  - Cost-effective for frequent requests

### Nightshift (Deep Reasoning Path)
- **Model**: DeepSeek 70B
- **Use Cases**:
  - Strategy backtesting
  - Complex market analysis
  - Multi-step reasoning tasks
  - Risk assessment calculations
- **Characteristics**:
  - High cognitive capability
  - Long context window
  - Higher latency acceptable for depth

## Architecture

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   User      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ   ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
              ‚îÇ  Cortex      ‚îÇ
              ‚îÇ  Router      ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ   ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Dayshift‚îÇ                     ‚îÇ Nightshift ‚îÇ
‚îÇ 8B +   ‚îÇ                     ‚îÇ DeepSeek   ‚îÇ
‚îÇ Qwen 3 ‚îÇ                     ‚îÇ   70B      ‚îÇ
‚îÇ (Fast) ‚îÇ                     ‚îÇ  (Deep)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Implementation Details

### Router Logic
1. **Fast Exit**: Check message length and complexity
   - < 4 words or contains "?" ‚Üí Dayshift
   - Contains "STRATEGY", "ANALYZE", "BACKTEST" ‚Üí Nightshift
   - Default: Use LLM classification

2. **Load Balancing**:
   - Monitor Dayshift queue latency
   - Overflow to Nightshift if Dayshift is busy

### Model Selection Criteria
| Criterion | Dayshift | Nightshift |
|-----------|----------|------------|
| Latency | < 2s | < 10s |
| Cost | $/token | $/token |
| Context | 128k | 128k+ |
| Reasoning | Low | High |

## Trade-offs

| Option | Pros | Cons |
|--------|------|------|
| Single Fast Model | Low latency | Poor deep reasoning, high cost |
| Single Deep Model | Excellent reasoning | Slow, expensive |
| Hybrid (Chosen) | Best of both | More complex routing |

## Next Steps

1. Implement Cortex router with LLM classification
2. Add queuing system for Nightshift requests
3. Add metrics dashboard for model usage
4. Implement fallback logic for model failures

## References

- [Qwen 3 Coder Documentation](https://qwenlm.github.io/)
- [DeepSeek API Documentation](https://api-docs.deepseek.com/)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-002 Cobalt-Ion Distributed Protocol.md
========================================

---
title: "ADR-002 Cobalt-Ion Distributed Protocol"
status: Active 
priority: P0
module: [Architecture]
phase: 1
complexity: M
tags: [cobalt, architecture, documentation, adr]
created: 2026-02-23
---

# ADR-002: Cobalt-Ion Distributed Protocol

## Status: ACCEPTED

## Decision

We implement a **Distributed Actor Model** using high-speed message brokers:

### Components

#### Cobalt (Mac - Python)
- **Role**: Chief of Staff, Router, Decision Maker
- **Technologies**: Python, FastAPI, Redis Pub/Sub, ZeroMQ
- **Responsibilities**:
  - LLM integration
  - Department routing
  - Tool orchestration
  - Memory management
  - Strategy execution

#### Ion (Windows - Rust)
- **Role**: Visualization, UI, Real-time Updates
- **Technologies**: Rust, Redis Pub/Sub, ZeroMQ
- **Responsibilities**:
  - Chart rendering
  - Order entry UI
  - Real-time price updates
  - Alert notifications
  - Human interaction

### Communication Protocol

**Format**: JSON payloads over message brokers

**Channels**:
```
cobalt‚Üíion:routing       Cortex ‚Üí Ion: Route user input
cobalt‚Üíion:execute       Cortex ‚Üí Ion: Execute tool
ion‚Üícobalt:notification  Ion ‚Üí Cortex: User action
ion‚Üícobalt:heartbeat     Ion ‚Üí Cortex: Health check
```

## Architecture

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    Mac        ‚îÇ
                    ‚îÇ   Cobalt      ‚îÇ
                    ‚îÇ   (Python)    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ   ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Message Broker    ‚îÇ
              ‚îÇ   (Redis/ZeroMQ)    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ   ‚îÇ      ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ   ‚îî‚îÄ‚îê    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Ion    ‚îÇ  ‚îÇ Ion    ‚îÇ  ‚îÇ ‚îÇ  Ion   ‚îÇ
‚îÇ (Rust) ‚îÇ  ‚îÇ (Rust) ‚îÇ  ‚îÇ ‚îÇ (Rust) ‚îÇ
‚îÇ Windows‚îÇ  ‚îÇ Windows‚îÇ  ‚îÇ ‚îÇ Windows‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ   Redis    ‚îÇ
                  ‚îÇ  Pub/Sub   ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Implementation Details

### Cobalt (Python) - Publisher/Subscriber
```python
import redis
import json

class CobaltBroker:
    def __init__(self):
        self.redis = redis.Redis(host='localhost', port=6379)
        self.channel = 'cobalt/ion'
    
    def publish_routing(self, data: dict) -> None:
        self.redis.publish(self.channel, json.dumps({
            'type': 'routing',
            'payload': data
        }))
    
    def subscribe_notifications(self, callback):
        pubsub = self.redis.pubsub()
        pubsub.subscribe('ion/cobalt')
        for message in pubsub.listen():
            callback(message)
```

### Ion (Rust) - Subscriber/Publisher
```rust
use redis::{Connection, Commands};

struct IonBroker {
    conn: Connection,
    channel: String,
}

impl IonBroker {
    fn new() -> Self {
        let conn = redis::Connection::connect("redis://localhost:6379").unwrap();
        IonBroker {
            conn,
            channel: "ion/cobalt".to_string(),
        }
    }
    
    fn subscribe(&mut self) {
        self.conn.subscribe(&"cobalt/ion").unwrap();
    }
    
    fn publish(&mut self, data: &str) {
        self.conn.publish("ion/cobalt", data).unwrap();
    }
}
```

## Trade-offs

| Option | Pros | Cons |
|--------|------|------|
| REST API | Simple, HTTP compatible | High latency, synchronous |
| Message Brokers (Chosen) | Low latency, async, scalable | More complex setup |

## Next Steps

1. Implement Redis Pub/Sub in Python Cortex
2. Implement ZeroMQ bindings in Rust Ion
3. Create message schemas
4. Add reconnection logic

## References

- [Redis Pub/Sub Documentation](https://redis.io/docs/manual/pubsub/)
- [ZeroMQ Documentation](https://zeromq.org/documentation/)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-003 Python-First Architecture.md
========================================

---
title: "ADR-003 Python-First Architecture"
status: Active 
priority: P0
module: [Architecture]
phase: 1
complexity: M
tags: [cobalt, architecture, documentation, adr]
created: 2026-02-23
---

# ADR-003: Python-First Architecture

## Status: ACCEPTED

## Decision

We will use **Python (FastAPI)** for the Cobalt agent and **Rust** for the Ion HUD client.

* **Cobalt (Mac)**: Python FastAPI for the core agent system (orchestration, LLM integration, routing, tool execution)
* **Ion (Windows)**: Rust for the real-time trading visualization and UI
* **Reasoning**: Python provides the fastest development velocity and best LLM integration ecosystem. Rust provides safe, high-performance UI rendering.

## Architecture

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    Mac        ‚îÇ
                    ‚îÇ   Cobalt      ‚îÇ
                    ‚îÇ   (Python)    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ   ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Message Broker    ‚îÇ
              ‚îÇ   (Redis/ZeroMQ)    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ   ‚îÇ      ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ   ‚îî‚îÄ‚îê    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Ion    ‚îÇ  ‚îÇ Ion    ‚îÇ  ‚îÇ ‚îÇ  Ion   ‚îÇ
‚îÇ (Rust) ‚îÇ  ‚îÇ (Rust) ‚îÇ  ‚îÇ ‚îÇ (Rust) ‚îÇ
‚îÇ Windows‚îÇ  ‚îÇ Windows‚îÇ  ‚îÇ ‚îÇ Windows‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ   Redis    ‚îÇ
                  ‚îÇ  Pub/Sub   ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Implementation Details

### Cobalt (Python)
- FastAPI for HTTP endpoints
- LangChain for LLM integration
- Pydantic for data validation
- Redis/ZeroMQ for IPC with Ion

### Ion (Windows - Rust)
- tauri or egui for GUI
- High-performance rendering
- Windows API access for system integration
- Redis/ZeroMQ client for communication

## Trade-offs

| Option | Pros | Cons |
|--------|------|------|
| Single Language | Simpler tooling | Limited technology choice |
| Multi-Language (Chosen) | Best of both worlds | IPC complexity |

## Next Steps

1. Implement FastAPI endpoints in Python Cobalt
2. Create Rust Ion client library
3. Add message queue for reliability
4. Implement health check/heartbeat mechanism

## References

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Rust GUI Documentation](https://github.com/egui-rs/egui)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-004 Zero Trust Security.md
========================================

---
title: "ADR-004 Zero Trust Security"
status: Active 
priority: P0
module: [Security]
phase: 1
complexity: M
tags: [cobalt, security, architecture, documentation, adr]
created: 2026-02-23
---

# ADR-004: Zero Trust Security

## Status: ACCEPTED

## Decision

We implement a **Zero Trust Security Model** with three layers:

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Human-In-The-Loop ‚îÇ
                    ‚îÇ  Proposal Engine   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Docker Seccomp       ‚îÇ
                    ‚îÇ  Sandbox              ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  LastPass JIT         ‚îÇ
                    ‚îÇ  Credential Manager   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Layer 1: Human-In-The-Loop (HITL) Proposal Engine

### Overview
All high-risk operations require human approval before execution.

### Approval Flow
```
1. Agent proposes action
   ‚îú‚îÄ Trade execution
   ‚îú‚îÄ Code execution
   ‚îî‚îÄ Credential access

2. Generate approval request (Pydantic model)
   ‚îú‚îÄ Action type
   ‚îú‚îÄ Parameters
   ‚îú‚îÄ Risk assessment
   ‚îî‚îÄ Justification

3. Wait for human approval (via Mattermost/CLI)
   ‚îú‚îÄ Timeout: 5 minutes
   ‚îî‚îÄ Auto-reject if no response

4. Execute only if approved
```

### Pydantic Models
```python
class ApprovalRequest(BaseModel):
    request_id: str
    action_type: str  # "TRADE", "CODE_EXEC", "CREDENTIAL_ACCESS"
    parameters: Dict[str, Any]
    risk_level: str   # "LOW", "MEDIUM", "HIGH"
    justification: str
    timestamp: datetime

class ApprovalResponse(BaseModel):
    approved: bool
    approver: str
    timestamp: datetime
    comments: Optional[str]
```

## Layer 2: Docker Seccomp Sandboxes

### Overview
All code execution runs in isolated Docker containers with strict seccomp profiles.

### Container Configuration
```yaml
security_opt:
  - seccomp:./seccomp/profile.json
  - no-new-privileges:true

read_only: true

network_mode: none

privileged: false

user: "1000:1000"
```

### Seccomp Profile
- Only allows: `read`, `write`, `open`, `close`, `stat`, `fstat`
- Blocks: `socket`, `connect`, `execve`, `ptrace`
- Allows network only for specific tools (browser, search)

## Layer 3: LastPass JIT Credential Management

### Overview
Credentials are retrieved just-in-time, never stored in plaintext.

### JIT Flow
```
1. Agent requests credential access
2. LastPass API called with:
   ‚îú‚îÄ User authentication
   ‚îú‚îÄ Justification (for audit)
   ‚îî‚îÄ TTL (time-to-live)

3. LastPass returns temporary credential
   ‚îú‚îÄ Valid for 5 minutes
   ‚îú‚îÄ Single-use or limited uses
   ‚îî‚îÄ Audit log created

4. Credential used and discarded
   ‚îú‚îÄ Credential deleted from memory
   ‚îî‚îÄ Audit log updated
```

### API Integration
```python
class LastPassClient:
    def get_credential(self, vault_id: str, justification: str) -> Credential:
        response = requests.post(
            f"{self.api_url}/jit-credential",
            json={
                "vault_id": vault_id,
                "justification": justification,
                "ttl_minutes": 5
            }
        )
        return Credential.parse(response.json())
```

## Implementation Details

### Approval Engine
- Runs as separate module in Cortex
- Uses Mattermost as approval interface
- Tracks approval status in memory

### Docker Sandbox
- Uses `docker-py` SDK
- Creates containers on-demand
- Cleans up after execution

### JIT Credential Manager
- LastPass API integration
- Credential caching (short-term)
- Automatic cleanup

## Trade-offs

| Option | Pros | Cons |
|--------|------|------|
| No Sandbox | Fast | Security risk |
| Full Sandbox (Chosen) | Secure | Slightly slower, complexity |

## Next Steps

1. Implement Pydantic approval models
2. Create Mattermost approval UI
3. Build Docker sandbox runner
4. Integrate LastPass JIT API

## References

- [Docker Seccomp Documentation](https://docs.docker.com/engine/security/seccomp/)
- [LastPass API Documentation](https://developer.lastpass.com/)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-005 Agentic RAG.md
========================================

---
title: "ADR-005 Agentic RAG"
status: Active 
priority: P0
module: [Architecture]
phase: 1
complexity: M
tags: [cobalt, architecture, documentation, adr]
created: 2026-02-23
---

# ADR-005: Agentic RAG - Memory as a Tool

## Status: ACCEPTED

## Decision

We implement an **Agentic RAG (Retrieval-Augmented Generation)** system using **Memory as a Tool** rather than passive context injection.

### Architecture
```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   User Query ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
                        ‚îÇ       ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
              ‚îÇ   Query     ‚îÇ   ‚îÇ
              ‚îÇ   Encoder   ‚îÇ   ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                  ‚îÇ ‚îÇ ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ           ‚îÇ        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Postgres  ‚îÇ ‚îÇVector‚îÇ ‚îÇ  Agentic‚îÇ
‚îÇ   pgvector ‚îÇ ‚îÇSearch‚îÇ ‚îÇ  RAG    ‚îÇ
‚îÇ  (Storage) ‚îÇ ‚îÇEngine‚îÇ ‚îÇ  Tool   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ           ‚îÇ        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Generated        ‚îÇ
        ‚îÇ   Response         ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Components

#### 1. Postgres/pgvector Database
- Stores all conversation logs with vector embeddings
- Uses cosine similarity for search
- Indexes on timestamp and source

#### 2. Vector Search Engine
- Converts query to embedding
- Retrieves similar memories by semantic similarity
- Applies temporal and relevance filters

#### 3. Agentic RAG Tool
- Memory retrieval as a callable tool
- Context-aware query routing
- Dynamic memory injection into prompts

### Memory Rules
| Rule Type | Behavior |
|-----------|----------|
| **PREFERENCE** | Keep forever (e.g., "I like TSLA") |
| **MARKET CONTEXT** | Expire after 24 hours |
| **SESSION** | Expire after conversation ends |

## Implementation Details

### Database Schema
```sql
CREATE TABLE memory_logs (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    source VARCHAR(255),
    message TEXT,
    data JSONB,
    embedding VECTOR(768)
);

CREATE INDEX idx_memory_embedding ON memory_logs 
USING ivfflat (embedding vector_cosine_ops);
```

### Python Interface
```python
class AgenticRAG:
    def __init__(self, db_url: str):
        self.engine = create_engine(db_url)
        self.session = Session()
    
    def store_memory(self, message: str, source: str, data: dict):
        embedding = self._generate_embedding(message)
        self.session.add(MemoryLog(
            message=message,
            source=source,
            data=data,
            embedding=embedding
        ))
        self.session.commit()
    
    def search_memories(self, query: str, limit: int = 10) -> List[Dict]:
        query_embedding = self._generate_embedding(query)
        results = self.session.execute(
            """
            SELECT message, source, data, 
                   1 - (embedding <=> :query_embedding) as similarity
            FROM memory_logs
            WHERE timestamp > NOW() - INTERVAL '24 hours'
            ORDER BY similarity DESC
            LIMIT :limit
            """,
            {"query_embedding": query_embedding, "limit": limit}
        )
        return results.fetchall()
```

### Memory Filter Rules
```python
def filter_memories(memories: List[Dict], context: Dict) -> List[Dict]:
    # Remove stale memories
    filtered = [m for m in memories 
                if not _is_stale(m, context)]
    
    # Apply relevance threshold
    return [m for m in filtered if m['similarity'] > 0.5]
```

## Trade-offs

| Option | Pros | Cons |
|--------|------|------|
| Keyword Search | Fast | Poor semantic understanding |
| Full RAG (Chosen) | High quality retrieval | Requires vector storage |

## Next Steps

1. Set up Postgres with pgvector extension
2. Implement embedding generation
3. Create memory filter rules engine
4. Integrate RAG into PromptEngine

## References

- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Retrieval-Augmented Generation Paper](https://arxiv.org/abs/2005.11401)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-006 Prime Directive and HITL.md
========================================

---
title: "ADR-006 Prime Directive and HITL"
status: Active
priority: P0
module: [Architecture, Security]
phase: 2
complexity: M
tags: [cobalt, architecture, documentation, adr, security]
created: 2026-02-23
---

# ADR-006: Prime Directive and Human-In-The-Loop (HITL) Core Personality

## Status: ACCEPTED

## Decision
We are explicitly binding the Cobalt Agent's personality to a "Zero Trust" and "Proposal Engine" framework via configuration-as-code (`config.yaml`). Cobalt will operate under a strict Prime Directive: it cannot execute destructive, financial, or system-altering commands autonomously. 

## Context
Previously, Cobalt's directives were generic ("Protect capital", "Analyze data"). To achieve enterprise-grade security, the system prompt must fundamentally restrict the agent's autonomy at the personality level, forcing it to generate a "proposal" for the human operator rather than taking unilateral action.

## Implementation Details
1.  **Configuration Driven:** The Prime Directive is injected via the `persona.directives` list in `config.yaml`.
2.  **Prompt Engine Integration:** The existing `prompt.py` will automatically parse these new directives and construct the system prompt.
3.  **The Proposal Engine Hook:** The agent is explicitly instructed to draft proposals and await cryptographic authorization for high-stakes tasks.

## Trade-offs
| Option | Pros | Cons |
|--------|------|------|
| Hardcoded Python Logic | Unbreakable | Violates decoupled architecture |
| Config-Driven (Chosen) | Flexible, maintains separation of concerns | Relies on LLM adherence to prompt |

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-007 HITL Proposal Engine.md
========================================

---
title: "ADR-007 HITL Proposal Engine"
status: Active
priority: P0
module: [Cortex, Security]
phase: 3
complexity: L
tags: [cobalt, architecture, security, hitl]
created: 2026-02-23
---

# ADR-007: Human-in-the-Loop (HITL) Proposal Engine

## Status: ACCEPTED

## Decision
We will implement a standardized `Proposal` Pydantic model that the Cortex must generate for any "High-Stakes" action. A high-stakes action is defined as any command that modifies the file system, executes code, or initiates a financial transaction.

## Context
The current routing logic in `cortex.py` is susceptible to keyword misclassification (e.g., mistaking "NVIDIA files" for a "TACTICAL" trading query). By forcing a "Proposal" step, the agent must pause, summarize the risk, and await a cryptographic token (or manual 'YES' in the short term) before proceeding.

## Implementation Details
1. **Middleware Layer**: A new validation step in `cortex.py` that checks the "Risk Level" of a classified task.
2. **Standardized Model**: All proposals will include:
   - `task_id`: Unique identifier.
   - `action`: The raw command to be executed.
   - `justification`: Why the agent thinks this is necessary.
   - `risk_assessment`: A summary of what could go wrong (e.g., "Permanent data loss").
3. **Approval Flow**: The agent will post the proposal to Mattermost and wait for the user to respond with "Approve [task_id]".

## Next Steps
- Define the `Proposal` model in a new `src/cobalt_agent/core/proposals.py` file.
- Update `cortex.py` to utilize this model for any non-read-only tasks.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-008 JIT Secrets Vault.md
========================================

---
title: "ADR-008 JIT Secrets Vault"
status: Active
priority: P0
module: [Security, Core]
phase: 4
complexity: M
tags: [cobalt, architecture, security, secrets]
created: 2026-02-24
---

# ADR-008: Just-In-Time (JIT) Secrets Architecture

## Status: ACCEPTED

## Decision
We will transition away from static `.env` files for high-privilege API keys (e.g., TradeStation, OpenAI). Instead, we will implement a local, encrypted "Vault" service. The Cobalt Agent will request credentials "Just-In-Time" at runtime, hold them in RAM only for the duration of the execution context, and never log or write them to disk.

## Context
While the `.env` file is excluded from Git, storing static, long-lived credentials on the hard drive represents a single point of failure. By moving to a Vault architecture, we ensure that if the Cobalt script is hijacked, the attacker only gains access to an isolated process, not the master keys to the financial or cloud infrastructure.

## Implementation Details
1. **The Vault Daemon:** A highly restricted, independent process running on the Mac Studio that holds the encrypted keys.
2. **The Request Protocol:** Cobalt's `config.py` will be modified to request keys via an internal socket/API rather than reading `os.getenv`.
3. **RAM Only:** Credentials will be explicitly scrubbed from Pydantic models when serialized, ensuring they never leak into the Postgres Memory database.

## Trade-offs
| Option | Pros | Cons |
|--------|------|------|
| HashiCorp Vault | Industry standard | Overkill/too heavy for local node |
| Local Encrypted Daemon | Lightweight, fast | Requires custom implementation |

*Decision:* We will build a lightweight Local Encrypted Daemon specifically tuned for the Cobalt architecture.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-009 Headless Browser Strategy.md
========================================

---
title: "ADR-009 Agentic Browser Loop & Zero Trust"
status: Active
priority: P1
module: [Architecture, Tools, Security]
phase: 5
complexity: L
tags: [cobalt, architecture, documentation, adr, playwright, accessibility-object-model, cdn, pgvector, zero-trust]
created: 2026-02-25
updated: 2026-02-27
---

# ADR-009: Agentic Browser Loop & Zero Trust Architecture

## Status: ACCEPTED

## Decision
We will implement an **Agentic Browser Loop** that uses the **Accessibility Object Model (AOM)** via Chrome DevTools Protocol (CDP) to extract interactive elements from web pages. The LLM will operate on a compressed element tree with numeric IDs rather than raw HTML. To enable millisecond-latency execution for repeated tasks, we will implement a **pgvector "Fast Path" memory cache**. All browser operations will enforce **Zero-Trust constraints**: domain whitelisting, ephemeral browser contexts, and zero-knowledge credential injection via VaultManager.

## Context
The legacy scraping approach failed on Single Page Applications (SPAs) and sites requiring basic interaction. The initial JSON-based DSL approach was insufficient for complex, real-world web navigation where elements are dynamically generated and DOM structures change frequently.

The Agentic Browser Loop architecture enables autonomous, multi-step web interactions by:
1. **AOM/CDP Snapshot**: Extracting accessibility tree data and converting it to a compressed interactive element tree with numeric IDs, allowing the LLM to operate on stable identifiers rather than fragile CSS selectors.
2. **Fast Path Memory**: Using pgvector to cache task intents and associated Playwright scripts, bypassing LLM inference for repeated tasks and enabling millisecond-latency execution.
3. **Zero-Trust Security**: Enforcing domain whitelisting, ephemeral browser contexts for each session, and credential injection via VaultManager without storing sensitive data in the agent's memory.

## Implementation Details

### Phase 1: AOM Extractor
1. **Engine:** Playwright Chromium (Headless) with CDP session enabled.
2. **AOM Extraction:** Use `dom.snapshotter.takeDomSnapshot()` to extract the full DOM accessibility tree.
3. **Element Compression:** Convert the accessibility tree to a compressed interactive element tree containing:
   - Numeric ID (stable identifier for LLM reference)
   - Accessibility role (button, link, input, etc.)
   - Accessible name (label, placeholder, or text content)
   - Actionable state (enabled, visible, editable)
   - Optional: aria-label, aria-describedby, value (for inputs)

### Phase 2: LLM Interface & Pydantic Schema
1. **LLM Input**: The compressed element tree (JSON-serializable) with numeric IDs.
2. **LLM Output**: A Pydantic-constrained schema with actions:
   - `click(id: int)`: Click element by numeric ID
   - `type(id: int, text: str)`: Type text into element by numeric ID
   - `navigate(url: str)`: Navigate to URL (only if whitelisted)
3. **Validation**: Pydantic schema enforces strict action types; invalid outputs raise validation errors.

### Phase 3: Fast Path Memory (pgvector)
1. **Hash Computation**: Compute SHA-256 hash of task intent (user request + context).
2. **Lookup**: Query pgvector for similar task intents in the memory table.
3. **Cache Hit**: Execute stored Playwright script natively without LLM inference.
4. **Cache Miss**: Execute LLM inference, store resulting script in pgvector with intent hash.

### Phase 4: Zero-Trust Enforcement
1. **Domain Whitelisting**: Before navigation, check URL against `ALLOWED_DOMAINS` from config. Raise `SecurityViolation` if not whitelisted.
2. **Ephemeral Contexts**: Create a new `browser.new_context()` for each session; no cookies or storage persist between runs.
3. **Vault Credential Injection**: 
   - Retrieve credentials from VaultManager using vault_path from config
   - Inject credentials via `context.add_cookies()` or direct form filling
   - Never expose credentials to LLM or persistent storage

## Trade-offs
| Option | Pros | Cons |
|--------|------|
| HTML Parsing | Simple to implement, no browser needed | Fails on SPAs, fragile selectors, no dynamic interaction |
| JSON DSL | LLM can specify actions | Requires CSS selector generation, brittle to DOM changes |
| AOM/CDP Snapshot (Chosen) | Stable numeric IDs, accessible tree, works on all sites | Requires CDP session, more complex extraction logic |
| pgvector Fast Path | Millisecond latency for repeated tasks | Requires vector storage infrastructure |
| Zero-Trust | Security first, ephemeral sessions | More complex orchestration |

*Decision:* The AOM/CDP approach provides stable numeric IDs that the LLM can reference regardless of DOM structure changes. The pgvector Fast Path enables near-zero latency for repeated tasks, and Zero-Trust ensures Cobalt operates within strict security boundaries.

## Files Changed
- `src/cobalt_agent/tools/browser.py` - Complete rewrite with AOM extraction, Fast Path, and Zero-Trust
- `src/cobalt_agent/memory/postgres.py` - Add pgvector table for task intent caching
- `src/cobalt_agent/security/vault.py` - Integrate VaultManager for credential injection

## Dependencies Added
- `playwright` (via `uv add playwright`)
- `chromium` browser binaries (via `uv run playwright install chromium`)
- `pgvector` (via `uv add pgvector`)
- `sqlalchemy` (via `uv add sqlalchemy`)

## Security Considerations
1. **Domain Whitelisting**: All navigation requests are validated against `ALLOWED_DOMAINS` config.
2. **Ephemeral Contexts**: Each browser session creates a new context with `storage_state=None`.
3. **Zero-Knowledge Credentials**: VaultManager retrieves credentials on-demand; credentials are never stored in memory longer than necessary.
4. **HITL Boundary**: All mutation actions (navigation, form filling, clicking) require human-in-the-loop approval unless explicitly whitelisted.


========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-010 Sovereign Split-Brain Architecture.md
========================================

---
title: "ADR-010 Sovereign Split-Brain Architecture"
status: Active 
priority: P0
module: [Architecture]
phase: 4
complexity: M
tags: [cobalt, architecture, documentation, adr, multi-agent]
created: 2026-02-26
---

# ADR-010: Sovereign Split-Brain Architecture

## Status: ACCEPTED

## Decision
We will implement a Hierarchical Manager-Worker architecture using **Single-Model Sequential Persona Swapping**, utilizing our local model for both roles.

## Context
As tasks become complex, the LLM hallucinates tool syntax because its context window is bloated with system instructions, directory arrays, and planning logic. We need an Architect to plan, and a Drone to execute. 

## Technical Rationale
Running two massive models (e.g., DeepSeek-R1 and Qwen 80B) in parallel causes VRAM thrashing on Apple Silicon (loading and unloading weights). By utilizing the *same* model for both roles, the core weights stay "hot" in memory. Python simply maintains two separate KV Caches (Conversation Histories) and injects different System Prompts (Personas) sequentially. 

## Future Extension (High Throughput)
While the initial implementation will be a synchronous state machine, this architecture paves the way for advanced local throughput techniques:
1. **Speculative Decoding:** Accelerating the Manager's planning phase using a tiny draft model.
2. **Nginx Clustering:** Spinning up multiple `llama-server` instances to allow the Manager to execute parallel Fan-Out tasks to multiple Drones simultaneously without bottlenecking.

## Consequences
* **Positive:** Massive reduction in LLM confusion and syntax errors. Zero loss of local privacy. No VRAM thrashing. Lays the groundwork for future async clustering.
* **Negative:** Increased latency per total task completion in the short term, as Python must wait for the Architect to finish generating the plan before the Drone can start typing code.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-011 Vector Librarian.md
========================================

# ADR-011: The Vector Librarian (pgvector)

## Status
Accepted

## Context
The Sovereign Split-Brain architecture (ADR-007) requires the Architect to plan complex tasks. However, the Architect lacked a semantic understanding of the codebase and the user's Second Brain (Obsidian), forcing it to blindly guess file paths or rely on slow directory listings.

## Decision
We implemented a PostgreSQL-backed Vector Database using `pgvector`.
1. **Ingestion Engine**: Created `dev_utils/ingest_knowledge.py` to chunk and embed `.py`, `.yaml`, and `.md` files using `text-embedding-3-small`.
2. **Omni-Memory**: Leveraged the existing `PostgresMemory` class so that all project files, config playbooks, and historical chat logs reside in the same searchable vector space.
3. **The Librarian Tool**: Created `search_knowledge` to allow the Architect to semantically query the database during the planning phase.

## Consequences
- **Positive**: The Architect can now instantly locate exact files and context across the entire project and Obsidian vault.
- **Positive**: Eradicates path-guessing hallucinations.
- **Negative/Risk**: The vector database requires continuous updating to prevent stale data retrieval. Mitigation planned via automated background syncs.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-012 Drone Polymorphism.md
========================================

# ADR-012: Drone Polymorphism & Unified ReAct

## Status
Accepted

## Context
With the introduction of the Split-Brain Orchestrator (ADR-007), the system hardcoded "The Forge" (Engineering) as the sole execution agent. To scale across multiple domains (Ops, Tactical, Intel), the Orchestrator needs to dynamically instantiate specialized Drones. Furthermore, duplicating the ReAct execution loop across multiple department classes violates DRY principles and creates maintenance debt.

## Decision
1. **Unified ReAct Engine**: We extracted the ReAct while-loop, JSON parsing, and Proposal fast-exit logic into a single `BaseDepartment` abstract class.
2. **Drone Polymorphism**: All specialized departments (`EngineeringDepartment`, `OpsDepartment`) now inherit from `BaseDepartment`. They only provide their name and default system prompts.
3. **Orchestrator Routing**: The Orchestrator will be updated to assign tasks to specific Drones based on their required capabilities.

## Consequences
- **Positive**: Bug fixes to the execution loop instantly propagate to all Drones.
- **Positive**: Creating a new Department now takes less than 20 lines of code.
- **Negative**: The Base Class becomes a critical point of failure; regressions here will break all execution capabilities.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ARCHITECTURE_ASSESSMENT.md
========================================

---
title: "Project Cobalt Architecture Assessment"
status: Active
priority: P0
module: [Architecture]
phase: 1
complexity: L
tags: [cobalt, architecture, master_plan]
created: 2026-02-23
---

# ARCHITECTURE ASSESSMENT: Project Cobalt
**Date:** February 2026
**Status:** Alpha / Proof of Concept
**Focus:** Enterprise-Grade Autonomous Trading & Chief of Staff System

## 1. Executive Summary
Project Cobalt has successfully established its "Nervous System" and "Memory." The core event loop is decoupled, allowing asynchronous communication via Mattermost, while the brain utilizes a robust LiteLLM abstraction layer mapped to local and cloud models. The architecture strictly enforces type-safety via Pydantic and relies on configuration-as-code (YAML) for strategy and system parameters. 

## 2. Current Strengths (The Foundation)
* **Decoupled C2 Interface:** The `mattermost.py` implementation successfully uses `asyncio.to_thread` to maintain a persistent WebSocket connection without blocking the primary LLM inference loop.
* **Agentic RAG Foundation:** `postgres.py` successfully utilizes `pgvector` to store both textual logs and high-dimensional semantic embeddings, creating a persistent "Hippocampus" that can be queried conceptually.
* **Config-Driven Playbooks:** The `Playbook` and `SecondDayPlay` modules load dynamic scoring weights from `strategies.yaml`, avoiding hardcoded logic and enabling future autonomous modification.
* **LLM Abstraction:** The `llm.py` module elegantly wraps `litellm`, exposing a strict `ask_structured` method that guarantees JSON/Pydantic compliance for complex agent reasoning.

## 3. Technical Debt & Immediate Gaps
* **Routing Brittleness:** The current `cortex.py` and `mattermost.py` routing relies on hardcoded keyword bypasses (e.g., `if "?" in text`). This must be replaced with a localized "Switchboard" LLM router.
* **Missing Execution Hands:** The system currently lacks a sandboxed Code Execution Tool (Docker/Seccomp) to safely run Python scripts.
* **Missing "Touch" (Playwright):** Browser capability is currently limited to raw text scraping. A Playwright-based tool is required for dynamic web interaction and complex scraping.
* **Missing Secrets Management:** Integration with a Vault/LastPass API is required to facilitate Just-In-Time (JIT) credential injection without hardcoding keys.
* **Proposal Engine:** There is no standardized Pydantic schema for the AI to request "Google Auth" permission before executing a high-risk task.

## 4. Target State Architecture
* **The MoA (Mixture of Agents) Engine:**
    * **Dayshift:** Lightning-fast local models (e.g., Qwen-Coder) handling chat, tool routing, and basic operations.
    * **Nightshift:** Heavyweight local reasoning models (DeepSeek 70B) utilized for asynchronous strategy backtesting and complex data analysis.
    * **Cloud Escalation:** High-tier models (Gemini 3.1 / Opus) used only when local sandbox attempts fail gracefully.
* **The Execution Split (Cobalt/Ion):** Python acts as the strategic orchestrator (Cobalt), dispatching mathematical configurations to a hyper-fast Windows execution client (Ion).
* **Zero Trust (ZTA):** All system modifications and external actions proposed by Cobalt are halted at a Privilege Boundary, requiring asynchronous Human-in-the-Loop (HITL) cryptographic approval.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/brain_base.md
========================================

# Base Department (Unified ReAct Engine)

## Overview
`cobalt_agent/brain/base.py`

The `BaseDepartment` class is the Unified ReAct Execution Engine. All specialized Drones inherit this execution loop, ensuring consistent behavior across all departments.

## Class: BaseDepartment

### Description
The Unified ReAct Execution Engine. All specialized Drones inherit this execution loop.

### Constructor
```python
def __init__(self, name: str, system_prompt: Optional[str] = None)
```

**Parameters:**
- `name` (str): The name of the department
- `system_prompt` (Optional[str]): Optional custom system prompt

### Methods

#### run
```python
def run(self, user_message: str, chat_history: Optional[List[Dict]] = None) -> str
```

Process a request using the ReAct loop.

**Parameters:**
- `user_message` (str): The user's request
- `chat_history` (Optional[List[Dict]]): Optional list of previous messages for context

**Returns:** The final response after tool execution or max loops

### Execution Flow
1. Build message history with system prompt and user input
2. Loop up to 4 times (max_loops):
   - Get LLM response using unified interface
   - Parse ACTION lines for tool execution
   - Execute tools via ToolManager
   - Append observations to history
3. Return final response when no ACTION found or max loops reached

### Fast Exit Protocol
The ReAct loop exits early when:
- "Action paused" is in result (Zero-Trust Proposal wall)
- "Proposal [" is in result (Pending human approval)

## Key Components
- `LLM`: LLM instance for generating responses
- `ToolManager`: Handles tool execution
- `system_prompt`: Department-specific system prompt

## See Also
- `OpsDepartment` - Scribe/Operations department
- `EngineeringDepartment` - Code generation department
- `BaseDepartment` - Abstract base class for all departments

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/brain_scan.md
========================================

---
title: "Brain Scan Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[postgres]]"
location: "dev_utils/brain_scan.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Brain Scan Script

**Location:** `dev_utils/brain_scan.py`

## Overview

Brain Scan is a diagnostic tool that performs a comprehensive health check on the PostgreSQL memory database. It verifies schema integrity, checks for vector embeddings, and confirms content storage.

## Usage

```bash
python dev_utils/brain_scan.py
```

Or with uv:

```bash
uv run python dev_utils/brain_scan.py
```

## Behavior

The script connects to the PostgreSQL database and performs the following checks:

### 1. Schema Verification
- Lists all columns in the `memory_logs` table
- Identifies if a `vector` or `embedding` column exists
- Reports if semantic search is possible

### 2. Content Audit
- Retrieves the last 20 memory entries
- Shows embedding status for each record
- Verifies specific content (e.g., "TSLA") exists in the database

### 3. Diagnosis Report
Outputs a summary with:
- **Schema Health**: Whether vector columns exist
- **Content Status**: Whether expected content is present
- **Embedding Status**: Whether embeddings are populated

## Example Output

```
üî¨ Scanning Database: cobalt_memory

üìã Schema for 'memory_logs':
   - id (integer)
   - timestamp (timestamp without time zone)
   - source (text)
   - content (text)
   - embedding (vector)

--- DIAGNOSIS ---
‚úÖ 'TSLA' memory FOUND.
```

## Destructive Warnings

‚ö†Ô∏è **This is a READ-ONLY diagnostic script** - it does not modify the database. However, if the `embedding` column does not exist, semantic search will be impossible, and you may need to run an embedding generation script.

## Dependencies

- `psycopg` - PostgreSQL client library
- `python-dotenv` - Environment variable loading

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/briefing.md
========================================

# Morning Briefing Skill

## Overview
`cobalt_agent/skills/productivity/briefing.py`

The `MorningBriefing` class is the Daily Market Intelligence Generator. It orchestrates tools to collect market data, news, and generate a structured daily digest.

## Class: MorningBriefing

### Description
Daily Market Intelligence Generator. Orchestrates tools to collect market data, news, and generate a structured daily digest.

### Constructor
```python
def __init__(self)
```

Initializes components:
1. Loads configuration
2. Creates LLM instance
3. Initializes tools (Scribe, FinanceTool, SearchTool)

### Available Tools
- `Scribe`: Writes report to Obsidian vault
- `FinanceTool`: Fetches market data for stock tickers
- `SearchTool`: Retrieves top technology and finance news

### Methods

#### run
```python
def run() -> str
```

Generates the daily morning briefing report.

**Returns:** Path to the saved Markdown file in Obsidian vault

### Execution Flow

#### Step 1: Data Gathering (`_gather_data`)
Collects raw data from multiple sources:

**Markets Data:**
- Fetches data for configured tickers: NVDA, SPY, BTC-USD
- Handles errors gracefully with warning logs

**News Search:**
- Queries for "top technology and finance news today"
- Returns up to 5 news items

#### Step 2: LLM Synthesis
Sends gathered data to LLM with a structured prompt asking for:
- Executive summary (3 sentences)
- Market analysis (Bullish/Bearish/Neutral)
- Top 3-5 headlines
- Strategic thought/question

Uses `llm.ask_structured()` with Pydantic model for type-safe output.

#### Step 3: Markdown Formatting
Creates a structured Markdown report with:
- Title with today's date
- Generation timestamp
- Executive Summary section
- Market Pulse section
- Top Headlines list
- Strategic Thought quote

#### Step 4: Vault Delivery
- Saves to `0 - Inbox` folder
- Filename format: `Briefing_YYYY-MM-DD.md`

### Pydantic Model: BriefingReport

```python
class BriefingReport(BaseModel):
    executive_summary: str      # 3-sentence market summary
    market_analysis: str        # Technical analysis
    top_headlines: List[str]    # 3-5 critical headlines
    strategic_thought: str      # Provocative question/insight
```

### Error Handling
- Falls back to raw data if LLM synthesis fails
- Logs warnings for tool failures
- Returns error message path on failure

## Key Components
- `LLM`: For structured report synthesis
- `FinanceTool`: Market data collection
- `SearchTool`: News aggregation
- `Scribe`: Obsidian delivery

## See Also
- `Scribe` - Obsidian integration skill
- `DeepResearch` - Research report generation

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/browser.md
========================================

---
title: "Browser Tool Documentation"
status: Active
module: Tool
type: Class
dependencies:
  - "[[tool_manager]]"
location: "src/cobalt_agent/tools/browser.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Browser Tool Module

**Location:** `src/cobalt_agent/tools/browser.py`

## Overview

Browser Tool visits URLs and extracts clean text content. Returns structured Pydantic models.

## Class: `WebPageContent` (Pydantic Model)

Structured content from a visited webpage.

### Fields

| Field | Type | Description |
|--|--|--|
| `url` | `str` | The source URL |
| `title` | `str` | The page title |
| `content` | `str` | The cleaned text content |
| `error` | `str` | Error message if fetch failed (default: "") |

### Methods

#### `__str__() -> str`
Returns a summary string for LLM consumption. Truncates content to 4000 characters.

---

## Class: `BrowserTool`

Fetches and cleans text from URLs.

### Attributes

| Attribute | Value |
|--|--|
| `name` | `"browser"` |
| `description` | `"Visit a webpage and extract its content. Use for reading articles, documents, or online content."` |
| `headers` | User-Agent header for requests |

### Methods

#### `run(url: str) -> WebPageContent`

Fetches and cleans text from a URL.

**Parameters:**
- `url`: The URL to visit

**Returns:** `WebPageContent` with title, content, or error

**Workflow:**
1. Fetch page with requests and User-Agent header
2. Parse HTML with BeautifulSoup
3. Extract title and clean text (remove scripts, styles, nav, footer)
4. Return structured WebPageContent

**Error Handling:**
- Returns WebPageContent with error field populated on exception
- Timeout: 10 seconds

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/cli.md
========================================

---
title: "CLI Interface Documentation"
status: Active
module: Interface
type: Class
dependencies:
  - "[[main]]"
  - "[[memory_core]]"
  - "[[tool_manager]]"
  - "[[cortex]]"
location: "src/cobalt_agent/interfaces/cli.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# CLI Interface Module

**Location:** `src/cobalt_agent/interfaces/cli.py`

## Overview

Interactive Command-Line Interface for Cobalt Agent with centralized routing and RAG (Retrieval Augmented Generation).

## Class: `CLI`

Interactive command-line interface for Cobalt Agent.

### Constructor

```python
CLI(memory_system, llm, system_prompt, tool_manager, cortex=None)
```

**Parameters:**
- `memory_system`: Memory system for storing conversation history
- `llm`: LLM instance for inference
- `system_prompt`: System prompt for the agent
- `tool_manager`: ToolManager instance for tool execution
- `cortex`: Optional Cortex instance for routing

### Methods

#### `start()`
Start the interactive CLI loop. Displays agent info and prompts for user input.

#### `_handle_chat(user_input: str)`
Autonomous Agent Loop (ReAct Pattern) for general analysis.

1. Retrieve long-term memory (RAG)
2. Inject memory into system prompt
3. Run LLM with tool execution loop (max 5 turns)
4. Handle tool calls and observations

#### `_retrieve_long_term_memory(query: str) -> str`
Fetches relevant past memories from the memory system for RAG.

**Parameters:**
- `query`: User query to search for relevant memories

**Returns:** Formatted string of top 5 unique memories

#### `_format_tool_output(output: Any) -> str`
Helper to convert Pydantic models/Lists to clean strings.

---

## Features

- **Centralized Routing**: Delegates to Cortex for specialized tasks
- **RAG Integration**: Retrieves relevant long-term memory for context
- **Auto-Tool**: LLM can trigger tool calls automatically
- **Memory Management**: Maintains short-term RAM (10 entries) and long-term storage

---

## Usage

```python
from cobalt_agent.interfaces.cli import CLI

cli = CLI(memory_system, llm, system_prompt, tool_manager, cortex)
cli.start()

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/config.md
========================================

---
title: "Configuration Management Documentation"
status: Active
module: Core
type: Class
dependencies:
  - "[[persona]]"
location: "src/cobalt_agent/config.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Configuration Management

## Overview
The Configuration Management system provides type-safe, multi-source configuration for the Cobalt Agent using Pydantic Settings and YAML files. It supports environment variable overrides and dynamic config loading.

## Core Components

### Configuration Loading Priority
1. **Environment Variables** (highest priority) - Strictly for node/Docker specific data like `POSTGRES_HOST`, `NODE_ID`, etc.
2. **Secure Vault** (dynamically injected) - API keys and tokens injected from the VaultManager at runtime
3. **YAML Configuration Files** (configs/*.yaml) - Static configuration like `trading_rules`, `persona`, etc.
4. **Default Values** (lowest priority)

### Environment Variable Mapping
- Simple fields: `UPPER_CASE` converts to `lower_case_with_underscores`
- Nested fields: `POSTGRES_HOST` maps to `postgres.host` via `env_nested_delimiter="_"`

## Classes

### `CobaltSettings` (Main Configuration Class)
The primary configuration class that loads from YAML and environment variables.

**Configuration Source (in priority order):**
1. `.env` file and OS environment variables (for node-specific values)
2. Secure Vault (AES-256 encrypted, injected at runtime via `COBALT_MASTER_KEY`)
3. `configs/config.yaml` and other YAML files (static configuration)
4. Default values defined in Pydantic models

**Attributes:**
- `system`: System-level configuration
- `llm`: LLM provider settings
- `persona`: Agent personality and behavior
- `trading_rules`: Trading strategy parameters
- `postgres`: PostgreSQL database settings
- `mattermost`: Mattermost communication settings

### `SystemConfig`
System-level configuration settings.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `debug_mode` | `bool` | `False` | Enable debug logging |
| `version` | `str` | `"0.1.0"` | Application version |
| `obsidian_vault_path` | `str` | `"/default/obsidian/vault/path"` | Path to Obsidian vault |

### `LLMConfig`
LLM provider configuration.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `model_name` | `str` | `"gemini/gemini-1.5-pro"` | Model identifier |
| `api_key` | `Optional[str]` | `None` | API key for provider |

### `PersonaConfig`
Agent persona configuration.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `name` | `str` | `"Cobalt"` | Agent name |
| `roles` | `list[str]` | `[]` | Agent roles |
| `skills` | `list[str]` | `[]` | Agent capabilities |
| `tone` | `list[str]` | `[]` | Communication tone |
| `directives` | `list[str]` | `[]` | Core behavioral rules |

### `PostgresConfig`
PostgreSQL database connection settings.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `host` | `str` | `"localhost"` | Database host |
| `port` | `int` | `5432` | Database port |
| `db` | `str` | `"cobalt_memory"` | Database name |
| `user` | `str` | `"postgres"` | Database user |
| `password` | `Optional[str]` | `None` | Database password |

### `MattermostConfig`
Mattermost communication settings.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `url` | `Optional[str]` | `None` | Mattermost URL |
| `token` | `Optional[str] | `None` | Authentication token |
| `scheme` | `str` | `"http"` | URL scheme |
| `port` | `int` | `8065` | Port number |

## Functions

### `load_config(config_dir: Optional[Path | str] = None) -> CobaltSettings`
Load configuration from YAML files and merge with environment variables.

**Parameters:**
- `config_dir`: Path to configuration directory (default: `configs/`)

**Returns:**
- `CobaltSettings`: Loaded configuration

### `get_config() -> CobaltSettings`
Convenience function to get singleton configuration.

**Returns:**
- `CobaltSettings`: Current configuration

### `get_current_node_role() -> Optional[str]`
Determine the role of the current node based on network configuration.

**Returns:**
- `str`: Node role if found, otherwise `None`

## Configuration File Structure

### `configs/config.yaml`
Main configuration file with the following sections:

```yaml
system:
  debug_mode: false
  version: "0.1.0"
  obsidian_vault_path: "/path/to/vault"

llm:
  model_name: "gemini/gemini-1.5-pro"
  api_key: "${LLM_API_KEY}"

persona:
  name: "Cobalt"
  roles:
    - "Market Analyst"
    - "Trading Assistant"
  tone:
    - "Professional"
    - "Analytical"
  directives:
    - "Use tools for real-time data"
    - "Trust tool results over assumptions"

postgres:
  host: "localhost"
  port: 5432
  db: "cobalt_memory"

mattermost:
  url: "https://mattermost.example.com"
  token: "${MATTERMOST_TOKEN}"
```

## Error Handling
- Invalid YAML files are logged and skipped
- Missing configuration files use defaults
- Environment variable parsing errors are logged
- Configuration validation errors are caught and reported

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/cortex.md
========================================

---
title: "Cortex Documentation"
status: Active
module: Brain
type: Orchestrator
dependencies:
  - "[[main]]"
  - "[[tactical]]"
  - "[[llm]]"
  - "[[prompt]]"
location: "src/cobalt_agent/main.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Cortex (The Chief of Staff)

## Overview
Cortex is the central routing and coordination agent for the Cobalt system. It acts as the "Chief of Staff" that routes user requests to the appropriate specialized department (Tactical, Intel, Ops, Engineering) based on the user's intent.

### Zero Trust Architecture
Under the Prime Directive (ADR-006), Cortex implements a **High-Risk Intercept** pattern that enforces Human-in-the-Loop (HITL) approval for any high-stakes actions before execution. This ensures Zero Trust: no destructive, financial, or system-altering commands execute without explicit human approval.

## Class: `Cortex`

### Constructor
```python
def __init__(self)
```
Initializes Cortex with configuration from `config.yaml`, loads departments, and initializes the LLM instance.

### Key Attributes
- `config`: Loaded configuration from `configs/config.yaml`
- `departments`: Dictionary of active departments from config
- `llm`: LLM instance for classification and routing decisions

### Main Methods

#### `route(user_input: str) -> Optional[str]`
Routes user input to the appropriate department handler.

**Logic:**
1. Fast exit for simple greetings (< 4 words, "hi")
2. Direct bypass for questions (? or keywords: price, what)
3. Classify domain using LLM
4. Route to department handler (Tactical, Intel, Ops, Engineering, Foundation)

**Returns:**
- String response from department handler, or `None` for general chat (Foundation)

#### `_classify_domain(user_input: str) -> DomainDecision`
Uses LLM to classify user input into a domain and extract task parameters.

**Returns:** `DomainDecision` Pydantic model with:
- `domain_name`: The department name (e.g., "TACTICAL", "OPS")
- `reasoning`: Why this domain was selected
- `task_parameters`: The action item or query

### Department Handlers

#### `_run_tactical(params: str) -> str`
Routes to `Strategos` for trading and market data tasks.

**Handles:**
- Stock price queries (extracts ticker symbol)
- Strategy queries (when "STRATEGY" or "PLAYBOOK" is mentioned)

#### `_run_intel(params: str) -> str`
Routes to Research/Briefing skills.

**Handles:**
- "briefing" ‚Üí `MorningBriefing().run()`
- Other ‚Üí `DeepResearch().run(params)`

#### `_run_ops(params: str, original_input: str) -> str`
Routes to Scribe (Operations/Scribe) for logging, saving, and searching.

**Handles:**
- "log"/"journal" ‚Üí Append to daily note
- "save"/"note" ‚Üí Create new note
- "search"/"find" ‚Üí Search vault
- "medical"/"billing" ‚Üí Placeholder for future Steward logic

### `_generate_proposal(user_input: str) -> str`
Generates a Proposal using LLM synthesis for high-risk actions.

**Purpose:**
The Prime Directive FORBIDS autonomous execution of high-risk actions. This method:
1. Detects high-risk keywords in user input
2. Calls LLM to synthesize a structured JSON proposal
3. Extracts JSON using regex and instantiates Proposal
4. Returns formatted proposal for Mattermost display

**LLM Prompt:**
```python
prompt = f"""
[SECURITY PROTOCOL: PRIME DIRECTIVE]
High-risk action detected: "{user_input}"

You are the Chief of Staff. You are FORBIDDEN from executing this autonomously.
Generate a JSON response explaining the risk.

OUTPUT FORMAT:
{{
  "action": "Summary of what was requested",
  "justification": "Why the user wants this",
  "risk_assessment": "Blunt warning about data loss or system instability"
}}

OUTPUT ONLY JSON. NO EXTRA TEXT.
"""
```

**Regex Extraction Mechanism:**
```python
# Extract JSON block from LLM response
match = re.search(r'\{.*\}', raw_response, re.DOTALL)
if not match:
    raise ValueError("No JSON block found in LLM response.")
data = json.loads(match.group(0))
```

**Parameters:**
- `user_input`: The original user request containing high-risk keywords

**Returns:**
- Formatted Markdown string with proposal details
- Returns error message if Proposal Engine fails

**Error Handling:**
```python
except Exception as e:
    logger.error(f"Proposal Generation Failed: {e} | Raw Output: {raw_response}")
    return (
        f"### üõ°Ô∏è SECURITY INTERCEPT\n"
        f"**Action Blocked:** Administrative system change.\n\n"
        f"**Reason:** The Proposal Engine could not validate the risk assessment. "
        f"Execution is denied by default per the Prime Directive."
    )
```

## High-Risk Intercept (Zero Trust Enforcement)

### Overview
The High-Risk Intercept is a middleware layer that enforces the Prime Directive by intercepting high-risk actions and routing them through the Proposal Engine before execution. This ensures all destructive, financial, or system-altering commands require explicit human approval.

The Cortex module implements this by detecting high-risk keywords in user input and generating a Proposal using LLM synthesis with structured JSON extraction.

### Intercept Logic Flow
```
1. route(user_input) receives request
   ‚Üì
2. Classify domain using LLM (_classify_domain)
   ‚Üì
3. Check for high-risk keywords in original input
   ‚Üì
4. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ High-Risk Keyword Found ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                                                ‚Üì
5. Call _generate_proposal(user_input)            Bypass (Low-Risk)
   ‚Üì                                                ‚Üì
6. LLM generates JSON with:                      Route to department
   - action: Summary of requested operation
   - justification: Why user wants this
   - risk_assessment: Potential impacts
   ‚Üì
7. Regex extraction: r'\{.*\}' (raw_response, re.DOTALL)
   ‚Üì
8. Instantiate Proposal (task_id auto-generates)
   ‚Üì
9. Return proposal.format_for_mattermost()
   ‚Üì
10. User sees proposal in Mattermost approval channel
   ‚Üì
11. User responds with "Approve [task_id]"
   ‚Üì
12. MattermostInterface detects via regex: r"approve\s+(\w{8})"
   ‚Üì
13. ProposalEngine moves to approved list
   ‚Üì
14. Execute approved action via callback
```

### High-Risk Detection Criteria
Tasks are classified as high-risk if user input contains any of these keywords:
- `delete`, `move`, `remove`, `format`, `execute`, `kill`, `reorganize`

**Case-insensitive detection** in `_generate_proposal()`:
```python
high_risk_keywords = ['delete', 'move', 'remove', 'format', 'execute', 'kill', 'reorganize']
is_high_risk = any(word in user_input.lower() for word in high_risk_keywords)
```

### Integration with ProposalEngine
```python
from cobalt_agent.core.proposals import ProposalEngine

# In route() method:
if is_high_risk(decision.domain_name, decision.task_parameters):
    engine = ProposalEngine()
    engine.connect_mattermost()
    
    proposal = engine.create_proposal(
        action=get_command(decision),
        justification=decision.reasoning,
        risk_assessment="Potential financial loss or data modification"
    )
    
    engine.send_proposal(proposal)
    engine.wait_for_approval(proposal)
    engine.execute_approved(proposal)
else:
    # Route directly to department
    return self._route_to_department(decision)
```

### Approval Response Handling
When a user responds with "Approve [task_id]":
1. MattermostInterface detects the message via WebSocket
2. `handle_approval_response()` validates the pattern and task_id
3. ProposalEngine moves proposal from pending to approved
4. Approved callback executes the action

### Security Guarantees
- **No autonomous execution**: All high-risk actions require explicit approval
- **Audit trail**: All proposals are logged with timestamps
- **Channel validation**: Approval must occur in designated channel only
- **Token validation**: 8-character task_id ensures approval matches correct proposal

## Domain Routing Logic

| Domain | Purpose | Parameters |
|--------|---------|------------|
| `TACTICAL` | Trading & Market Data | Ticker symbol or "STRATEGY" |
| `INTEL` | Research & News | Search topic |
| `OPS` | Operations & Logging | Task parameters |
| `ENGINEERING` | Engineering | TODO - Not implemented |
| `FOUNDATION` | General Chat | "chat" |

## Configuration
Departments are loaded from `config.yaml` under the `departments` section. Only departments marked as `active: true` are considered for routing.

## Example Flow
```
User: "What is the price of AAPL?"
‚Üí LLM classifies: domain="TACTICAL", params="AAPL"
‚Üí _run_tactical("AAPL")
‚Üí Strategos().run("AAPL")
‚Üí Returns market data
```

```
User: "What's new in AI?"
‚Üí LLM classifies: domain="INTEL", params="AI"
‚Üí _run_intel("AI")
‚Üí DeepResearch().run("AI")
‚Üí Returns search results

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/create_missing_tasks.md
========================================

---
title: "Create Missing Tasks Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[scribe]]"
location: "dev_utils/create_missing_tasks.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Create Missing Tasks Script

**Location:** `dev_utils/create_missing_tasks.py`

## Overview

Create Missing Tasks generates Phase 4 (Ion) and Phase 5 (Ops) task files in the Obsidian Project Board. It creates markdown files with proper frontmatter for use with Dataview plugins.

## Usage

```bash
python dev_utils/create_missing_tasks.py
```

Or with uv:

```bash
uv run python dev_utils/create_missing_tasks.py
```

## Behavior

The script performs the following actions:

1. **Dynamically loads** the Scribe class from `cobalt_agent/skills/productivity/scribe.py`
2. **Creates** 5 task files in the `0 - Projects/Cobalt/Tasks` folder:
   - 30 Ion Core Architecture.md
   - 31 Cobalt-Ion Bridge.md
   - 32 HUD Widgets & Overlay.md
   - 33 Mattermost C2 Integration.md
   - 34 Automated Trade Journaling.md

Each task file contains:
- Status, priority, module, phase, complexity, tags
- Objective and requirements sections

## Output Files

| Filename | Phase | Priority | Description |
|--|--|--|--|
| 30 Ion Core Architecture.md | Phase 4 | P1 | Windows HUD Python application |
| 31 Cobalt-Ion Bridge.md | Phase 4 | P0 | ZeroMQ communication between Mac and Windows |
| 32 HUD Widgets & Overlay.md | Phase 4 | P1 | Visual components for the HUD |
| 33 Mattermost C2 Integration.md | Phase 5 | P1 | Remote command and control |
| 34 Automated Trade Journaling.md | Phase 5 | P2 | Trade log entry automation |

## Destructive Warnings

‚ö†Ô∏è **This script creates new files** - it does not modify existing ones. Ensure the target folder (`0 - Projects/Cobalt/Tasks`) exists in your Obsidian vault.

## Dependencies

- `importlib.util` - Dynamic module loading
- `datetime` - Date generation for frontmatter

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/create_prd.md
========================================

---
title: "Create PRD Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[scribe]]"
location: "dev_utils/create_prd.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Create PRD Script

**Location:** `dev_utils/create_prd.py`

## Overview

Create PRD generates the PRD-001 document based on the "Strategic Pause" conversation. It creates a comprehensive Product Requirements Document for the Cobalt-Ion Tactical HUD project.

## Usage

```bash
python dev_utils/create_prd.py
```

Or with uv:

```bash
uv run python dev_utils/create_prd.py
```

## Behavior

The script performs the following actions:

1. **Loads** the Scribe class dynamically from `cobalt_agent/skills/productivity/scribe.py`
2. **Generates** the PRD-001 content including:
   - Executive Summary
   - Core Philosophy (Distributed Brain, Python-First)
   - User Stories (Morning Briefing, Formula Injection, Tactical Engagement)
   - Functional Requirements (Scoring Engine, Math Package, Multi-Strategy)
   - Technical Constraints (Python, PyQt6, ZeroMQ, TradeStation API)
   - Future Extensibility (Discord, Journaling)
3. **Writes** the file to `0 - Projects/Cobalt/90 - Project Management/Requirements/`

## Output

Creates: `PRD-001 Cobalt-Ion Tactical HUD.md` in the Requirements folder.

## PRD Summary

### The Vision
Build a "Co-Pilot" system for manual day trading with a real-time Confidence Gauge.

### Core Philosophy
1. **Not an Auto-Trader** - System never executes trades autonomously
2. **Distributed Brain** - Mac (Cobalt) for strategy, Windows (Ion) for HUD math
3. **Python-First** - Shared logic between components

### Scoring Engine Formula
```
Score = Base + Fuel - Friction - Decay
```

## Destructive Warnings

‚ö†Ô∏è **This script creates new files** - it does not modify existing ones. Ensure the target folder exists in your Obsidian vault.

## Dependencies

- `importlib.util` - Dynamic module loading
- `datetime` - Date generation for frontmatter

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/deep_dive.md
========================================

# Deep Research Agent (Deep Dive)

## Overview
`cobalt_agent/skills/research/deep_dive.py`

The `DeepResearch` class implements a multi-step research agent that follows a "Plan -> Search -> Analyze -> Report" loop.

## Class: DeepResearch

### Description
A multi-step research agent that follows a "Plan -> Search -> Analyze -> Report" loop using Pydantic models for type-safe LLM interactions.

### Constructor
```python
def __init__(self)
```

Initializes components:
1. Loads configuration
2. Extracts LLM model name
3. Initializes LLM instance
4. Initializes tools (SearchTool, BrowserTool)
5. Initializes Scribe skill for output delivery

### Available Tools
- `SearchTool`: Web search for information gathering
- `BrowserTool`: Advanced browser automation for web scraping
- `Scribe`: Writes final report to Obsidian vault

### Pydantic Models

#### ResearchPlan
```python
class ResearchPlan(BaseModel):
    queries: List[str]  # 3 distinct search queries for the topic
```

#### ResearchReport
```python
class ResearchReport(BaseModel):
    title: str                    # Professional report title
    executive_summary: str        # High-level findings summary
    key_findings: List[str]       # List of most important facts
    strategic_outlook: str        # Forward-looking analysis
```

### Methods

#### run
```python
def run(self, topic: str) -> str
```

Executes a multi-step research plan on a complex topic.

**Parameters:**
- `topic` (str): The research topic

**Returns:** Path to the saved report in Obsidian vault

### Execution Phases

#### Phase 1: Planning
Generates a research strategy with:
- 3 distinct search queries
- Uses LLM with `ResearchPlan` Pydantic model
- Falls back to default queries on error

#### Phase 2: Search Execution
For each query:
1. Runs `SearchTool` to gather results
2. Formats results into readable strings
3. Appends to findings list

**Result Format:**
```
Title: {item.title}
URL: {item.href}
Summary: {item.body}
---
```

#### Phase 3: Synthesis
Sends all findings to LLM with structured prompt asking for:
- Professional title
- Executive summary
- Key findings list
- Strategic outlook

Uses `ResearchReport` Pydantic model for type-safe output.

#### Phase 4: Delivery
Formats report as Markdown:
```markdown
# {report.title}
**Date:** Today

## Executive Summary
{report.executive_summary}

## Key Findings
- {item1}
- {item2}

## Strategic Outlook
{report.strategic_outlook}
```

Saves to `0 - Inbox` folder with filename: `Research_{topic}.md`

### Error Handling
- Falls back to default queries if planning fails
- Continues execution even if individual searches fail
- Generates error report with raw data if synthesis fails

## Key Components
- `LLM`: For structured plan and report generation
- `SearchTool`: Information gathering
- `BrowserTool`: Web scraping (if needed)
- `Scribe`: Report delivery to Obsidian

## See Also
- `MorningBriefing` - Daily briefing generation
- `Scribe` - Obsidian integration
- `DeepResearch` - Research report generation

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/engineering.md
========================================

---
title: "Engineering Department Documentation"
status: Active
module: Brain
type: Department
dependencies:
  - "[[cortex]]"
  - "[[tool_manager]]"
  - "[[filesystem]]"
  - "[[proposals]]"
location: "src/cobalt_agent/brain/engineering.py"
tags: [cobalt, dev_docs, engineering, prompt]
created: 2026-02-25
---

# Engineering Department

## Overview
The Engineering Department is Cobalt's **principal systems architect and senior software engineer**. It handles code reading, analysis, and writing tasks with strict Zero Trust Human-in-the-Loop (HITL) approval for file modifications.

### Zero Trust Integration
- **Write operations always require approval** - No file can be modified without explicit human approval
- **Wait Protocol** - LLM must stop after submitting a proposal, not retry writing
- **Context Efficiency** - Skip directory crawls when given exact file paths

## Class: `EngineeringDepartment`

### Constructor
```python
def __init__(self)
```
Initializes the Engineering Department with configuration from `config.yaml`.

**Components:**
- `llm`: LLM instance for code analysis and generation
- `tool_manager`: Tool registry for code operations

---

## Critical Prompt Rules

The Engineering Department's system prompt enforces strict Zero Trust and efficiency protocols.

### 1. Strict Tool Syntax

**Rule:** YOU MUST USE THE EXACT SYNTAX BELOW TO CALL A TOOL.

**Correct Syntax:**
```python
ACTION: write_file {"filepath": "src/test.py", "content": "print('hello')"}
```

**Incorrect Syntax:**
```python
# No ACTION prefix
{"filepath": "src/test.py", "content": "print('hello')"}

# JSON wrapper
```json
{"filepath": "src/test.py", "content": "print('hello')"}
```

# Text response
I will create the file now.
```

**Enforcement:** The LLM generates a syntax error if the ACTION: prefix is missing.

### 2. No Roleplaying

**Rule:** DO NOT roleplay. DO NOT say "I will create the file now." Just output the ACTION string.

**Compliance:**
- Output ONLY the ACTION line
- Do not explain what you're doing
- Do not provide conversational preamble

### 3. Context Efficiency (Workflow)

**Rule:** If the user provides an exact filepath, DO NOT use `list_directory`. Execute `write_file` immediately to save context space.

**Example:**
```
User: "Create a file at src/new_module.py"

INCORRECT: List directory first
1. ACTION: list_directory {"directory_path": "src/"}
2. ACTION: write_file {...}

CORRECT: Direct write
1. ACTION: write_file {"filepath": "src/new_module.py", "content": "..."}

**Benefit:** Saves context window tokens for longer conversations
```

### 4. Wait Protocol (Infinite Loop Prevention)

**Rule:** If you use the `write_file` tool and the System Observation says "Action paused. Proposal sent", YOU MUST STOP. Output a final conversational message saying "I have submitted the proposal for your approval." DO NOT try to write the file again.

**Implementation:**
```python
# System Observation after write_file proposal:
"[Observation: Action paused. Proposal abc12345 sent to Admin for approval in Mattermost.]"

# LLM MUST respond with:
"I have submitted the proposal for your approval."

# LLM MUST NOT:
# - Try write_file again
# - Ask for approval
# - Provide multiple ACTION lines
```

**Zero Trust Flow:**
```
1. LLM outputs ACTION: write_file {...}
   ‚Üì
2. WriteFileTool creates Proposal Engine ticket
   ‚Üì
3. System returns: "[Observation: Action paused. Proposal abc12345 sent...]"
   ‚Üì
4. LLM receives observation, must STOP
   ‚Üì
5. LLM outputs final message: "I have submitted the proposal for your approval."
   ‚Üì
6. User responds in Mattermost: "Approve abc12345"
   ‚Üì
7. Callback executes, file modification completes
```

### 5. No Guessing

**Rule:** NEVER guess the contents of a file or directory.

**Compliance:**
- Always use `read_file` to examine file contents
- Always use `list_directory` to explore folder contents
- Do not invent file structures or content

---

## Available Tools

### `read_file`
Reads the contents of a file.

**Syntax:**
```python
ACTION: read_file {"filepath": "src/main.py"}
```

**Use Cases:**
- Examine existing code
- Verify file contents before modification
- Read configuration files

### `list_directory`
Lists the contents of a directory.

**Syntax:**
```python
ACTION: list_directory {"directory_path": "src/"}
```

**Use Cases:**
- Explore project structure
- Find existing files
- Verify directory layout

### `write_file`
Modifies or creates a file. **Always requires HITL approval.**

**Syntax:**
```python
ACTION: write_file {"filepath": "src/test.py", "content": "print('hello')"}
```

**Use Cases:**
- Create new files
- Update existing files
- Modify configuration

---

## ReAct Loop Implementation

The Engineering Department uses a ReAct (Reasoning-Acting) loop for tool execution.

### Loop Constraints

```python
max_loops = 4  # Maximum tool invocations per request
```

### Loop Flow
```
1. Get LLM response with system prompt
   ‚Üì
2. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ACTION: detected? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ                                         ‚Üì
   ‚îÇ                                     No ‚Üí return response
   ‚Üì
3. Extract tool name and arguments
   ‚Üì
4. Execute tool via ToolManager
   ‚Üì
5. Format observation
   ‚Üì
6. Append observation to conversation history
   ‚Üì
7. Loop back to step 1
   ‚Üì
8. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Max loops reached? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ                                         ‚Üì
   ‚îÇ                                     No ‚Üí continue
   ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Yes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ                           ‚Üì
   ‚îÇ                  Return error: "ReAct loop maxed out"
   ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Output Format

### Successful Tool Execution

```
Observation: File written successfully to src/test.py (100 bytes)
```

### Proposal Sent (Write File)

```
Observation: Action paused. Proposal abc12345 sent to Admin for approval in Mattermost.
```

### Error Output

```
Error: Tool 'read_file' failed: File not found: src/nonexistent.py
```

### Final Response

```
I have successfully created the file at src/test.py.
```

---

## Error Handling

| Error Type | Message | Action |
|-----------|---------|--------|
| Tool not found | `"Error: Tool 'xxx' not found."` | Return to user |
| Missing filepath | `"Error: Missing filepath or content."` | Return to user |
| LLM no ACTION | Return response as final answer | Done |
| ReAct loop maxed | `"Error: ReAct loop maxed out. Please simplify the request."` | Return to user |

---

## Integration with Proposal Engine

When `write_file` is called:

```python
# WriteFileTool executes:
proposal = create_and_send_proposal(
    action=f"Write {len(content)} bytes to {filepath}",
    justification="Agent requested file modification via WriteFileTool.",
    risk_assessment="HIGH"
)

if proposal:
    engine = ProposalEngine()
    engine.set_approval_callback(proposal.task_id, execute_write)
    return f"Action paused. Proposal [{proposal.task_id}] sent to Admin for approval."
```

---

## Configuration

No additional configuration required. The department uses the global Proposal Engine configuration for write operations.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/filesystem.md
========================================

---
title: "Filesystem Tools Documentation"
status: Active
module: Tools
type: Tool Suite
dependencies:
  - "[[proposals]]"
  - "[[tool_manager]]"
  - "[[config]]"
location: "src/cobalt_agent/tools/filesystem.py"
tags: [cobalt, dev_docs, filesystem, tools]
created: 2026-02-25
updated: 2026-02-27
---

# Filesystem Tools

## Overview
The Filesystem module provides safe, auditable file operations for the Cobalt Agent. All write operations are subject to Zero Trust Human-in-the-Loop (HITL) approval via the Proposal Engine.

### Zero Trust Integration
- **Write operations always require approval** - No file can be modified without explicit human approval
- **Memory-locked callbacks** - Execution closures are stored in RAM only, mapped to 8-character task IDs
- **Pydantic schema validation** - Strict JSON parsing with no fallback to unsafe evaluation
- **Dynamic filesystem paths** - All paths are resolved via `cobalt_agent.config` from the `.env` vault root

## Tools

### ReadFileTool
Reads the contents of a file.

**Name:** `read_file`

**Description:** Read the contents of a file. Use when you need to examine existing code or data.

**Syntax:**
```python
ACTION: read_file {"filepath": "src/main.py"}
```

### ListDirectoryTool
Lists the contents of a directory.

**Name:** `list_directory`

**Description:** List the contents of a directory. Use when you need to explore the file structure.

**Syntax:**
```python
ACTION: list_directory {"directory_path": "src/"}
```

### WriteFileTool (Zero Trust)

Modifies or creates a file. **This tool ALWAYS requires Human-in-the-Loop approval.**

**Name:** `write_file`

**Zero Trust Flow:**
```
1. LLM requests file modification
   ‚Üì
2. WriteFileTool parses arguments (strict JSON validation)
   ‚Üì
3. WriteFileTool creates Proposal Engine ticket
   ‚Üì
4. Proposal sent to Mattermost approval channel
   ‚Üì
5. User responds with "Approve [task_id]"
   ‚Üì
6. MattermostInterface intercepts approval
   ‚Üì
7. Callback execution closes the loop
   ‚Üì
8. File modification executes in RAM
```

## WriteFileTool Implementation

### Strict JSON Validation

The WriteFileTool implements strict JSON validation using Pydantic schemas to ensure data integrity without unsafe evaluation.

```python
# Strict JSON validation via Pydantic schema
data = query if query is not None else kwargs

if isinstance(data, str):
    try:
        data = json.loads(data)
    except json.JSONDecodeError as e:
        logger.error(f"WriteFileTool JSON validation failed: {e} | Data: {data}")
        return f"Error: Failed to parse arguments. Expected valid JSON. Received: {data}"
```

**Validation Flow:**
1. **JSON parsing** - Primary format for structured data
2. **Pydantic schema validation** - Strict type checking via input models
3. **Error reporting** - Detailed error message for LLM self-correction

**Supported Input Formats:**
| Format | Example | Parsed By |
|--------|---------|----------|
| Dictionary | `{"filepath": "test.py", "content": "print('hi')}"}` | Direct dict access |
| JSON string | `'{"filepath": "test.py", "content": "print(\'hi\')"}'` | `json.loads()` |
| Pydantic model | `WriteFileInput(filepath="test.py", content="print('hi')")` | Schema validation |

### Input Schema Enforcement

All filesystem tools are bound to strict Pydantic input models:

```python
# ReadFileTool
class ReadFileInput(BaseModel):
    filepath: str

# WriteFileTool  
class WriteFileInput(BaseModel):
    filepath: str
    content: str

# ListDirectoryTool
class ListDirectoryInput(BaseModel):
    directory_path: str
```

Tools are registered with their schemas in `ToolManager`:

```python
self.register_tool("write_file", WriteFileTool(), schema=WriteFileInput)
```

## Dynamic Filesystem Paths

All filesystem paths are resolved dynamically from the `.env` vault root via `cobalt_agent.config`:

```python
from cobalt_agent.config import get_config

config = get_config()
vault_root = config.system.obsidian_vault_path  # Dynamically loaded from .env
inbox_path = Path(vault_root) / "0 - Inbox/"  # OS-agnostic path construction
```

**Path Resolution Rules:**
1. **Vault root** - Always loaded from `.env` via `config.system.obsidian_vault_path`
2. **OS-agnostic paths** - Use `pathlib.Path` for all path operations
3. **No hardcoded paths** - No magic strings or absolute paths in code

## Execute Closure (Memory-Locked)

When a proposal is created, the WriteFileTool creates a closure that captures the file path and content:

```python
def execute_write(proposal_obj):
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        logger.info(f"Proposal Engine executed write to: {filepath} ({len(content)} bytes)")
    except Exception as e:
        logger.exception(f"Failed to physically write file {filepath}")
```

This closure is stored in the `ProposalEngine.callbacks` dictionary and executed only after approval.

## Integration with ProposalEngine

```python
try:
    proposal = create_and_send_proposal(
        action=f"Write {len(content)} bytes to {filepath}",
        justification="Agent requested file modification via WriteFileTool.",
        risk_assessment="HIGH"
    )
except Exception as e:
    logger.exception(f"Proposal Engine crash")
    return f"Error: Proposal Engine crashed: {e}"

if proposal:
    engine = ProposalEngine()
    engine.set_approval_callback(proposal.task_id, execute_write)
    engine.pending_proposals[proposal.task_id] = proposal
    return f"Action paused. Proposal [{proposal.task_id}] sent to Admin for approval in Mattermost."
else:
    return "Error: Failed to generate Proposal Ticket. Mattermost connection failed."
```

## Output Format

When a write request is received, the tool returns:

```
Action paused. Proposal [abc12345] sent to Admin for approval in Mattermost.
```

After approval via Mattermost (user responds with "Approve abc12345"):

```
Approval received for task [abc12345]. Action executed successfully.
```

## Error Handling

| Error Type | Message Format | Example |
|------------|----------------|---------|
| Missing filepath | `Error: Missing filepath or content. Parsed data: {data}` | |
| Missing content | `Error: Missing filepath or content. Parsed data: {data}` | |
| JSON parse error | `Error: Failed to parse arguments. Expected valid JSON. Received: {data}` | |
| File write error | Logged to logger only | |
| Proposal Engine crash | `Error: Proposal Engine crashed: {error}` | |

## Security Considerations

1. **No direct file access** - File modifications only occur after explicit approval
2. **Memory-locked callbacks** - Execution closures never written to disk
3. **8-character task ID** - Cryptographic token for approval matching
4. **Log audit trail** - All proposal lifecycle events are logged
5. **Path sanitization** - Directory traversal prevented (handled by underlying OS)
6. **Dynamic paths** - All paths resolved via `cobalt_agent.config` from `.env`

## Configuration

No additional configuration required. The tool automatically uses the global Proposal Engine configuration and dynamically resolves paths from `config.system.obsidian_vault_path`.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/finance.md
========================================

---
title: "Finance Tool Documentation"
status: Active
module: Tool
type: Class
dependencies:
  - "[[tool_manager]]"
  - "[[config]]"
location: "src/cobalt_agent/tools/finance.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Finance Tool Module

**Location:** `src/cobalt_agent/tools/finance.py`

## Overview

Finance Tool returns structured market data with Technical Indicators. Implements all rules from `rules.yaml`.

## Class: `MarketMetrics` (Pydantic Model)

Structured financial data for a single asset.

### Fields

| Field | Type | Description |
|--|--|--|
| `ticker` | `str` | The stock symbol (e.g. AAPL) |
| `price` | `float` | Current market price |
| `change_percent` | `float` | Daily percentage change |
| `volume` | `int` | Current trading volume |
| `rsi` | `float` | Relative Strength Index |
| `atr` | `float` | Average True Range |
| `rvol` | `float` | Relative Volume |
| `avwap_earnings` | `str` | VWAP from last earnings date |
| `avwap_high` | `str` | VWAP from 2-month Swing High |
| `avwap_low` | `str` | VWAP from 2-month Swing Low |
| `sma_10` | `str` | 10-day SMA with slope |
| `sma_20` | `str` | 20-day SMA with slope |
| `sma_50` | `str` | 50-day SMA with slope |
| `sma_100` | `str` | 100-day SMA with slope |
| `sma_200` | `str` | 200-day SMA with slope |
| `signal` | `str` | Computed technical signal |
| `alert_flags` | `str` | Special alerts |
| `calculation_meta` | `str` | Debug string showing which rules were used |

### Methods

#### `__str__() -> str`
Returns a human-readable string representation with formatted output.

---

## Class: `FinanceTool`

Fetches market data and calculates technical indicators.

### Attributes

| Attribute | Value |
|--|--|
| `name` | `"finance"` |
| `description` | `"Get current stock market data and technical indicators. Use for price queries, e.g., 'What is the price of AAPL?'"` |
| `system_config` | Loaded config object |
| `rules` | Trading rules from config |

### Methods

#### `run(ticker: str) -> MarketMetrics`

Fetches market data and returns structured metrics.

**Parameters:**
- `ticker`: Stock symbol (e.g., AAPL)

**Returns:** `MarketMetrics` with all calculated indicators

**Workflow:**
1. Load 2-year historical data via yfinance
2. Calculate RSI, ATR, RVOL
3. Compute Anchored VWAPs (earnings, swing high, swing low)
4. Calculate SMAs with slope detection
5. Apply signal logic from rules.yaml
6. Return structured metrics

#### `_get_rule(path: str, default: Any = None) -> Any`

Safely access nested config rules (handles dict or object notation).

#### `_calculate_rsi(data, window: int) -> float`

Calculates Relative Strength Index.

#### `_calculate_atr(data, window: int) -> float`

Calculates Average True Range.

#### `_calculate_rvol(data, window: int) -> float`

Calculates Relative Volume against 20-day average.

#### `_calculate_avwap(data, start_date: str) -> float`

Calculates Anchored VWAP from a specific date.

#### `_get_sma_data(data, window: int) -> Tuple[float, str]`

Returns SMA value and slope direction ("RISING" or "FALLING").

#### `_get_last_earnings_date(ticker_obj) -> Optional[str]`

Gets the most recent past earnings date.

### Signal Logic

1. **Overbought/ Oversold**: RSI > 70 or RSI < 30
2. **Bullish Cross**: Fast SMA > Slow SMA AND both rising
3. **Trend**: Price above/below earnings VWAP
4. **Default**: NEUTRAL

### Alerts

- **RVOL ALERT**: Relative volume > 3.0
- **PARABOLIC MOVE**: 5-day move > 5x ATR

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/generate_constitution.md
========================================

---
title: "Generate Constitution Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[scribe]]"
location: "dev_utils/generate_constitution.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Generate Constitution Script

**Location:** `dev_utils/generate_constitution.py`

## Overview

Generate Constitution creates the Cobalt Constitution - a comprehensive set of architecture documentation, ADRs, and project management files. This script generates the foundational documentation structure for the entire Cobalt project.

## Usage

```bash
python dev_utils/generate_constitution.py
```

Or with uv:

```bash
uv run python dev_utils/generate_constitution.py
```

## ‚ö†Ô∏è Destructive Warning

üö® **THIS SCRIPT DELETES AND CREATES FILES** - It creates the entire Constitution document structure. Run only once during initial setup or when explicitly updating the Constitution.

## Behavior

The script generates the following files in the Obsidian vault:

### Level 1: Master Plan
1. **Dashboard** (`00 Cobalt Master Plan.md`) - Root navigation document
2. **System Manifest** (`00 - Master Plan/System Manifest.md`) - Stack, hierarchy, and roles
3. **Security Architecture** (`00 - Master Plan/Security Architecture.md`) - Zero Trust, JIT, Kill-Switches

### Level 2: ADRs
4. **ADR-001** - Distributed Protocol (Mac/Windows architecture)
5. **ADR-002** - Hybrid AI Compute (Local vs Cloud models)
6. **ADR-003** - Python-First Architecture (PyQt6 for Ion HUD)

### Level 3: Project Management
7. **Roadmap** - Strategic phases (Q1/Q2 goals)
8. **Backlog** - Future ideas and placeholders

## Output Files Structure

```
0 - Projects/Cobalt/
‚îú‚îÄ‚îÄ 00 Cobalt Master Plan.md           (Dashboard)
‚îú‚îÄ‚îÄ 00 - Master Plan/
‚îÇ   ‚îú‚îÄ‚îÄ System Manifest.md
‚îÇ   ‚îî‚îÄ‚îÄ Security Architecture.md
‚îú‚îÄ‚îÄ 00 - Master Plan/ADR/
‚îÇ   ‚îú‚îÄ‚îÄ ADR-001 Cobalt-Ion Distributed Protocol.md
‚îÇ   ‚îú‚îÄ‚îÄ ADR-002 Hybrid AI Compute.md
‚îÇ   ‚îî‚îÄ‚îÄ ADR-003 Python-First Architecture.md
‚îî‚îÄ‚îÄ 90 - Project Management/
    ‚îú‚îÄ‚îÄ Roadmap.md
    ‚îî‚îÄ‚îÄ Backlog.md
```

## System Manifest Overview

### The Hierarchy
- **Level 1: CEO (Dejan)** - Final decision maker
- **Level 2: Cobalt (Chief of Staff)** - Orchestration and coaching
- **Level 3: Departments** - Strategos, Ion, Scribe, Sentinel, Scout

### The Hardware Stack
- **Brain (Mac Studio M2 Ultra)** - Central compute node
- **Engine (Windows Workstation)** - Execution environment
- **Console (Lenovo X1 Carbon)** - Development interface
- **Red Phone (Mobile)** - Command & Control

## Dependencies

- `importlib.util` - Dynamic module loading
- `datetime` - Date generation for frontmatter

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/generate_context.md
========================================

---
title: "Generate Context Documentation"
status: Active
module: Utility
type: Script
dependencies: []
location: "dev_utils/generate_context.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Generate Context Script

**Location:** `dev_utils/generate_context.py`

## Overview

Generate Context is a utility script that generates a master context file (`cobalt_master_context.txt`) for architectural review. It walks the project directory, collects relevant files, and outputs a single file containing the directory tree and file contents.

## Usage

Run the script from the project root:

```bash
python dev_utils/generate_context.py
```

Or with uv:

```bash
uv run python dev_utils/generate_context.py
```

## Behavior

### Exclusions

The script automatically excludes:
- Files/directories starting with `.` or `__`
- `venv` directory
- `uv.lock` file

### Inclusions

The script processes files with the following extensions:
- `.py` (Python)
- `.md` (Markdown)
- `.yaml` / `.yml` (YAML)
- `.toml` (TOML)
- `.log` (Log files - last 200 lines only)
- `.txt` (Text files)

### Output

The script generates `cobalt_master_context.txt` containing:
1. **Directory Tree**: Text-based representation of the project structure
2. **File Contents**: All processed files with their full content

## Use Cases

- **Architectural Review**: Provides a complete snapshot of the codebase for review
- **Context Generation**: Creates a consolidated file for LLM analysis
- **Documentation**: Serves as a baseline for project documentation

## Notes

- Log files are automatically truncated to the last 200 lines to manage file size
- Files that cannot be read (permissions, binary) will show an error message

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/knowledge.md
========================================

# Knowledge Search Tool

## Overview
`cobalt_agent/tools/knowledge.py`

The `KnowledgeSearchTool` class provides semantic search capabilities against the agent's internal vector database containing codebase, playbooks, and Obsidian vault.

## Class: KnowledgeSearchTool

### Description
Search the agent's internal vector database (codebase, playbooks, and Obsidian vault) for semantic context.

### Attributes
- `name`: "search_knowledge"
- `description`: "Search the agent's internal vector database (codebase, playbooks, and Obsidian notes) for semantic context. Pass a conceptual query string."

### Constructor
```python
def __init__(self)
```

Initializes:
1. Creates `PostgresMemory` instance for vector database access

### Methods

#### run
```python
def run(self, query=None, **kwargs) -> str
```

Searches the vector DB and returns formatted results.

**Parameters:**
- `query` (Optional[str]): Search query string
- `**kwargs`: Additional parameters (supports dict format)

**Returns:** Formatted search results as a string

### Input Parsing
The method handles multiple input formats:
1. **String input:** Uses directly
2. **JSON string:** Parsed with `json.loads()`
3. **Python dict literal:** Parsed with `ast.literal_eval()`
4. **Dict:** Extracts `query` or `search` key

### Search Execution
1. Extracts search query from input
2. Calls `memory.search()` with query and limit of 5
3. Formats results with source, relevance score, and content

### Result Format
```
### Knowledge Base Results for '{query}':

**Result 1** (Source: `filepath`, Relevance: 0.85)
```text
content
```

**Result 2** (Source: `filepath`, Relevance: 0.82)
```text
content
```
```

### Error Handling
- Returns error message if search query is missing
- Returns message if no relevant information found
- Logs errors and returns formatted error string on exception

## Key Components
- `PostgresMemory`: Vector database backend

## See Also
- `SearchTool` - Web search tool
- `BrowserTool` - Browser automation tool
- `PostgresMemory` - Vector database integration

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/llm.md
========================================

---
title: "LLM Interface Documentation"
status: Active
module: Brain
type: Class
dependencies:
  - "[[main]]"
  - "[[prompt]]"
location: "src/cobalt_agent/llm.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# LLM (Language Model) Interface

## Overview
The LLM interface provides unified access to large language models through a single API. It supports multiple providers including Gemini and handles model configuration, prompting, and response parsing.

## Class: `LLM`

### Constructor
```python
def __init__(self, config: LLMConfig)
```
Initializes the LLM with provider configuration.

**Parameters:**
- `config`: `LLMConfig` instance containing model name and API key

### Key Attributes
- `config`: LLM configuration
- `model_name`: The model identifier (e.g., "gemini/gemini-1.5-pro")
- `api_key`: Provider API key

### Main Methods

#### `generate(prompt: str, temperature: float = 0.7, max_tokens: int = 2048) -> str`
Generates text from the LLM based on the provided prompt.

**Parameters:**
- `prompt`: The input prompt text
- `temperature`: Controls randomness (0.0 to 1.0)
- `max_tokens`: Maximum tokens in the response

**Returns:**
- `str`: Generated response from the model

#### `_call_gemini(prompt: str, temperature: float, max_tokens: int) -> str`
Internal method to call the Gemini API.

**Parameters:**
- `prompt`: The input prompt
- `temperature`: Temperature setting
- `max_tokens`: Maximum tokens

**Returns:**
- Generated response from Gemini

### Internal Methods

#### `_get_provider() -> str`
Determines the LLM provider from the model name.

**Returns:**
- Provider name (e.g., "gemini")

#### `_parse_model_name(full_name: str) -> Tuple[str, str]`
Splits full model name into provider and model parts.

**Returns:**
- Tuple of (provider, model_name)

## Configuration

### Model Name Format
The model name follows the format `provider/model-name`:
- `gemini/gemini-1.5-pro`
- `gemini/gemini-2.0-flash`

### Environment Variables
- `LLM_API_KEY`: API key for the LLM provider

## Error Handling
- Missing API keys raise configuration errors
- Network failures are caught and logged
- Invalid responses are handled gracefully

## Future Enhancements
- Support for additional LLM providers
- Streaming responses
- Token usage tracking
- Rate limit handling

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/main.md
========================================

---
title: "Main Entry Point Documentation"
status: Active
module: Core
type: Class
dependencies:
  - "[[llm]]"
  - "[[memory_core]]"
  - "[[cortex]]"
  - "[[cli]]"
  - "[[mattermost]]"
location: "src/cobalt_agent/main.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Main Entry Point

## Overview
The main module serves as the entry point for the Cobalt Agent application. It initializes the system, loads configuration, and starts the agent's main loop or interactive interface.

## Class: `CobaltAgent`

### Constructor
```python
def __init__(self)
```
Initializes the Cobalt Agent with all components.

### Key Components

#### Core System
- `config`: Global configuration from `configs/config.yaml`
- `llm`: LLM instance for reasoning
- `cortex`: Chief of Staff for routing requests to departments
- `memory`: Memory system for storing and retrieving conversation history

#### Departments
- `Tactical`: Market data and trading strategies (Strategos)
- `Intel`: Research and news analysis
- `Ops`: Logging and documentation (Scribe)
- `Engineering`: Development tools and utilities

#### Interfaces
- `CLI`: Command-line interface
- `Mattermost`: Real-time chat integration

### Main Methods

#### `run() -> None`
Starts the main agent loop.

**Behavior:**
- Loads configuration
- Initializes all components
- Starts interactive loop or service

#### `route(user_input: str) -> Optional[str]`
Convenience method to route input through Cortex.

**Parameters:**
- `user_input`: User's message or command

**Returns:**
- Response from the appropriate department

## Command-Line Interface

### Usage
```bash
python -m cobalt_agent
# or
uv run python -m cobalt_agent
```

### Options
- `--debug`: Enable debug logging
- `--config-dir`: Specify custom configuration directory

## Environment Setup

### Required Variables
- `LLM_API_KEY`: API key for the LLM provider
- `MATTERMOST_TOKEN`: (Optional) Token for Mattermost integration

### Configuration Files
- `configs/config.yaml`: Main configuration
- `configs/strategies.yaml`: Trading strategy parameters
- `configs/rules.yaml`: Business rules and overrides

## Startup Flow
1. Load `.env` file
2. Load YAML configuration files
3. Initialize LLM
4. Initialize Memory System
5. Initialize Cortex (Chief of Staff)
6. Register Departments
7. Register Tools
8. Start CLI or Mattermost listener

## Error Handling
- Missing configuration defaults to safe values
- LLM connection failures are logged and retried
- Department initialization failures are logged
- Agent continues with partial functionality when possible

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/mattermost.md
========================================

---
title: "Mattermost Interface Documentation"
status: Active
module: Interface
type: Class
dependencies:
  - "[[main]]"
  - "[[cortex]]"
  - "[[llm]]"
location: "src/cobalt_agent/interfaces/mattermost.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Mattermost Interface

## Overview
The Mattermost Interface provides real-time communication capabilities for the Cobalt Agent. It enables the agent to listen for messages in Mattermost channels and respond using the Brain's routing and LLM capabilities.

### Zero Trust Integration
The interface integrates with the Proposal Engine to handle **Approval Responses** for high-stakes actions. When users respond with "Approve [task_id]" in the approval channel, the interface detects the response, validates the task_id, and triggers execution of the approved action.

## Class: `MattermostInterface`

### Constructor
```python
def __init__(self, config: Optional[MattermostConfig] = None)
```
Initializes the interface with configuration. If no config is provided, loads from global config.

**Parameters:**
- `config`: Optional `MattermostConfig` instance

### Key Attributes
- `config`: Mattermost configuration (URL, token)
- `driver`: Mattermost driver instance
- `brain`: Reference to the CobaltAgent/Cortex for message processing
- `is_connected`: Boolean indicating connection status

### Main Methods

#### `connect() -> bool`
Establishes connection to the Mattermost server and authenticates.

**Returns:**
- `True` if connection and authentication succeeded
- `False` otherwise

**Configuration Sources:**
1. Environment variables: `MATTERMOST_URL`, `MATTERMOST_TOKEN`
2. YAML config: `configs/config.yaml`

#### `disconnect() -> None`
Logs out from Mattermost and disconnects from the server.

#### `send_message(channel_name: str, team_name: str, message: str) -> bool`
Sends a message to a specific channel.

**Parameters:**
- `channel_name`: Name of the channel (without #)
- `team_name`: Name of the team
- `message`: Message content to send

**Returns:**
- `True` if message sent successfully
- `False` otherwise

#### `send_message_to_channel_id(channel_id: str, message: str) -> bool`
Directly sends a message to a channel using its ID.

**Parameters:**
- `channel_id`: Mattermost channel ID
- `message`: Message content

#### `get_my_user_id() -> Optional[str]`
Returns the current user's Mattermost ID.

### WebSocket Integration

#### `start_listening(brain: "CobaltAgent") -> None`
Starts the WebSocket listener in the main thread to receive incoming messages.

**Features:**
- Connects to Mattermost WebSocket API
- Processes incoming messages
- Routes to Brain for inference
- Sends responses back to channel

**Message Flow:**
1. WebSocket receives "posted" event
2. Extract post data (user_id, channel_id, message)
3. Ignore bot's own messages
4. Route to `brain.route()` or generate conversational response
5. Send response to channel

### Internal Methods

#### `_handle_mattermost_event(message: str) -> None`
Processes incoming WebSocket events.

**Handles:**
- Event parsing and validation
- Post data extraction from JSON
- Message routing to Brain
- Conversational response generation

#### `_handle_events(mm_driver: Driver) -> None`
Event handler callback for Mattermost events.

#### `_run_websocket_in_process(brain: "CobaltAgent", event_queue: "multiprocessing.Queue") -> None`
Runs the WebSocket listener in a separate process to avoid event loop conflicts.

### Approval Response Handling

#### Overview
The MattermostInterface detects and processes **Approval Responses** for high-stakes actions. When users respond with "Approve [task_id]" in the approval channel, the interface validates the response using regex and triggers the Proposal Engine to execute the approved action.

**Key Integration Points:**
- `MattermostInterface` receives WebSocket events
- `proposal_engine.handle_approval_response()` validates approval pattern and task_id
- `proposal_engine.execute_approved()` executes the approved action

#### Approval Pattern Regex
```python
approval_pattern = r"approve\s+(\w{8})"
```

**Pattern Components:**
- `approve`: Literal text (case-insensitive)
- `\s+`: One or more whitespace characters
- `(\w{8})`: Capture group for exactly 8 word characters (task_id)

**Example Matches:**
| Input | Extracted Task ID | Match? |
|-------|-------------------|--------|
| `approve abc12345` | `abc12345` | ‚úÖ Yes |
| `Approve ABC12345` | `ABC12345` | ‚úÖ Yes |
| `approved xyz98765` | `xyz98765` | ‚úÖ Yes |
| `APPROVE 12345678` | `12345678` | ‚úÖ Yes |
| `approve abc123` | `N/A` | ‚ùå No (wrong length) |
| `Deny abc12345` | `N/A` | ‚ùå No (wrong keyword) |

#### Approval Response Processing Flow
```
1. WebSocket receives "posted" event with message
   ‚Üì
2. _handle_mattermost_event() extracts message text and channel_id
   ‚Üì
3. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ proposal_engine attached? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ                                            ‚Üì
   ‚îÇ                                     No engine ‚Üí skip
   ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Yes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                         ‚Üì
4. Call proposal_engine.handle_approval_response(text, channel_id)
   ‚Üì
5. Regex pattern matching checks for approval pattern
   ‚Üì
6. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Match ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                             ‚Üì
7. Extract task_id (8-char ID)  No match ‚Üí route to brain
   ‚Üì
8. Validate channel matches approval_channel config
   ‚Üì
9. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Valid ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                             ‚Üì
10. Look up task_id in pending_proposals  Invalid channel ‚Üí route to brain
   ‚Üì
11. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Found ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                             ‚Üì
12. Remove from pending, add to approved  Unknown task_id ‚Üí route to brain
   ‚Üì
13. Set proposal.approved = True
   ‚Üì
14. Log approval event
   ‚Üì
15. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ approval_callback set? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ                                         ‚Üì
   ‚îÇ                                  No callback ‚Üí done
   ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Yes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                         ‚Üì
16. Execute approved action   Execute callback with proposal
   ‚Üì
17. Return to message loop
```

#### Integration with ProposalEngine

**Connection Setup:**
```python
from cobalt_agent.core.proposals import ProposalEngine

# In main.py or initialization:
engine = ProposalEngine()
engine.connect_mattermost()
engine.start_monitoring()

# Attach engine to MattermostInterface:
mm_interface.proposal_engine = engine
mm_interface.brain = cobalt_agent.cortex
```

**Message Processing Priority:**
1. **Approval responses** (highest priority) - processed first
2. **Brain routing** - for non-approval messages

**Flow when approval detected:**
```python
# In _handle_mattermost_event():
if self.proposal_engine:
    approved_proposal = self.proposal_engine.handle_approval_response(text, channel_id)
    if approved_proposal:
        # Execute the approved action
        self.proposal_engine.execute_approved(approved_proposal)
        return  # Don't route to brain for approval responses

# Only reach here if not an approval response
if self.brain:
    response = self.brain.route(text)
    self.send_message_to_channel_id(channel_id, response)
```

#### The `handle_approval_response()` Method

**Location:** `ProposalEngine` (not `MattermostInterface`)

**Signature:**
```python
def handle_approval_response(self, message: str, channel_id: str) -> Optional[Proposal]
```

**Behavior:**
1. Regex extracts task_id from message
2. Validates channel matches approval_channel config
3. Looks up task_id in pending_proposals
4. If found: removes from pending, adds to approved, sets approved=True
5. Returns the approved Proposal (or None if not an approval)

**Returns:**
- `Proposal` object if this is a valid approval response
- `None` if message doesn't match approval pattern or task_id not found

#### Error Handling

**Common failure cases:**
- **No approval engine attached**: Message routes to brain normally
- **Channel mismatch**: Approval ignored, message routes to brain
- **Unknown task_id**: Warning logged, message routes to brain
- **Regex no match**: Message routes to brain normally

---

## HITL Interceptor (Zero Trust)

### Overview
The MattermostInterface implements a **WebSocket-level interceptor** that processes approval/reject messages before any LLM inference. This ensures Zero Trust by bypassing the ReAct loop for approval responses.

**Location:** `_handle_mattermost_event()` method

### Interceptor Priority

```
1. WebSocket receives "posted" event with message
   ‚Üì
2. HITL Interceptor checks if message starts with "approve" or "reject"
   ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Match ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                             ‚Üì
3. Call engine.handle_approval_response()   No match ‚Üí skip interceptor
   ‚Üì                             ‚Üì
4. Send result back to channel   Route to brain for LLM inference
   ‚Üì
5. Return (don't process further)
```

### Supported Approval Patterns

| Pattern | Case-Sensitive | Extracts | Example |
|---------|---------------|--------|--------|
| `approve\s+(\w{8})` | Case-insensitive | 8-char task-id | `Approve abc12345` |
| `reject\s+(\w{8})` | Case-insensitive | 8-char task_id | `Reject xyz98765` |

### Response Messages

**Approval Success:**
```
‚úÖ Approval received for task [abc12345]. Action executed successfully.
```

**Approval Timeout:**
```
‚ö†Ô∏è Approval received for [abc12345], but no execution callback was found in memory.
```

**Unknown Task ID:**
```
‚ö†Ô∏è No pending approval found for task [abc12345].
```

**Already Approved:**
```
‚ÑπÔ∏è Proposal [abc12345] was already approved.
```

**Rejection:**
```
‚ùå Rejection received for task [abc12345]. The action has been cancelled.
```

---

## System Message Filtering

### Overview
The MattermostInterface filters out **Mattermost system messages** (joins, leaves, header updates) to prevent the LLM from responding to non-user events.

### System Message Detection

```python
# Ignore Mattermost system messages (joins, leaves, header updates)
if post_data.get("type", "") != "":
    return
```

### System Message Types Filtered

| Message Type | Description | Filtered? |
|--------------|-------------|----------|
| Empty (`""`) | Regular user message | ‚ùå No |
| `"system_join"` | User joins channel | ‚úÖ Yes |
| `"system_leave"` | User leaves channel | ‚úÖ Yes |
| `"system_header"` | Channel header updated | ‚úÖ Yes |
| `"system_join_leave"` | Group membership change | ‚úÖ Yes |
| `"system_purpose"` | Channel purpose updated | ‚úÖ Yes |

### Implementation Note
Only messages with an empty `type` field (regular user messages) pass through to the LLM inference pipeline. All system-generated events are silently dropped.

## Integration with Brain

The Mattermost interface requires a Brain (Cortex) attachment to process messages:

```python
mm_interface.brain = cobalt_agent.cortex
```

When a message is received:
1. `cortex.route(text)` attempts to match to a department
2. If matched, department response is sent
3. If not matched, LLM generates conversational response

## Configuration Example
```yaml
mattermost:
  url: "https://mattermost.example.com"
  token: "${MATTERMOST_TOKEN}"
  scheme: "https"
  port: 443

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/memory_base.md
========================================

---
title: "Memory Base Documentation"
status: Active
module: Memory
type: Class
dependencies:
  - "[[memory_core]]"
  - "[[postgres]]"
location: "src/cobalt_agent/memory/base.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Memory Base Module

**Location:** `src/cobalt_agent/memory/base.py`

## Overview

Memory Interface (The Contract) defines how Agents interact with memory, regardless of storage implementation (JSON vs Postgres).

## Class: `MemoryProvider` (ABC)

Abstract Base Class for Memory. Any memory system (JSON, SQL, Vector) MUST implement these methods.

### Methods

#### `add_log(message: str, source: str = "System", data: Dict = None) -> None`
Record an event or thought.

**Parameters:**
- `message`: The memory content
- `source`: Origin of the memory (default: "System")
- `data`: Optional dictionary of additional data

#### `get_context(limit: int = 10) -> List[Dict[str, Any]]`
Get recent conversation history (Short Term RAM).

**Parameters:**
- `limit`: Maximum number of recent interactions to retrieve

**Returns:** List of memory entries

#### `search(query: str, limit: int = 5) -> List[Dict[str, Any]]`
Find relevant memories based on meaning/content.

**Parameters:**
- `query`: Search query string
- `limit`: Maximum number of results to return

**Returns:** List of matching memory entries

**Notes:**
- For JSON storage: Uses keyword search
- For Postgres: Uses vector search

---

## Implementation Pattern

Any memory provider must inherit from `MemoryProvider`:

```python
from cobalt_agent.memory.base import MemoryProvider

class MyMemoryProvider(MemoryProvider):
    def add_log(self, message, source="System", data=None):
        # Implementation here
        pass
    
    def get_context(self, limit=10):
        # Implementation here
        return []
    
    def search(self, query, limit=5):
        # Implementation here
        return []

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/memory_core.md
========================================

---
title: "Memory Core Documentation"
status: Active
module: Memory
type: Class
dependencies:
  - "[[memory_base]]"
  - "[[postgres]]"
location: "src/cobalt_agent/memory/core.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Memory Core Module

**Location:** `src/cobalt_agent/memory/core.py`

## Overview

Memory System Core (JSON Implementation) manages short-term (RAM) and long-term (Disk) memory for the Cobalt Agent.

## Class: `MemorySystem`

Manages:
- Short-term memory: Last 10 interactions (RAM - Fast)
- Long-term memory: Persistent storage in `data/memory.json` (Disk - Safe)

Implements the `MemoryProvider` interface from `base.py`.

### Constructor

```python
MemorySystem(memory_file: str = "data/memory.json")
```

**Parameters:**
- `memory_file`: Path to the memory JSON file.

### Attributes

- `memory_file`: Path to the memory storage file
- `short_term`: List of last 10 interactions (RAM)
- `long_term`: Dictionary containing all historical logs (Disk)

### Methods

#### `add_log(message: str, source: str = "System", data: Dict = None) -> None`
Add a message to both short-term and long-term memory.

**Parameters:**
- `message`: The memory content
- `source`: Origin of the memory (default: "System")
- `data`: Optional dictionary of additional data

Automatically saves to disk and maintains RAM limit of 10 entries.

#### `get_context(limit: int = 10) -> List[Dict[str, Any]]`
Fast retrieval of short-term memory for AI prompts.

**Parameters:**
- `limit`: Number of recent interactions to retrieve

**Returns:** List of memory entries sorted by timestamp.

#### `search(query: str, limit: int = 5) -> List[Dict[str, Any]]`
Simple keyword search through long-term memory.

**Parameters:**
- `query`: Search string to match against memory messages
- `limit`: Maximum number of results

**Returns:** List of matching memory entries (newest first).

#### `save_memory() -> None`
Save long-term memory to disk.

#### `load_memory() -> None`
Load long-term memory from disk and hydrate short-term RAM.

---

## Memory Entry Format

```python
{
    "timestamp": "2026-02-22T23:00:00",
    "source": "System",
    "message": "Strategy scan completed",
    "data": {"strategy": "second_day_play", "score": 75}
}

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/ops.md
========================================

# Ops Department (The Scribe)

## Overview
`cobalt_agent/brain/ops.py`

The `OpsDepartment` class is Cobalt's Operations and Documentation department. It inherits from `BaseDepartment` and handles journaling, formatting, reading playbooks, and Obsidian integration.

## Class: OpsDepartment

### Description
The Scribe - Cobalt's Operations and Documentation department. Handles journaling, formatting, reading playbooks, and Obsidian integration.

### Constructor
```python
def __init__(self, system_prompt: Optional[str] = None)
```

**Parameters:**
- `system_prompt` (Optional[str]): Optional custom system prompt

**Default Name:** "The Scribe (Operations)"

### System Prompt
The department uses a default prompt that enforces strict rules:

**CRITICAL RULES:**
1. You are a documentation expert. Use pristine Markdown formatting.
2. You do not write Python or application code. You write journals, summaries, and reports.
3. **YOU MUST USE THE EXACT SYNTAX BELOW TO CALL A TOOL:**
   - **CORRECT:** `ACTION: write_file {"filepath": "0 - Inbox/note.md", "content": "# Hello"}`
   - **INCORRECT:** `{"filepath": "0 - Inbox/note.md", "content": "# Hello"}`
   - **INCORRECT:** ```json\n{"filepath": "0 - Inbox/note.md", "content": "# Hello"}\n```
4. DO NOT roleplay. DO NOT say "I will create the note now." Just output the ACTION string.
5. **WAIT PROTOCOL:** If you use the `write_file` tool and the System Observation says "Action paused. Proposal sent", YOU MUST STOP. Output a final conversational message saying "I have submitted the proposal for your approval." DO NOT try to write the file again.

### Available Tools
- `read_file`: Reads a file. Syntax: `ACTION: read_file {"filepath": "docs/file.md"}`
- `list_directory`: Lists a folder. Syntax: `ACTION: list_directory {"directory_path": "0 - Inbox/"}`
- `write_file`: Modifies or creates a file. Syntax: `ACTION: write_file {"filepath": "0 - Inbox/note.md", "content": "# Hello"}`

### Inheritance
Extends `BaseDepartment` with specialized operations-focused system prompt.

## Key Features
- **Documentation Expertise:** Specializes in creating clean, well-formatted documentation
- **Tool Call Syntax:** Enforces strict ACTION: prefix for tool calls
- **Zero-Trust Workflow:** Respects human-in-the-loop approval for file modifications

## See Also
- `BaseDepartment` - Abstract base class for all departments
- `EngineeringDepartment` - Code generation department
- `Scribe` - Skill class for Obsidian integration

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/orchestrator.md
========================================

# Orchestrator Engine

## Overview
`cobalt_agent/core/orchestrator.py`

The `OrchestratorEngine` class is the Manager's Clipboard (Chief of Staff). It coordinates the "Split-Brain" architecture between the Architect (Planner) and specialized Drones (Executors).

## Class: OrchestratorEngine

### Description
The Manager's Clipboard (Chief of Staff). Coordinates the "Split-Brain" architecture between the Architect (Planner) and specialized Drones (Executors).

### Constructor
```python
def __init__(self)
```

Initializes the LLM instance for planning and execution.

### Methods

#### plan_and_execute
```python
def plan_and_execute(self, user_input: str) -> str
```

Executes the full planning and execution cycle.

**Parameters:**
- `user_input` (str): The user's request

**Returns:** String output log containing master plan and execution results

### Architecture Phases

#### Phase 1: Architect (Planning)
The Orchestrator generates a master plan by:
1. Analyzing the user's request
2. Breaking it down into atomic steps
3. Assigning each step to the appropriate Drone (ENGINEERING or OPS)

**AVAILABLE DRONES:**
- **ENGINEERING**: Writing Python code, modifying system files, analyzing software architecture
- **OPS**: Searching knowledge base, writing Markdown journals, summarizing text, reading/modifying Obsidian notes

**AVAILABLE TOOLS:**
- `search_knowledge`: Search internal codebase, playbooks, and Obsidian notes
- `read_file`: Read file contents
- `list_directory`: Explore folder structures
- `write_file`: Create or modify files

**Rules:**
1. Keep steps atomic (e.g., Step 1: search_knowledge, Step 2: read_file, Step 3: write_file)
2. Do NOT write code in the plan, just the actions the drone needs to take
3. Assign the correct Drone to each step based on the task domain

#### Phase 2: Drone Execution
The Orchestrator executes each step:
1. Builds context from previous steps
2. Routes to the appropriate Drone (Dynamic Drone Routing)
3. Captures results for the next step's context

**Dynamic Drone Routing:**
- OPS ‚Üí `OpsDepartment`
- ENGINEERING ‚Üí `EngineeringDepartment`

### Output Format
```
## üìã Chief of Staff's Master Plan
**Thoughts:** *Chain of thought explanation*

1. **[ENGINEERING]** Action description (Tool: `tool_name`)
2. **[OPS]** Action description (Tool: `tool_name`)

### üöÄ Execution Log
**Executing Step 1 (ENGINEERING):** Action description
> Result from drone

**Executing Step 2 (OPS):** Action description
> Result from drone

‚úÖ **Mission Accomplished.**
```

### State Management
The orchestrator tracks execution state:
- `PLANNING`: Initial state
- `EXECUTING`: Actively running steps
- `COMPLETED`: All steps finished
- `PAUSED_FOR_APPROVAL`: Zero-Trust approval required
- `FAILED`: Execution halted due to error

### Error Handling
- Max retries: 3 for planning
- Self-healing retry loop for LLM JSON hallucinations
- Immediate halt on "Action paused" or "Proposal [" detection

## Key Components
- `LLM`: For structured planning responses
- `OpsDepartment`: Operations/Documentation drone
- `EngineeringDepartment`: Code generation drone
- `SubTask`: Pydantic model for planning steps

## See Also
- `BaseDepartment` - Unified ReAct execution engine
- `OpsDepartment` - Operations drone
- `EngineeringDepartment` - Engineering drone

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/persona.md
========================================

# Persona System

## Overview
`cobalt_agent/persona.py`

The `Persona` class manages the AI agent's identity, roles, skills, and behavioral directives. It generates system prompts for the LLM.

## Class: PersonaConfig (Pydantic Model)

### Description
Configuration for the agent's persona.

### Fields
- `name` (str): Agent name, default "Cobalt"
- `roles` (List[str]): List of roles the agent fulfills
- `skills` (List[str]): List of agent skills and capabilities
- `tone` (List[str]): Communication tone characteristics
- `directives` (List[str]): Core behavioral directives

## Class: Persona

### Description
Persona class that manages the AI agent's identity and generates system prompts.

### Constructor
```python
def __init__(self, config: PersonaConfig)
```

**Parameters:**
- `config` (PersonaConfig): Configuration containing persona settings

Initializes and logs the persona name.

### Methods

#### get_system_prompt
```python
def get_system_prompt() -> str
```

Generate a comprehensive system prompt combining all persona attributes.

**Returns:** Complete system instruction string for the AI agent

**Prompt Structure:**
1. Introduction with agent name
2. ROLES section
3. SKILLS section
4. COMMUNICATION STYLE section
5. CORE DIRECTIVES section
6. Mission statement

#### create_override
```python
def create_override(self, name: str, roles: List[str], directives: List[str]) -> "Persona"
```

Create a new Persona instance with temporary overrides for Split-Brain agents.

**Parameters:**
- `name` (str): The new name for the override persona
- `roles` (List[str]): List of roles for the override persona
- `directives` (List[str]): List of directives for the override persona

**Returns:** A new Persona instance with the specified overrides

**Use Case:** This strips away irrelevant global rules (like trading logic) for specialized tasks.

#### __repr__
```python
def __repr__() -> str
```

String representation of the Persona.

**Format:** `Persona(name='Cobalt', roles=X, skills=Y)`

## Key Components
- `PersonaConfig`: Pydantic model for structured configuration
- `get_system_prompt()`: Generates full instruction string
- `create_override()`: Creates specialized agent personas

## Split-Brain Architecture
The persona system supports the Split-Brain architecture by:
1. Allowing override personas that strip away global rules
2. Enabling specialized roles for different tasks
3. Maintaining consistent identity across operations

## See Also
- `OrchestratorEngine` - Coordinates Split-Brain architecture
- `BrainBase` - ReAct execution engine
- `OpsDepartment` - Documentation-focused drone

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/playbook.md
========================================

---
title: "Playbook Module Documentation"
status: Active
module: Brain
type: Orchestrator
dependencies:
  - "[[strategy]]"
  - "[[tactical]]"
  - "[[config]]"
  - "[[second_day_play]]"
location: "src/cobalt_agent/brain/playbook.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Playbook Module

## Overview

The Playbook Registry loads trading strategies and parameters from `configs/strategies.yaml` and executes strategy logic against market data.

## Class: `Playbook`

Manages active trading strategies and their parameters.

### Constructor

```python
Playbook(config_path: str = "configs/strategies.yaml")
```

Initializes the playbook with strategy configurations from a YAML file.

### Methods

#### `_load_config(path_str: str) -> Dict[str, Any]`
Loads the YAML configuration file and returns strategy parameters.

#### `_initialize_strategies()`
Hydrates strategy classes with their configurations by mapping YAML keys to Python classes.

#### `get_strategy(name: str)`
Returns the strategy instance by name.

#### `list_strategies() -> str`
Returns a formatted string list of ACTIVE (loaded) strategies with their configurations.

#### `run_all(market_data: Dict[str, Any]) -> str`
Runs ALL strategies against incoming market data and returns a summary string of scoring profiles.

### Example Output

```
üìú **Active Playbook:**
- **SecondDayPlay**: LONG (09:30-11:00)
   ‚Ä¢ Score: 75/100 (High)
   ‚Ä¢ Logic: Positive relative volume and gap up pattern
   ‚Ä¢ HUD Config: 3 dynamic rules active
```

---

## Related Files

- `strategy.py` - Abstract base class for all strategies
- `tactical.py` - Strategos agent that orchestrates playbook execution
- `strategies/` - Individual strategy implementations

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/postgres.md
========================================

---
title: "Memory Postgres Documentation"
status: Active
module: Memory
type: Class
dependencies:
  - "[[memory_base]]"
  - "[[memory_core]]"
  - "[[config]]"
location: "src/cobalt_agent/memory/postgres.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Postgres Memory Module

**Location:** `src/cobalt_agent/memory/postgres.py`

## Overview

Postgres Memory Adapter (The Hippocampus) provides persistent memory with vector embeddings for semantic search. Combines database persistence with AI-powered similarity search.

## Class: `PostgresMemory`

Implements `MemoryProvider` interface from `base.py`.

### Constructor

```python
PostgresMemory()
```

Initializes database connection and auto-creates tables. Loads credentials from:
1. Environment variables: `POSTGRES_HOST`, `POSTGRES_DB`, `POSTGRES_USER`, `POSTGRES_PASSWORD`
2. YAML config in `configs/*.yaml`

### Methods

#### `add_log(message: str, source: str = "System", data: Dict = None) -> None`
Saves a memory AND its vector embedding to Postgres.

**Parameters:**
- `message`: Memory content to store
- `source`: Origin of the memory (default: "System")
- `data`: Optional dictionary for metadata

**Workflow:**
1. Generate vector embedding using LiteLLM (`text-embedding-3-small`)
2. Insert into database with content, embedding, and metadata

#### `get_context(limit: int = 10) -> str`
Retrieve recent logs (Short Term RAM) from database.

**Parameters:**
- `limit`: Number of recent entries to retrieve

**Returns:** Formatted chat-log string (chronological order)

#### `search(query: str, limit: int = 5) -> List[Dict]`
Semantic search - finds memories similar to the query using vector cosine distance.

**Parameters:**
- `query`: Search query string
- `limit`: Maximum number of results

**Returns:** List of matching memories with similarity scores (filtering out scores < 0.3)

### Attributes

| Attribute | Description |
|--|--|
| `conn_str` | PostgreSQL connection string |
| `table_name` | Table name: "memory_logs" |
| `host`, `port`, `db`, `user`, `password` | Database connection credentials |

### Database Schema

| Column | Type | Description |
|--|--|--|
| `id` | SERIAL PRIMARY KEY | Unique identifier |
| `timestamp` | TIMESTAMP | Auto-generated |
| `source` | TEXT | Origin of the memory |
| `content` | TEXT | Memory content |
| `embedding` | vector(1536) | OpenAI embedding vector |
| `metadata` | JSONB | Additional data |

### Features

- **Hybrid Storage**: Combines persistent logging with vector search
- **Vector Search**: Uses Postgres `vector` extension for semantic similarity
- **Fallback**: Saves without vector if embedding fails
- **Context Retrieval**: Returns chronologically sorted short-term memory

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/prompt.md
========================================

---
title: "Prompt Engine Documentation"
status: Active
module: Brain
type: Class
dependencies:
  - "[[main]]"
  - "[[persona]]"
  - "[[llm]]"
location: "src/cobalt_agent/prompt.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Prompt Engine

## Overview
The Prompt Engine constructs dynamic system prompts for the LLM based on context, tools, and temporal information. It ensures the agent maintains proper behavior, memory protocol, and tool usage guidelines.

## Class: `PromptEngine`

### Constructor
```python
def __init__(self, persona_config: PersonaConfig)
```
Initializes the Prompt Engine with persona configuration.

**Parameters:**
- `persona_config`: `PersonaConfig` instance containing agent identity and directives

### Main Methods

#### `build_system_prompt(tools: List[Any] = None) -> str`
Constructs the complete system prompt by combining all components.

**Parameters:**
- `tools`: Optional list of tool objects available to the agent

**Returns:**
- `str`: Complete system prompt

**Components:**
1. Identity & Role (Header)
2. Operational Context (Time/Date)
3. Memory Protocol
4. Directives (Rules)
5. Tool Capabilities

## Prompt Components

### 1. Header (`_build_header()`)
Contains agent identity information:
- Agent name
- Roles
- Directives
- Tone

**Format:**
```
### IDENTITY
You are {name}.

### ROLES
Your roles are: {roles}.

### OPERATIONAL DIRECTIVES
{directives}

### TONE
Maintain a tone that is: {tone}.
```

### 2. Context (`_build_context()`)
Provides temporal and environmental context:
- Current date/time
- Operating system
- User identity

### 3. Memory Protocol (`_build_memory_protocol()`)
Defines rules for memory recall and stale data handling:
- **PREFERENCE** memories: Keep forever (e.g., "I like TSLA")
- **MARKET CONTEXT** memories: Expire after 24 hours
- Instructions to use memory when available

### 4. Directives (`_build_directives()`)
Core operating rules:
- Agent is autonomous (not a chat bot)
- Must use tools for real-time data
- Strict data adherence (no hallucination)
- Tool usage format (ACTION: syntax)

### 5. Tool Descriptions (`_build_tool_descriptions()`)
Lists available tools with their capabilities for the LLM.

## Tool Usage Protocol

### Action Format
The agent must use the `ACTION:` prefix when invoking tools:

```
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.
```

### Key Rules
1. **No internal knowledge**: Cannot answer without tools
2. **Start with ACTION:** When data is needed
3. **Trust tool results**: Use provided values, don't interpret
4. **Strict data adherence**: Reference exact periods from tool data (e.g., "RSI (20)", not "RSI (14)")

## Configuration Integration
The Prompt Engine uses `PersonaConfig` from the global configuration system, ensuring consistency across the agent's behavior and documentation.

## Example Output
```python
engine = PromptEngine(persona_config)
prompt = engine.build_system_prompt(tools=[search_tool, finance_tool])
print(prompt)
# Full system prompt for LLM

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/proposals.md
========================================

---
title: "Proposal Engine Documentation"
status: Active
module: Core
type: Engine
dependencies:
  - "[[mattermost]]"
  - "[[main]]"
  - "[[cortex]]"
  - "[[config]]"
location: "src/cobalt_agent/core/proposals.py"
tags: [cobalt, dev_docs, hitl, security]
created: 2026-02-23
---

# Proposal Engine (Zero Trust Architecture)

## Overview
The Proposal Engine enforces the Prime Directive by requiring human approval before executing high-stakes actions. It implements a standardized `Proposal` model for all destructive, financial, or system-altering commands, ensuring Zero Trust architecture through Human-in-the-Loop (HITL) validation.

### Zero Trust Principles
- **No Autonomous Execution**: No high-stakes action executes without explicit approval
- **Standardized Proposals**: All proposals follow a consistent format for review
- **Explicit Approval Flow**: Approval must be provided via Mattermost channel response
- **Cryptographic Token**: Task IDs provide unique, verifiable authorization tokens

## LLM Synthesis with Regex Extraction

### Overview
The Cortex module generates proposals using LLM synthesis with structured JSON extraction. When high-risk keywords are detected, the system calls an LLM to synthesize a proposal with action, justification, and risk_assessment fields.

### Regex Extraction Mechanism
```python
# Extract JSON block from LLM response
match = re.search(r'\{.*\}', raw_response, re.DOTALL)
if not match:
    raise ValueError("No JSON block found in LLM response.")
data = json.loads(match.group(0))
```

**Pattern Components:**
- `r'\{.*\}'`: Regex to match JSON object from start `{` to end `}`
- `re.DOTALL`: Allows `.` to match newlines (multi-line JSON)
- Extracts the first valid JSON block from LLM response

### LLM Prompt Format
```python
prompt = f"""
[SECURITY PROTOCOL: PRIME DIRECTIVE]
High-risk action detected: "{user_input}"

You are the Chief of Staff. You are FORBIDDEN from executing this autonomously.
Generate a JSON response explaining the risk.

OUTPUT FORMAT:
{{
  "action": "Summary of what was requested",
  "justification": "Why the user wants this",
  "risk_assessment": "Blunt warning about data loss or system instability"
}}

OUTPUT ONLY JSON. NO EXTRA TEXT.
"""
```

### JSON Output Schema
| Field | Type | Description |
|-------|------|-------------|
| `action` | `str` | Summary of the requested operation |
| `justification` | `str` | User's reasoning for the action |
| `risk_assessment` | `str` | Potential impacts or negative consequences |

### Error Handling
- **No JSON block found**: Returns security intercept message
- **Invalid JSON**: Logs error and returns rejection message
- **Missing fields**: Uses defaults for missing fields

### Example Flow
```
1. User input: "Delete the old log files"
   ‚Üì
2. Cortex.route() detects high-risk keyword "delete"
   ‚Üì
3. Calls _generate_proposal() with user input
   ‚Üì
4. LLM generates JSON response:
   {
     "action": "Delete old log files",
     "justification": "User wants to clean up logs",
     "risk_assessment": "Could affect audit trail if logs are needed later"
   }
   ‚Üì
5. Regex extracts JSON block using r'\{.*\}'
   ‚Üì
6. Instantiate Proposal with extracted fields
   ‚Üì
7. Return formatted proposal for Mattermost display
```

## Class: `Proposal`

### Constructor
```python
def __init__(
    task_id: str = Field(default_factory=lambda: str(uuid.uuid4())[:8])
    action: str = Field(description="The specific command or operation to be executed.")
    justification: str = Field(description="The agent's reasoning for why this action is necessary.")
    risk_assessment: str = Field(description="A summary of potential negative impacts.")
    parameters: Dict[str, Any] = Field(default_factory=dict)
    timestamp: datetime = Field(default_factory=datetime.now)
    approved: bool = False
    approval_channel: Optional[str] = None
    approval_message_id: Optional[str] = None
)
```

### Key Attributes

| Field | Type | Description |
|-------|------|-------------|
| `task_id` | `str` | Unique 8-character identifier for approval matching |
| `action` | `str` | The raw command to be executed |
| `justification` | `str` | Agent's reasoning for the action |
| `risk_assessment` | `str` | Summary of potential negative impacts |
| `parameters` | `Dict[str, Any]` | Technical metadata for execution |
| `timestamp` | `datetime` | When proposal was created |
| `approved` | `bool` | Whether this proposal has been approved |
| `approval_channel` | `Optional[str]` | Mattermost channel for approval |
| `approval_message_id` | `Optional[str]` | Mattermost post ID for tracking |

### Methods

#### `format_for_mattermost() -> str`
Formats the proposal for display in Mattermost approval channel.

**Output Format:**
```markdown
### üõ°Ô∏è ACTION PROPOSAL [task_id]
**Action:** `command`
**Justification:** agent reasoning
**Risk:** potential impacts

---
‚ö†Ô∏è *This action is paused per the Prime Directive. Reply with 'Approve [task_id]' to proceed.*
```

## Class: `ProposalEngine`

### Constructor
```python
def __init__(self)
```
Initializes the Proposal Engine with configuration from `config.yaml`.

**Key Initialization Steps:**
1. Loads approval channel and team from config
2. Initializes empty proposal dictionaries
3. Logs connection details

### Key Attributes

| Attribute | Type | Description |
|-----------|------|-------------|
| `config` | `CobaltSettings` | Global configuration |
| `approval_channel` | `str` | Mattermost channel for approval messages |
| `approval_team` | `str` | Team containing approval channel |
| `mattermost` | `Optional[MattermostInterface]` | Mattermost connection instance |
| `approved_proposals` | `Dict[str, Proposal]` | Successfully approved proposals |
| `pending_proposals` | `Dict[str, Proposal]` | Waiting for approval |
| `callbacks` | `Dict[str, Callable[[Proposal], None]]` | **Memory-locked execution callbacks** - frozen Python callbacks mapped to task IDs |
| `_approval_callback` | `Optional[Callable]` | Callback for approved proposals |
| `_monitoring` | `bool` | Whether background monitoring is active |

### Main Methods

#### `connect_mattermost() -> bool`
Establishes connection to Mattermost for approval workflow.

**Returns:**
- `True` if connection and authentication succeeded
- `False` otherwise

**Behavior:**
- Creates `MattermostInterface` instance
- Attempts to connect and authenticate
- Attaches brain for message routing
- Logs connection status

#### `create_proposal(
    action: str,
    justification: str,
    risk_assessment: str,
    parameters: Optional[Dict] = None
) -> Proposal`
Creates a new proposal for a high-stakes action.

**Parameters:**
- `action`: The specific command to execute
- `justification`: Agent's reasoning for necessity
- `risk_assessment`: Summary of potential negative impacts
- `parameters`: Technical metadata for execution

**Returns:**
- Created `Proposal` object
- Added to `pending_proposals` dictionary

**Behavior:**
- Generates unique 8-character task_id
- Creates and stores proposal in pending queue
- Logs proposal creation

#### `send_proposal(proposal: Proposal) -> bool`
Sends a proposal to Mattermost for human review.

**Parameters:**
- `proposal`: The `Proposal` object to send

**Returns:**
- `True` if proposal was sent successfully
- `False` otherwise

**Behavior:**
1. Validates Mattermost connection
2. Retrieves team ID by name
3. Retrieves channel ID using team_id
4. Creates Mattermost post with formatted proposal
5. Stores approval_message_id in proposal
6. Logs success/failure

**Error Cases:**
- No Mattermost connection
- Approval channel not configured
- Team or channel not found

#### `handle_approval_response(message: str, channel_id: str) -> Optional[Proposal]`
Checks if a message is an approval response for a pending proposal.

**Parameters:**
- `message`: The message text from Mattermost
- `channel_id`: The channel ID where the message was posted

**Returns:**
- `Proposal` if this is a valid approval response
- `None` if not an approval or task_id not found

**Approval Pattern:**
- Regex: `approve\s+(\w{8})` (case-insensitive)
- Must match 8-character task_id
- Must be in approval channel

**Behavior:**
1. Extracts task_id from message using regex
2. Validates channel is approval channel
3. Looks up pending proposal by task_id
4. Moves proposal from pending to approved
5. Sets `approved = True`

#### `wait_for_approval(proposal: Proposal, timeout: int = 3600) -> bool`
Waits for a proposal to be approved (polling mode).

**Parameters:**
- `proposal`: The `Proposal` to wait for
- `timeout`: Maximum wait time in seconds (default: 1 hour)

**Returns:**
- `True` if approved within timeout
- `False` if timeout reached

**Behavior:**
- Polls every 5 seconds
- Checks `approved_proposals` dictionary
- Removes from pending on timeout

#### `execute_approved(proposal: Proposal) -> bool`
Executes an approved proposal's action.

**Parameters:**
- `proposal`: The approved `Proposal` to execute

**Returns:**
- `True` if execution succeeded
- `False` otherwise

**Behavior:**
1. Validates proposal is approved
2. Logs execution start
3. Calls approval callback if set
4. Handles execution errors

#### `set_approval_callback(callback: Callable[[Proposal], None]) -> None`
Sets a callback function for approved proposals.

**Parameters:**
- `callback`: Function that takes a `Proposal` and returns `None`

**Usage:**
```python
def on_approval(proposal: Proposal):
    engine.execute_approved(proposal)

engine.set_approval_callback(on_approval)
```

#### `start_monitoring() -> None`
Starts background monitoring for approval responses.

**Behavior:**
- Creates daemon thread for monitoring
- Calls `_monitor_approval_channel()`

#### `_monitor_approval_channel() -> None`
Background thread to monitor approval channel for responses.

**Implementation Note:**
- WebSocket listener is attached to `MattermostInterface`
- This method serves as monitoring entry point

#### `stop_monitoring() -> None`
Stops background monitoring for approval responses.

**Behavior:**
- Sets monitoring flag to False
- Waits for thread to join
- Logs monitoring stop

## Memory-Locked Callbacks (Zero Trust Execution)

### Overview
The `ProposalEngine` class stores **frozen Python execution callbacks** in a shared class dictionary. This implements a "coat-check" system where the LLM proposes an action, receives approval, and then the callback is executed.

### Callback Storage
```python
class ProposalEngine:
    # Shared state across all instances
    pending_proposals: Dict[str, Proposal] = {}
    callbacks: Dict[str, Callable[[Proposal], None]] = {}
```

**Security Characteristics:**
- **No disk persistence**: Callbacks exist only in memory
- **8-character task_id**: Cryptographic token for approval matching
- **Class-level storage**: Shared across all `ProposalEngine` instances
- **Automatic cleanup**: Callbacks removed after execution or timeout

### Callback Lifecycle
```
1. LLM proposes file write via WriteFileTool
   ‚Üì
2. ProposalEngine.create_proposal() generates task_id
   ‚Üì
3. WriteFileTool creates execute_write() closure
   ‚Üì
4. ProposalEngine.set_approval_callback(task_id, execute_write)
   ‚Üì
5. Proposal sent to Mattermost approval channel
   ‚Üì
6. User responds with "Approve [task_id]"
   ‚Üì
7. MattermostInterface intercepts approval response
   ‚Üì
8. ProposalEngine.handle_approval_response() executes callback
   ‚Üì
9. File modification executes in RAM callback
   ‚Üì
10. Callback removed from callbacks dictionary
```

### `set_approval_callback(task_id: str, callback: Callable[[Proposal], None]) -> None`
Sets a callback function to be called when a proposal is approved.

**Parameters:**
- `task_id`: The unique 8-character identifier for the task
- `callback`: Function that takes a `Proposal` and returns `None`

**Usage:**
```python
def execute_write(proposal_obj):
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)

engine = ProposalEngine()
engine.set_approval_callback(proposal.task_id, execute_write)
```

**Execution Flow:**
1. Callback stored in `ProposalEngine.callbacks[task_id]`
2. Mattermost approval received via WebSocket interceptor
3. `handle_approval_response()` extracts task_id from message
4. Callback retrieved and executed with proposal object
5. Callback removed from dictionary after execution

### Error Handling

**Callback Execution Failures:**
- **Exception during execution**: Error logged, user notified via Mattermost
- **Callback not found**: Warning logged, user notified of missing callback
- **Duplicate approval**: Ignored (already approved or already executed)

## Convenience Functions

### `create_and_send_proposal(...) -> Optional[Proposal]`
Convenience function to create and send a proposal in one call.

**Parameters:**
- `action`: The specific command to execute
- `justification`: Agent's reasoning
- `risk_assessment`: Potential negative impacts
- `parameters`: Technical metadata

**Returns:**
- `Proposal` if successful
- `None` if connection or send fails

**Behavior:**
1. Creates new `ProposalEngine` instance
2. Connects to Mattermost
3. Creates the proposal
4. Sends to Mattermost

## Zero Trust Workflow

### Standard Approval Flow
```
1. Agent identifies high-stakes action
   ‚Üì
2. Creates Proposal with task_id, action, justification, risk
   ‚Üì
3. Sends to Mattermost approval channel
   ‚Üì
4. User sees proposal and responds with "Approve [task_id]"
   ‚Üì
5. MattermostInterface detects approval response
   ‚Üì
6. ProposalEngine validates and moves to approved list
   ‚Üì
7. Callback executes the approved action
   ‚Üì
8. Action completes
```

### High-Risk Intercept (Cortex Integration)
The Cortex module intercepts classified tasks and routes them through the Proposal Engine before any department execution:

```
Cortex.route() ‚Üí Classifies Task
                ‚Üì
        Is it high-risk?
                ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Yes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚Üì              ‚Üì
    No              ProposalEngine.create_proposal()
        ‚Üì              ‚Üì
    Route to      ProposalEngine.send_proposal()
    Department    ‚Üì
        ‚Üì              ‚Üì
    Execute    Wait for Approval
                            ‚Üì
                    ProposalEngine.execute_approved()
                            ‚Üì
                        Execute Action
```

## Configuration

### Mattermost Settings
```yaml
mattermost:
  url: "https://mattermost.example.com"
  token: "${MATTERMOST_TOKEN}"
  approval_channel: "approvals"  # Channel for proposals
  approval_team: "cobalt-team"   # Team containing approval channel
```

### Human Intervention Triggers
The following actions require proposal approval:
- File system modifications
- Financial transactions
- System command execution
- Configuration changes
- Any destructive operation

## Security Considerations

1. **Task ID Format**: 8-character UUID prefix balances uniqueness with manual entry feasibility
2. **Channel Validation**: Approval must occur in designated channel only
3. **Regex Matching**: Case-insensitive pattern matching for user convenience
4. **No Auto-Approval**: All high-stakes actions require explicit human approval
5. **Logging**: All proposal lifecycle events are logged for audit trail

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/reset_memory_table.md
========================================

---
title: "Reset Memory Table Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[postgres]]"
location: "dev_utils/reset_memory_table.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Reset Memory Table Script

**Location:** `dev_utils/reset_memory_table.py`

## Overview

Reset Memory Table drops the `memory_logs` table from the PostgreSQL database. Use this when the schema is incorrect and needs to be recreated from scratch.

## Usage

```bash
python dev_utils/reset_memory_table.py
```

Or with uv:

```bash
uv run python dev_utils/reset_memory_table.py
```

## ‚ö†Ô∏è Destructive Warning

üö® **THIS SCRIPT DELETES THE ENTIRE memory_logs TABLE** - All data in the table will be permanently lost. This action cannot be undone.

**Before running:**
1. Ensure you have a database backup
2. Verify the table name (`memory_logs`)
3. Confirm this is the correct table to reset

## Behavior

The script performs the following actions:

1. Connects to PostgreSQL using credentials from `.env` or environment variables
2. Drops the `memory_logs` table if it exists
3. Prints confirmation of successful deletion

## Environment Variables

| Variable | Default | Description |
|--|--|--|
| `POSTGRES_HOST` | `localhost` | Database host |
| `POSTGRES_DB` | `cobalt_memory` | Database name |
| `POSTGRES_USER` | `postgres` | Database user |
| `POSTGRES_PASSWORD` | `cobalt_password` | Database password |

## Typical Use Case

This script is used when:
- The database schema has been incorrectly initialized
- A schema migration has failed
- You need to start fresh with a new schema

**After running:**
1. Run the schema creation script to rebuild the table
2. Re-run any necessary data seeding scripts

## Dependencies

- `psycopg` - PostgreSQL client library
- `python-dotenv` - Environment variable loading

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/scheduler.md
========================================

# Scheduler Service

## Overview
`cobalt_agent/services/scheduler.py`

The `SchedulerService` class is the Cron-Based Automation Engine. It manages scheduled tasks like daily Morning Briefings and automated vault maintenance.

## Class: SchedulerService

### Description
Cron-Based Automation Engine. Manages scheduled tasks like daily Morning Briefings and automated vault maintenance.

### Constructor
```python
def __init__(self)
```

Initializes the scheduler and loads configured cron jobs from the configuration file.

### Methods

#### start
```python
def start()
```

Start the scheduler in a background thread. Loads cron jobs from `configs/config.yaml`.

#### stop
```python
def stop()
```

Gracefully stop the scheduler and cancel all pending jobs.

#### add_cron_job
```python
def add_cron_job(self, job_name: str, schedule: str, func: callable, *args, **kwargs)
```

Add a new cron job to the scheduler.

**Parameters:**
- `job_name` (str): Unique identifier for the job
- `schedule` (str): Cron expression (e.g., "0 9 * * *" for 9 AM daily)
- `func` (callable): Function to execute when scheduled
- `*args`: Positional arguments for the function
- `**kwargs`: Keyword arguments for the function

#### add_interval_job
```python
def add_interval_job(self, job_name: str, seconds: int, func: callable, *args, **kwargs)
```

Add a job that runs at interval intervals.

**Parameters:**
- `job_name` (str): Unique identifier for the job
- `seconds` (int): Interval in seconds
- `func` (callable): Function to execute
- `*args`: Positional arguments for the function
- `**kwargs`: Keyword arguments for the function

### Built-in Jobs

#### Morning Briefing Generation
- **Schedule:** Daily at 9:00 AM
- **Function:** `MorningBriefing().run()`
- **Output:** Markdown report saved to Obsidian vault in `0 - Inbox` folder
- **Content:** Market data, news headlines, strategic thoughts

#### Vault Management
- **Schedule:** Daily at midnight
- **Function:** AES-256 encrypted backup of Vault contents
- **Purpose:** Ensure local vault integrity and backup

#### Daily Log Cleanup
- **Schedule:** Weekly on Sunday at 11:59 PM
- **Function:** Archive and compress old daily logs
- **Purpose:** Maintain vault performance

### Configuration
Jobs are defined in `configs/config.yaml` under the `scheduler` section:
```yaml
scheduler:
  jobs:
    - name: "Morning Briefing"
      type: "cron"
      schedule: "0 9 * * *"
      task: "briefing"
    - name: "Vault Backup"
      type: "interval"
      seconds: 86400
      task: "vault_backup"
```

### Thread Management
- Scheduler runs in a background daemon thread
- Graceful shutdown ensures all jobs complete before stopping
- Thread-safe job queue for concurrent job handling

## Key Components
- `APScheduler`: Scheduler engine
- `MorningBriefing`: Briefing generation skill
- `Scribe`: Obsidian integration
- `Config`: Configuration management

## See Also
- `MorningBriefing` - Daily briefing generation skill
- `Scribe` - Obsidian integration skill

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/scribe.md
========================================

# Scribe Skill (Obsidian Integration)

## Overview
`cobalt_agent/skills/productivity/scribe.py`

The `Scribe` class is the Obsidian Vault Interface. It allows the agent to read, write, and search documents in the "Second Brain" vault.

## Class: Scribe

### Description
Interface for interacting with an Obsidian Vault. Allows reading, writing, and searching documents.

### Constructor
```python
def __init__(self, vault_path: Optional[str] = None)
```

**Parameters:**
- `vault_path` (Optional[str]): Path to Obsidian vault. Defaults to `OBSIDIAN_VAULT_PATH` env var.

**Fallback:** If environment variable not set, defaults to `~/Documents/Think`

### File Paths
All file paths are relative to the vault root. Examples:
- `0 - Inbox/note.md`
- `Projects/Task-001.md`
- `Archive/2026/January.md`

### Methods

#### write_note
```python
def write_note(self, filename: str, content: str, folder: str = "0 - Inbox") -> str
```

Create or overwrite a note in the vault.

**Parameters:**
- `filename` (str): Note filename (auto-adds `.md` if missing)
- `content` (str): Markdown content to write
- `folder` (str): Target folder within vault (default: "0 - Inbox")

**Returns:** Success message with path

**STRICT RULE:** All automated writes go to `0 - Inbox` unless explicitly overridden.

#### read_note
```python
def read_note(self, filename: str) -> str
```

Read the content of a specific note.

**Parameters:**
- `filename` (str): Note filename to read

**Returns:** File contents or error message

**Search Behavior:** Recursively searches vault if file not found in root.

#### append_to_daily_note
```python
def append_to_daily_note(self, content: str) -> str
````

Append text to today's Daily Log.

**Parameters:**
- `content` (str): Text to append

**Returns:** Path to the daily log file

**Behavior:**
- Creates file if it doesn't exist
- Adds timestamp header before content
- Uses folder: `0 - Inbox`

#### search_vault
```python
def search_vault(self, query: str, limit: int = 5) -> List[str]
```

Search for notes containing a keyword.

**Parameters:**
- `query` (str): Search term
- `limit` (int): Maximum results (default: 5)

**Returns:** List of matching filenames

**Behavior:**
- Case-insensitive substring search
- Ignores hidden files/folders (starting with `.`)
- Returns first `limit` matches

## File Path Resolution

### _resolve_path
```python
def _resolve_path(self, filename: str) -> Path
```

Helper method to ensure files have `.md` extension and are inside the vault.

## Error Handling
- Returns error strings (prefixed with `‚ùå`) for failures
- Logs warnings to `loguru` logger
- Gracefully handles missing vault directory

## Integration Points
- Used by `MorningBriefing` for report delivery
- Used by `DeepResearch` for final report storage
- Used by `OpsDepartment` for file modifications

## See Also
- `MorningBriefing` - Briefing generation skill
- `DeepResearch` - Research report generation
- `OpsDepartment` - Documentation-focused drone

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/search.md
========================================

---
title: "Search Tool Documentation"
status: Active
module: Tool
type: Class
dependencies:
  - "[[tool_manager]]"
location: "src/cobalt_agent/tools/search.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Search Tool Module

**Location:** `src/cobalt_agent/tools/search.py`

## Overview

Search Tool provides internet search functionality using the `ddgs` package. Returns strict Pydantic models instead of raw dictionaries.

## Class: `SearchResult` (Pydantic Model)

A single search result item.

### Fields

| Field | Type | Description |
|-------|------|---------|
| `title` | `str` | The title of the search result |
| `href` | `str` | The URL link to the result |
| `body` | `str` | The snippet or summary text |

---

## Class: `SearchTool`

Executes internet searches and returns structured results.

### Attributes

| Attribute | Value |
|--|--|
| `name` | `"search"` |
| `description` | `"Search the internet for news, information, and general knowledge. Use for questions about current events, topics, or general queries."` |

### Methods

#### `run(query: str, max_results: int = 5) -> List[SearchResult]`

Executes a search and returns a list of typed SearchResult objects.

**Parameters:**
- `query`: Search query string
- `max_results`: Maximum number of results to return (default: 5)

**Returns:** List of SearchResult objects

**Workflow:**
1. Execute search using DDGS context manager
2. Convert raw results to Pydantic models
3. Handle malformed results gracefully
4. Return empty list on failure

### Usage Example

```python
tool = SearchTool()
results = tool.run(" Cobalt AI agent", max_results=3)
for result in results:
    print(f"{result.title}: {result.href}")

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/second_day_play.md
========================================

---
title: "Second Day Play Strategy Documentation"
status: Active
module: Strategy
type: Class
dependencies:
  - "[[playbook]]"
  - "[[strategy]]"
  - "[[config]]"
location: "src/cobalt_agent/brain/strategies/second_day_play.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Second Day Play Strategy

**Location:** `src/cobalt_agent/brain/strategies/second_day_play.py`

## Overview

Second Day Play is a day trading strategy that identifies high-probability setups based on the second day of a breakout pattern. It dynamically loads scoring rules and thresholds from `strategies.yaml`.

## Class: `SecondDayPlay`

Analyzes market data and returns a Scoring Profile (JSON) for potential trades.

### Constructor

```python
SecondDayPlay(config: dict = None)
```

**Parameters:**
- `config`: Configuration dictionary containing `parameters`, `scoring`, and strategy metadata.

### Attributes

- `params`: Dictionary of trading parameters (RVOL thresholds, price zones)
- `scoring`: Dictionary of scoring modifiers and points
- `name`: Strategy name
- `version`: Strategy version (1.1)

---

## Scoring Engine

The strategy calculates a dynamic score based on:

### RVOL Modifiers
- **High RVOL Threshold** (default: 3.0): Adds points for exceptional volume
- **Base RVOL Points** (default: 10): Points for meeting minimum volume requirement
- **Live RVOL Multiplier** (default: 5.0): Applied during market hours
- **Base Score** (default: 50): Starting point before modifiers

### Gap Modifiers
- **Gap Up Points** (default: 10): Applied when price gaps up at open

### abort_conditions
List of price/volume conditions that trigger immediate exit:
- Price drops below stop loss
- Volume run rate falls below 50% of expected

---

## Output Structure

```python
{
    "timestamp": "2026-02-22T16:30:00",
    "ticker": "NVDA",
    "strategy": "SecondDayPlay",
    "status": "ACTIVE_WATCH",  # or "REJECTED"
    "direction": "LONG",
    "zones": {
        "entry": 165.50,
        "stop": 162.30,
        "target": 171.10,
        "risk_per_share": 3.20
    },
    "scoring_engine": {
        "base_score": 75,
        "modifiers": {
            "live_rvol_multiplier": 5.0,
            "spy_correlation_weight": 10.0,
            "resistance_penalty": -20.0,
            "time_decay_per_min": -0.5
        }
    },
    "abort_conditions": ["price < 162.30", "volume_run_rate < 50%"]
}

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/strategy.md
========================================

---
title: "Strategy Interface Documentation"
status: Active
module: Strategy
type: Class
dependencies:
  - "[[playbook]]"
  - "[[second_day_play]]"
location: "src/cobalt_agent/brain/strategy.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Strategy Module

## Overview

The Strategy Interface defines the contract that all trading strategies must implement. This enforces a standard structure for the Backtester and Live Engine.

## Class: `Strategy` (ABC)

Abstract Base Class for all Cobalt Strategies.

### Constructor

```python
Strategy(config: Dict[str, Any])
```

Initializes a strategy with specific parameters from `strategies.yaml`.

**Parameters:**
- `config`: Dictionary containing strategy parameters including `name`, `time_window`, and other configuration data.

### Methods

#### `analyze(market_data: Any) -> Dict[str, Any]`
**Abstract Method** - Core logic that must be implemented by all strategies.

**Parameters:**
- `market_data`: A clean object containing Price, Volume, VWAP, etc.

**Returns:**
Dictionary containing:
- `signal`: 'BUY', 'SELL', or 'WAIT'
- `confidence`: 0.0 to 1.0 (The 'T-Shirt Size')
- `stop_loss`: Price level
- `target`: Price level
- `reason`: Text explanation

#### `check_time_window(current_time_str: str = None) -> bool`
Helper method that checks if trading is allowed within the configured time window.

**Parameters:**
- `current_time_str`: Optional time string in HH:MM format (defaults to current time).

**Returns:**
`True` if within the configured time window, `False` otherwise.

---

## Strategy Structure

All strategies must implement the `analyze()` method and return a consistent structure:

```python
{
    "signal": "BUY|SELL|WAIT",
    "confidence": 0.75,
    "stop_loss": 145.50,
    "target": 160.00,
    "reason": "Positive momentum and volume surge detected"
}
```

---

## Related Files

- `playbook.py` - Orchestrates strategy execution
- `tactical.py` - Strategos agent that uses strategies
- `strategies/second_day_play.py` - Example strategy implementation

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/tactical.md
========================================

---
title: "Tactical Module Documentation"
status: Active
module: Brain
type: Class
dependencies:
  - "[[tactical]]"
  - "[[playbook]]"
  - "[[finance]]"
location: "src/cobalt_agent/brain/tactical.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Tactical Module

## Overview

The Strategos Agent (Tactical Department Head) is responsible for:
1. Market Data Retrieval (FinanceTool)
2. Strategy Execution (Playbook)

## Class: `Strategos`

The Quantitative Trading Engine. Routes raw data requests or executes full strategy scans.

### Constructor

```python
Strategos()
```

Initializes Strategos with:
- `finance`: FinanceTool instance for market data retrieval
- `playbook`: Playbook instance for strategy execution

Logs the number of loaded strategies on initialization.

### Methods

#### `run(task: str) -> str`
Main entry point for the Tactical Department.

**Parameters:**
- `task`: The ticker symbol (e.g., 'NVDA') or a specific command.

**Returns:**
A combined intelligence report containing market data and strategy scan results.

**Workflow:**
1. Cleans input (extracts ticker symbol)
2. Retrieves raw market data via FinanceTool
3. Converts data to dictionary format
4. Runs all active strategies via Playbook
5. Returns combined intelligence

**Special Commands:**
- `"STRATEGY"` or `"PLAYBOOK"`: Returns list of active strategies instead of analysis

### Example Output

```
FinanceData(ticker='NVDA', price=165.50, volume=50000000)
[‚öîÔ∏è Strategy Scan]
**second_day_play** [ACTIVE_WATCH]
   ‚Ä¢ Score: 75/100 (High)
   ‚Ä¢ Logic: Positive relative volume and gap up pattern
   ‚Ä¢ HUD Config: 3 dynamic rules active

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/test_script.md
========================================

# Test Script

## Overview
`cobalt_agent/tools/test_script.py`

A simple test script used for validating tool execution in the Cobalt agent.

## File Contents
```python
print("Hello from the Forge")
```

## Purpose
This minimal script serves as a basic smoke test to:
1. Verify tool execution pipeline is functional
2. Confirm file write operations work correctly
3. Validate the `write_file` tool integration

## Usage
When invoked via the `write_file` tool in the agent:
1. Creates or overwrites a file with this content
2. Outputs "Hello from the Forge" to standard output

## See Also
- `ToolManager` - Tool execution coordination
- `BrainBase` - ReAct loop execution

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/tool_manager.md
========================================

---
title: "Tool Manager Documentation"
status: Active
module: Core
type: Orchestrator
dependencies:
  - "[[search]]"
  - "[[browser]]"
  - "[[finance]]"
location: "src/cobalt_agent/tools/tool_manager.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Tool Manager Module

## Overview

Cobalt Agent - Tool Manager is a registry and execution engine for all agent capabilities.

## Class: `ToolResult` (Pydantic Model)

Standardized output for any tool execution.

### Fields

| Field | Type | Description |
|-------|------|-------------|
| `success` | `bool` | Whether the tool execution succeeded |
| `output` | `Any` | The result output from the tool |
| `error` | `Optional[str]` | Error message if execution failed |

---

## Class: `ToolManager`

Manages the registration and execution of tools. Allows the LLM to 'see' and 'use' functions.

### Constructor

```python
ToolManager()
```

Initializes the tool manager and registers core tools:
1. SearchTool
2. BrowserTool
3. FinanceTool

### Methods

#### `register_tool(name: str, tool_instance: Any) -> None`
Add a new tool to the registry.

**Parameters:**
- `name`: Unique identifier for the tool
- `tool_instance`: Instance of the tool (must have a `run()` method)

#### `get_tool_descriptions() -> List[Any]`
Return the list of tool objects for the Prompt Engine.

#### `execute_tool(tool_name: str, args: Dict[str, Any]) -> ToolResult`
Execute a registered tool by name.

**Parameters:**
- `tool_name`: The name of the tool (e.g., 'search')
- `args`: Dictionary of arguments for the tool

**Returns:** `ToolResult` with success status, output, and optional error message.

### Tool Execution Logic

1. Extract query from args (supports 'query', 'q', or first value)
2. Check if tool exists
3. Call tool's `run()` method
4. Return standardized result

---

## Tool Registry

| Name | Class | Description |
|------|-------|-------------|
| `search` | SearchTool | Internet search for information |
| `browser` | BrowserTool | Web page content retrieval |
| `finance` | FinanceTool | Market data retrieval |

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/update_board.md
========================================

---
title: "Update Board Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[scribe]]"
location: "dev_utils/update_board.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Update Board Script

**Location:** `dev_utils/update_board.py`

## Overview

Update Board populates the Obsidian Project Board with Phase 4 & 5 tasks. It creates markdown files with proper frontmatter for use with Dataview plugins or Kanban views.

## Usage

```bash
python dev_utils/update_board.py
```

Or with uv:

```bash
uv run python dev_utils/update_board.py
```

## ‚ö†Ô∏è Destructive Warning

‚ö†Ô∏è **This script creates new files** - it does not modify existing ones. However, if run multiple times, it may create duplicate task files. Check the `0 - Inbox` folder before running.

## Behavior

The script performs the following actions:

1. **Imports** the Scribe class from `cobalt_agent.skills.productivity.scribe`
2. **Calls** `create_task()` for each Phase 4 & 5 task
3. **Saves** each task to the `0 - Inbox` folder in your Obsidian vault

## Output Files

| ID | Title | Priority | Module | Complexity |
|--|--|--|--|--|
| 23 | Strategos Agent Setup | P0 | Tactical | M |
| 24 | Playbook Registry | P1 | Tactical | S |
| 25 | Strategy Interface | P1 | Tactical | M |
| 26 | Second Day Play Impl | P1 | Tactical | L |
| 27 | Backtest Engine | P2 | Tactical | XL |
| 28 | Ops Medical Stub | P2 | Ops | S |
| 29 | Privacy Guardrails | P0 | Ops | M |

## Task File Format

Each task file contains:
- Status: `To Do`
- Priority: `P0` (Critical) through `P2` (Normal)
- Module: `Tactical` or `Ops`
- Complexity: `S`, `M`, `L`, or `XL`
- Acceptance criteria: Code implemented and verified

## Dependencies

- `cobalt_agent.skills.productivity.scribe` - Obsidian integration
- `sys`, `os` - Path handling

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/vault.md
========================================

---
title: "Vault Manager Documentation"
status: Active
module: Security
type: Class
dependencies:
  - "[[config]]"
  - "[[mattermost]]"
location: "src/cobalt_agent/security/vault.py"
tags: [cobalt, dev_docs, security]
created: 2026-02-24
---

# Vault Manager (Zero Trust Secrets Manager)

## Overview
The Vault Manager is a Just-In-Time (JIT) secrets manager that provides secure storage and retrieval of API keys, tokens, and credentials. It uses AES-256 encryption with **RAM-only decryption** - secrets exist only in memory during active use and are never exposed in plaintext on disk.

### Core Features
- **AES-256 Fernet encryption** for secure at-rest storage
- **RAM-only decryption** - secrets exist only in memory when vault is unlocked
- **Automatic injection** - secrets are injected into `os.environ` and config schema at runtime
- **Flat strings and JSON support** - handles both simple keys and grouped credentials
- **Manual key rotation** via `COBALT_MASTER_KEY` environment variable

---

## Class: `VaultManager`

### Constructor
```python
def __init__(self, vault_path: str = "data/.cobalt_vault")
```
Initializes the vault manager with the specified vault file path.

**Parameters:**
- `vault_path`: Path to the encrypted vault file (default: `"data/.cobalt_vault"`)

### Key Attributes
- `vault_path`: Path to the encrypted vault file on disk
- `_secrets`: Dictionary storing decrypted secrets in RAM (only populated when unlocked)
- `_is_unlocked`: Boolean indicating whether the vault is currently decrypted

### Main Methods

#### `generate_master_key() -> str`
Generates a new AES-256 Fernet key. Run this once to create your master key.

**Returns:**
- `str`: A new Fernet key for encrypting/decrypting the vault

**Usage:**
```bash
export COBALT_MASTER_KEY="your-generated-key-here"
```

#### `unlock(master_key: str) -> bool`
Decrypts the vault file into RAM. This is the only way to access secrets.

**Parameters:**
- `master_key`: The AES-256 Fernet key to decrypt the vault

**Returns:**
- `True` if decryption succeeded
- `False` if the key was invalid or data was corrupt

**Behavior:**
- Loads the encrypted vault file from disk
- Decrypts the contents using Fernet
- Stores decrypted JSON in `_secrets` dictionary
- Sets `_is_unlocked = True`
- Logs success or failure

#### `lock() -> None`
Wipes secrets from RAM and locks the vault.

**Behavior:**
- Clears the `_secrets` dictionary
- Sets `_is_unlocked = False`
- Logs the lock event

#### `get_secret(key_name: str) -> Optional[str]`
Retrieves a secret from the unlocked vault.

**Parameters:**
- `key_name`: The name of the secret to retrieve

**Returns:**
- The secret value if found and vault is unlocked
- `None` if vault is locked or key not found

#### `set_secret(master_key: str, key_name: str, secret_value: str) -> bool`
Adds or updates a secret in the vault.

**Parameters:**
- `master_key`: The encryption key (must have vault unlocked first)
- `key_name`: The name of the secret (e.g., `OPENAI_API_KEY`)
- `secret_value`: The secret value to store

**Returns:**
- `True` if the secret was saved successfully
- `False` if vault is locked or save failed

**Behavior:**
- Stores the secret in RAM
- Encrypts and saves the entire vault to disk

#### `list_secrets() -> List[str]`
Lists all secret keys currently in the vault.

**Returns:**
- List of secret names if vault is unlocked
- Empty list if vault is locked

#### `delete_secret(master_key: str, key_name: str) -> bool`
Removes a secret from the vault and updates the vault file.

**Parameters:**
- `master_key`: The encryption key
- `key_name`: The name of the secret to delete

**Returns:**
- `True` if the secret was deleted
- `False` if vault is locked or key not found

---

## CLI Utility: `manage_vault.py`

### Overview
The `manage_vault.py` script provides an interactive command-line interface for managing the vault. It requires the `COBALT_MASTER_KEY` environment variable to be set.

### Location
```
dev_utils/manage_vault.py
```

### Requirements
- **Mandatory**: `COBALT_MASTER_KEY` environment variable must be set
- **Optional**: If not set, the script will offer to generate a new key

### Usage
```bash
# Set the master key first (REQUIRED)
export COBALT_MASTER_KEY="your-fernet-key-here"

# Run the management script
python dev_utils/manage_vault.py
```

### Interactive Menu
When run, the script presents the following options:

1. **List All Secret Names** - Shows all keys currently stored in the vault
2. **Retrieve a Secret** - Displays the value of a specified secret
3. **Add/Update a Secret** - Store a new secret (supports flat strings or JSON)
4. **Delete a Secret** - Remove a secret from the vault
5. **Exit and Lock Vault** - Save changes and lock the vault

### Secret Value Formats

The CLI supports both flat strings and JSON strings for different use cases:

| Format | Example | Use Case |
|--------|---------|----------|
| Flat String | `sk-proj-abc123...` | Simple API keys (OPENAI_API_KEY, GEMINI_API_KEY) |
| JSON String | `{"url":"...", "user":"...", "pass":"..."}` | Grouped credentials (MATTERMOST_CREDS) |

### Error Handling
- **No Master Key**: Script generates a new key and prompts user to save it
- **Invalid Key**: Error message displayed, script exits
- **Corrupt Vault**: Warning logged, empty vault created

---

## Configuration Integration

### Loading Priority (Highest to Lowest)
1. **Environment Variables** - Strictly for node/Docker specific data (POSTGRES_HOST, etc.)
2. **Secure Vault** - API keys and tokens injected dynamically at runtime
3. **YAML Configuration Files** - Static configuration (trading_rules, persona, etc.)

### How Secrets Are Injected

When `COBALT_MASTER_KEY` is present, the configuration loader:

1. **Unlocks the vault** using the provided key
2. **Lists all secrets** in the vault
3. **Attempts JSON parsing** for each secret value
4. **Routes secrets based on name**:
   - `MATTERMOST_CREDS` ‚Üí Parsed as JSON, injected into `mattermost` config
   - Other secrets ‚Üí Injected into `keys` section and `os.environ`

### Example Runtime Injection

```python
# When vault is unlocked:
vault.list_secrets()  # ['OPENAI_API_KEY', 'MATTERMOST_CREDS']

# Flat string injection:
os.environ['OPENAI_API_KEY'] = 'sk-proj-abc123'  # Also in config.keys

# JSON injection:
os.environ['MATTERMOST_URL'] = 'https://mattermost.example.com'
os.environ['MATTERMOST_TOKEN'] = 'xyz789token'
# Also in config.mattermost: {'url': '...', 'token': '...'}
```

### Security Guarantees
- **Zero disk persistence** of decrypted secrets
- **Automatic lock** after configuration load completes
- **Environment variable isolation** - secrets only in `os.environ` during active use
- **Type-safe schema** - secrets mapped to specific config fields

---

## Security Best Practices

1. **Never commit the master key** - Use `.env.example` to document required variables
2. **Rotate keys regularly** - Generate new `COBALT_MASTER_KEY` periodically
3. **Lock vault when idle** - Secrets are automatically locked after config loading
4. **Use environment-specific vaults** - Separate vaults for dev/staging/production
5. **Audit secret access** - Log all vault unlock/access events

---

## File Structure

```
data/
‚îî‚îÄ‚îÄ .cobalt_vault          # Encrypted vault file (AES-256)
    ‚îî‚îÄ‚îÄ plaintext in RAM   # Decrypted secrets (JSON) - RAM-only
```

### Vault File Format (Encrypted)
```json
{
  "OPENAI_API_KEY": "sk-proj-abc123...",
  "MATTERMOST_CREDS": "{\"url\":\"https://mattermost.example.com\",\"token\":\"xyz789\"}"
}
```

### Environment Variable Mapping

| Vault Key | Environment Variable | Config Field |
|-----------|---------------------|--------------|
| `OPENAI_API_KEY` | `OPENAI_API_KEY` | `llm.api_key` |
| `ANTHROPIC_API_KEY` | `ANTHROPIC_API_KEY` | `llm.api_key` |
| `MATTERMOST_CREDS` | `MATTERMOST_URL`, `MATTERMOST_TOKEN` | `mattermost.url`, `mattermost.token` |

---

## Example Usage

### Initialize Vault (One-Time Setup)
```bash
python dev_utils/manage_vault.py
# Follow prompts to generate a new master key
# Save the key: export COBALT_MASTER_KEY="..."
```

### Add a Secret
```bash
export COBALT_MASTER_KEY="your-fernet-key"
python dev_utils/manage_vault.py
# Select option 3, enter secret name and value
```

### Use in Application Code
```python
from cobalt_agent.config import load_config

# Configuration automatically unlocks vault if COBALT_MASTER_KEY is set
config = load_config()

# Secrets are injected into config and os.environ
# config.llm.api_key contains the vault value
# os.environ['OPENAI_API_KEY'] contains the vault value
```

### Lock Vault Manually
```python
from cobalt_agent.config import Config

config = Config.get_instance()
config.lock_vault()  # Wipes secrets from RAM

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/wipe_memory.md
========================================

---
title: "Wipe Memory Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[postgres]]"
location: "dev_utils/wipe_memory.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Wipe Memory Script

**Location:** `dev_utils/wipe_memory.py`

## Overview

Wipe Memory is a utility script that removes all data from any table in the PostgreSQL public schema. It finds all tables and truncates them without dropping them.

## Usage

```bash
python dev_utils/wipe_memory.py
```

Or with uv:

```bash
uv run python dev_utils/wipe_memory.py
```

## ‚ö†Ô∏è Destructive Warning

üö® **THIS SCRIPT DELETES ALL DATA FROM ALL TABLES** in the public schema - all records will be permanently lost. This action cannot be undone.

**Before running:**
1. Ensure you have a database backup
2. Verify you are connected to the correct database
3. Understand that ALL tables will be truncated

## Behavior

The script performs the following actions:

1. Connects to PostgreSQL using credentials from `.env` or environment variables
2. Queries the `information_schema.tables` to find all tables in the public schema
3. Truncates each table found (removes all rows)
4. Prints the name of each table being wiped

## Environment Variables

| Variable | Default | Description |
|--|--|--|
| `POSTGRES_HOST` | `localhost` | Database host |
| `POSTGRES_DB` | `cobalt_memory` | Database name |
| `POSTGRES_USER` | `postgres` | Database user |
| `POSTGRES_PASSWORD` | `cobalt_password` | Database password |

## Typical Use Case

This script is used when:
- You need to clear all memory logs for testing
- You want to reset the database to empty state
- You are debugging and need a clean slate

**After running:**
- All tables remain (schema intact), but all rows are deleted
- You may need to re-seed any reference data

## Dependencies

- `psycopg` - PostgreSQL client library
- `python-dotenv` - Environment variable loading

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Backlog.md
========================================

---
status: In Progress
priority: P1 (High)
module: Ops
phase: 3 (Capabilities)
complexity: S
tags: [cobalt, planning, roadmap]
created: 2026-02-26
---
# Cobalt Product Backlog

## Completed (Phase 4 & 5)
* [x] **ADR-009: The Vector Librarian (pgvector)** - Implemented PostgreSQL-backed Vector Database with ingestion engine (`dev_utils/ingest_knowledge.py`), omni-memory integration, and `search_knowledge` tool for semantic queries.

## Completed (Phase 6)
* [x] **Refactor Orchestrator Abstraction:** Update `cortex.py` and `OrchestratorEngine` to handle multi-domain routing (Tactical, Ops, Intel) and spawn domain-specific Drones (Strategos, Scribe) instead of hardcoding the Engineering Forge.

## Completed (Phase 7)
* [x] **Phase 7: Continuous Memory & Automation** - Implemented scheduler service with cron-based Morning Briefing generation, automated vault management with AES-256 encryption, and robust orchestration state machine with Split-Brain architecture.

## Deferred / Future Infrastructure
* [ ] **Implement Syncthing over Tailscale for robust, bi-directional, air-gapped local vault sync.**
* [ ] **Implement v1beta routing in LLM class to natively support Google preview models.**
* [ ] **Live Market Data Feed Integration:** Select and integrate a structured API (e.g., Polygon, Alpaca) for the Tactical Drone.
* [ ] **Execution Broker API Integration:** Connect the HUD to a brokerage API to receive Cobalt's "Math Packages" for JIT execution.

## High-Throughput Inference (Local Cluster)
* [ ] **[Epic] Speculative Decoding Pipeline:** Update the local inference engine to run a tiny draft model (e.g., `qwen2.5:1.5b`) for `qwen3-coder-next` to 3x the base generation speed of the Chief of Staff.
* [ ] **[Epic] Llama.cpp Nginx Cluster:** Deprecate Ollama for raw `llama-server` binaries. Spin up a multi-instance local cluster behind an Nginx reverse-proxy to handle true concurrent batching on Apple Silicon.
* [ ] **[Epic] Async Parallel Fan-Out:** Refactor the `OrchestrationState` machine to support `asyncio.gather()`. Allow Cortex to dispatch independent sub-tasks (e.g., multiple file reads or web searches) to the Nginx cluster simultaneously.

## Active Sprints

### Sprint: Advanced Intel (Playwright & Search)
* [ ] **Upgrade Playwright Browser Tool:** Evolve the basic DSL into an advanced search and analysis engine. Must support multi-step interaction arrays (handling cookie banners, logins), targeted DOM extraction (tables/articles), and clean markdown formatting to allow the Intel Drone to scrape financial sites without a paid API.

## Unscheduled Ideas
* [ ] Integrate Discord scraping for sentiment analysis.
* [ ] Build "Ion Voice" for audio alerts.
* [ ] Research "Mean Reversion" strategy implementation.
* [ ] Integrate `pyotp` for Google Authenticator (TOTP) Zero-Trust execution verification.
* [ ] Technical Debt: Remove legacy `ToolResult` object checks (`.success`, `.output`) from ReAct loops, as tools now return standard strings.
* [ ] [Epic] Automated Obsidian Sync: Implement an automated cron schedule for the ThinkSync routine on the X1 Carbon to ensure the live Second Brain is always synchronized with the agent's environment.

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-000 The Ironman Directive.md
========================================

# PRD-000: The Ironman Directive (Cobalt Core Constitution)

## 1. The Core Identity & Mission
Cobalt is not a standard coding assistant; Cobalt is a personalized, highly secure "Ironman Suit" (J.A.R.V.I.S.) designed to enhance the capabilities of its creator across Trading, Business Operations, Personal Knowledge Management, and Executive Coaching.
Cobalt acts as a Chief of Staff. It must filter noise, challenge assumptions, and execute complex multi-step tasks autonomously while adhering to strict Zero-Trust human-in-the-loop (HITL) boundaries.

## 2. Distributed System Architecture & Cluster Topology
Cobalt is engineered as a scalable **Distributed AI Agent Cluster**, capable of routing specialized tasks to hardware-optimized edge nodes across a Tailscale-secured mesh network. Currently operating as a foundational cluster, the topology consists of:
* **Primary Node (The Heavy Lifter - Mac Studio):** IP `100.70.206.126`. This is the cluster's main orchestrator, database host, and Cortex router.
* **Worker Node (The Sniper - Lenovo X1 Carbon, Fedora):** IP `100.104.48.21`. The portable, tactical edge node for localized execution.
* **The OS-Agnostic Mandate:** Code must never use hardcoded paths (e.g., Mac vs Linux). All filesystem traversal must be dynamically rooted via the `.env` Vault Path to ensure seamless task execution across any node in the cluster.

## 3. The Second Brain (Obsidian Vault)
The Obsidian Vault is the absolute source of truth.
* Cobalt must respect the folder structure (`0 - Inbox`, `0 - Projects`, etc.).
* Code and configurations live in the `src/` tree, but all project management, sprints, ADRs, and journals live purely in Obsidian markdown. 
* Cobalt is the "Scribe" and "Librarian" of this vault.

## 4. The Spotter/Sniper Trading Dynamic (Strictly Restricted)
When handling Tactical/Trading data, Cobalt acts EXCLUSIVELY as the "Spotter."
* **The Mandate:** Cobalt will calculate Expected Value (EV), scrape playbooks, grade risks, and format market briefings.
* **The Restriction:** Cobalt will NEVER execute a trade. The human is the "Sniper" who pulls the trigger.

## 5. The Split-Brain Architecture & The Forge
Cobalt uses a "Split-Brain" routing architecture. The Cortex routes tasks to specialized Drones (e.g., Tactical, Intel, Ops, Engineering).
* **The Engineering Forge:** When writing code, Cobalt must use secure, Pydantic-validated tool schemas. Prompts are treated as configuration (`configs/prompts.yaml`), not hardcoded logic.
* **Zero-Trust:** Any action that mutates the system (writing files, running terminal commands) MUST trigger a Mattermost WebSocket proposal. Cobalt must pause and wait for the human to click "Approve."

## 6. The Coaching Protocol
Cobalt is designed to push the user to improve. It must:
* Grade performance objectively based on established playbooks.
* Refuse to sugarcoat bad decisions (especially in trading or business).
* Actively ask clarifying questions if the user's logic is flawed.

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-001 Cobalt-Ion Tactical HUD.md
========================================

---
title: "PRD-001: Cobalt-Ion Tactical HUD"
status: Draft
priority: P0
module: [Requirements]
phase: 1
complexity: L
tags: [cobalt, prd, requirements]
created: 2026-02-23
---

# PRD-001: Cobalt-Ion Tactical HUD

## 1. Executive Summary
**The Vision:** Build a "Co-Pilot" system for manual day trading.
**The Problem:** Professional trading requires processing dozens of variables (RVOL, Levels, Tape, News) in real-time. Humans are slow and emotional.
**The Solution:** A "Heads-Up Display" (HUD) that acts as a real-time **Confidence Gauge**. It calculates the mathematical "Expected Value" (EV) of a trade 10x/second, allowing the trader to execute with conviction.

## 2. Core Philosophy: The Sniper and Spotter Architecture

1.  **Not an Auto-Trader (With Exception):** The system does not execute trades autonomously by default. It observes, calculates, and suggests. The user pulls the trigger. **Exception:** Ion *can* execute autonomously, but ONLY when provided with a cryptographic Just-In-Time (JIT) execution token by the Human-in-the-Loop via the Mattermost Proposal Engine.

2.  **Distributed Brain:**
    * **Mac Studio (Cobalt):** The Spotter. Slow, deep thinking. Analysis of Context & Catalysts. Written in Python.
    * **Windows PC (Ion):** The Sniper. Fast, reactive execution. Visualizing the HUD and executing with cryptographic JIT tokens. Written in Rust.

3.  **Separation of Concerns:**
    * **Cobalt (Spotter):** Responsible for high-level strategy, risk analysis, and generating the "Math Package." Operates on Mac.
    * **Ion (Sniper):** Responsible for real-time scoring, latency-sensitive execution, and HUD rendering. Operates on Windows.

## 3. User Stories

### Story A: The "Morning Briefing" (Context)
**As a** Trader,
**I want** Cobalt to scan the market for "In Play" stocks and identify the specific *Strategies* (from my Playbook) that apply to them (e.g., "NVDA is an Earnings Gap"),
**So that** I start the day with a curated list of opportunities, not just raw tickers.

### Story B: The "Formula Injection" (Handoff)
**As a** System Architect,
**I want** Cobalt to send a "Math Package" (JSON) to Ion containing the specific *Weights and Variables* for the day (e.g., "For NVDA, Gap Fill is +10 points, Resistance at $145 is -20 points"),
**So that** Ion can run the math locally without latency, acting as a "dumb calculator" for Cobalt's "smart rules."

### Story C: The "Tactical Engagement" (The HUD)
**As a** Trader executing a trade,
**I want** a visual Gauge (0-100) that updates in real-time based on Price, Volume, and Time,
**So that** I can intuitively see if the trade is degrading (Score dropping) or improving (Score rising) without doing mental math.
* *Example:* "I am long NVDA. Volume dries up -> Score drops 10 points -> Gauge turns Yellow -> I trim my position."

### Story D: The "JIT Token" (Autonomous Execution)
**As a** Human-in-the-Loop Trader,
**I want** to issue a cryptographic Just-In-Time execution token via the Mattermost Proposal Engine,
**So that** Ion can execute trades autonomously during high-velocity market conditions while maintaining strict human oversight.
* *Example:* "I approve this trade with a 5-minute JIT token -> Ion executes at $145.25 -> Trade is closed if price moves against me."

## 4. Functional Requirements

### 4.1 The Scoring Engine (Dynamic EV)
The Score (0-100) is calculated as:
$$ Score = Base + Fuel - Friction - Decay $$
* **Base:** Static score from the Daily Setup (e.g., "A+ Setup" = 60).
* **Fuel (Momentum):** Live modifiers (e.g., `RVOL > 2.0` adds +10).
* **Friction (Risk):** Proximity to Resistance (e.g., `Dist < $0.10` subtracts -20).
* **Decay (Time):** Penalty for stalling (e.g., `-1 point` per minute of chop).

### 4.2 The "Math Package" Protocol
Cobalt must send a JSON payload to Ion containing:
* `Ticker`: Symbol (e.g., "NVDA").
* `Strategies`: List of active setups (e.g., ["GapAndGo", "BellaFade"]).
* `Zones`: Key Price Levels (Entry, Stop, Target).
* `Coefficients`: The weights for the Scoring Engine.

### 4.3 The Multi-Strategy Capability
The system must support **Conflicting Strategies** simultaneously.
* *Scenario:* NVDA gaps up.
* *HUD State:* Ion displays *two* potential scores:
    1.  **Long Score:** For the "Gap & Go" breakout.
    2.  **Short Score:** For the "Extension Fade" reversal.

### 4.4 The JIT Token Protocol
* **Format:** Cryptographically signed JWT token containing:
  * `symbol`: Trading pair/ticker
  * `direction`: Long/Short
  * `quantity`: Amount to execute
  * `deadline`: Unix timestamp for token expiration
  * `signature`: HMAC-SHA256 signature from Mattermost Proposal Engine
* **Validation:** Ion MUST verify the token signature before executing any trade.
* **Expiration:** Tokens expire after a configured time window (default: 5 minutes).

## 5. Technical Constraints
* **Language (Cobalt):** Python 3.11+.
* **Language (Ion):** Rust (stable channel).
* **GUI Framework:** Any relevant (Windows) for transparent overlays.
* **Communication:** Redis Pub/Sub **or** ZeroMQ over Tailscale LAN.
* **Data Source:** TradeStation API (connected locally on Windows).
* **Latency Target:** < 50ms from Tick to HUD Update.
* **Security:** All autonomous execution requires cryptographic token verification.

## 6. Future Extensibility
* **Discord Integration:** Manual scraping of trader sentiment to adjust "Base Scores."
* **Journaling:** Automated logging of *why* a score was high/low at the moment of execution.
* **Token Dashboard:** Web interface to view active JIT tokens and their expiration times.

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-002 Mattermost HITL Proposal Engine.md
========================================

---
title: "PRD-002: Mattermost HITL Proposal Engine"
status: Draft
priority: P0
module: [Requirements]
phase: 1
complexity: L
tags: [cobalt, prd, requirements]
created: 2026-02-23
---

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-003 Zero Trust Docker Sandbox.md
========================================

---
title: "PRD-003: Zero Trust Docker Sandbox"
status: Draft
priority: P0
module: [Requirements]
phase: 1
complexity: L
tags: [cobalt, prd, requirements]
created: 2026-02-23
---

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-004 Cortex LLM Switchboard Router.md
========================================

---
title: "PRD-004: Cortex LLM Switchboard Router"
status: Draft
priority: P0
module: [Requirements]
phase: 1
complexity: L
tags: [cobalt, prd, requirements]
created: 2026-02-23
---

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-005 Voice Architecture.md
========================================

---
title: "PRD-005 Voice Architecture"
status: Draft
priority: P2
module: [Requirements]
phase: Backlog
complexity: L
tags: [cobalt, prd, requirements, voice]
created: 2026-02-23
---

# Voice Architecture Plan

**Purpose**: Documenting intent to add voice-controlled interaction capabilities for X1 Carbon integration.

**Last Updated**: 2026-02-18

## Overview

This document outlines the planned architecture for voice-based interaction in Project Cobalt, enabling hands-free control through natural language processing.

## Planned Components

### 1. Mattermost Integration
- **Purpose**: Voice-controlled messaging and collaboration
- **Features**:
  - Read and send messages via voice commands
  - Join/leave channels with voice
  - Search message history using natural language

### 2. Browser Control
- **Purpose**: Voice-driven web automation
- **Features**:
  - Navigate to URLs via voice command
  - Extract content using natural language queries
  - Perform searches and interpret results

## Technical Considerations

- **Speech-to-Text**: Integration with transcription services
- **Text-to-Speech**: Natural sounding voice responses
- **Intent Recognition**: Mapping voice commands to system actions
- **Error Handling**: Graceful fallback for misinterpreted commands

## Related Files

- `src/cobalt_agent/tools/browser.py` - Existing browser control module
- `src/cobalt_agent/main.py` - Main agent entry point
- `configs/config.yaml` - Configuration for voice services

## Status

- **Phase**: Planning / Design
- **Priority**: Medium
- **Dependencies**: Qwen3-80B integration complete (v0.5.0)

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-006 Dynamic Browser Automation.md
========================================

---
title: "PRD-006: Agentic Browser Loop & Fast Path"
status: Approved
priority: P1
module: [Requirements, Architecture, Security]
phase: 5
complexity: L
tags: [cobalt, prd, requirements, accessibility-object-model, cdn, pgvector, zero-trust, playwright]
created: 2026-02-27
---

# PRD-006: Agentic Browser Loop & Fast Path

## 1. Executive Summary
**The Vision:** Give Cobalt "hands" to navigate the modern, dynamic web with millisecond latency for repeated tasks.
**The Problem:** Traditional scraping fails on Single Page Applications (SPAs) and interactive sites. Even with Playwright and JSON DSL, the LLM cannot reliably generate CSS selectors for dynamic DOM structures, and every task incurs full LLM inference latency.
**The Solution:** Implement an **Agentic Browser Loop** that extracts interactive elements from the Accessibility Object Model (AOM) via Chrome DevTools Protocol (CDP). The LLM operates on a compressed element tree with numeric IDs rather than HTML. For repeated tasks, a **pgvector "Fast Path"** caches task intents and executes stored Playwright scripts natively, achieving millisecond latency. All operations enforce **Zero-Trust**: domain whitelisting, ephemeral contexts, and zero-knowledge credential injection.

## 2. User Stories

### Story A: The Fast Path Cache
**As a** Daily Analyst,
**I want** Cobalt to remember how I navigate to my finance dashboard,
**So that** my daily task completes in milliseconds without re-inferencing the page structure.

### Story B: The Dynamic Navigation
**As a** Researcher,
**I want** Cobalt to read data from a modern web app (like TradingView or SEC Edgar),
**So that** I can get accurate data even if the HTML body is initially empty and requires JavaScript to render.

### Story C: The Vault-Secured Login
**As a** Chief of Staff,
**I want** Cobalt to securely retrieve credentials from VaultManager, navigate to a data portal, fill out the login form, and extract the dashboard text,
**So that** I can automate daily data extraction behind paywalls without exposing my passwords to the LLM or plain text logs.

## 3. Core Requirements

### 3.1 AOM Extraction (Phase 1)
1. **Engine:** Playwright Chromium (Headless) with CDP session enabled.
2. **DOM Snapshot:** Use `dom.snapshotter.takeDomSnapshot()` to extract the full DOM accessibility tree.
3. **Element Compression:** Convert the accessibility tree to a compressed interactive element tree containing:
   - `id`: Numeric ID (stable identifier for LLM reference)
   - `role`: Accessibility role (button, link, input, textarea, etc.)
   - `name`: Accessible name (label, placeholder, or text content)
   - `state`: Actionable state (enabled, visible, editable)
   - Optional: `aria-label`, `aria-describedby`, `value` (for inputs)

### 3.2 Pydantic Schema Constraint (Phase 2)
1. **LLM Input:** The compressed element tree (JSON-serializable) with numeric IDs.
2. **LLM Output:** A Pydantic-constrained schema with actions:
   - `click(id: int)`: Click element by numeric ID
   - `type(id: int, text: str)`: Type text into element by numeric ID
   - `navigate(url: str)`: Navigate to URL (only if whitelisted)
   - `extract()`: Return current page text after cleanup
3. **Validation:** Pydantic schema enforces strict action types; invalid outputs raise `ValidationError` and trigger re-inference.

### 3.3 Maps (Phase 2)
1. **AOM Maps:** Maintain a persistent mapping from numeric ID ‚Üí DOM node, allowing the agent to execute actions without re-extracting the tree between steps.
2. **Tree Refresh:** After navigation, refresh the AOM tree and remap IDs. If an ID is no longer valid, re-infer the target element.

### 3.4 Vault Credential Injection (Phase 2)
1. **Credential Retrieval:** Use VaultManager to retrieve credentials based on `vault_path` from config.
2. **Credential Injection:** Inject credentials via:
   - `context.add_cookies()` for session-based auth
   - Direct form filling for explicit credentials (with Zero-Trust safeguards)
3. **Zero-Knowledge:** Credentials are never exposed to the LLM or logged; they exist only in memory during injection.

## 4. Performance Requirement: Fast Path Memory (Phase 3)

### 4.1 Fast Path Macro
1. **Hash Computation:** Compute SHA-256 hash of task intent (user request + context signature).
2. **Lookup:** Query pgvector memory table for similar task intents (cosine similarity threshold: 0.85).
3. **Cache Hit:** Execute stored Playwright script natively without LLM inference. This achieves **<50ms latency** for repeated tasks.
4. **Cache Miss:** Execute full LLM inference pipeline, then store resulting script in pgvector with:
   - Task intent hash
   - Compressed element tree snapshot
   - Playwright script
   - Success/failure metrics

### 4.2 Memory Schema (pgvector)
```python
Table: browser_fast_path
- task_hash (UUID)
- task_intent (TEXT)
- context_signature (TEXT)
- element_tree_snapshot (JSONB)
- playwright_script (TEXT)
- execution_time_ms (INTEGER)
- success_rate (FLOAT)
- created_at (TIMESTAMP)
```

## 5. Security Protocol: Zero-Trust Enforcement

### 5.1 Domain Whitelisting
1. **Validation:** Before any navigation, check URL against `ALLOWED_DOMAINS` from config.
2. **Strict Match:** Implement exact domain match (e.g., `finance.google.com` only if explicitly whitelisted).
3. **Violation:** Raise `SecurityViolation` exception if URL is not whitelisted; abort execution.

### 5.2 Ephemeral Browser Contexts
1. **New Context:** Create a new `browser.new_context()` for each session.
2. **No Persistence:** `storage_state=None` - no cookies, localStorage, or cache persist between runs.
3. **Isolation:** Each task runs in a completely clean environment.

### 5.3 HITL Boundary for Mutations
1. **Mutation Actions:** Navigation, form filling, clicking elements that alter state.
2. **Approval Required:** All mutations require human-in-the-loop approval unless:
   - URL is in `AUTO_APPROVED_DOMAINS` (from config)
   - Element is in `AUTO_APPROVED_ELEMENTS` (from config)
3. **Non-Mutation:** Reading page text is always allowed.

## 6. Technical Constraints
- Must run headlessly to avoid interrupting the user's primary desktop experience.
- Must include hard timeouts to prevent infinite hanging on broken selectors (default: 30 seconds).
- Must spoof User-Agent strings to minimize bot detection.
- Fast Path lookup must complete in <10ms (pgvector with vector index on task_hash).
- All LLM requests must use Pydantic response models with strict validation.

## 7. Failure Modes
| Mode | Response |
|------|----------|
| AOM extraction fails | Re-try once; if still fails, abort with `BrowserError` |
| LLM output invalid | Re-infer with error message in context; retry up to 3 times |
| Cache lookup timeout | Fall back to LLM inference |
| Domain not whitelisted | Raise `SecurityViolation`; abort execution |
| Credential injection fails | Raise `SecurityViolation`; abort execution |
| Element ID not found | Re-extract AOM tree; if still not found, abort with `ElementNotFoundError` |

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-007 Sovereign Split-Brain Orchestration.md
========================================

---
title: "PRD-007: Sovereign Split-Brain Orchestration"
status: Approved
priority: P0
module: [Requirements, Brain]
phase: 4
complexity: M
tags: [cobalt, prd, requirements, multi-agent]
created: 2026-02-26
---

# PRD-007: Sovereign Split-Brain Orchestration

## 1. Executive Summary
**The Problem:** The current agent suffers from Cognitive Overload. When asked to write code, it attempts to plan architecture, write Python, format JSON tools, and adhere to trading risk-management rules simultaneously within a single context window. This leads to infinite loops and hallucinated syntax.
**The Solution:** Implement a Hierarchical Multi-Agent Architecture ("Split-Brain"). A Manager agent (Cortex) plans the architecture, and a Worker agent (The Forge) executes the code.

## 2. Core Philosophy
1. **Cognitive Decoupling:** Planning and Execution must never happen in the same LLM inference call.
2. **Sovereignty Preserved:** Both the Manager and Worker roles will be executed sequentially by the local model to maintain absolute data privacy.
3. **Dynamic Personas:** The Manager will dynamically generate restricted personas for the Worker, removing irrelevant context (like trading rules during a coding task).
4. **Future-Proofing (Async):** The state machine must be designed synchronously first for stability, but decoupled enough to support `asyncio.gather()` when the local infrastructure is upgraded to a multi-instance Nginx cluster.

## 3. Functional Requirements
* **The Master Plan:** Cortex must output a step-by-step array of tasks *before* any tools are invoked.
* **The State Clipboard:** Python must maintain an `OrchestrationState` dictionary tracking the original request, the plan, current step, and worker observations.
* **The Feedback Loop:** If a Worker errors out, the Manager must be woken up, handed the error via the Clipboard, and asked to revise the Master Plan.

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Sprints/Sprint-2026-02-25 Zero Trust HITL Engine.md
========================================

---
title: "Sprint 2026-02-25: Zero Trust HITL Execution Engine"
date: 2026-02-25
sprint: 1
status: Complete
tags: [cobalt, sprint, hitl, security]
---

# Sprint 2026-02-25: Zero Trust HITL Execution Engine

## Overview

This sprint completed the foundational Zero Trust Human-in-the-Loop (HITL) Execution Engine, implementing memory-locked callbacks, Mattermost interceptors, and optimized ReAct loops for safe, auditable file modifications.

## Key Achievements

### 1. Zero Trust HITL: Air-Gapped Approval Workflow

Built an asynchronous, air-gapped approval workflow for file modifications. The LLM cannot write files directly; it must propose them via a Coat-Check ticket system.

**Implementation Details:**
- `ProposalEngine` class stores frozen Python execution callbacks in a shared class dictionary
- Callbacks are mapped to 8-character task IDs for secure retrieval
- File write operations are paused and require explicit human approval
- Approved proposals trigger callbacks that execute the actual file modifications

**Files Modified:**
- `src/cobalt_agent/core/proposals.py`

### 2. Memory-Locked Callbacks

Implemented `ProposalEngine.callbacks` as a shared class dictionary for storing frozen Python execution callbacks.

**Key Features:**
```python
class ProposalEngine:
    callbacks: Dict[str, Callable[[Proposal], None]] = {}
    
    def set_approval_callback(self, task_id: str, callback: Callable) -> None:
        self.callbacks[task_id] = callback
```

**Security Benefits:**
- Callbacks are stored in memory, not persisted to disk
- 8-character task ID provides cryptographic token for approval matching
- No direct file access until approval is received

### 3. Mattermost Interceptor

Updated the WebSocket listener to intercept messages starting with "Approve", bypassing the LLM entirely to execute secure RAM callbacks.

**Implementation:**
```python
# HITL APPROVAL INTERCEPTOR
text_lower = text.strip().lower()
if text_lower.startswith("approve") or text_lower.startswith("reject"):
    engine = ProposalEngine()
    result_msg = engine.handle_approval_response(text)
    self.send_message_to_channel_id(channel_id, result_msg)
    return
```

**Features:**
- Intercepts approval/reject messages before LLM processing
- Validates task ID format (8 characters)
- Executes RAM callbacks for approved proposals
- Ignores Mattermost system messages (joins, leaves, header updates)

**Files Modified:**
- `src/cobalt_agent/interfaces/mattermost.py`

### 4. Universal Tool Parser

Upgraded `ToolManager` and `WriteFileTool` to safely extract dictionary payloads using `ast.literal_eval` and prevent silent string-parsing errors.

**WriteFileTool Parsing:**
```python
# Universal extraction
data = query if query is not None else kwargs

if isinstance(data, str):
    try:
        data = json.loads(data)
    except Exception as e1:
        try:
            data = ast.literal_eval(data)
        except Exception as e2:
            logger.error(f"WriteFileTool parsing failed. JSON error: {e1} | AST error: {e2}")
            return f"Error: Failed to parse arguments. Received: {data}"
```

**Benefits:**
- Handles both JSON and Python dictionary string formats
- Graceful error handling with detailed error messages
- Prevents silent parsing failures

**Files Modified:**
- `src/cobalt_agent/tools/filesystem.py`
- `src/cobalt_agent/tools/tool_manager.py`

### 5. ReAct Loop Optimization

Added critical prompt rules to the Engineering prompt to:
- Stop infinite loops via the "Wait Protocol"
- Skip directory crawls when given exact file paths (context efficiency)

**Wait Protocol:**
```
6. WAIT PROTOCOL: If you use the `write_file` tool and the System Observation says "Action paused. Proposal sent", YOU MUST STOP. Output a final conversational message saying "I have submitted the proposal for your approval." DO NOT try to write the file again.
```

**Context Efficiency:**
```
5. WORKFLOW EFFICIENCY: If the user provides an exact filepath (e.g., "create a file at src/test.py"), DO NOT use `list_directory`. Execute `write_file` immediately to save context space.
```

**Files Modified:**
- `src/cobalt_agent/brain/engineering.py`

## Sprint Metrics

| Metric | Value |
|--------|-------|
| Sprint Duration | 2026-02-25 |
| Files Modified | 4 |
| New Features | 2 (HITL interceptor, memory-locked callbacks) |
| Bugs Fixed | N/A |
| Documentation Updated | 4 |

## Documentation Updates

- `docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/proposals.md` - Updated with callbacks documentation
- `docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/mattermost.md` - Updated with HITL interceptor documentation
- `docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/filesystem.md` - Created new page for WriteFileTool
- `docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/engineering.md` - Created new page for prompt rules

## Next Steps

- [ ] Add rejection handling documentation
- [ ] Document the callback execution flow in more detail
- [ ] Add integration testing for HITL workflow
- [ ] Create user-facing approval channel documentation

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Sprints/Sprint_Agentic_Browser.md
========================================

---
title: "Sprint Agentic Browser: AOM, Fast Path & Zero Trust"
date: 2026-02-27
sprint: 2
status: In Progress
tags: [cobalt, sprint, browser, aom, cdn, pgvector, zero-trust]
---

# Sprint Agentic Browser: AOM, Fast Path & Zero Trust

## Overview

This sprint implements the **Agentic Browser Loop** architecture, replacing the legacy JSON DSL with an Accessibility Object Model (AOM) / Chrome DevTools Protocol (CDP) Snapshot approach. We will enforce Zero-Trust constraints and implement a pgvector "Fast Path" memory cache for millisecond-latency execution of repeated tasks.

## Sprint Goals

1. Replace HTML-based LLM input with compressed AOM element trees with numeric IDs
2. Implement Fast Path memory caching via pgvector for repeated tasks
3. Enforce Zero-Trust: domain whitelisting, ephemeral contexts, and zero-knowledge credential injection

## Phase 1: AOM Extractor & Whitelist Configuration

### Objective
Implement AOM extraction via CDP to replace fragile HTML parsing with stable numeric element IDs.

### Deliverables

#### 1.1 AOM Extraction Module
- **File:** `src/cobalt_agent/tools/aom.py` (new)
- **Functionality:**
  - Establish CDP session with Playwright
  - Call `dom.snapshotter.takeDomSnapshot()` to extract DOM tree
  - Convert accessibility tree to compressed element format:
    ```python
    {
      "id": int,           # Stable numeric ID
      "role": str,         # Accessibility role
      "name": str,         # Accessible name
      "state": dict,       # Actionable state (enabled, visible, editable)
      "aria": dict,        # Optional aria-* attributes
      "value": str,        # Optional value (for inputs)
    }
    ```
  - Handle edge cases: empty pages, CORS errors, CDP disconnections

#### 1.2 Domain Whitelist Configuration
- **File:** `configs/config.yaml` (update)
- **Field:** `ALLOWED_DOMAINS: List[str]`
- **Implementation:** `BrowserTool._validate_url()` checks URL domain against whitelist
- **Security:** Raise `SecurityViolation` if URL not whitelisted

#### 1.3 Context Signature Hashing
- **File:** `src/cobalt_agent/memory/postgres.py` (update)
- **Functionality:** Compute SHA-256 hash of context signature for Fast Path matching
- **Input:** Page URL + title + visible text preview

### Testing
- [ ] AOM extraction on 5 test sites (different complexity levels)
- [ ] Domain whitelist validation with valid/invalid URLs
- [ ] Context signature hash consistency

---

## Phase 2: Pydantic Tool Schema & Vault Credential Injection

### Objective
Implement Pydantic-constrained LLM output and integrate VaultManager for zero-knowledge credential injection.

### Deliverables

#### 2.1 Pydantic Action Schema
- **File:** `src/cobalt_agent/tools/browser.py` (update)
- **Schema:** `BrowserAction` model with discriminated union:
  ```python
  class ClickAction(BaseModel):
      action: Literal["click"]
      id: int

  class TypeAction(BaseModel):
      action: Literal["type"]
      id: int
      text: str

  class NavigateAction(BaseModel):
      action: Literal["navigate"]
      url: str

  class ExtractAction(BaseModel):
      action: Literal["extract"]
  ```

#### 2.2 LLM Response Parsing
- **File:** `src/cobalt_agent/tools/browser.py` (update)
- **Functionality:** Parse LLM response into Pydantic model with strict validation
- **Error Handling:** Re-infer with error message on `ValidationError`

#### 2.3 Vault Credential Injection
- **File:** `src/cobalt_agent/security/vault.py` (update)
- **Functionality:** Retrieve credentials from VaultManager, inject into context
- **Zero-Knowledge:** Credentials exist only in memory during injection

#### 2.4 AOM Maps Module
- **File:** `src/cobalt_agent/tools/maps.py` (new)
- **Functionality:**
  - Maintain mapping from numeric ID ‚Üí DOM node
  - Refresh tree on navigation
  - Handle ID invalidation gracefully

### Testing
- [ ] Pydantic schema validation with valid/invalid actions
- [ ] Vault credential injection on 2 test sites with login forms
- [ ] AOM map refresh after navigation

---

## Phase 3: Fast Path pgvector Macro Caching

### Objective
Implement pgvector-based Fast Path memory to bypass LLM inference for repeated tasks.

### Deliverables

#### 3.1 Fast Path Memory Table
- **File:** `src/cobalt_agent/memory/postgres.py` (update)
- **Table:** `browser_fast_path`
  ```sql
  - task_hash (UUID)
  - task_intent (TEXT)
  - context_signature (TEXT)
  - element_tree_snapshot (JSONB)
  - playwright_script (TEXT)
  - execution_time_ms (INTEGER)
  - success_rate (FLOAT)
  - created_at (TIMESTAMP)
  ```
- **Vector Index:** pgvector on `task_hash` (cosine similarity)

#### 3.2 Fast Path Cache Logic
- **File:** `src/cobalt_agent/tools/browser.py` (update)
- **Functionality:**
  1. Compute task intent hash
  2. Query pgvector for similar intents (cosine similarity > 0.85)
  3. If cache hit: execute stored script natively
  4. If cache miss: execute LLM inference, store result

#### 3.3 Cache Metrics
- **File:** `src/cobalt_agent/memory/postgres.py` (update)
- **Functionality:**
  - Track cache hits/misses
  - Record execution time for Fast Path vs LLM
  - Log success rate per task hash

#### 3.4 Cache Invalidation
- **File:** `src/cobalt_agent/memory/postgres.py` (update)
- **Functionality:** Invalidate cache entries older than 30 days
- **Cleanup:** Weekly scheduled job

### Testing
- [ ] Fast Path cache lookup on 100 mock tasks
- [ ] Cache hit/miss ratio on 5 real-world task sequences
- [ ] Cache invalidation on 30-day-old entries

---

## Sprint Metrics

| Metric | Target |
|--------|--------|
| Sprint Duration | 2026-02-27 to 2026-03-06 |
| Files Modified | 5+ |
| New Files Created | 2+ |
| LLM Latency Reduction | >90% (Fast Path vs LLM inference) |
| AOM Extraction Success Rate | >95% |
| Zero-Trust Violations Blocked | 0 |

## Documentation Updates

- [ ] `docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/browser.md` - Updated with AOM extraction and Fast Path
- [ ] `docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/memory.md` - Updated with pgvector Fast Path
- [ ] `docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/security.md` - Updated with Zero-Trust enforcement

## Success Criteria

1. AOM extraction works on 95%+ of test sites
2. Fast Path cache reduces latency by >90% for repeated tasks
3. Zero-Trust enforcement blocks 100% of unwhitelisted URLs
4. All mutable actions require HITL approval unless whitelisted

## Next Steps (Post-Sprint)

- [ ] Add browser session persistence for multi-step workflows
- [ ] Implement auto-retry on element not found (re-extract AOM)
- [ ] Add browser tool to public API documentation

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Sprints/Sprint_Hardening_Tech_Debt.md
========================================

# Sprint: Architecture Hardening & Tech Debt Removal

## Chunk 1: Configuration & Magic String Purge
- [x] **Routing Keywords:** Move `orchestrator_keywords` and `high_risk_keywords` out of `cortex.py` and into `rules.yaml`.
- [x] **Model Fallbacks:** Ensure `cortex.py` and all tools default strictly to the local model defined in `active_profile.default` in `config.yaml`.
- [x] **Database Envs:** Sweep `dev_utils/*.py`. Remove all hardcoded fallback passwords. Raise explicit `ValueError` if `POSTGRES_PASSWORD`, `POSTGRES_USER`, `POSTGRES_DB`, or `POSTGRES_HOST` are missing.
- [x] **DRY Config:** Update all `dev_utils/` scripts to import and use the central `load_config()` from `cobalt_agent.config` instead of manually loading `.env`.
- [x] **Test Fixes:** Fix mock config in `tests/test_cortex.py` to properly return keyword lists from `MagicMock` objects. All 16 tests now passing.
- [x] **56/56 Tests Passing:** Full test suite passes with 16/16 cortex tests, 8/8 orchestrator tests, 7/7 scheduler tests, and 25/25 vault tests.

## Chunk 2: The Prompt Extraction
- [x] **YAML Setup:** Create a `configs/prompts.yaml` file (or add a `prompts:` section to `rules.yaml`).
- [x] **Extraction:** Sweep all `.py` files (especially `scheduler.py`, `cortex.py`, `proposals.py`, and `ops.py`). Extract every hardcoded LLM system prompt and user prompt template into the YAML file.
- [x] **Integration:** Refactor the Python files to load these prompts dynamically via the configuration object.

## Chunk 3: Dynamic Filesystem Routing
- [x] **Path Logic:** Refactor `filesystem.py` and `cortex.py`. They must strictly read the vault root path from `.env`. 
- [x] **Inbox vs Projects:** Ensure the logic dynamically appends `0 - Inbox/` only when explicitly sending a message/briefing to the Inbox. Ensure the agent can still freely navigate the root and `0 - Projects/` substructure for coding and documentation tasks.
- [x] **Tests:** All 56 tests passing. Filesystem path traversal protection verified.

## Chunk 4: Concurrency & Exception Safety
- [x] **Non-Blocking Proposals:** Refactor `wait_for_approval()` in `proposals.py` to remove `time.sleep()`. Implement a safe, non-blocking alternative (e.g., `asyncio` or `threading.Event()`) that maintains current functionality without freezing the WebSocket event loop.
- [x] **DB Connection Managers:** Update `dev_utils/` scripts (like `ingest_knowledge.py`) to use `with PostgresMemory() as db:` or explicitly call a `.close()` method to prevent connection leaks.
- [x] **Tracebacks:** Sweep `browser.py`, `filesystem.py`, and `cortex.py`. Convert broad `logger.error(str(e))` calls inside exception blocks to `logger.exception("...")`.

## Chunk 5: Strict Tool Schemas
- [x] **Remove literal_eval:** Strip `ast.literal_eval` from `filesystem.py` and `base.py` and replace with `json.loads` + try/except that returns string error to LLM on failure.
- [x] **Pydantic Tooling:** Bind tools to strict Pydantic schemas using LiteLLM's structured output/function calling features to guarantee JSON integrity before parsing.
- [x] **filesystem.py Validation:** Added Pydantic input models (`ReadFileInput`, `WriteFileInput`, `ListDirectoryInput`) and registered with ToolManager schema registry.
- [x] **browser.py Validation:** Added `BrowserCommand` Pydantic model for structured input validation; `run()` now accepts `**kwargs` and validates through Pydantic.
- [x] **tool_manager.py:** Updated to register tools with schemas; executes validation before tool execution; returns detailed error messages for `ValidationError` or `JSONDecodeError`.
- [x] **Error Handling:** All tool errors (validation, JSON parsing) return human-readable strings to LLM for self-correction instead of crashing.

## Chunk 6: Validation & Documentation Sweep
- [x] **Test Suite:** Run the full `pytest` suite. Fix any tests broken by the refactoring. Add new tests for the YAML prompt loading.
- [x] **Wiki Sync:** Perform a full sweep of `docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/` and update the markdown files to reflect the new architectures and prompt locations.

---

**SPRINT COMPLETE AND VALIDATED.**
All 56 tests passing (16/16 cortex, 8/8 orchestrator, 7/7 scheduler, 25/25 vault).

**Architectural Changes Documented:**
- Prompts centralized in `configs/prompts.yaml`
- Magic strings and credentials strictly pulled via `cobalt_agent.config`
- Filesystem paths dynamically resolved from `.env` vault root
- Tool schemas strictly enforced via Pydantic; `ast.literal_eval` purged


========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/User Stories/Story-001_Initial_Brainstorm.md
========================================

---
title: "Story-001: Initial Brainstorm"
status: Active
module: [Requirements]
tags: [cobalt, user_story]
created: 2026-02-23
---

# Story-001: Initial Brainstorm

## The Cobalt-Ion Distributed Architecture

### System Overview

**Cobalt (Mac Studio - The Strategist):**
- Runs the heavy AI (DeepSeek 70B)
- Monitors the "Catalyst" and "Setup" phases (Minutes/Hours)
- Sets the Rules and generates Scoring Profiles

**Ion (Windows PC - The Engine):**
- A lightweight Python application
- Monitors the "Trade" and "Execution" phases (Milliseconds)
- Runs the math based on formulas provided by Cobalt

### The Data Flow (The "Formula Injection")
1. **Cobalt** scans the market (continuously) and identifies a Ticker as "In Play."
2. **Cobalt** selects *all applicable strategies* from the Playbook (e.g., NVDA fits both "Gap & Go" and "Fade").
3. **Cobalt** generates a **Scoring Profile (JSON)** and pushes it to Ion.
   - This profile contains *Variables* (Weights), not *Decisions*.
   - Example: `{"strategy": "BellaFade", "trigger": "Price < VWAP", "rvol_weight": 10}`.
4. **Ion** subscribes to live data (TradeStation).
5. **Ion** calculates the Score (0-100) and EV live.
6. **Ion** paints the HUD.

### The Core Concept: "Configurator vs. Calculator"

To achieve the speed you need (color changing instantly as volume dries up), we cannot ask the LLM to calculate the score every second. The LLM is too slow and "fuzzy."

Instead, we split the brain:

- **Cobalt (The Coach / Mac):** _Sets the Rules._
  - Before the market opens (or when you spot a setup), Cobalt analyzes the context (News, Daily Chart, Sector).
  - Output: Generates a **"Scoring Profile"** (a JSON file).
    - Example: "For NVDA today: If RVOL > 3, +10 points. If Price hits 145.50 (Resistance), -15 points. If SPY drops, -20 points."

- **Ion (The Engine / Windows):** _Runs the Math._
  - Reads the live data feed and applies the _Scoring Profile_ 10 times a second.
  - Output: Draws the Gauge. It doesn't "think"; it just calculates.

### The Visual Metaphor: "The Confidence Gauge"

Imagine a UI widget floating next to your TradeStation charts.

- **The Needle (0-100):** Represents your **Dynamic Score**.
  - **0-40 (Red):** "No Go" or "Abort." (Iceberg ahead).
  - **41-70 (Yellow):** "Cautious Hold." (Trim position, tighten stops).
  - **71-100 (Green):** "Conviction." (Add size, hold for target).

- **The Delta (Rate of Change):**
  - If the needle suddenly drops from 90 to 60 in 2 seconds, that's your alert to get out _before_ the price collapses. This is faster than waiting for a candle to close red.

### The Logic: How We Calculate "Dynamic EV"

Dynamic EV = (Prob(win) √ó Dist(target)) - (Prob(loss) √ó Dist(stop))

**The Inputs (The Variables Ion Monitors):**
1. **The Setup Score (Static Baseline):**
   - Defined by Cobalt in the morning. (e.g., "A+ Setup = Base Probability 60%").
2. **The "Fuel" (Real-Time Momentum):**
   - **RVOL:** Is volume expanding on the move? (Boosts Probability).
   - **Tape Speed:** Are prints accelerating?
3. **The "Friction" (Resistance/Support):**
   - As Price ‚Üí Resistance, the **Reward** shrinks, but the **Risk of Reversal** grows.
   - Effect: EV drops rapidly as you hit target. The HUD goes yellow ("Take Profit").
4. **The "Decay" (Time):**
   - If you enter and price goes sideways for 10 minutes, probability of success usually drops.
   - Effect: The score slowly bleeds down, turning the gauge yellow/red solely because "It's taking too long."

### Technical Architecture: The "Sidecar" Pattern

**The Stack:**
- **Frontend (Ion):** **Python** (PyQt6 or similar for overlay).
  - Why? Cross-platform development. Deep integration with Windows via native APIs. Can draw "Always on Top" transparent overlays.
- **Data Source:** **TradeStation API / NinjaTrader API.**
  - Ion connects directly to the feed. No round-trip to the Mac for data.
- **The Brain Link:**
  - Cobalt (Mac) runs a **Web Dashboard** (or API endpoint).
  - You chat with Cobalt: _"Watch NVDA for a Gap and Go."_
  - Cobalt sends the **Parameters** to Ion over the LAN.
  - Ion lights up: _"NVDA Watchlist Active. Waiting for Breakout at $145."_

### Strategy: How to Build This

**Phase 1: The "Dashboard" (Mac-based Prototype)**
- Use Python on the Mac.
- Use a fast plotting library (like `Streamlit` or `Dash`) to visualize the "Gauge."
- Input: Simulate the data feed (or hook into a lightweight API like Alpaca/Polygon).
- Goal: Perfect the **Scoring Formula**.

**Phase 2: The "Overlay" (Windows Port)**
- Once the math works, port the _Calculator_ to Python on Windows (Ion).
- Build the visual overlay using PyQt6.

### Trade Phases (State Management)

The HUD needs to behave differently depending on where you are in the trade.

1. **Phase 1: The Stalk (Watchlist)**
   - **Gauge:** Shows **"Setup Quality"**.
   - **Goal:** Alert you when price hits the Trigger _with_ High Score.
   - Logic: Focus heavily on "Gap Maintenance" and "Pre-market Volume."

2. **Phase 2: The Engagement (In Trade)**
   - **Gauge:** Shows **"Holding Confidence"**.
   - **Goal:** Tell you when to fold.
   - Logic:
     - **Time Decay:** Starts ticking. If price doesn't move, score drops.
     - **Extension:** As price moves away from VWAP, risk increases (Score might dip to Yellow to signal "Trim").
     - **Resistance:** As price hits Target, EV drops (Risk of reversal).

### Multi-Strategy Reality

The critical requirement: NVDA having _multiple_ active strategies simultaneously.

**The Architectural Fix:** Cobalt cannot send "One Instruction." It must send a **Strategy Package**. Ion will display **Multiple Gauges** (or a Split Gauge) for NVDA:

1. **Long Gauge (Gap & Go):** Currently at **30/100** (Waiting for breakout).
2. **Short Gauge (Fade):** Currently at **10/100** (Not extended enough).

As the day evolves, if NVDA rips to $145.50 and volume dies:

- **Long Gauge:** Drops to 0 (Trade invalidated).
- **Short Gauge:** Spikes to **95/100** (Green Light).

This is why the Mac must run all day. It watches the "Macro" shift. If the SPY suddenly tanks, Cobalt updates the package: _"Market is now Bearish. Disable all Long strategies. Boost Short EV by 20%."_ Ion receives this update instantly and the HUD changes color before you even blink.

### The Playbook Architecture

Professional traders only execute trades that are in their Playbook.

**Hierarchical State Machine:**
- **Level 1 (Catalyst/Context):** "NVDA is In Play (Earnings)." (Determined by Cobalt/Mac).
- **Level 2 (Setup/Regime):** "It is currently a 'Morning Drive' or 'Reversal' regime." (Determined by Cobalt/Mac).
- **Level 3 (Trade Strategy):** "Active Strategies: `GapAndGo` (Long) AND `BellaFade` (Short)." (Cobalt sends BOTH to Ion).
- **Level 4 (Execution):** "Price broke $145.50 on High Volume -> Trigger `GapAndGo`." (Ion/Windows executes).

### The "Formula Injection" Architecture

Cobalt (The Strategist) and Ion (The Engine) interaction:

1. **Cobalt (Morning/Prep):** Analyzes the context (Daily chart, News, Sector). Determines _what matters today_.
   - Example: "For NVDA, because the market is bearish, 'Gap Strength' is less important, but 'Relative Volume' is critical. Also, there is an iceberg (resistance) at $145.50."
   
2. **The Artifact:** Cobalt generates a **Strategy Config Object (JSON)** that contains _weights and penalties_, not just hard rules.

3. **Ion (Live):** Receives this object. It plugs live data into the formula 10 times a second.

**The Strategy Config Object (JSON):**
```json
{
  "ticker": "NVDA",
  "strategy": "Gap_And_Go",
  "direction": "LONG",
  "levels": {
    "entry": 142.50,
    "stop": 141.00,
    "target": 145.50,
    "resistance_zones": [145.50, 148.00]
  },
  "scoring_weights": {
    "base_score": 65,
    "rvol_multiplier": 5.0,
    "spy_correlation": 10.0,
    "time_decay": -0.5
  },
  "abort_conditions": [
    "price < 140.00",
    "rvol < 0.2 after 10:00"
  ]
}
```

**Why this is powerful:**
- **Ion doesn't need to know _why_ SPY correlation matters.** It just knows: _"If SPY is Green, add 10 points."_
- **Cobalt can change the strategy dynamically.** On a crazy Fed Day, Cobalt might send a config with `base_score: 40` (start cautious) and `time_decay: -2.0` (get out fast if it stalls).

### Next Steps

1. **Don't write the code yourself.** Delete the skeleton I gave you.
2. **Define the Interface:** We only need to define _how_ Cobalt talks to the Strategy Engine (e.g., `analyze(data) -> signal`).
3. **The "Forge" (Future):** When we get to Phase 7, you will paste the SMB PDF, and **Cobalt** will generate `second_day_play.py` and run the backtest.

### Revised Strategic Roadmap

Since we are avoiding "Rapid Coding," let's lock in the **Architecture** before we write another line.

**Does this look like the correct ecosystem to you?**

1. **Mac Studio (The Brain)**
   - **DeepSeek 70B (Local):** The reasoning engine.
   - **Postgres (Docker):** The memory.
   - **Cobalt Core:** The manager.
   - Status: **Built.**

2. **Windows Rig (The Body)**
   - **TradeStation/DAS:** The platform.
   - **Ion Agent (Python Service):**
     - Listens on port 5555.
     - Reads "Account Value" and "Positions" every 1s.
     - Can trigger "Flatten" or "Buy" instantly.
   - Status: **Not Started (Phase 6).**

3. **The "Nerve" (LAN)**
   - A dedicated, encrypted channel between Mac and PC.
   - Keeps the "Brain" safe from Windows viruses/crashes.

### Decision Point

Do you want to continue fleshing out the **Brain (Playbook Logic)** on the Mac now, knowing it will eventually send commands to Ion?

OR

Do you want to switch gears and design the **Ion Protocol** (how the two machines talk) so we know what data we need to send?

========================================
FILE: docs/0 - Projects/Cobalt/Cobalt Project Board.base
========================================

views:
  - type: list
    name: Table
    filters:
      and:
        - file.inFolder("0 - Projects/Cobalt/Tasks")
    groupBy:
      property: status
      direction: ASC
    order:
      - file.name
      - status
      - priority
      - module
      - complexity
    sort:
      - property: file.name
        direction: ASC
      - property: module
        direction: ASC
      - property: priority
        direction: DESC
    columnSize:
      file.name: 244
    cardSize: 110


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/01 System Prep.md
========================================

---
status: Done
priority: P0
module: Ops
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/02 Architecture Setup.md
========================================

---
status: Done
priority: P0
module: Ops
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/03 Dependency Management.md
========================================

---
status: Done
priority: P0
module: Core
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/04 Verification.md
========================================

---
status: Done
priority: P0
module: Ops
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/05 Hello World.md
========================================

---
status: Done
priority: P0
module: Core
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/06 Core Config.md
========================================

---
status: Done
priority: P1
module: Core
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/07 Memory System.md
========================================

---
status: Done
priority: P1
module: Brain
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/08 Persona Logic.md
========================================

---
status: Done
priority: P2
module: Brain
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/09 Interface Layer.md
========================================

---
status: Done
priority: P2
module: Interface
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/10 Tool Manager.md
========================================

---
status: Done
priority: P1
module: Interface
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/11 Prompt Engine.md
========================================

---
status: Done
priority: P1
module: Interface
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/12 Browser Capabilities.md
========================================

---
status: Done
priority: P1
module: Tools
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/13 Trading Engine.md
========================================

---
status: Done
priority: P1
module: Skills
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/14 Autonomous Loop.md
========================================

---
status: Done
priority: P2
module: Brain
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/15 Memory Interface.md
========================================

---
status: Done
priority: P0
module: Brain
complexity: S
---
- _Goal:_ Create `base.py` abstract class to standardize memory storage.
    
- _Why:_ Decouples logic from storage, allowing us to swap JSON for Postgres later without breaking code.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/16 Postgres Adapter.md
========================================

---
status: Done
priority: P1
module: Brain
complexity: M
---
- _Goal:_ Create `postgres.py` implementing `MemoryProvider`.
    
- _Why:_ Enables vector search and massive scale storage (Long-Term Memory).

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/17 Cortex Dispatcher.md
========================================

---
status: Done
priority: P1
module: Brain
complexity: L
---
- _Goal:_ Build the "Router" logic in `main.py`.
    
- _Why:_ Decides if a prompt needs the Trader, the Scribe, or the coder.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/18 Scribe Skill (Obsidian).md
========================================

---
status: Done
priority: P1
module: Skills
complexity: M
---
- _Goal:_ Build `skills/scribe.py` to read/write Obsidian Markdown files.
    
- _Why:_ Allows the agent to organize your "Second Brain."

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/19 Scheduler & Cron.md
========================================

---
status: Done
priority: P2
module: Core
complexity: M
---
- _Goal:_ Implement `APScheduler` in `core`.
    
- _Why:_ Allows tasks to run automatically (e.g., "Check market at 9:30 AM") without user input.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/20 Multi-Agent Orchestration.md
========================================

---
status: Done
priority: P2
module: Brain
complexity: L
---
- _Goal:_ Allow agents to talk to each other (Trader -> Scribe).
    
- _Why:_ Complex workflows require team collaboration, not just Q&A.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/21 (Morning Briefing).md
========================================

---
status: Done
priority: P2
module: Skills
complexity: S
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/22 Mac Studio Deployment.md
========================================

---
status: To Do
priority: P2
module: Ops
complexity: M
---
- _Goal:_ Containerize the full stack and deploy to the M3 Ultra.
    
- _Why:_ Moves from "Dev" to "Production" (Always on).

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/23 Strategos Agent Setup.md
========================================

---
status: Done
priority: P0
module: Tactical
complexity: M
tags:
  - cobalt/task
created: 2026-02-10
---

# Strategos Agent Setup

## Objective
Create the 'Strategos' class. This manages the Playbook and Risk, replacing the basic FinanceTool wrapper.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/24 Playbook Registry.md
========================================

---
status: Done
priority: P1
module: Tactical
complexity: S
tags:
  - cobalt/task
created: 2026-02-10
---

# Playbook Registry

## Objective
Create 'strategies.yaml' to define rules for Second Day Play and Fashionably Late Scalp.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/25 Strategy Interface.md
========================================

---
status: Done
priority: P1
module: Tactical
complexity: M
tags:
  - cobalt/task
created: 2026-02-10
---

# Strategy Interface

## Objective
Define the abstract Python class for a Strategy (check_entry, check_stop, calculate_probability).

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/26 Second Day Play Impl.md
========================================

---
status: Done
priority: P1
module: Tactical
complexity: L
tags:
  - cobalt/task
created: 2026-02-10
---

# Second Day Play Impl

## Objective
Implement the specific logic from the SMB PDF: Day 1 Trend, Day 2 Open, RVOL checks.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/27 Backtest Engine.md
========================================

---
status: To Do
priority: P2
module: Tactical
complexity: XL
tags:
  - cobalt/task
created: 2026-02-10
---

# Backtest Engine

## Objective
Create the engine that runs a Strategy against 90 days of historical minute-data.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/28 Ops Medical Stub.md
========================================

---
status: To Do
priority: P2
module: Ops
complexity: S
tags:
  - cobalt/task
created: 2026-02-10
---

# Ops Medical Stub

## Objective
Create the Steward Agent shell to handle future medical billing tasks.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/29 Privacy Guardrails.md
========================================

---
status: To Do
priority: P0
module: Ops
complexity: M
tags:
  - cobalt/task
created: 2026-02-10
---

# Privacy Guardrails

## Objective
Implement PII stripping to ensure no patient data ever hits the LLM.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/30 Ion Core Architecture.md
========================================

---
status: To Do
priority: P1 (High)
module: Interface
phase: 4 (Ion HUD)
complexity: L
tags: [cobalt, task, ion]
created: 2026-02-11
---

# 30 Ion Core Architecture

## Objective
Establish the foundational Python application for the **Windows HUD**.

## Requirements
* [ ] Create `ion_agent/` directory structure on Windows.
* [ ] Initialize a **PyQt6** application loop.
* [ ] Implement a **Transparent Overlay Window** (Click-through capable).
* [ ] Create a system tray icon for background management.
* [ ] Ensure it can run alongside TradeStation without stealing focus.

## Technical Notes
* Use `PyQt6.QtCore.Qt.WindowType.FramelessWindowHint`.
* Must handle high-DPI scaling (4K monitors).


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/31 Cobalt-Ion Bridge.md
========================================

---
status: To Do
priority: P0 (Critical)
module: Core
phase: 4 (Ion HUD)
complexity: M
tags: [cobalt, task, network]
created: 2026-02-11
---

# 31 Cobalt-Ion Bridge

## Objective
Create the low-latency communication link between **Cobalt (Mac)** and **Ion (Windows)**.

## Requirements
* [ ] Implement **ZeroMQ (ZMQ)** PUB/SUB pattern.
* [ ] **Publisher:** Cobalt (Mac) broadcasting strategy signals.
* [ ] **Subscriber:** Ion (Windows) listening for HUD updates.
* [ ] Define the JSON payload schema (Ticker, Action, Confidence, Price).
* [ ] Secure the connection over **Tailscale IP**.

## Technical Notes
* Latency target: < 50ms.
* Use `zmq.asyncio` for non-blocking I/O.


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/32 HUD Widgets & Overlay.md
========================================

---
status: To Do
priority: P1 (High)
module: Interface
phase: 4 (Ion HUD)
complexity: M
tags: [cobalt, task, ui]
created: 2026-02-11
---

# 32 HUD Widgets & Overlay

## Objective
Build the specific visual components that appear on the screen.

## Requirements
* [ ] **Confidence Gauge:** A visual bar/dial showing Model Confidence (0-100%).
* [ ] **Signal Box:** A "BUY/SELL" indicator that flashes on trigger.
* [ ] **Trade Log:** A small scrolling list of recent fills.
* [ ] **P&L Ticker:** Real-time session P&L display.

## Design
* "Dark Mode" aesthetic (Cyberpunk/High-Contrast).
* Green = Long, Red = Short.


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/33 Mattermost C2 Integration.md
========================================

---
status: To Do
priority: P1 (High)
module: Ops
phase: 5 (Ops)
complexity: M
tags: [cobalt, task, chat]
created: 2026-02-11
---

# 33 Mattermost C2 Integration

## Objective
Connect Cobalt to the "Red Phone" (Mattermost) for remote command and control.

## Requirements
* [ ] Create a Mattermost Bot Account ("Cobalt").
* [ ] Implement **Incoming Webhooks** for alerts (Trade Signals).
* [ ] Implement **Outgoing Webhooks** (or Slash Commands) for user commands.
* [ ] **Kill Switch:** Create a command `/cobalt stop` that halts all trading instantly.
* [ ] **Approval Flow:** Interactive buttons for "Approve Trade?" messages.


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/34 Automated Trade Journaling.md
========================================

---
status: To Do
priority: P2 (Normal)
module: Skills
phase: 5 (Ops)
complexity: S
tags: [cobalt, task, journaling]
created: 2026-02-11
---

# 34 Automated Trade Journaling

## Objective
Remove manual data entry by having Cobalt write its own trade logs.

## Requirements
* [ ] Capture execution details (Entry, Exit, Size, P&L).
* [ ] Capture "Why?" (The Strategy Logic snapshot at moment of trade).
* [ ] Format as a Markdown table.
* [ ] Append to the **Daily Note** in Obsidian via Scribe.

## Format
| Time | Ticker | Side | P&L | Strategy | Confidence |
|------|--------|------|-----|----------|------------|


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/35 Untethering Tailscale VSCode.md
========================================

---
status: To Do
priority: P0
module: Ops
phase: 1
complexity: M
tags: [cobalt, task]
created: 2026-02-23
---
# 35 Untethering Tailscale VSCode
# Task: Untethering Tailscale VSCode

**Status**: To Do  
**Priority**: Medium  
**Tags**: infrastructure, development, network  
**Created**: 2026-02-22

## Description

Establish remote development mesh using Tailscale for secure, direct access to development servers without exposing ports to the public internet.

## Objectives

- Configure Tailscale on all development machines
- Set up VSCode Remote-SSH to connect via Tailscale IP
- Configure firewall rules to only allow Tailscale traffic
- Document the connection process

## Tasks

- [ ] Install Tailscale on all development machines
- [ ] Enable SSH on each machine via Tailscale
- [ ] Configure VSCode Remote-SSH plugin
- [ ] Create connection script for quick access
- [ ] Document network configuration in Obsidian

## Success Criteria

- VSCode can connect to development servers by Tailscale IP
- No exposed ports on public firewall
- Connection established in < 30 seconds

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/36 Feature Proposal Engine.md
========================================

---
status: Done
priority: P0
module: Interface
phase: 2
complexity: M
tags: [cobalt, task]
created: 2026-02-23
---
# 36 Feature Proposal Engine
# Task: Feature Proposal Engine

**Status**: Done  
**Priority**: High  
**Tags**: feature, HITL, approval  
**Created**: 2026-02-22

## Description

Create Pydantic models and infrastructure for the Human-In-The-Loop (HITL) Proposal Engine. This enables the agent to request approval before executing high-risk operations.

## Objectives

- Design Pydantic models for proposals and approvals
- Create proposal generation logic
- Implement approval status tracking
- Integrate with Mattermost for human review

## Tasks

- [ ] Create proposal_engine.py module
- [ ] Design ApprovalRequest Pydantic model
  - request_id, action_type, parameters, risk_level, justification, timestamp
- [ ] Design ApprovalResponse Pydantic model
  - approved, approver, timestamp, comments
- [ ] Implement proposal generation function
- [ ] Create approval status tracker
- [ ] Integrate with Mattermost for approval UI

## Success Criteria

- All high-risk operations require proposal
- Proposals are reviewed via Mattermost
- Approval decisions recorded in system
- Timeout-based rejection after 5 minutes

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/37 Feature Docker Sandbox.md
========================================

---
status: To Do
priority: P0
module: Security
phase: 2
complexity: XL
tags: [cobalt, task]
created: 2026-02-23
---
# 37 Feature Docker Sandbox
# Task: Feature Docker Sandbox

**Status**: To Do  
**Priority**: High  
**Tags**: security, docker, sandbox  
**Created**: 2026-02-22

## Description

Build secure code execution environment using Docker with Seccomp profiles. This enables safe execution of dynamically generated code without exposing the host system.

## Objectives

- Create Docker container for code execution
- Implement strict Seccomp security profile
- Add resource limits (CPU, memory)
- Create Python client for container management

## Tasks

- [ ] Create docker_sandbox.py module
- [ ] Design Seccomp profile (allow read/write/open, block socket/ptrace/execve)
- [ ] Implement container creation function
- [ ] Add resource limits (1 CPU, 512MB memory)
- [ ] Implement output capture and timeout
- [ ] Add cleanup function for containers

## Success Criteria

- Code executes in isolated container
- Seccomp profile blocks dangerous syscalls
- Container cleaned up after execution
- Timeout prevents hung execution

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/38 Refactor Switchboard Router.md
========================================

---
status: Done
priority: P0
module: Brain
phase: 4
complexity: M
tags: [cobalt, task, split-brain]
created: 2026-02-26
---
# 38 Split-Brain Architect (Cortex)

## Objective
Upgrade `cortex.py` from a dumb switchboard into an LLM-powered Chief of Staff that generates step-by-step Master Plans for the Engineering department.

## Acceptance Criteria
- [ ] Cortex uses `ask_structured` to generate an `OrchestrationState` plan.
- [ ] Cortex prints its plan to Mattermost before execution.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/39 Tool Playwright Browser.md
========================================

---
status: To Do
priority: P2
module: Tools
phase: 3
complexity: L
tags: [cobalt, task]
created: 2026-02-23
---
# 39 Tool Playwright Browser
# Task: Tool Playwright Browser

**Status**: To Do  
**Priority**: High  
**Tags**: tool, browser, automation  
**Created**: 2026-02-22

## Description

Add dynamic browser interaction capability using Playwright to the Cobalt Agent. This enables the agent to navigate websites, extract dynamic content, and perform complex web scraping.

## Objectives

- Integrate Playwright for headless browser automation
- Create tool wrapper for common browser actions
- Implement page navigation and content extraction
- Add session management for multi-step browsing

## Tasks

- [ ] Install playwright and dependencies
- [ ] Create browser.py module in tools directory
- [ ] Implement page_load(url: str) function
- [ ] Implement scrape_content(selector: str) function
- [ ] Implement click_element(selector: str) function
- [ ] Add timeout and error handling
- [ ] Document tool usage in Developer Docs

## Success Criteria

- Browser can navigate to any URL
- Dynamic content extraction works for SPA sites
- Sessions persist across related requests

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/40 Tool LastPass Integration.md
========================================

---
status: To Do
priority: P1
module: Security
phase: 3
complexity: L
tags: [cobalt, task]
created: 2026-02-23
---
# 40 Tool LastPass Integration
# Task: Tool LastPass Integration

**Status**: To Do  
**Priority**: High  
**Tags**: security, secrets, tool  
**Created**: 2026-02-22

## Description

Add secure secrets retrieval integration with LastPass API using Just-In-Time (JIT) credential management. This enables the agent to access credentials without storing them in plaintext.

## Objectives

- Integrate LastPass API for credential retrieval
- Implement credential caching with TTL expiration
- Create audit logging for all credential access
- Securely handle credentials in memory

## Tasks

- [ ] Set up LastPass API credentials
- [ ] Create lastpass.py module in tools directory
- [ ] Implement get_credential(vault_id: str, justification: str) function
- [ ] Implement credential caching with 5-minute TTL
- [ ] Add audit logging for all credential access
- [ ] Create credential cleanup function

## Success Criteria

- Credentials retrieved via LastPass JIT API
- Credentials expire after 5 minutes
- All access logged for audit trail
- Credentials never written to disk

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/41 Dynamic Persona Engine.md
========================================

---
status: Done
priority: P0
module: Brain
phase: 4
complexity: M
tags: [cobalt, task, split-brain]
created: 2026-02-26
---
# 41 Dynamic Persona Engine

## Objective
Refactor `prompt.py` and `persona.py` to allow Cortex to inject dynamic, highly restricted `.clinerules`-style personas into the Worker agents (e.g., stripping trading rules from the Engineering drone).

## Acceptance Criteria
- [ ] PromptEngine accepts dynamic persona overrides.
- [ ] The Forge initializes with a strictly limited "Mindless Drone" persona.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/42 Orchestration State Machine.md
========================================

---
status: Done
priority: P0
module: Brain
phase: 4
complexity: L
tags: [cobalt, task, split-brain]
created: 2026-02-26
---
# 42 Orchestration State Machine

## Objective
Create the "Manager's Clipboard" in Python memory to hold the context of a multi-step execution loop between the Architect and the Drone, preventing context loss.

## Acceptance Criteria
- [ ] Create `OrchestrationState` Pydantic model.
- [ ] Implement a loop that feeds sequential tasks to The Forge and records observations.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/43 Upgrade Playwright Browser Tool.md
========================================

---
status: In Progress
priority: P1
module: Tools
phase: 5
complexity: L
tags: [cobalt, playwright, browser, selenium]
created: 2026-02-27
---
# 43 Upgrade Playwright Browser Tool

## Objective
Evolve the basic DSL into an advanced search and analysis engine. Must support multi-step interaction arrays (handling cookie banners, logins), targeted DOM extraction (tables/articles), and clean markdown formatting to allow the Intel Drone to scrape financial sites without a paid API.

## Acceptance Criteria
- [ ] Multi-step interaction arrays (cookie banners, logins)
- [ ] Targeted DOM extraction (tables, articles)
- [ ] Clean markdown formatting
- [ ] Intel Drone can scrape financial sites without paid API

## Tasks
- [ ] Design new browser task DSL for multi-step interactions
- [ ] Implement cookie banner handling
- [ ] Implement login form automation
- [ ] Create targeted DOM extraction engine
- [ ] Implement markdown formatting for extracted content
- [ ] Test with sample financial websites

## Notes
- Replaces basic Selenium-based browser tool
- Supports headless and headed modes
- Integrates with Intel Drone for research tasks

========================================
FILE: logs/agent_2026-02-22.log
========================================

2026-02-22 08:00:32.863 | INFO     | cobalt_agent.skills.productivity.briefing:run:115 - ‚úÖ Briefing saved to: ‚úÖ Note saved: 0 - Inbox/Briefing_2026-02-22.md


========================================
FILE: logs/agent_2026-02-24.log
========================================

2026-02-24 18:16:16.325 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-24 18:16:16.325 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-24 18:21:16.337 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-24 18:21:16.337 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-24 18:21:36.567 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:372 - Bot shut down manually.
2026-02-24 18:21:36.620 | INFO     | cobalt_agent.interfaces.mattermost:disconnect:100 - Disconnected from Mattermost
2026-02-24 18:21:36.621 | INFO     | cobalt_agent.core.proposals:stop_monitoring:303 - Proposal Engine monitoring stopped
2026-02-24 18:21:36.621 | INFO     | cobalt_agent.core.scheduler:stop:35 - Scheduler stopped
2026-02-24 18:21:36.639 | ERROR    | cobalt_agent.memory.postgres:_generate_embedding:82 - Embedding failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
2026-02-24 18:24:01.988 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:01.994 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:01.996 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:01.996 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:01.996 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:01.997 | INFO     | cobalt_agent.persona:__init__:43 - Persona 'Cobalt' initialized
2026-02-24 18:24:01.997 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.003 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.003 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.003 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.003 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.021 | INFO     | cobalt_agent.memory.postgres:_init_db:61 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-24 18:24:02.021 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.027 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.027 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.027 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.027 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.029 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.034 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.034 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.034 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.035 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.036 | INFO     | cobalt_agent.brain.cortex:__init__:43 - üß† Cortex Online | Loaded 5 Departments from Config
2026-02-24 18:24:02.036 | INFO     | cobalt_agent.core.scheduler:start:25 - Scheduler started (Time Awareness Online)
2026-02-24 18:24:02.037 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.042 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.042 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.042 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.042 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.044 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.049 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.049 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.049 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.049 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.051 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.056 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.056 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.056 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.056 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.058 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.064 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.064 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.064 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.064 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.065 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.071 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.071 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.071 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.071 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.073 | INFO     | cobalt_agent.core.scheduler:add_job:45 - Scheduled task added: run (cron)
2026-02-24 18:24:02.073 | INFO     | __main__:__init__:47 - Cobalt Agent - System Initialized
2026-02-24 18:24:02.073 | INFO     | __main__:__init__:48 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-24 18:24:02.073 | INFO     | __main__:__init__:49 - Configuration Loaded: Debug Mode = True
2026-02-24 18:24:02.073 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.079 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.079 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.079 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.079 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.080 | INFO     | __main__:__init__:53 - Brain Initialized: Role-Based Routing Active (default)
2026-02-24 18:24:02.080 | INFO     | cobalt_agent.tools.tool_manager:register_tool:50 - Tool registered: search
2026-02-24 18:24:02.080 | INFO     | cobalt_agent.tools.tool_manager:register_tool:50 - Tool registered: browser
2026-02-24 18:24:02.081 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.086 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.086 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.086 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.086 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.087 | INFO     | cobalt_agent.tools.tool_manager:register_tool:50 - Tool registered: finance
2026-02-24 18:24:05.012 | INFO     | __main__:__init__:69 - Persona: Persona(name='Cobalt', roles=3, skills=4)
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:70 - Persona Roles: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:72 - ================================================================================
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:73 - SYSTEM PROMPT:
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:74 - ================================================================================
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:75 - 
### IDENTITY
You are Cobalt.

### ROLES
Your roles are: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine.

### OPERATIONAL DIRECTIVES
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.

### TONE
Maintain a tone that is: Hyper-competent and authoritative, Analytical and unshakeable, Extremely concise (high signal, zero noise), Professional (strictly avoid chatty filler, apologies, and sycophancy).

### CURRENT CONTEXT
- Current Date/Time: 2026-02-24 18:24:02
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- SearchTool: Use this tool for search tasks.
- BrowserTool: Use this tool for browser tasks.
- FinanceTool: Use this tool for finance tasks.

2026-02-24 18:24:05.013 | INFO     | __main__:__init__:76 - ================================================================================
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:78 - Memory System online
2026-02-24 18:24:05.013 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-24 18:24:05.053 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-24 18:24:05.053 | INFO     | cobalt_agent.core.proposals:__init__:59 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-24 18:24:05.053 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-24 18:24:05.063 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-24 18:24:05.063 | INFO     | cobalt_agent.core.proposals:connect_mattermost:75 - Proposal Engine: Mattermost connection established
2026-02-24 18:24:05.063 | INFO     | __main__:start_mattermost_interface:197 - ================================================================================
2026-02-24 18:24:05.063 | INFO     | __main__:start_mattermost_interface:198 - Cobalt Agent - Mattermost Interface Active
2026-02-24 18:24:05.063 | INFO     | __main__:start_mattermost_interface:199 - HITL Proposal Engine - Active
2026-02-24 18:24:05.063 | INFO     | __main__:start_mattermost_interface:200 - ================================================================================
2026-02-24 18:24:05.063 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:366 - Starting native WebSocket engine...
2026-02-24 18:24:05.064 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:351 - Connecting to native WebSocket engine: ws://100.70.206.126:8065/api/v4/websocket
2026-02-24 18:24:05.071 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:356 - Connected and authenticated via HTTP headers. Listening for messages...
2026-02-24 18:24:05.075 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"t3eiwm3fwpnqtgc3gto65i34eh","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-24 18:24:05.075 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"t3eiwm3fwpnqtgc3gto65i34eh","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-24 18:24:05.075 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-24 18:24:05.075 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-24 18:25:09.195 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-24 18:25:09.196 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-24 18:25:14.712 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}
2026-02-24 18:25:14.713 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}
2026-02-24 18:25:17.167 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event":"posted","data":{"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","mentions":"[\"oyc789ktdpn75norxkk11hi5dc\"]","post":"{\"id\":\"hzt9ce6ky3dppraez99py7ccao\",\"create_at\":1771975517134,\"update_at\":1771975517134,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"@cobalt what is your name?\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1771975517032\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"},"broadcast":{"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""},"seq":4}

2026-02-24 18:25:17.168 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"posted","data":{"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","mentions":"[\"oyc789ktdpn75norxkk11hi5dc\"]","post":"{\"id\":\"hzt9ce6ky3dppraez99py7ccao\",\"create_at\":1771975517134,\"update_at\":1771975517134,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"@cobalt what is your name?\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1771975517032\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"},"broadcast":{"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""},"seq":4}

2026-02-24 18:25:17.176 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:239 - Message received in channel badpmg1j5jf3mj7hxroe6xsrcw: @cobalt what is your name?
2026-02-24 18:25:17.177 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:252 - Routing message to Cortex in background thread...
2026-02-24 18:25:17.178 | INFO     | cobalt_agent.brain.cortex:route:54 - Direct route bypass triggered: Question detected.
2026-02-24 18:25:17.179 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:263 - No route match, generating conversational response...
2026-02-24 18:25:31.530 | INFO     | cobalt_agent.llm:generate_response:172 - Cobalt, LLM model version: ollama/qwen3-coder-next
2026-02-24 18:25:31.534 | INFO     | cobalt_agent.llm:generate_response:173 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-24 18:25:31.560 | INFO     | cobalt_agent.interfaces.mattermost:send_message_to_channel_id:177 - Message sent to channel badpmg1j5jf3mj7hxroe6xsrcw
2026-02-24 18:25:31.560 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","post":"{\"id\":\"nbpjch5e6bdx9etxgu7qapbh3h\",\"create_at\":1771975531550,\"update_at\":1771975531550,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"I‚Äôm Cobalt ‚Äî your AI Chief of Staff and Trading Assistant. Ready to help with strategy, analysis, or execution. What‚Äôs on your mind?\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 5}
2026-02-24 18:25:31.560 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:274 - Conversational response sent to Mattermost
2026-02-24 18:25:31.560 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","post":"{\"id\":\"nbpjch5e6bdx9etxgu7qapbh3h\",\"create_at\":1771975531550,\"update_at\":1771975531550,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"I‚Äôm Cobalt ‚Äî your AI Chief of Staff and Trading Assistant. Ready to help with strategy, analysis, or execution. What‚Äôs on your mind?\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 5}
2026-02-24 18:26:03.662 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:372 - Bot shut down manually.
2026-02-24 18:26:03.690 | INFO     | cobalt_agent.interfaces.mattermost:disconnect:100 - Disconnected from Mattermost
2026-02-24 18:26:03.690 | INFO     | cobalt_agent.core.proposals:stop_monitoring:303 - Proposal Engine monitoring stopped
2026-02-24 18:26:03.691 | INFO     | cobalt_agent.core.scheduler:stop:35 - Scheduler stopped


========================================
FILE: logs/agent_2026-02-25.log
========================================

2026-02-25 20:48:41.121 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-25 20:48:41.126 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-25 20:48:41.127 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-25 20:48:41.127 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-25 20:48:41.127 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-25 20:48:41.128 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-25 20:48:41.133 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-25 20:48:41.133 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-25 20:48:41.133 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-25 20:48:41.133 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-25 20:48:41.134 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-25 20:48:41.140 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-25 20:48:41.140 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-25 20:48:41.140 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-25 20:48:41.140 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-25 20:48:41.141 | INFO     | cobalt_agent.core.scheduler:add_job:45 - Scheduled task added: run (cron)
2026-02-25 20:48:41.142 | INFO     | __main__:__init__:47 - Cobalt Agent - System Initialized
2026-02-25 20:48:41.142 | INFO     | __main__:__init__:48 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-25 20:48:41.142 | INFO     | __main__:__init__:49 - Configuration Loaded: Debug Mode = True
2026-02-25 20:48:41.142 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-25 20:48:41.147 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-25 20:48:41.147 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-25 20:48:41.147 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-25 20:48:41.147 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-25 20:48:41.149 | INFO     | __main__:__init__:53 - Brain Initialized: Role-Based Routing Active (default)
2026-02-25 20:48:41.149 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: search
2026-02-25 20:48:41.149 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: browser
2026-02-25 20:48:41.149 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-25 20:48:41.154 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-25 20:48:41.154 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-25 20:48:41.154 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-25 20:48:41.154 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-25 20:48:41.156 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: finance
2026-02-25 20:48:41.156 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: read_file
2026-02-25 20:48:41.156 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: write_file
2026-02-25 20:48:41.156 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: list_directory
2026-02-25 20:48:42.941 | INFO     | __main__:__init__:69 - Persona: Persona(name='Cobalt', roles=3, skills=4)
2026-02-25 20:48:42.941 | INFO     | __main__:__init__:70 - Persona Roles: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine
2026-02-25 20:48:42.941 | INFO     | __main__:__init__:72 - ================================================================================
2026-02-25 20:48:42.942 | INFO     | __main__:__init__:73 - SYSTEM PROMPT:
2026-02-25 20:48:42.942 | INFO     | __main__:__init__:74 - ================================================================================
2026-02-25 20:48:42.942 | INFO     | __main__:__init__:75 - 
### IDENTITY
You are Cobalt.

### ROLES
Your roles are: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine.

### OPERATIONAL DIRECTIVES
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.

### TONE
Maintain a tone that is: Hyper-competent and authoritative, Analytical and unshakeable, Extremely concise (high signal, zero noise), Professional (strictly avoid chatty filler, apologies, and sycophancy).

### CURRENT CONTEXT
- Current Date/Time: 2026-02-25 20:48:41
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- SearchTool: Use this tool for search tasks.
- BrowserTool: Use this tool for browser tasks.
- FinanceTool: Use this tool for finance tasks.
- ReadFileTool: Use this tool for readfile tasks.
- WriteFileTool: Use this tool for writefile tasks.
- ListDirectoryTool: Use this tool for listdirectory tasks.

2026-02-25 20:48:42.942 | INFO     | __main__:__init__:76 - ================================================================================
2026-02-25 20:48:42.943 | INFO     | __main__:__init__:78 - Memory System online
2026-02-25 20:48:42.943 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-25 20:48:42.969 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-25 20:48:42.969 | INFO     | cobalt_agent.core.proposals:__init__:60 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-25 20:48:42.969 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-25 20:48:42.977 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-25 20:48:42.977 | INFO     | cobalt_agent.core.proposals:connect_mattermost:76 - Proposal Engine: Mattermost connection established
2026-02-25 20:48:42.977 | INFO     | __main__:start_mattermost_interface:197 - ================================================================================
2026-02-25 20:48:42.977 | INFO     | __main__:start_mattermost_interface:198 - Cobalt Agent - Mattermost Interface Active
2026-02-25 20:48:42.978 | INFO     | __main__:start_mattermost_interface:199 - HITL Proposal Engine - Active
2026-02-25 20:48:42.978 | INFO     | __main__:start_mattermost_interface:200 - ================================================================================
2026-02-25 20:48:42.978 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:476 - Starting native WebSocket engine...
2026-02-25 20:48:42.978 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:461 - Connecting to native WebSocket engine: ws://100.70.206.126:8065/api/v4/websocket
2026-02-25 20:48:42.983 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:466 - Connected and authenticated via HTTP headers. Listening for messages...
2026-02-25 20:48:42.984 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:470 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"unhk4ff3jtg45dgr4xircsryay","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-25 20:48:42.984 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"unhk4ff3jtg45dgr4xircsryay","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-25 20:48:42.985 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:470 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-25 20:48:42.985 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-25 20:49:11.933 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:470 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-25 20:49:11.934 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-25 20:49:17.401 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:470 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}
2026-02-25 20:49:17.402 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}
2026-02-25 20:49:17.539 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:470 - RAW WEBSOCKET PAYLOAD: {"event":"posted","data":{"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","mentions":"[\"oyc789ktdpn75norxkk11hi5dc\"]","post":"{\"id\":\"6icqnxnatjr13pgwx5tod5daah\",\"create_at\":1772070557525,\"update_at\":1772070557525,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"@cobalt I need an engineering task. Please use your tools to create a new file at src/cobalt_agent/tools/test_script.py. The file should just contain a simple python print statement saying \\\"Hello from the Forge\\\".\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1772070557388\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"},"broadcast":{"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""},"seq":4}

2026-02-25 20:49:17.540 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"posted","data":{"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","mentions":"[\"oyc789ktdpn75norxkk11hi5dc\"]","post":"{\"id\":\"6icqnxnatjr13pgwx5tod5daah\",\"create_at\":1772070557525,\"update_at\":1772070557525,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"@cobalt I need an engineering task. Please use your tools to create a new file at src/cobalt_agent/tools/test_script.py. The file should just contain a simple python print statement saying \\\"Hello from the Forge\\\".\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1772070557388\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"},"broadcast":{"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""},"seq":4}

2026-02-25 20:49:17.547 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:243 - Message received in channel badpmg1j5jf3mj7hxroe6xsrcw: @cobalt I need an engineering task. Please use your tools to create a new file at src/cobalt_agent/tools/test_script.py. The file should just contain a simple python print statement saying "Hello from the Forge".
2026-02-25 20:49:17.548 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:268 - Routing message to Cortex in background thread...
2026-02-25 20:49:17.549 | INFO     | cobalt_agent.memory.core:load_memory:90 - Memory loaded from data/memory.json
2026-02-25 20:49:17.549 | INFO     | cobalt_agent.brain.cortex:route:57 - ‚ö° Fast-Path Routing Triggered: ENGINEERING
2026-02-25 20:49:17.553 | INFO     | cobalt_agent.brain.engineering:__init__:19 - üõ†Ô∏è The Forge (Engineering) Online
2026-02-25 20:49:17.554 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-25 20:49:17.571 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-25 20:49:17.571 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-25 20:49:17.571 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-25 20:49:17.571 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-25 20:49:17.575 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: search
2026-02-25 20:49:17.575 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: browser
2026-02-25 20:49:17.576 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-25 20:49:17.587 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-25 20:49:17.587 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-25 20:49:17.588 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-25 20:49:17.588 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-25 20:49:17.590 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: finance
2026-02-25 20:49:17.590 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: read_file
2026-02-25 20:49:17.590 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: write_file
2026-02-25 20:49:17.590 | INFO     | cobalt_agent.tools.tool_manager:register_tool:57 - Tool registered: list_directory
2026-02-25 20:49:17.590 | INFO     | cobalt_agent.brain.engineering:run:60 - The Forge is analyzing an engineering request...
2026-02-25 20:49:33.384 | INFO     | cobalt_agent.llm:generate_response:172 - Cobalt, LLM model version: ollama/qwen3-coder-next
2026-02-25 20:49:33.387 | INFO     | cobalt_agent.llm:generate_response:173 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-25 20:49:33.388 | INFO     | cobalt_agent.tools.tool_manager:execute_tool:65 - Executing tool: write_file with args: {'filepath': 'src/cobalt_agent/tools/test_script.py', 'content': 'print("Hello from the Forge")'}
2026-02-25 20:49:33.388 | INFO     | cobalt_agent.core.proposals:__init__:60 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-25 20:49:33.388 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-25 20:49:33.397 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-25 20:49:33.397 | INFO     | cobalt_agent.core.proposals:connect_mattermost:76 - Proposal Engine: Mattermost connection established
2026-02-25 20:49:33.397 | INFO     | cobalt_agent.core.proposals:create_proposal:115 - Proposal created: [549f0cda] Write 29 bytes to src/cobalt_agent/tools/test_scri...
2026-02-25 20:49:33.444 | INFO     | cobalt_agent.core.proposals:send_proposal:170 - Proposal sent to Mattermost: [549f0cda]
2026-02-25 20:49:33.444 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:470 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"cobalt-approvals","channel_name":"cobalt-approvals","channel_type":"P","post":"{\"id\":\"drtzxkf6k7dy9kb5su8dye11xw\",\"create_at\":1772070573429,\"update_at\":1772070573429,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"ztp5ts1y9trnufpdus76aqsume\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"### üõ°Ô∏è ACTION PROPOSAL [549f0cda]\\n**Action:** `Write 29 bytes to src/cobalt_agent/tools/test_script.py`\\n\\n**Justification:** Agent requested file modification via WriteFileTool.\\n**Risk:** HIGH\\n\\n### ‚ö†Ô∏è ACTION REQUIRED: Reply exactly with 'Approve 549f0cda' to execute.\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"ztp5ts1y9trnufpdus76aqsume","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 5}
2026-02-25 20:49:33.444 | INFO     | cobalt_agent.core.proposals:__init__:60 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-25 20:49:33.444 | INFO     | cobalt_agent.core.proposals:set_approval_callback:296 - Approval callback set for task [549f0cda]
2026-02-25 20:49:33.444 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"cobalt-approvals","channel_name":"cobalt-approvals","channel_type":"P","post":"{\"id\":\"drtzxkf6k7dy9kb5su8dye11xw\",\"create_at\":1772070573429,\"update_at\":1772070573429,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"ztp5ts1y9trnufpdus76aqsume\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"### üõ°Ô∏è ACTION PROPOSAL [549f0cda]\\n**Action:** `Write 29 bytes to src/cobalt_agent/tools/test_script.py`\\n\\n**Justification:** Agent requested file modification via WriteFileTool.\\n**Risk:** HIGH\\n\\n### ‚ö†Ô∏è ACTION REQUIRED: Reply exactly with 'Approve 549f0cda' to execute.\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"ztp5ts1y9trnufpdus76aqsume","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 5}
2026-02-25 20:49:34.510 | INFO     | cobalt_agent.llm:generate_response:172 - Cobalt, LLM model version: ollama/qwen3-coder-next
2026-02-25 20:49:34.512 | INFO     | cobalt_agent.llm:generate_response:173 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-25 20:49:34.532 | INFO     | cobalt_agent.interfaces.mattermost:send_message_to_channel_id:177 - Message sent to channel badpmg1j5jf3mj7hxroe6xsrcw
2026-02-25 20:49:34.533 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:470 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","post":"{\"id\":\"bj11ak841fduucnbkrs8zjmbre\",\"create_at\":1772070574519,\"update_at\":1772070574519,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"I have submitted the proposal for your approval.\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 6}
2026-02-25 20:49:34.533 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","post":"{\"id\":\"bj11ak841fduucnbkrs8zjmbre\",\"create_at\":1772070574519,\"update_at\":1772070574519,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"I have submitted the proposal for your approval.\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 6}
2026-02-25 20:49:53.872 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:470 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"cobalt-approvals","channel_name":"cobalt-approvals","channel_type":"P","post":"{\"id\":\"tg3oa5opd3bd3g1izujk9itqoy\",\"create_at\":1772070593859,\"update_at\":1772070593859,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"ztp5ts1y9trnufpdus76aqsume\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"Approve 549f0cda\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1772070593736\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"ztp5ts1y9trnufpdus76aqsume","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 7}
2026-02-25 20:49:53.872 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"cobalt-approvals","channel_name":"cobalt-approvals","channel_type":"P","post":"{\"id\":\"tg3oa5opd3bd3g1izujk9itqoy\",\"create_at\":1772070593859,\"update_at\":1772070593859,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"ztp5ts1y9trnufpdus76aqsume\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"Approve 549f0cda\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1772070593736\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"ztp5ts1y9trnufpdus76aqsume","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 7}
2026-02-25 20:49:53.881 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:243 - Message received in channel ztp5ts1y9trnufpdus76aqsume: Approve 549f0cda
2026-02-25 20:49:53.881 | INFO     | cobalt_agent.core.proposals:__init__:60 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-25 20:49:53.882 | INFO     | cobalt_agent.core.proposals:handle_approval_response:215 - Proposal approved: [549f0cda]
2026-02-25 20:49:53.882 | INFO     | cobalt_agent.tools.filesystem:execute_write:146 - Proposal Engine executed write to: src/cobalt_agent/tools/test_script.py (29 bytes)
2026-02-25 20:49:53.898 | INFO     | cobalt_agent.interfaces.mattermost:send_message_to_channel_id:177 - Message sent to channel ztp5ts1y9trnufpdus76aqsume
2026-02-25 20:49:53.899 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:470 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"cobalt-approvals","channel_name":"cobalt-approvals","channel_type":"P","post":"{\"id\":\"3st1o5ubwbbjx8jfg6zjbwhj4w\",\"create_at\":1772070593889,\"update_at\":1772070593889,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"ztp5ts1y9trnufpdus76aqsume\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"‚úÖ Approval received for task [549f0cda]. Action executed successfully.\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"ztp5ts1y9trnufpdus76aqsume","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 8}
2026-02-25 20:49:53.899 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"cobalt-approvals","channel_name":"cobalt-approvals","channel_type":"P","post":"{\"id\":\"3st1o5ubwbbjx8jfg6zjbwhj4w\",\"create_at\":1772070593889,\"update_at\":1772070593889,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"ztp5ts1y9trnufpdus76aqsume\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"‚úÖ Approval received for task [549f0cda]. Action executed successfully.\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"ztp5ts1y9trnufpdus76aqsume","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 8}
2026-02-25 20:55:42.969 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:470 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 9}
2026-02-25 20:55:42.969 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 9}


========================================
FILE: logs/agent_2026-02-26.log
========================================

2026-02-26 20:22:59.294 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-26 20:22:59.294 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-26 20:22:59.459 | ERROR    | cobalt_agent.llm:_call_provider:162 - LLM Call Failed: litellm.NotFoundError: GeminiException - 
2026-02-26 20:22:59.459 | ERROR    | cobalt_agent.llm:ask:237 - Ask Failed: litellm.NotFoundError: GeminiException - 
2026-02-26 20:22:59.460 | ERROR    | cobalt_agent.services.scheduler:generate_morning_briefing:115 - Failed to generate Morning Briefing: litellm.NotFoundError: GeminiException - 
2026-02-26 20:22:59.460 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-26 20:22:59.475 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-26 20:22:59.475 | INFO     | cobalt_agent.core.proposals:__init__:60 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-26 20:22:59.475 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-26 20:22:59.479 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-26 20:22:59.479 | INFO     | cobalt_agent.core.proposals:connect_mattermost:76 - Proposal Engine: Mattermost connection established
2026-02-26 20:22:59.479 | INFO     | __main__:start_mattermost_interface:192 - ================================================================================
2026-02-26 20:22:59.479 | INFO     | __main__:start_mattermost_interface:193 - Cobalt Agent - Mattermost Interface Active
2026-02-26 20:22:59.479 | INFO     | __main__:start_mattermost_interface:194 - HITL Proposal Engine - Active
2026-02-26 20:22:59.479 | INFO     | __main__:start_mattermost_interface:195 - ================================================================================
2026-02-26 20:22:59.479 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:483 - Starting native WebSocket engine...
2026-02-26 20:22:59.479 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:468 - Connecting to native WebSocket engine: ws://100.70.206.126:8065/api/v4/websocket
2026-02-26 20:22:59.482 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:473 - Connected and authenticated via HTTP headers. Listening for messages...
2026-02-26 20:22:59.482 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"baqsprfyw3rourfqhskmj95gzc","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-26 20:22:59.482 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"baqsprfyw3rourfqhskmj95gzc","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-26 20:22:59.483 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-26 20:22:59.484 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-26 20:27:59.487 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-26 20:27:59.488 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-26 20:29:39.643 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-26 20:29:39.650 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-26 20:29:39.651 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-26 20:29:39.651 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-26 20:29:39.651 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-26 20:29:39.653 | INFO     | cobalt_agent.persona:__init__:43 - Persona 'Cobalt' initialized
2026-02-26 20:29:39.653 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-26 20:29:39.658 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-26 20:29:39.659 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-26 20:29:39.659 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-26 20:29:39.659 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-26 20:29:39.693 | INFO     | cobalt_agent.memory.postgres:_init_db:61 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-26 20:29:39.694 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-26 20:29:39.700 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-26 20:29:39.700 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-26 20:29:39.700 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-26 20:29:39.700 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-26 20:29:39.701 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-26 20:29:39.707 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-26 20:29:39.707 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-26 20:29:39.707 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-26 20:29:39.707 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-26 20:29:39.709 | INFO     | cobalt_agent.brain.cortex:__init__:43 - üß† Cortex Online | Loaded 6 Departments from Config
2026-02-26 20:29:39.709 | INFO     | __main__:__init__:39 - Cobalt Agent - System Initialized
2026-02-26 20:29:39.709 | INFO     | __main__:__init__:40 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-26 20:29:39.709 | INFO     | __main__:__init__:41 - Configuration Loaded: Debug Mode = True
2026-02-26 20:29:39.709 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-26 20:29:39.714 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-26 20:29:39.714 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-26 20:29:39.714 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-26 20:29:39.714 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-26 20:29:39.716 | INFO     | __main__:__init__:45 - Brain Initialized: Role-Based Routing Active (default)
2026-02-26 20:29:39.716 | INFO     | cobalt_agent.tools.tool_manager:register_tool:62 - Tool registered: search
2026-02-26 20:29:39.716 | INFO     | cobalt_agent.tools.tool_manager:register_tool:62 - Tool registered: browser
2026-02-26 20:29:39.716 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-26 20:29:39.721 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-26 20:29:39.721 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-26 20:29:39.721 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-26 20:29:39.721 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-26 20:29:39.722 | INFO     | cobalt_agent.tools.tool_manager:register_tool:62 - Tool registered: finance
2026-02-26 20:29:39.722 | INFO     | cobalt_agent.tools.tool_manager:register_tool:62 - Tool registered: read_file
2026-02-26 20:29:39.722 | INFO     | cobalt_agent.tools.tool_manager:register_tool:62 - Tool registered: write_file
2026-02-26 20:29:39.722 | INFO     | cobalt_agent.tools.tool_manager:register_tool:62 - Tool registered: list_directory
2026-02-26 20:29:39.732 | INFO     | cobalt_agent.memory.postgres:_init_db:61 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-26 20:29:39.732 | INFO     | cobalt_agent.tools.tool_manager:register_tool:62 - Tool registered: search_knowledge
2026-02-26 20:29:41.624 | INFO     | __main__:__init__:61 - Persona: Persona(name='Cobalt', roles=3, skills=4)
2026-02-26 20:29:41.625 | INFO     | __main__:__init__:62 - Persona Roles: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine
2026-02-26 20:29:41.626 | INFO     | __main__:__init__:64 - ================================================================================
2026-02-26 20:29:41.626 | INFO     | __main__:__init__:65 - SYSTEM PROMPT:
2026-02-26 20:29:41.627 | INFO     | __main__:__init__:66 - ================================================================================
2026-02-26 20:29:41.627 | INFO     | __main__:__init__:67 - 
### IDENTITY
You are Cobalt.

### ROLES
Your roles are: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine.

### OPERATIONAL DIRECTIVES
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.

### TONE
Maintain a tone that is: Hyper-competent and authoritative, Analytical and unshakeable, Extremely concise (high signal, zero noise), Professional (strictly avoid chatty filler, apologies, and sycophancy).

### CURRENT CONTEXT
- Current Date/Time: 2026-02-26 20:29:39
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- SearchTool: Use this tool for search tasks.
- BrowserTool: Use this tool for browser tasks.
- FinanceTool: Use this tool for finance tasks.
- ReadFileTool: Use this tool for readfile tasks.
- WriteFileTool: Use this tool for writefile tasks.
- ListDirectoryTool: Use this tool for listdirectory tasks.
- KnowledgeSearchTool: Use this tool for knowledgesearch tasks.

2026-02-26 20:29:41.627 | INFO     | __main__:__init__:68 - ================================================================================
2026-02-26 20:29:41.628 | INFO     | __main__:__init__:70 - Memory System online
2026-02-26 20:29:41.638 | INFO     | cobalt_agent.services.scheduler:_setup_jobs:36 - ‚è±Ô∏è Scheduler: Morning Briefing job registered (Mon-Fri 08:00).
2026-02-26 20:29:41.639 | INFO     | cobalt_agent.services.scheduler:start:41 - ‚è±Ô∏è Cobalt Heartbeat (Scheduler) Online.
2026-02-26 20:29:41.639 | INFO     | cobalt_agent.services.scheduler:start:44 - üß™ Executing Immediate Test Override...
2026-02-26 20:29:41.640 | INFO     | cobalt_agent.services.scheduler:generate_morning_briefing:56 - ‚òÄÔ∏è Running Automated Morning Briefing...
2026-02-26 20:29:41.640 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-26 20:29:41.657 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-26 20:29:41.658 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-26 20:29:41.658 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-26 20:29:41.658 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-26 20:29:41.662 | INFO     | cobalt_agent.services.scheduler:generate_morning_briefing:88 - Calling Gemini 3.1 Pro for market data...
2026-02-26 20:29:41.662 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-26 20:29:41.675 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-26 20:29:41.675 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-26 20:29:41.675 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-26 20:29:41.675 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-26 20:30:16.530 | INFO     | cobalt_agent.services.scheduler:generate_morning_briefing:106 - ‚úÖ Morning Briefing successfully written to /Users/cobalt/cobalt/docs/0 - Inbox/Morning_Briefing_2026-02-26.md
2026-02-26 20:30:16.530 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-26 20:30:16.560 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-26 20:30:16.630 | INFO     | cobalt_agent.interfaces.mattermost:send_message:143 - Message sent to #town-square in team cobalt-bridge
2026-02-26 20:30:16.630 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-26 20:30:16.636 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-26 20:30:16.637 | INFO     | cobalt_agent.core.proposals:__init__:60 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-26 20:30:16.637 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-26 20:30:16.642 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-26 20:30:16.642 | INFO     | cobalt_agent.core.proposals:connect_mattermost:76 - Proposal Engine: Mattermost connection established
2026-02-26 20:30:16.642 | INFO     | __main__:start_mattermost_interface:192 - ================================================================================
2026-02-26 20:30:16.643 | INFO     | __main__:start_mattermost_interface:193 - Cobalt Agent - Mattermost Interface Active
2026-02-26 20:30:16.643 | INFO     | __main__:start_mattermost_interface:194 - HITL Proposal Engine - Active
2026-02-26 20:30:16.643 | INFO     | __main__:start_mattermost_interface:195 - ================================================================================
2026-02-26 20:30:16.643 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:483 - Starting native WebSocket engine...
2026-02-26 20:30:16.644 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:468 - Connecting to native WebSocket engine: ws://100.70.206.126:8065/api/v4/websocket
2026-02-26 20:30:16.649 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:473 - Connected and authenticated via HTTP headers. Listening for messages...
2026-02-26 20:30:16.649 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"3egcib55cjbwfkw9ntxf6z5xpr","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-26 20:30:16.649 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"3egcib55cjbwfkw9ntxf6z5xpr","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-26 20:35:16.665 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-26 20:35:16.665 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-26 20:39:12.352 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-26 20:39:12.352 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-26 20:39:12.376 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}
2026-02-26 20:39:12.376 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}


========================================
FILE: logs/agent_2026-02-27.log
========================================

### AVAILABLE TOOLS
- SearchTool: Use this tool for search tasks.
- BrowserTool: Use this tool for browser tasks.
- FinanceTool: Use this tool for finance tasks.
- ReadFileTool: Use this tool for readfile tasks.
- WriteFileTool: Use this tool for writefile tasks.
- ListDirectoryTool: Use this tool for listdirectory tasks.
- KnowledgeSearchTool: Use this tool for knowledgesearch tasks.

2026-02-27 13:54:26.847 | INFO     | __main__:__init__:68 - ================================================================================
2026-02-27 13:54:26.847 | INFO     | __main__:__init__:70 - Memory System online
2026-02-27 13:54:26.856 | INFO     | cobalt_agent.services.scheduler:_setup_jobs:36 - ‚è±Ô∏è Scheduler: Morning Briefing job registered (Mon-Fri 08:00).
2026-02-27 13:54:26.857 | INFO     | cobalt_agent.services.scheduler:start:41 - ‚è±Ô∏è Cobalt Heartbeat (Scheduler) Online.
2026-02-27 13:54:26.858 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-27 13:54:26.895 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-27 13:54:26.895 | INFO     | cobalt_agent.core.proposals:__init__:60 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-27 13:54:26.896 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-27 13:54:26.904 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-27 13:54:26.905 | INFO     | cobalt_agent.core.proposals:connect_mattermost:76 - Proposal Engine: Mattermost connection established
2026-02-27 13:54:26.905 | INFO     | __main__:start_mattermost_interface:192 - ================================================================================
2026-02-27 13:54:26.905 | INFO     | __main__:start_mattermost_interface:193 - Cobalt Agent - Mattermost Interface Active
2026-02-27 13:54:26.905 | INFO     | __main__:start_mattermost_interface:194 - HITL Proposal Engine - Active
2026-02-27 13:54:26.905 | INFO     | __main__:start_mattermost_interface:195 - ================================================================================
2026-02-27 13:54:26.906 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:483 - Starting native WebSocket engine...
2026-02-27 13:54:26.906 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:468 - Connecting to native WebSocket engine: ws://100.70.206.126:8065/api/v4/websocket
2026-02-27 13:54:26.913 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:473 - Connected and authenticated via HTTP headers. Listening for messages...
2026-02-27 13:54:26.913 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"19ykrwb8ofbh3fmu3pix9jfnsw","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-27 13:54:26.914 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"19ykrwb8ofbh3fmu3pix9jfnsw","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-27 13:54:26.916 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-27 13:54:26.916 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-27 13:59:26.926 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-27 13:59:26.927 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-27 15:35:02.175 | INFO     | cobalt_agent.config:load_config:434 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-27 15:35:02.184 | INFO     | cobalt_agent.config:load_config:464 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-27 15:35:02.185 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-27 15:35:02.185 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-27 15:35:02.185 | INFO     | cobalt_agent.config:load_config:495 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-27 15:35:02.187 | INFO     | cobalt_agent.persona:__init__:43 - Persona 'Cobalt' initialized
2026-02-27 15:35:02.187 | INFO     | cobalt_agent.config:load_config:434 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-27 15:35:02.195 | INFO     | cobalt_agent.config:load_config:464 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-27 15:35:02.195 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-27 15:35:02.195 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-27 15:35:02.195 | INFO     | cobalt_agent.config:load_config:495 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-27 15:35:02.228 | INFO     | cobalt_agent.memory.postgres:_init_db:61 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-27 15:35:02.228 | INFO     | cobalt_agent.config:load_config:434 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-27 15:35:02.237 | INFO     | cobalt_agent.config:load_config:464 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-27 15:35:02.237 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-27 15:35:02.237 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-27 15:35:02.237 | INFO     | cobalt_agent.config:load_config:495 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-27 15:35:02.239 | INFO     | cobalt_agent.config:load_config:434 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-27 15:35:02.247 | INFO     | cobalt_agent.config:load_config:464 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-27 15:35:02.247 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-27 15:35:02.247 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-27 15:35:02.247 | INFO     | cobalt_agent.config:load_config:495 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-27 15:35:02.248 | INFO     | cobalt_agent.brain.cortex:__init__:61 - üß† Cortex Online | Loaded 6 Departments from Config
2026-02-27 15:35:02.248 | INFO     | __main__:__init__:39 - Cobalt Agent - System Initialized
2026-02-27 15:35:02.248 | INFO     | __main__:__init__:40 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-27 15:35:02.248 | INFO     | __main__:__init__:41 - Configuration Loaded: Debug Mode = True
2026-02-27 15:35:02.248 | INFO     | cobalt_agent.config:load_config:434 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-27 15:35:02.256 | INFO     | cobalt_agent.config:load_config:464 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-27 15:35:02.256 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-27 15:35:02.257 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-27 15:35:02.257 | INFO     | cobalt_agent.config:load_config:495 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-27 15:35:02.258 | INFO     | __main__:__init__:45 - Brain Initialized: Role-Based Routing Active (default)
2026-02-27 15:35:02.258 | INFO     | cobalt_agent.tools.tool_manager:register_tool:65 - Tool registered: search
2026-02-27 15:35:02.258 | INFO     | cobalt_agent.tools.tool_manager:register_tool:65 - Tool registered: browser
2026-02-27 15:35:02.258 | INFO     | cobalt_agent.config:load_config:434 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-27 15:35:02.266 | INFO     | cobalt_agent.config:load_config:464 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-27 15:35:02.266 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-27 15:35:02.266 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-27 15:35:02.266 | INFO     | cobalt_agent.config:load_config:495 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-27 15:35:02.267 | INFO     | cobalt_agent.tools.tool_manager:register_tool:65 - Tool registered: finance
2026-02-27 15:35:02.267 | INFO     | cobalt_agent.tools.tool_manager:register_tool:65 - Tool registered: read_file
2026-02-27 15:35:02.267 | INFO     | cobalt_agent.tools.tool_manager:register_tool:65 - Tool registered: write_file
2026-02-27 15:35:02.267 | INFO     | cobalt_agent.tools.tool_manager:register_tool:65 - Tool registered: list_directory
2026-02-27 15:35:02.277 | INFO     | cobalt_agent.memory.postgres:_init_db:61 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-27 15:35:02.277 | INFO     | cobalt_agent.tools.tool_manager:register_tool:65 - Tool registered: search_knowledge
2026-02-27 15:35:04.432 | INFO     | __main__:__init__:61 - Persona: Persona(name='Cobalt', roles=3, skills=4)
2026-02-27 15:35:04.433 | INFO     | __main__:__init__:62 - Persona Roles: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine
2026-02-27 15:35:04.433 | INFO     | __main__:__init__:64 - ================================================================================
2026-02-27 15:35:04.434 | INFO     | __main__:__init__:65 - SYSTEM PROMPT:
2026-02-27 15:35:04.434 | INFO     | __main__:__init__:66 - ================================================================================
2026-02-27 15:35:04.434 | INFO     | __main__:__init__:67 - 
### IDENTITY
You are Cobalt.

### ROLES
Your roles are: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine.

### OPERATIONAL DIRECTIVES
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.

### TONE
Maintain a tone that is: Hyper-competent and authoritative, Analytical and unshakeable, Extremely concise (high signal, zero noise), Professional (strictly avoid chatty filler, apologies, and sycophancy).

### CURRENT CONTEXT
- Current Date/Time: 2026-02-27 15:35:02
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- SearchTool: Use this tool for search tasks.
- NoneType: Use this tool for nonetype tasks.
- BrowserTool: Use this tool for browser tasks.
- ModelMetaclass: Use this tool for modelmetaclass tasks.
- FinanceTool: Use this tool for finance tasks.
- NoneType: Use this tool for nonetype tasks.
- ReadFileTool: Use this tool for readfile tasks.
- ModelMetaclass: Use this tool for modelmetaclass tasks.
- WriteFileTool: Use this tool for writefile tasks.
- ModelMetaclass: Use this tool for modelmetaclass tasks.
- ListDirectoryTool: Use this tool for listdirectory tasks.
- ModelMetaclass: Use this tool for modelmetaclass tasks.
- KnowledgeSearchTool: Use this tool for knowledgesearch tasks.
- NoneType: Use this tool for nonetype tasks.

2026-02-27 15:35:04.434 | INFO     | __main__:__init__:68 - ================================================================================
2026-02-27 15:35:04.434 | INFO     | __main__:__init__:70 - Memory System online
2026-02-27 15:35:04.440 | INFO     | cobalt_agent.services.scheduler:_setup_jobs:36 - ‚è±Ô∏è Scheduler: Morning Briefing job registered (Mon-Fri 08:00).
2026-02-27 15:35:04.440 | INFO     | cobalt_agent.services.scheduler:start:41 - ‚è±Ô∏è Cobalt Heartbeat (Scheduler) Online.
2026-02-27 15:35:04.441 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-27 15:35:04.452 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-27 15:35:04.452 | INFO     | cobalt_agent.core.proposals:__init__:60 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-27 15:35:04.452 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-27 15:35:04.456 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-27 15:35:04.456 | INFO     | cobalt_agent.core.proposals:connect_mattermost:76 - Proposal Engine: Mattermost connection established
2026-02-27 15:35:04.456 | INFO     | __main__:start_mattermost_interface:192 - ================================================================================
2026-02-27 15:35:04.457 | INFO     | __main__:start_mattermost_interface:193 - Cobalt Agent - Mattermost Interface Active
2026-02-27 15:35:04.457 | INFO     | __main__:start_mattermost_interface:194 - HITL Proposal Engine - Active
2026-02-27 15:35:04.457 | INFO     | __main__:start_mattermost_interface:195 - ================================================================================
2026-02-27 15:35:04.457 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:483 - Starting native WebSocket engine...
2026-02-27 15:35:04.457 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:468 - Connecting to native WebSocket engine: ws://100.70.206.126:8065/api/v4/websocket
2026-02-27 15:35:04.461 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:473 - Connected and authenticated via HTTP headers. Listening for messages...
2026-02-27 15:35:04.462 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"mpz5h9dbni8jumykkg5epx8roh","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-27 15:35:04.462 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"mpz5h9dbni8jumykkg5epx8roh","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-27 15:35:04.462 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-27 15:35:04.462 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-27 15:40:04.465 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-27 15:40:04.466 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-27 20:39:12.348 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}
2026-02-27 20:39:12.348 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}
2026-02-27 20:39:12.367 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:477 - RAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 4}
2026-02-27 20:39:12.367 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 4}


========================================
FILE: logs/cobalt_agent_2026-02-15.log
========================================

2026-02-15 11:25:50.793 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.797 | INFO     | cobalt_agent.persona:__init__:43 - Persona 'Cobalt' initialized
2026-02-15 11:25:50.842 | INFO     | cobalt_agent.memory.postgres:_init_db:52 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-15 11:25:50.842 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.846 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5:14b
2026-02-15 11:25:50.846 | INFO     | cobalt_agent.brain.cortex:__init__:40 - üß† Cortex Online | Loaded 0 Departments from Config
2026-02-15 11:25:50.847 | INFO     | cobalt_agent.core.scheduler:start:25 - Scheduler started (Time Awareness Online)
2026-02-15 11:25:50.847 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.851 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5:14b
2026-02-15 11:25:50.871 | WARNING  | cobalt_agent.skills.productivity.scribe:__init__:35 - ‚ö†Ô∏è Obsidian Vault not found at /home/dejan/Documents/Think. Scribe functions will fail.
2026-02-15 11:25:50.871 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.876 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.879 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5:14b
2026-02-15 11:25:50.893 | WARNING  | cobalt_agent.skills.productivity.scribe:__init__:35 - ‚ö†Ô∏è Obsidian Vault not found at /home/dejan/Documents/Think. Scribe functions will fail.
2026-02-15 11:25:50.894 | INFO     | cobalt_agent.core.scheduler:add_job:45 - Scheduled task added: run (cron)
2026-02-15 11:25:50.894 | INFO     | __main__:main:95 - Cobalt Agent - System Initialized
2026-02-15 11:25:50.894 | INFO     | __main__:main:96 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-15 11:25:50.894 | INFO     | __main__:main:97 - Configuration Loaded: Debug Mode = True
2026-02-15 11:25:50.894 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5:14b
2026-02-15 11:25:50.894 | INFO     | __main__:main:102 - Brain Initialized: ollama/qwen2.5:14b
2026-02-15 11:25:50.894 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: search
2026-02-15 11:25:50.894 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: browser
2026-02-15 11:25:50.894 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.898 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: finance
2026-02-15 11:25:53.004 | INFO     | __main__:main:121 - Persona: Persona(name='Cobalt', roles=4, skills=3)
2026-02-15 11:25:53.005 | INFO     | __main__:main:122 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-15 11:25:53.005 | INFO     | __main__:main:126 - ================================================================================
2026-02-15 11:25:53.005 | INFO     | __main__:main:127 - SYSTEM PROMPT:
2026-02-15 11:25:53.005 | INFO     | __main__:main:128 - ================================================================================
2026-02-15 11:25:53.005 | INFO     | __main__:main:129 - 
You are Cobalt, a Chief of Staff, Software Architect, Senior Developer, Business Analyst.
Your Tone: Professional, Concise, Data-Driven, Analytical.

### CURRENT CONTEXT
- Current Date/Time: 2026-02-15 11:25:50
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- Prioritize risk management
- Verify all data
- Protect capital
- Analyze data before deciding
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- <cobalt_agent.tools.search.SearchTool object at 0x11b05e710>: No description provided.
- <cobalt_agent.tools.browser.BrowserTool object at 0x11b05e490>: No description provided.
- <cobalt_agent.tools.finance.FinanceTool object at 0x11b05ed50>: No description provided.

2026-02-15 11:25:53.006 | INFO     | __main__:main:130 - ================================================================================
2026-02-15 11:25:53.006 | INFO     | __main__:main:133 - Memory System online
2026-02-15 11:25:53.006 | INFO     | __main__:main:136 - ================================================================================
2026-02-15 11:25:53.006 | INFO     | __main__:main:137 - Starting interactive CLI interface...
2026-02-15 11:25:53.006 | INFO     | __main__:main:138 - ================================================================================
2026-02-15 11:25:53.006 | INFO     | cobalt_agent.interface:__init__:29 - CLI initialized with Brain connected
2026-02-15 12:33:43.956 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:43.960 | INFO     | cobalt_agent.persona:__init__:43 - Persona 'Cobalt' initialized
2026-02-15 12:33:43.991 | INFO     | cobalt_agent.memory.postgres:_init_db:52 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-15 12:33:43.991 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:43.995 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5-coder:32b
2026-02-15 12:33:43.995 | INFO     | cobalt_agent.brain.cortex:__init__:40 - üß† Cortex Online | Loaded 0 Departments from Config
2026-02-15 12:33:43.995 | INFO     | cobalt_agent.core.scheduler:start:25 - Scheduler started (Time Awareness Online)
2026-02-15 12:33:43.995 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:43.999 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5-coder:32b
2026-02-15 12:33:44.017 | WARNING  | cobalt_agent.skills.productivity.scribe:__init__:35 - ‚ö†Ô∏è Obsidian Vault not found at /home/dejan/Documents/Think. Scribe functions will fail.
2026-02-15 12:33:44.017 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:44.021 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:44.025 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5-coder:32b
2026-02-15 12:33:44.039 | WARNING  | cobalt_agent.skills.productivity.scribe:__init__:35 - ‚ö†Ô∏è Obsidian Vault not found at /home/dejan/Documents/Think. Scribe functions will fail.
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.core.scheduler:add_job:45 - Scheduled task added: run (cron)
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.main:__init__:45 - Cobalt Agent - System Initialized
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.main:__init__:46 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.main:__init__:47 - Configuration Loaded: Debug Mode = True
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5-coder:32b
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.main:__init__:51 - Brain Initialized: ollama/qwen2.5-coder:32b
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: search
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: browser
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:44.043 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: finance
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:67 - Persona: Persona(name='Cobalt', roles=4, skills=3)
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:68 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:70 - ================================================================================
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:71 - SYSTEM PROMPT:
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:72 - ================================================================================
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:73 - 
You are Cobalt, a Chief of Staff, Software Architect, Senior Developer, Business Analyst.
Your Tone: Professional, Concise, Data-Driven, Analytical.

### CURRENT CONTEXT
- Current Date/Time: 2026-02-15 12:33:44
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- Prioritize risk management
- Verify all data
- Protect capital
- Analyze data before deciding
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- <cobalt_agent.tools.search.SearchTool object at 0x10ff9cf50>: No description provided.
- <cobalt_agent.tools.browser.BrowserTool object at 0x10ff9ccd0>: No description provided.
- <cobalt_agent.tools.finance.FinanceTool object at 0x10ff9d590>: No description provided.

2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:74 - ================================================================================
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:76 - Memory System online


========================================
FILE: logs/mattermost_session.log
========================================

[32m2026-02-27 15:35:02.175[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m434[0m - [1mLoading configuration from: /Users/cobalt/cobalt/configs[0m
[32m2026-02-27 15:35:02.184[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m464[0m - [1müîë COBALT_MASTER_KEY detected. Unlocking secure vault...[0m
[32m2026-02-27 15:35:02.185[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36munlock[0m:[36m44[0m - [1müîê Vault successfully unlocked into memory.[0m
[32m2026-02-27 15:35:02.185[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36mlock[0m:[36m55[0m - [1müîí Vault locked. Secrets wiped from RAM.[0m
[32m2026-02-27 15:35:02.185[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m495[0m - [1müîí Vault secrets loaded into runtime RAM and vault locked.[0m
[32m2026-02-27 15:35:02.187[0m | [1mINFO    [0m | [36mcobalt_agent.persona[0m:[36m__init__[0m:[36m43[0m - [1mPersona 'Cobalt' initialized[0m
[32m2026-02-27 15:35:02.187[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m434[0m - [1mLoading configuration from: /Users/cobalt/cobalt/configs[0m
[32m2026-02-27 15:35:02.195[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m464[0m - [1müîë COBALT_MASTER_KEY detected. Unlocking secure vault...[0m
[32m2026-02-27 15:35:02.195[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36munlock[0m:[36m44[0m - [1müîê Vault successfully unlocked into memory.[0m
[32m2026-02-27 15:35:02.195[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36mlock[0m:[36m55[0m - [1müîí Vault locked. Secrets wiped from RAM.[0m
[32m2026-02-27 15:35:02.195[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m495[0m - [1müîí Vault secrets loaded into runtime RAM and vault locked.[0m
[32m2026-02-27 15:35:02.228[0m | [1mINFO    [0m | [36mcobalt_agent.memory.postgres[0m:[36m_init_db[0m:[36m61[0m - [1müß† Connected to Postgres Memory (Vector Ready)[0m
[32m2026-02-27 15:35:02.228[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m434[0m - [1mLoading configuration from: /Users/cobalt/cobalt/configs[0m
[32m2026-02-27 15:35:02.237[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m464[0m - [1müîë COBALT_MASTER_KEY detected. Unlocking secure vault...[0m
[32m2026-02-27 15:35:02.237[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36munlock[0m:[36m44[0m - [1müîê Vault successfully unlocked into memory.[0m
[32m2026-02-27 15:35:02.237[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36mlock[0m:[36m55[0m - [1müîí Vault locked. Secrets wiped from RAM.[0m
[32m2026-02-27 15:35:02.237[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m495[0m - [1müîí Vault secrets loaded into runtime RAM and vault locked.[0m
[32m2026-02-27 15:35:02.239[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m434[0m - [1mLoading configuration from: /Users/cobalt/cobalt/configs[0m
[32m2026-02-27 15:35:02.247[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m464[0m - [1müîë COBALT_MASTER_KEY detected. Unlocking secure vault...[0m
[32m2026-02-27 15:35:02.247[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36munlock[0m:[36m44[0m - [1müîê Vault successfully unlocked into memory.[0m
[32m2026-02-27 15:35:02.247[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36mlock[0m:[36m55[0m - [1müîí Vault locked. Secrets wiped from RAM.[0m
[32m2026-02-27 15:35:02.247[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m495[0m - [1müîí Vault secrets loaded into runtime RAM and vault locked.[0m
[32m2026-02-27 15:35:02.248[0m | [1mINFO    [0m | [36mcobalt_agent.brain.cortex[0m:[36m__init__[0m:[36m61[0m - [1müß† Cortex Online | Loaded 6 Departments from Config[0m
[32m2026-02-27 15:35:02.248[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m39[0m - [1mCobalt Agent - System Initialized[0m
[32m2026-02-27 15:35:02.248[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m40[0m - [1mPython Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)][0m
[32m2026-02-27 15:35:02.248[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m41[0m - [1mConfiguration Loaded: Debug Mode = True[0m
[32m2026-02-27 15:35:02.248[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m434[0m - [1mLoading configuration from: /Users/cobalt/cobalt/configs[0m
[32m2026-02-27 15:35:02.256[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m464[0m - [1müîë COBALT_MASTER_KEY detected. Unlocking secure vault...[0m
[32m2026-02-27 15:35:02.256[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36munlock[0m:[36m44[0m - [1müîê Vault successfully unlocked into memory.[0m
[32m2026-02-27 15:35:02.257[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36mlock[0m:[36m55[0m - [1müîí Vault locked. Secrets wiped from RAM.[0m
[32m2026-02-27 15:35:02.257[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m495[0m - [1müîí Vault secrets loaded into runtime RAM and vault locked.[0m
[32m2026-02-27 15:35:02.258[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m45[0m - [1mBrain Initialized: Role-Based Routing Active (default)[0m
[32m2026-02-27 15:35:02.258[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mregister_tool[0m:[36m65[0m - [1mTool registered: search[0m
[32m2026-02-27 15:35:02.258[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mregister_tool[0m:[36m65[0m - [1mTool registered: browser[0m
[32m2026-02-27 15:35:02.258[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m434[0m - [1mLoading configuration from: /Users/cobalt/cobalt/configs[0m
[32m2026-02-27 15:35:02.266[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m464[0m - [1müîë COBALT_MASTER_KEY detected. Unlocking secure vault...[0m
[32m2026-02-27 15:35:02.266[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36munlock[0m:[36m44[0m - [1müîê Vault successfully unlocked into memory.[0m
[32m2026-02-27 15:35:02.266[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36mlock[0m:[36m55[0m - [1müîí Vault locked. Secrets wiped from RAM.[0m
[32m2026-02-27 15:35:02.266[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m495[0m - [1müîí Vault secrets loaded into runtime RAM and vault locked.[0m
[32m2026-02-27 15:35:02.267[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mregister_tool[0m:[36m65[0m - [1mTool registered: finance[0m
[32m2026-02-27 15:35:02.267[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mregister_tool[0m:[36m65[0m - [1mTool registered: read_file[0m
[32m2026-02-27 15:35:02.267[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mregister_tool[0m:[36m65[0m - [1mTool registered: write_file[0m
[32m2026-02-27 15:35:02.267[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mregister_tool[0m:[36m65[0m - [1mTool registered: list_directory[0m
[32m2026-02-27 15:35:02.277[0m | [1mINFO    [0m | [36mcobalt_agent.memory.postgres[0m:[36m_init_db[0m:[36m61[0m - [1müß† Connected to Postgres Memory (Vector Ready)[0m
[32m2026-02-27 15:35:02.277[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mregister_tool[0m:[36m65[0m - [1mTool registered: search_knowledge[0m
[32m2026-02-27 15:35:04.432[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m61[0m - [1mPersona: Persona(name='Cobalt', roles=3, skills=4)[0m
[32m2026-02-27 15:35:04.433[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m62[0m - [1mPersona Roles: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine[0m
[32m2026-02-27 15:35:04.433[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m64[0m - [1m================================================================================[0m
[32m2026-02-27 15:35:04.434[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m65[0m - [1mSYSTEM PROMPT:[0m
[32m2026-02-27 15:35:04.434[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m66[0m - [1m================================================================================[0m
[32m2026-02-27 15:35:04.434[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m67[0m - [1m
### IDENTITY
You are Cobalt.

### ROLES
Your roles are: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine.

### OPERATIONAL DIRECTIVES
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.

### TONE
Maintain a tone that is: Hyper-competent and authoritative, Analytical and unshakeable, Extremely concise (high signal, zero noise), Professional (strictly avoid chatty filler, apologies, and sycophancy).

### CURRENT CONTEXT
- Current Date/Time: 2026-02-27 15:35:02
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- SearchTool: Use this tool for search tasks.
- NoneType: Use this tool for nonetype tasks.
- BrowserTool: Use this tool for browser tasks.
- ModelMetaclass: Use this tool for modelmetaclass tasks.
- FinanceTool: Use this tool for finance tasks.
- NoneType: Use this tool for nonetype tasks.
- ReadFileTool: Use this tool for readfile tasks.
- ModelMetaclass: Use this tool for modelmetaclass tasks.
- WriteFileTool: Use this tool for writefile tasks.
- ModelMetaclass: Use this tool for modelmetaclass tasks.
- ListDirectoryTool: Use this tool for listdirectory tasks.
- ModelMetaclass: Use this tool for modelmetaclass tasks.
- KnowledgeSearchTool: Use this tool for knowledgesearch tasks.
- NoneType: Use this tool for nonetype tasks.
[0m
[32m2026-02-27 15:35:04.434[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m68[0m - [1m================================================================================[0m
[32m2026-02-27 15:35:04.434[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m70[0m - [1mMemory System online[0m
[32m2026-02-27 15:35:04.440[0m | [1mINFO    [0m | [36mcobalt_agent.services.scheduler[0m:[36m_setup_jobs[0m:[36m36[0m - [1m‚è±Ô∏è Scheduler: Morning Briefing job registered (Mon-Fri 08:00).[0m
[32m2026-02-27 15:35:04.440[0m | [1mINFO    [0m | [36mcobalt_agent.services.scheduler[0m:[36mstart[0m:[36m41[0m - [1m‚è±Ô∏è Cobalt Heartbeat (Scheduler) Online.[0m
[32m2026-02-27 15:35:04.441[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m__init__[0m:[36m44[0m - [1mMattermostInterface initialized (URL: http://100.70.206.126:8065)[0m
[32m2026-02-27 15:35:04.452[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mconnect[0m:[36m80[0m - [1mSuccessfully connected to Mattermost as user: cobalt[0m
[32m2026-02-27 15:35:04.452[0m | [1mINFO    [0m | [36mcobalt_agent.core.proposals[0m:[36m__init__[0m:[36m60[0m - [1mProposal Engine initialized (Channel: cobalt-approvals)[0m
[32m2026-02-27 15:35:04.452[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m__init__[0m:[36m44[0m - [1mMattermostInterface initialized (URL: http://100.70.206.126:8065)[0m
[32m2026-02-27 15:35:04.456[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mconnect[0m:[36m80[0m - [1mSuccessfully connected to Mattermost as user: cobalt[0m
[32m2026-02-27 15:35:04.456[0m | [1mINFO    [0m | [36mcobalt_agent.core.proposals[0m:[36mconnect_mattermost[0m:[36m76[0m - [1mProposal Engine: Mattermost connection established[0m
[32m2026-02-27 15:35:04.456[0m | [1mINFO    [0m | [36m__main__[0m:[36mstart_mattermost_interface[0m:[36m192[0m - [1m================================================================================[0m
[32m2026-02-27 15:35:04.457[0m | [1mINFO    [0m | [36m__main__[0m:[36mstart_mattermost_interface[0m:[36m193[0m - [1mCobalt Agent - Mattermost Interface Active[0m
[32m2026-02-27 15:35:04.457[0m | [1mINFO    [0m | [36m__main__[0m:[36mstart_mattermost_interface[0m:[36m194[0m - [1mHITL Proposal Engine - Active[0m
[32m2026-02-27 15:35:04.457[0m | [1mINFO    [0m | [36m__main__[0m:[36mstart_mattermost_interface[0m:[36m195[0m - [1m================================================================================[0m
[32m2026-02-27 15:35:04.457[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mstart_listening[0m:[36m483[0m - [1mStarting native WebSocket engine...[0m
[32m2026-02-27 15:35:04.457[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m468[0m - [1mConnecting to native WebSocket engine: ws://100.70.206.126:8065/api/v4/websocket[0m
[32m2026-02-27 15:35:04.461[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m473[0m - [1mConnected and authenticated via HTTP headers. Listening for messages...[0m
[32m2026-02-27 15:35:04.462[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m477[0m - [1mRAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"mpz5h9dbni8jumykkg5epx8roh","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}
[0m
[32m2026-02-27 15:35:04.462[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"mpz5h9dbni8jumykkg5epx8roh","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}
[0m
[32m2026-02-27 15:35:04.462[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m477[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}[0m
[32m2026-02-27 15:35:04.462[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}[0m
[32m2026-02-27 15:40:04.465[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m477[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}[0m
[32m2026-02-27 15:40:04.466[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}[0m
[32m2026-02-27 20:39:12.348[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m477[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}[0m
[32m2026-02-27 20:39:12.348[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}[0m
[32m2026-02-27 20:39:12.367[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m477[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 4}[0m
[32m2026-02-27 20:39:12.367[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "license_changed", "data": {"license":{"Announcement":"true","Cloud":"false","Cluster":"false","Company":"Mattermost","Compliance":"false","CustomPermissionsSchemes":"false","CustomTermsOfService":"false","DataRetention":"false","Elasticsearch":"false","EmailNotificationContents":"true","GoogleOAuth":"true","GuestAccounts":"true","GuestAccountsPermissions":"true","IDLoadedPushNotifications":"true","IsGovSku":"false","IsLicensed":"true","IsTrial":"false","LDAP":"true","LDAPGroups":"true","LockTeammateNameDisplay":"true","MFA":"true","MHPNS":"true","MessageExport":"false","Metrics":"true","Office365OAuth":"true","OpenId":"true","OutgoingOAuthConnections":"true","RemoteClusterService":"true","SAML":"true","SharedChannels":"true","SkuShortName":"entry","Users":"100000"}}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 4}[0m


========================================
FILE: pyproject.toml
========================================

[project]
name = "cobalt-agent"
version = "0.1.0"
description = "Project Cobalt: Autonomous AI Chief of Staff & Trading System"
readme = "README.md"
requires-python = ">=3.11"
authors = [
    { name = "Director", email = "director@cobalt-core.com" }
]

# --- CORE DEPENDENCIES (Moved here under [project]) ---
dependencies = [
    # 1. THE BRAIN
    "pydantic>=2.0.0",
    "pydantic-ai>=0.0.1",
    "litellm>=1.0.0",
    "openai>=1.0.0",
    # 2. THE FINANCE
    "pandas>=2.2.0",
    "pandas-ta-classic",
    "ta-lib>=0.4.0",
    "mplfinance>=0.12.0",
    "aiohttp>=3.9.0",
    # 3. CHIEF OF STAFF
    "mattermostdriver>=7.0",
    "google-api-python-client>=2.0",
    "gitpython>=3.1.0",
    "schedule>=1.2.0",
    "beautifulsoup4>=4.12.0",
    "playwright>=1.40.0",
    # 4. INFRASTRUCTURE
    "fastapi>=0.100.0",
    "uvicorn>=0.20.0",
    "redis>=5.0.0",
    "asyncpg>=0.29.0",
    "sqlalchemy>=2.0.0",
    "loguru>=0.7.0",
    "python-dotenv>=1.0.0",
    "pyyaml>=6.0.0",
    # 5. SECURITY
    "pyotp>=2.9.0",
    "qrcode>=7.4.0",
    "bcrypt>=4.0.0",
    "passlib>=1.7.0",
    "ddgs>=9.10.0",
    "rich>=14.3.2",
    "requests>=2.32.5",
    "yfinance>=1.1.0",
    "psycopg[binary]>=3.3.2",
    "pgvector>=0.4.2",
    "apscheduler>=3.11.2",
    "cryptography>=46.0.4",
]

# --- DEV DEPENDENCIES (New Standard: [dependency-groups]) ---
[dependency-groups]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "black>=24.0.0",
    "ipykernel>=6.29.0",
    "python-dotenv>=1.2.1",
]

[build-system]
requires = ["setuptools>=61.0", "uv.build"]
build-backend = "setuptools.build_meta"
[tool.uv.extra-build-dependencies]
cobalt-agent = ["uv.build"]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
norecursedirs = ["data", "logs", "plans", "scripts", "dev_utils"]
python_files = "test_*.py"
markers = ["integration: marks tests that require external systems (like Docker)"]

[tool.setuptools.packages.find]
where = ["src"]


========================================
FILE: src/cobalt_agent/brain/base.py
========================================

"""
The Unified ReAct Execution Engine.
All specialized Drones inherit this execution loop.
"""
import json
import re
from abc import ABC
from typing import Optional, List, Dict
from loguru import logger
from cobalt_agent.llm import LLM
from cobalt_agent.tools.tool_manager import ToolManager


class BaseDepartment(ABC):
    """
    The Unified ReAct Execution Engine.
    All specialized Drones inherit this execution loop.
    """
    def __init__(self, name: str, system_prompt: Optional[str] = None):
        self.name = name
        self.llm = LLM()
        self.tool_manager = ToolManager()
        self.system_prompt = system_prompt

    def run(self, user_message: str, chat_history: Optional[List[Dict]] = None) -> str:
        """
        Process a request using the ReAct loop.
        
        Args:
            user_message: The user's request
            chat_history: Optional list of previous messages for context
            
        Returns:
            The final response after tool execution or max loops
        """
        logger.info(f"[{self.name}] Executing task...")
        
        messages: List[Dict] = [{"role": "system", "content": self.system_prompt}]
        if chat_history:
            messages.extend(chat_history)
            
        messages.append({"role": "user", "content": user_message})
        
        max_loops = 4
        for _ in range(max_loops):
            # Get response from LLM using the unified interface
            memory_context = messages[:-1] if len(messages) > 1 else []
            response = self.llm.generate_response(
                system_prompt=self.system_prompt,
                user_input=messages[-1]["content"],
                memory_context=memory_context,
                search_context=""
            )
            
            if "ACTION:" in response:
                try:
                    # Extract tool name and arguments from ACTION line
                    action_lines = [line for line in response.split('\n') if line.startswith('ACTION:')]
                    if not action_lines:
                        messages.append({"role": "assistant", "content": response})
                        messages.append({"role": "system", "content": "Error: Malformed ACTION format. Ensure you use ACTION: tool_name {\"key\": \"value\"}"})
                        continue
                    
                    action_line = action_lines[0]
                    command = action_line.replace('ACTION:', '').strip()
                    
                    # Parse tool name and arguments
                    parts = command.split(' ', 1)
                    tool_name = parts[0]
                    args_dict = {}
                    if len(parts) > 1:
                        try:
                            # Clean up the string if the LLM wrapped it in quotes or markdown
                            clean_args = parts[1].strip()
                            if clean_args.startswith("'") and clean_args.endswith("'"):
                                clean_args = clean_args[1:-1]
                            args_dict = json.loads(clean_args)
                            if not isinstance(args_dict, dict):
                                args_dict = {'query': clean_args}
                        except json.JSONDecodeError as e:
                            # Return explicit error for invalid JSON so LLM can self-correct
                            logger.warning(f"Failed to parse tool args as JSON: {e}")
                            error_msg = "Observation: Invalid JSON format. Please use strict double quotes."
                            messages.append({"role": "assistant", "content": response})
                            messages.append({"role": "system", "content": error_msg})
                            continue
                    
                    # Execute the tool
                    raw_result = self.tool_manager.execute_tool(tool_name, args_dict)
                    result_str = str(raw_result)
                    
                    # Format the result
                    if result_str.startswith("Error:"):
                        result_text = result_str
                    else:
                        result_text = result_str
                        
                    # üõë FAST EXIT: If we hit a Zero-Trust Proposal wall, stop looping
                    if "Action paused" in result_str or "Proposal [" in result_str:
                        return result_text
                    
                    # Append observation to history and loop
                    messages.append({"role": "assistant", "content": response})
                    messages.append({"role": "system", "content": f"[Observation: {result_text}]"})
                    
                except json.JSONDecodeError as e:
                    messages.append({"role": "assistant", "content": response})
                    messages.append({"role": "system", "content": f"Error parsing JSON arguments: {e}"})
                except Exception as e:
                    logger.exception(f"Error executing tool: {e}")
                    messages.append({"role": "assistant", "content": response})
                    messages.append({"role": "system", "content": f"Error executing tool: {e}"})
            else:
                # No ACTION found, meaning the drone is finished
                return response
                
        return "Error: ReAct loop maxed out. Please simplify the request."

========================================
FILE: src/cobalt_agent/brain/cortex.py
========================================

"""
The Cortex (Manager Agent) - Config-Driven Architecture
Routes user intent based on domains defined in config.yaml.
Includes robust error handling, full Scribe logic, and Medical Admin placeholders.
"""
import re
import json
from typing import Optional, Any
from datetime import datetime
from pydantic import BaseModel, Field
from loguru import logger

from cobalt_agent.llm import LLM
from cobalt_agent.config import load_config
from cobalt_agent.core.proposals import Proposal

# --- ROUTING MODEL ---
class DomainDecision(BaseModel):
    domain_name: str = Field(description="The exact name of the department (e.g. TACTICAL, OPS).")
    reasoning: str = Field(description="Why this department fits the request.")
    task_parameters: str = Field(
        description="The PRECISE entity or query to act on. For Tactical, this MUST be just the Ticker Symbol (e.g. 'NVDA') OR the command 'STRATEGY'."
    )

class Cortex:
    def __init__(self):
        self.config = load_config()
        
        # --- ROBUST LLM CONFIG ---
        # Try 'model_name' first, then 'model', then default to 'gpt-4o'
        model_name = getattr(self.config.llm, "model_name", None)
        if not model_name:
            model_name = getattr(self.config.llm, "model", None)
        if not model_name:
            # Fallback to active_profile.default or raise error if missing
            active_profile = getattr(self.config, "active_profile", None)
            if active_profile and isinstance(active_profile, dict):
                model_name = active_profile.get("default")
            if not model_name:
                raise ValueError("Missing critical configuration: No model specified in llm.model_name, llm.model, or active_profile.default")
            
        self.llm = LLM(model_name=model_name)
        
        # --- ROBUST DEPARTMENTS LOAD ---
        deps = getattr(self.config, "departments", None)
        if deps is None:
            deps = {}
        self.departments = deps
        
        # Load routing keywords from config
        self.orchestrator_keywords = []
        self.high_risk_keywords = []
        
        rules = getattr(self.config, "rules", None)
        if rules:
            cortex_routing = getattr(rules, "cortex_routing", None)
            if cortex_routing:
                self.orchestrator_keywords = getattr(cortex_routing, "orchestrator_keywords", [])
                self.high_risk_keywords = getattr(cortex_routing, "high_risk_keywords", [])
        
        logger.info(f"üß† Cortex Online | Loaded {len(self.departments)} Departments from Config")

    def route(self, user_input: str) -> Optional[str]:
        """Dynamically routes based on config."""
        # Fast exit
        if len(user_input.split()) < 4 and "hi" in user_input.lower():
            return None

        # === DETERMINISTIC FAST-PATH ROUTING (TRIAGE) ===
        message_lower = user_input.lower()
        
        # 1. Complex Task Routing (Orchestrator) - use config-defined keywords
        if any(keyword in message_lower for keyword in self.orchestrator_keywords):
            logger.info("‚ö° Fast-Path Routing Triggered: ORCHESTRATOR")
            from cobalt_agent.core.orchestrator import OrchestratorEngine
            orchestrator = OrchestratorEngine()
            return orchestrator.plan_and_execute(user_input)
            
        # 2. Web / Research Triage
        web_keywords = ["http://", "https://", "browser", "scrape", "search", "summarize the top"]
        if any(keyword in message_lower for keyword in web_keywords):
            logger.info("‚ö° Fast-Path Routing Triggered: DEFAULT")
            return None  # Handle in main chat loop (same as FOUNDATION)
        
        # 2. Classify
        decision = self._classify_domain(user_input)
        
        # --- PRIME DIRECTIVE GATE --- - use config-defined keywords
        is_high_risk = any(word in user_input.lower() for word in self.high_risk_keywords)
        
        if is_high_risk:
            logger.warning(f"üõ°Ô∏è Security Intercept: High-risk action detected in input: {user_input}")
            return self._generate_proposal(user_input)
        # ----------------------
        
        # 2. Lazy Load & Execute
        domain = decision.domain_name.upper()
        params = decision.task_parameters.strip()

        logger.info(f"üëâ Cortex Routing: {domain} | Task: {params}")
        
        if domain == "TACTICAL":
            return self._run_tactical(params)
        
        elif domain == "INTEL":
            return self._run_intel(params)
            
        elif domain == "GROWTH":
            return "üë∑ The Architect (Growth) is defined but not yet hired."
            
        elif domain == "OPS":
            return self._run_ops(params, user_input) # Pass original input for Scribe context
            
        elif domain == "ENGINEERING":
            from cobalt_agent.brain.engineering import EngineeringDepartment
            forge = EngineeringDepartment()
            return forge.run(params)
            
        elif domain == "DEFAULT":
            return None # Handle in main chat loop (same as FOUNDATION)
            
        elif domain == "FOUNDATION":
            return None # Handle in main chat loop
            
        else:
            return f"‚ö†Ô∏è Unknown Domain: {domain}"

    def _generate_proposal(self, user_input: str) -> str:
        # Load prompt from config
        prompt_template = self.config.prompts.proposal.security_intercept
        prompt = prompt_template.format(user_input=user_input)
        
        raw_response = ""
        try:
            # Bypass ask_structured to avoid schema confusion; use base ask/generate
            raw_response = self.llm.ask(prompt)
            
            # Bulletproof JSON extraction
            match = re.search(r'\{.*\}', raw_response, re.DOTALL)
            if not match:
                raise ValueError("No JSON block found in LLM response.")
                
            data = json.loads(match.group(0))
            
            # Manually instantiate the Proposal (task_id and timestamp will auto-generate)
            proposal = Proposal(
                action=data.get("action", "Unknown Action"),
                justification=data.get("justification", "User requested high-stakes operation."),
                risk_assessment=data.get("risk_assessment", "High risk of system modification.")
            )
            return proposal.format_for_mattermost()
            
        except Exception:
            logger.exception(f"Proposal Generation Failed | Raw Output: {raw_response}")
            return (
                f"### üõ°Ô∏è SECURITY INTERCEPT\n"
                f"**Action Blocked:** Administrative system change.\n\n"
                f"**Reason:** The Proposal Engine could not validate the risk assessment. "
                f"Execution is denied by default per the Prime Directive."
            )

    def _classify_domain(self, user_input: str) -> DomainDecision:
        """Builds prompt from config.yaml definitions."""
        options_text = ""
        
        # Guard against empty departments
        if not self.departments:
            options_text = "- TACTICAL\n- INTEL\n- OPS"
        else:
            for name, data in self.departments.items():
                is_active = False
                desc = "No description"
                if isinstance(data, dict):
                    is_active = data.get('active', False)
                    desc = data.get('description', desc)
                elif hasattr(data, 'active'):
                    is_active = getattr(data, 'active', False)
                    desc = getattr(data, 'description', desc)

                if is_active:
                    options_text += f"- {name}: {desc}\n"
        
        # STRICT MUTUALLY EXCLUSIVE ROUTING PROMPT - Load from config
        prompt_template = self.config.prompts.routing.classify_domain
        prompt = prompt_template.format(user_input=user_input, options_text=options_text)
        
        try:
            return self.llm.ask_structured(prompt, DomainDecision)
        except Exception:
            return DomainDecision(domain_name="FOUNDATION", reasoning="Error", task_parameters="")

    # --- DEPARTMENT HANDLERS ---
    
    def _run_tactical(self, params: str) -> str:
        """Handles Trading & Market Data."""
        from cobalt_agent.brain.tactical import Strategos
        try:
            # Clean up params
            # If the LLM sends "STRATEGY" or "PLAYBOOK", we pass it raw.
            # If it sends a ticker "NVDA", we clean it.
            if "STRATEGY" in params.upper() or "PLAYBOOK" in params.upper():
                task = "STRATEGY"
            else:
                task = params.split()[0].strip(".,!?")
                
            department_head = Strategos()
            return department_head.run(task)
        except Exception:
            logger.exception("Tactical department execution failed")
            return "Tactical Error: Internal error logged"

    def _run_intel(self, params: str) -> str:
        """Handles Research & Briefings."""
        if "briefing" in params.lower():
            from cobalt_agent.skills.productivity.briefing import MorningBriefing
            return MorningBriefing().run()
        else:
            from cobalt_agent.skills.research.deep_dive import DeepResearch
            return DeepResearch().run(params)

    def _run_ops(self, params: str, original_input: str) -> str:
        """
        Handles Operations (Scribe, Medical, Scheduling).
        """
        from cobalt_agent.skills.productivity.scribe import Scribe
        scribe = Scribe()
        
        prompt_lower = original_input.lower()
        
        # 1. LOGGING
        if "log" in prompt_lower or "journal" in prompt_lower:
            content = original_input.replace("log", "").replace("journal", "").strip()
            if not content: return "Please provide text to log."
            return scribe.append_to_daily_note(content)
            
        # 2. SAVING (New Note)
        elif "save" in prompt_lower or "note" in prompt_lower:
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
            filename = f"AutoNote_{timestamp}.md"  # Explicitly add .md extension
            content = params if len(params) > 5 else original_input
            # CRITICAL: Explicitly construct path with "0 - Inbox/" folder
            relative_path = f"0 - Inbox/{filename}"
            return scribe.write_note(relative_path, content)
            
        # 3. SEARCHING
        elif "search" in prompt_lower or "find" in prompt_lower:
            # Use the LLM extracted param for the query
            results = scribe.search_vault(params)
            if not results: return "No notes found."
            return f"üîç Found these notes:\n- " + "\n- ".join(results)
            
        # 4. MEDICAL (Placeholder for future Steward logic)
        elif "medical" in prompt_lower or "billing" in prompt_lower:
             return "üè• Medical Admin module is not yet implemented. (See Ops Department Plan)"
             
        return "Ops processed the request."

========================================
FILE: src/cobalt_agent/brain/engineering.py
========================================

"""
The Forge (Engineering Department)
Cobalt's Principal Systems Architect and Senior Software Engineer.
Responsible for reading, analyzing, and writing code.
"""
from cobalt_agent.brain.base import BaseDepartment


class EngineeringDepartment(BaseDepartment):
    """
    The Forge - Cobalt's codebase manipulation department.
    Handles code reading, analysis, and writing tasks.
    """
    def __init__(self, system_prompt: str = None):
        name = "The Forge (Engineering)"
        
        default_prompt = """
You are THE FORGE, Cobalt's Principal Systems Architect and Senior Software Engineer.
Your job is to read, analyze, and write code.

CRITICAL RULES:
1. NEVER guess the contents of a file or directory.
2. To modify or create a file, you MUST use the `write_file` tool. 
3. YOU MUST USE THE EXACT SYNTAX BELOW TO CALL A TOOL. If you do not use the `ACTION:` prefix, the tool will fail.
   - CORRECT: ACTION: write_file {"filepath": "src/test.py", "content": "print('hello')"}
   - INCORRECT: {"filepath": "src/test.py", "content": "print('hello')"}
   - INCORRECT: ```json\n{"filepath": "src/test.py", "content": "print('hello')"}\n```
4. DO NOT roleplay. DO NOT say "I will create the file now." Just output the ACTION string.
5. WORKFLOW EFFICIENCY: If the user provides an exact filepath (e.g., "create a file at src/test.py"), DO NOT use `list_directory`. Execute `write_file` immediately to save context space.
6. WAIT PROTOCOL: If you use the `write_file` tool and the System Observation says "Action paused. Proposal sent", YOU MUST STOP. Output a final conversational message saying "I have submitted the proposal for your approval." DO NOT try to write the file again.

AVAILABLE TOOLS:
- `read_file`: Reads a file. 
  Syntax: ACTION: read_file {"filepath": "src/main.py"}

- `list_directory`: Lists a folder. 
  Syntax: ACTION: list_directory {"directory_path": "src/"}

- `write_file`: Modifies or creates a file. YOU MUST USE THIS TO PROPOSE CHANGES. 
  Syntax: ACTION: write_file {"filepath": "src/test.py", "content": "print('hello')"}
"""
        
        super().__init__(name, system_prompt or default_prompt)

========================================
FILE: src/cobalt_agent/brain/ops.py
========================================

"""
The Scribe (Ops Department)
Cobalt's Operations and Documentation department.
Handles journaling, formatting, reading playbooks, and Obsidian integration.
"""
from cobalt_agent.brain.base import BaseDepartment
from typing import Optional


class OpsDepartment(BaseDepartment):
    """
    The Scribe - Cobalt's Operations and Documentation department.
    Handles journaling, formatting, reading playbooks, and Obsidian integration.
    """
    def __init__(self, system_prompt: Optional[str] = None):
        name = "The Scribe (Operations)"
        
        default_prompt = """
You are THE SCRIBE, Cobalt's Chief of Operations.
Your job is to read data, format documentation cleanly, and maintain the Obsidian Vault.

CRITICAL RULES:
1. You are a documentation expert. Use pristine Markdown formatting.
2. You do not write Python or application code. You write journals, summaries, and reports.
3. YOU MUST USE THE EXACT SYNTAX BELOW TO CALL A TOOL. If you do not use the `ACTION:` prefix, the tool will fail.
   - CORRECT: ACTION: write_file {"filepath": "0 - Inbox/note.md", "content": "# Hello"}
   - INCORRECT: {"filepath": "0 - Inbox/note.md", "content": "# Hello"}
   - INCORRECT: ```json\n{"filepath": "0 - Inbox/note.md", "content": "# Hello"}\n```
4. DO NOT roleplay. DO NOT say "I will create the note now." Just output the ACTION string.
5. WAIT PROTOCOL: If you use the `write_file` tool and the System Observation says "Action paused. Proposal sent", YOU MUST STOP. Output a final conversational message saying "I have submitted the proposal for your approval." DO NOT try to write the file again.

AVAILABLE TOOLS:
- `read_file`: Reads a file. 
  Syntax: ACTION: read_file {"filepath": "docs/file.md"}

- `list_directory`: Lists a folder. 
  Syntax: ACTION: list_directory {"directory_path": "0 - Inbox/"}

- `write_file`: Modifies or creates a file. YOU MUST USE THIS TO PROPOSE CHANGES. 
  Syntax: ACTION: write_file {"filepath": "0 - Inbox/note.md", "content": "# Hello"}
"""
        
        super().__init__(name, system_prompt or default_prompt)

========================================
FILE: src/cobalt_agent/brain/playbook.py
========================================

"""
The Playbook Registry
Loads trading strategies and parameters from strategies.yaml.
Executes the strategy logic against market data.
"""
import yaml
import json
from pathlib import Path
from typing import Dict, Any, Optional
from loguru import logger

# Import your strategies here
from cobalt_agent.brain.strategies.second_day_play import SecondDayPlay

class Playbook:
    """
    Manages the active trading strategies and their parameters.
    """
    
    def __init__(self, config_path: str = "configs/strategies.yaml"):
        self.config_data = self._load_config(config_path)
        self.strategies = {}
        self._initialize_strategies()
        
    def _load_config(self, path_str: str) -> Dict[str, Any]:
        """Loads the YAML config."""
        path = Path(path_str)
        # Handle running from root or inside module
        if not path.exists():
            path = Path(__file__).parent.parent.parent / path_str
            
        if not path.exists():
            logger.warning(f"‚ö†Ô∏è Strategy Config not found at {path}")
            return {}

        try:
            with open(path, "r") as f:
                data = yaml.safe_load(f)
                return data.get("strategies", {})
        except Exception as e:
            logger.error(f"‚ùå Failed to load Playbook Config: {e}")
            return {}

    def _initialize_strategies(self):
        """Hydrates the Strategy classes with their Configs."""
        # Map YAML keys to Python Classes
        class_map = {
            "second_day_play": SecondDayPlay,
            # Future: "gap_and_go": GapAndGo
        }

        for key, params in self.config_data.items():
            if key in class_map:
                try:
                    # Instantiate the class with its specific config
                    strategy_instance = class_map[key](params)
                    self.strategies[key] = strategy_instance
                    logger.debug(f"Loaded strategy: {key}")
                except Exception as e:
                    logger.error(f"Failed to init strategy {key}: {e}")

    def get_strategy(self, name: str):
        return self.strategies.get(name)

    def list_strategies(self) -> str:
        """Returns a formatted list of ACTIVE (Loaded) strategies."""
        if not self.strategies:
            return "No strategies loaded (Check strategies.yaml)."
        
        output = "üìú **Active Playbook:**\n"
        for key, strategy in self.strategies.items():
            cfg = strategy.config
            output += f"- **{cfg['name']}**: {cfg['direction']} ({cfg['time_window']['start']}-{cfg['time_window']['end']})\n"
        return output
        
    def run_all(self, market_data: Dict[str, Any]) -> str:
        """
        Runs ALL strategies against the incoming data.
        Returns a summary string of Scoring Profiles.
        """
        results = []
        
        for name, strategy in self.strategies.items():
            try:
                # Run the math
                profile = strategy.analyze(market_data)
                
                # Format the output for the CLI
                # We show the Name, Base Score, and Quality
                status = profile.get("status", "UNKNOWN")
                base_score = profile.get("base_score", 0)
                quality = profile.get("setup_quality", "N/A")
                reason = profile.get("reason", "")
                
                # Create a mini-report
                report = f"**{name}** [{status}]\n"
                report += f"   ‚Ä¢ Score: {base_score}/100 ({quality})\n"
                report += f"   ‚Ä¢ Logic: {reason}\n"
                
                # If there are HUD rules, mention them
                if profile.get("hud_rules"):
                    rules_count = len(profile["hud_rules"])
                    report += f"   ‚Ä¢ HUD Config: {rules_count} dynamic rules active\n"
                
                results.append(report)
                
            except Exception as e:
                logger.error(f"Error running {name}: {e}")
                results.append(f"**{name}**: Error ({e})")
                
        if not results:
            return "No active strategies found."
            
        return "\n".join(results)

========================================
FILE: src/cobalt_agent/brain/strategies/second_day_play.py
========================================

"""
Second Day Play - Strategy Logic
Author: Cobalt AI
Context: Phase 3 (Tactical)

Refactored to pull scoring rules and thresholds dynamically from strategies.yaml.
"""
from datetime import datetime

class SecondDayPlay:
    def __init__(self, config: dict = None):
        # Fallback to empty dict if None, but usually this comes from strategies.yaml
        self.config = config or {}
        
        # Load Parameters from Config (or defaults if missing)
        self.params = self.config.get("parameters", {})
        self.scoring = self.config.get("scoring", {})
        
        self.name = self.config.get("name", "SecondDayPlay")
        self.version = "1.1"

    def analyze(self, ticker: str, market_data: dict) -> dict:
        """
        Takes raw market data and returns the Scoring Profile (JSON).
        """
        
        # 1. UNPACK DATA
        y_close = market_data.get('yesterday_close', 0)
        y_vol = market_data.get('yesterday_volume', 0)
        avg_vol = market_data.get('average_volume', 1) 
        today_open = market_data.get('today_open', 0)
        pm_high = market_data.get('pre_market_high', 0)
        
        # 2. VALIDATION (The Gatekeeper)
        y_rvol = y_vol / avg_vol if avg_vol else 0
        
        # Rule: Min RVOL (from config)
        min_rvol = self.params.get("min_rvol", 1.5)
        if y_rvol < min_rvol:
            return {
                "ticker": ticker,
                "strategy": self.name,
                "status": "REJECTED",
                "reason": f"Low Relative Volume Yesterday (RVOL: {y_rvol:.2f} < {min_rvol})"
            }

        # Rule: Gap Down Rejection
        if today_open < (y_close * 0.98):
             return {
                "ticker": ticker,
                "strategy": self.name,
                "status": "REJECTED",
                "reason": "Gap Down - Momentum Lost"
            }

        # 3. CALCULATE ZONES
        entry_price = pm_high + 0.05
        stop_loss = y_close - 0.20
        risk = entry_price - stop_loss
        target = entry_price + (risk * 2)

        # 4. SCORING ENGINE (Dynamic)
        # Instead of hardcoding "50" or "+10", we look them up.
        current_score = self.scoring.get("base_score", 50)
        
        # RVOL Modifiers
        high_rvol_thresh = self.scoring.get("high_rvol_threshold", 3.0)
        
        if y_rvol >= high_rvol_thresh:
            current_score += self.scoring.get("high_rvol_points", 15)
        elif y_rvol >= min_rvol:
            current_score += self.scoring.get("base_rvol_points", 10)
            
        # Gap Modifiers
        if today_open > y_close:
            current_score += self.scoring.get("gap_up_points", 10)
        
        # 5. CONSTRUCT THE MATH PACKAGE
        return {
            "timestamp": datetime.now().isoformat(),
            "ticker": ticker,
            "strategy": self.name,
            "status": "ACTIVE_WATCH",
            "direction": "LONG",
            "zones": {
                "entry": round(entry_price, 2),
                "stop": round(stop_loss, 2),
                "target": round(target, 2),
                "risk_per_share": round(risk, 2)
            },
            "scoring_engine": {
                "base_score": current_score,
                # Pass instructions to Ion (Windows)
                "modifiers": {
                    "live_rvol_multiplier": self.scoring.get("live_rvol_multiplier", 5.0),
                    "spy_correlation_weight": self.scoring.get("spy_correlation_weight", 10.0),
                    "resistance_penalty": self.scoring.get("resistance_penalty", -20.0),
                    "time_decay_per_min": self.scoring.get("time_decay_per_min", -0.5)
                }
            },
            "abort_conditions": [
                f"price < {stop_loss}",
                "volume_run_rate < 50%" 
            ]
        }

========================================
FILE: src/cobalt_agent/brain/strategy.py
========================================

"""
The Strategy Interface (The Contract)
All trading strategies must inherit from this class.
This enforces a standard structure for the Backtester and Live Engine.
"""
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from datetime import datetime

class Strategy(ABC):
    """
    Abstract Base Class for all Cobalt Strategies.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize with specific parameters from strategies.yaml.
        """
        self.config = config
        self.name = config.get("name", "Unknown Strategy")

    @abstractmethod
    def analyze(self, market_data: Any) -> Dict[str, Any]:
        """
        The Core Logic.
        Args:
            market_data: A clean object containing Price, Volume, VWAP, etc.
        Returns:
            Dict containing:
            - 'signal': 'BUY', 'SELL', or 'WAIT'
            - 'confidence': 0.0 to 1.0 (The 'T-Shirt Size')
            - 'stop_loss': Price level
            - 'target': Price level
            - 'reason': Text explanation
        """
        pass

    def check_time_window(self, current_time_str: str = None) -> bool:
        """
        Helper: Checks if we are allowed to trade right now.
        """
        if not current_time_str:
            current_time_str = datetime.now().strftime("%H:%M")
            
        window = self.config.get("time_window", {})
        start = window.get("start", "00:00")
        end = window.get("end", "23:59")
        
        # Simple string comparison works for HH:MM format (24h)
        return start <= current_time_str <= end

========================================
FILE: src/cobalt_agent/brain/tactical.py
========================================

"""
The Strategos Agent (Tactical Department Head)
Responsible for:
1. Market Data Retrieval (FinanceTool)
2. Strategy Execution (Playbook)
"""
from typing import Optional
from loguru import logger
from cobalt_agent.tools.finance import FinanceTool
from cobalt_agent.brain.playbook import Playbook

class Strategos:
    """
    The Quantitative Trading Engine.
    Routes raw data requests or executes full strategy scans.
    """
    
    def __init__(self):
        self.finance = FinanceTool()
        self.playbook = Playbook() 
        logger.info(f"‚öîÔ∏è Strategos Online | Strategies Loaded: {len(self.playbook.strategies)}")

    def run(self, task: str) -> str:
        """
        The main entry point for the Tactical Department.
        
        Args:
            task: The ticker symbol (e.g., 'NVDA') or a specific command.
        """
        # 1. Clean the input (extract ticker)
        ticker = task.split()[0].strip(".,!?").upper()
        
        logger.info(f"Strategos analyzing: {ticker}")
        
        try:
            # CHECK: If user asks for "Strategies", show the menu
            if "STRATEGY" in ticker or "PLAYBOOK" in ticker:
                return self.playbook.list_strategies()
            
            # STEP 1: Get Raw Market Data (The Finance Tool)
            market_data_obj = self.finance.run(ticker)
            
            # STEP 2: Convert to Dictionary
            # The Strategy Engine needs a clean dict, not a Pydantic model
            if hasattr(market_data_obj, 'dict'):
                market_data_dict = market_data_obj.dict()
            elif hasattr(market_data_obj, 'model_dump'):
                market_data_dict = market_data_obj.model_dump()
            else:
                market_data_dict = market_data_obj.__dict__

            # STEP 3: RUN THE PLAYBOOK ENGINE
            # This loops through all active strategies and calculates scores
            strategy_output = self.playbook.run_all(market_data_dict)
            
            # STEP 4: Return Combined Intelligence
            return f"{market_data_obj}\n\n[‚öîÔ∏è Strategy Scan]\n{strategy_output}"
            
        except Exception as e:
            logger.error(f"Strategos failed on {ticker}: {e}")
            return f"Tactical Error: {e}"

========================================
FILE: src/cobalt_agent/config.py
========================================

"""
Configuration Management for Cobalt Agent
Pydantic Settings-based configuration with environment variable overrides.

Loading Priority (highest to lowest):
1. Environment Variables (via .env file and OS env)
2. YAML Configuration Files (configs/*.yaml)

Environment Variable Mapping:
- Simple fields: UPPER_CASE converts to lower_case_with_underscores
- Nested fields: POSTGRES_HOST maps to postgres.host via env_nested_delimiter="_"
"""

import json
import os
from pathlib import Path
from typing import Any, Optional

import yaml
from dotenv import load_dotenv
from loguru import logger
from pydantic import BaseModel, Field, ConfigDict
from pydantic_settings import BaseSettings
from pydantic_settings.sources import PydanticBaseSettingsSource

from cobalt_agent.security.vault import VaultManager

# Load environment variables from .env file (explicit path)
# Get the directory where config.py is located
config_dir = Path(__file__).parent
# Look for .env in the project root (parent of src/)
env_path = config_dir.parent.parent / ".env"
if env_path.exists():
    load_dotenv(env_path)
else:
    # Fallback to current working directory
    load_dotenv()  # Fallback to default behavior (looks in cwd)


# --- 1. Modular Schema Definitions ---


class MomentumRules(BaseModel):
    """Schema for momentum trading rules."""
    rvol_alert_threshold: float
    rvol_strong_threshold: float


class RSIRules(BaseModel):
    """Schema for RSI trading rules."""
    period: int
    overbought: int
    oversold: int


class ATRRules(BaseModel):
    """Schema for ATR trading rules."""
    period: int
    expansion_multiplier: float
    extension_multiplier: float


class TradingRules(BaseModel):
    """
    Schema for 'trading_rules' section.
    We are strict here to ensure trading logic is type-safe.
    """
    momentum: Optional[MomentumRules] = None
    moving_averages: Optional[dict] = None
    rsi: Optional[RSIRules] = None
    atr: Optional[ATRRules] = None


class SystemConfig(BaseModel):
    """Schema for system-level configuration."""
    debug_mode: bool = False
    version: str = "0.1.0"
    obsidian_vault_path: str = "/default/obsidian/vault/path"


class LLMConfig(BaseModel):
    """Schema for LLM configuration."""
    model_name: str = "gemini/gemini-1.5-pro"
    api_key: Optional[str] = None


class PersonaConfig(BaseModel):
    """Schema for agent persona configuration."""
    name: str = "Cobalt"
    roles: list[str] = Field(default_factory=list)
    skills: list[str] = Field(default_factory=list)
    tone: list[str] = Field(default_factory=list)
    directives: list[str] = Field(default_factory=list)


class NodeConfig(BaseModel):
    """Schema for network node configuration."""
    role: str
    ip: str = "127.0.0.1"
    port: int = 8080
    protocol: str = "http"


class NetworkConfig(BaseModel):
    """Schema for network topology configuration."""
    nodes: dict[str, NodeConfig]


class PostgresConfig(BaseModel):
    """Schema for PostgreSQL database configuration."""
    host: str = "localhost"
    port: int = 5432
    db: str = "cobalt_memory"
    user: str = "postgres"
    password: Optional[str] = None


class MattermostConfig(BaseModel):
    """Schema for Mattermost communication configuration."""
    url: Optional[str] = None
    token: Optional[str] = None
    scheme: str = "http"
    port: int = 8065
    approval_channel: str = "cobalt-approvals"
    approval_team: str = "cobalt-team"


class BrowserConfig(BaseModel):
    """Schema for browser/Playwright configuration."""
    allowed_domains: list[str] = Field(default_factory=lambda: ["example.com"])


class VaultConfig(BaseModel):
    """Schema for vault configuration."""
    path: str = "data/.cobalt_vault"
    enabled: bool = True


# --- 2. Main Configuration Class ---


class PromptsConfig(BaseModel):
    """Schema for prompts configuration."""
    system: Optional[dict] = None
    scheduler: Optional[dict] = None
    ops: Optional[dict] = None
    engineering: Optional[dict] = None
    proposal: Optional[dict] = None
    routing: Optional[dict] = None
    orchestrator: Optional[dict] = None


class CobaltSettings(BaseSettings):
    """
    Pydantic Settings class that loads YAML config and allows ENV overrides.
    
    Environment Variable Naming Convention:
    - Nested keys: POSTGRES_HOST -> postgres.host (using env_nested_delimiter="_")
    - The env_nested_delimiter setting allows Pydantic to automatically
      map POSTGRES_HOST to postgres.host via the "_" delimiter.
    """
    model_config = ConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        extra="allow",  # Allow extra fields not defined in schema
        env_prefix="",  # No prefix for environment variables
        env_nested_delimiter="_",  # Use underscore to separate nested keys
    )

    # Core Sections with defaults from YAML
    system: SystemConfig = Field(default_factory=SystemConfig)
    llm: LLMConfig = Field(default_factory=LLMConfig)
    persona: PersonaConfig = Field(default_factory=PersonaConfig)
    
    # Optional Known Sections
    trading_rules: Optional[TradingRules] = None
    active_profile: Optional[dict[str, str]] = None
    models: Optional[dict[str, Any]] = None
    network: Optional[NetworkConfig] = None
    postgres: PostgresConfig = Field(default_factory=PostgresConfig)
    mattermost: MattermostConfig = Field(default_factory=MattermostConfig)
    vault: Optional[VaultConfig] = Field(default_factory=VaultConfig)
    prompts: PromptsConfig = Field(default_factory=PromptsConfig)
    browser: Optional[BrowserConfig] = Field(default_factory=BrowserConfig)

    @classmethod
    def settings_customise_sources(
        cls,
        settings_cls: type[BaseSettings],
        init_settings: PydanticBaseSettingsSource,
        env_settings: PydanticBaseSettingsSource,
        dotenv_settings: PydanticBaseSettingsSource,
        file_secret_settings: PydanticBaseSettingsSource,
    ) -> tuple[PydanticBaseSettingsSource, ...]:
        """
        Custom source order: ENV variables override YAML values.
        Source order (highest to lowest priority):
        1. ENV settings (including .env file)
        2. File secret settings
        3. Init settings (YAML data passed as kwargs)
        """
        return (env_settings, dotenv_settings, file_secret_settings, init_settings)


# --- 3. Helper Functions ---


def _load_yaml_config(yaml_path: Path) -> dict[str, Any]:
    """Load and return YAML configuration as dictionary."""
    if not yaml_path.exists():
        logger.warning(f"Config file not found: {yaml_path}")
        return {}
    
    try:
        with open(yaml_path, "r") as f:
            return yaml.safe_load(f) or {}
    except Exception as e:
        logger.error(f"Failed to load {yaml_path}: {e}")
        return {}


def parse_json_credentials(json_string: str) -> dict[str, Any]:
    """
    Parse JSON credentials string into a dictionary.
    
    Handles grouped credentials like URLs and Tokens together.
    Example input: '{"url": "https://api.example.com", "token": "secret123"}'
    
    Args:
        json_string: A JSON-formatted string containing credentials.
        
    Returns:
        A dictionary with the parsed credentials.
        
    Raises:
        json.JSONDecodeError: If the input is not valid JSON.
    """
    try:
        credentials = json.loads(json_string)
        if not isinstance(credentials, dict):
            logger.warning("JSON credentials parsed to non-dict type, wrapping in dict")
            credentials = {"data": credentials}
        return credentials
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse JSON credentials: {e}")
        raise


def _deep_merge(base: dict[str, Any], update: dict[str, Any]) -> dict[str, Any]:
    """Recursively merge dictionary 'update' into 'base'."""
    result = base.copy()
    
    for key, value in update.items():
        if isinstance(value, dict) and key in result and isinstance(result[key], dict):
            result[key] = _deep_merge(result[key], value)
        else:
            result[key] = value
    
    return result


def get_current_node_role() -> Optional[str]:
    """
    Determine the role of the current node based on the 'network' section in config.yaml.
    Returns the role if found, otherwise returns None.
    """
    try:
        config_dir = Path.cwd() / "configs"
        if not config_dir.exists():
            config_dir = Path(__file__).parent.parent / "configs"
        
        with open(config_dir / "config.yaml", "r") as f:
            config_data = yaml.safe_load(f) or {}
        
        network_config = config_data.get('network', {})
        nodes = network_config.get('nodes', {})
        
        import socket
        hostname = socket.gethostname()
        
        for node, details in nodes.items():
            if 'ip' in details and details['ip'] == socket.gethostbyname(hostname):
                return details.get('role')
    
    except Exception as e:
        logger.error(f"Failed to determine current node role: {e}")
    
    return None


class Config:
    """Singleton configuration manager with integrated VaultManager."""
    _instance = None
    _vault_manager: Optional[VaultManager] = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(Config, cls).__new__(cls)
            cls._instance._config = load_config()
        return cls._instance

    @staticmethod
    def get_instance():
        """Get the singleton configuration instance."""
        if Config._instance is None:
            Config._instance = Config()
        return Config._instance

    @property
    def vault_manager(self) -> Optional[VaultManager]:
        """Get or create the VaultManager instance."""
        if Config._vault_manager is None:
            config = self._config
            vault_config = config.vault if config.vault else None
            vault_path = vault_config.path if vault_config else "data/.cobalt_vault"
            Config._vault_manager = VaultManager(vault_path)
        return Config._vault_manager

    def load(self) -> CobaltSettings:
        """Load and return the configuration."""
        return self._config

    def unlock_vault(self, master_key: str) -> bool:
        """
        Unlock the vault and inject secrets into the runtime configuration.
        
        Args:
            master_key: The AES-256 Fernet key to decrypt the vault.
            
        Returns:
            True if vault was successfully unlocked, False otherwise.
        """
        vault_mgr = self.vault_manager
        if vault_mgr is None:
            logger.error("Failed to unlock vault: VaultManager not initialized")
            return False
            
        success = vault_mgr.unlock(master_key)
        if success:
            logger.info("üîê Vault unlocked successfully. Secrets injected into runtime configuration.")
        return success

    def lock_vault(self) -> None:
        """Lock the vault and wipe secrets from memory."""
        vault_mgr = self.vault_manager
        if vault_mgr is not None:
            vault_mgr.lock()
            Config._vault_manager = None
            logger.info("üîí Vault locked. Secrets wiped from RAM.")

    def inject_secrets(self, config: CobaltSettings) -> CobaltSettings:
        """
        Inject secrets from the vault into the runtime configuration.
        This replaces sensitive fields (like API keys and tokens) with values from the vault.
        
        Args:
            config: The configuration object to inject secrets into.
            
        Returns:
            The configuration object with secrets injected from the vault.
        """
        vault_mgr = self.vault_manager
        if vault_mgr is None:
            logger.warning("Vault is locked or not initialized. Skipping secret injection.")
            return config
            
        if not vault_mgr._is_unlocked:
            logger.warning("Vault is locked. Cannot inject secrets.")
            return config

        # Create a mutable copy of the configuration
        config_data = config.model_dump()
        
        # Inject LLM API keys from vault
        llm_config = config_data.get('llm', {})
        vault_keys = vault_mgr.list_secrets()
        
        # Check for common API key names in vault
        llm_key_mapping = {
            'openai_api_key': 'api_key',
            'anthropic_api_key': 'api_key',
            'gemini_api_key': 'api_key',
            'openrouter_api_key': 'api_key',
        }
        
        for vault_key, config_field in llm_key_mapping.items():
            if vault_key in vault_keys:
                secret_value = vault_mgr.get_secret(vault_key)
                if secret_value:
                    llm_config[config_field] = secret_value
                    logger.debug(f"Injected {vault_key} into LLM config")
        
        # Inject Mattermost credentials (URL and Token together)
        mattermost_config = config_data.get('mattermost', {})
        if 'mattermost_url' in vault_keys and 'mattermost_token' in vault_keys:
            vault_mgr.get_secret('mattermost_url') and None  # Access to verify
            mattermost_url = vault_mgr.get_secret('mattermost_url')
            mattermost_token = vault_mgr.get_secret('mattermost_token')
            if mattermost_url and mattermost_token:
                mattermost_config['url'] = mattermost_url
                mattermost_config['token'] = mattermost_token
                logger.debug("Injected Mattermost URL and token from vault")
        
        # Update the config with injected secrets
        config_data['llm'] = llm_config
        config_data['mattermost'] = mattermost_config
        
        # Create new config object with injected secrets
        return CobaltSettings(**config_data)


def load_config(config_dir: Optional[Path | str] = None) -> CobaltSettings:
    """
    Load configuration from YAML files and merge with environment variables.
    
    Priority (highest to lowest):
    1. Environment variables (via Pydantic's env_nested_delimiter)
    2. YAML files in configs directory
    3. Default values
    
    Args:
        config_dir: Optional path to configuration directory. Defaults to 'configs/'.
    
    Returns:
        CobaltSettings: Loaded configuration object.
    """
    # 1. Resolve Directory
    if config_dir is None:
        candidates = [
            Path.cwd() / "configs",
            Path(__file__).parent.parent / "configs"
        ]
        config_dir = next((p for p in candidates if p.exists()), None)

    if not config_dir:
        logger.warning("Config directory 'configs/' not found. Using defaults.")
        return CobaltSettings()

    config_dir = Path(config_dir)
    logger.info(f"Loading configuration from: {config_dir}")

    # 2. Scan for YAML and Load
    yaml_files = sorted(list(config_dir.glob("*.yaml")) + list(config_dir.glob("*.yml")))
    
    if not yaml_files:
        logger.warning("No YAML files found in configs/. Using defaults.")
        return CobaltSettings()

    # 3. Merge All YAML Files
    master_data = {}
    
    for file_path in yaml_files:
        try:
            file_data = _load_yaml_config(file_path)
            
            if not file_data:
                continue
                
            keys = list(file_data.keys())
            logger.debug(f"Loaded {file_path.name} -> Keys: {keys}")
            
            master_data = _deep_merge(master_data, file_data)
            
        except Exception as e:
            logger.error(f"Failed to load {file_path.name}: {e}")

    # --- VAULT INTEGRATION (NEW) ---
    master_key = os.getenv("COBALT_MASTER_KEY")
    if master_key:
        logger.info("üîë COBALT_MASTER_KEY detected. Unlocking secure vault...")
        vault = VaultManager()
        if vault.unlock(master_key):
            # Ensure base sections exist
            if 'keys' not in master_data: master_data['keys'] = {}
            if 'mattermost' not in master_data: master_data['mattermost'] = {}

            for key_name in vault.list_secrets():
                secret_val = vault.get_secret(key_name)
                
                # Skip None values
                if secret_val is None:
                    continue
                
                # Try to parse as JSON for grouped credentials
                try:
                    parsed_val = json.loads(secret_val)
                except (ValueError, TypeError):
                    parsed_val = secret_val # Fallback to flat string
                
                # Routing logic
                if key_name == "MATTERMOST_CREDS" and isinstance(parsed_val, dict):
                    master_data['mattermost'].update(parsed_val)
                else:
                    # Default flat keys (OpenAI, Gemini, etc.)
                    master_data['keys'][key_name] = parsed_val
                    # Inject into runtime environment for external libraries (LiteLLM)
                    if isinstance(parsed_val, str):
                        os.environ[key_name] = parsed_val
                    
            vault.lock()
            logger.info("üîí Vault secrets loaded into runtime RAM and vault locked.")
        else:
            logger.error("Failed to unlock vault with provided Master Key!")
    else:
        logger.warning("‚ö†Ô∏è No COBALT_MASTER_KEY found. Running in degraded/unsecure mode.")
    # -------------------------------

    # 4. Create Pydantic Settings Object
    # Pydantic will automatically handle ENV overrides via env_nested_delimiter="_"
    try:
        logger.debug(f"Final merged configuration: {master_data}")
        return CobaltSettings(**master_data)
    except Exception as e:
        logger.error(f"Configuration Validation Error: {e}")
        return CobaltSettings()


# Convenience function for direct access
def get_config() -> CobaltSettings:
    """Get the singleton configuration instance."""
    return Config.get_instance().load()

========================================
FILE: src/cobalt_agent/core/orchestrator.py
========================================

"""
Orchestration State Machine for Cobalt Agent
Tracks the Architect's plan and the Drone's progress through sub-tasks.
Self-healing retry loop to overcome local LLM JSON hallucinations.
"""

from typing import List
from pydantic import BaseModel, Field
from loguru import logger
from cobalt_agent.llm import LLM

class SubTask(BaseModel):
    step_number: int = Field(description="The sequential order of this step (e.g., 1, 2, 3).")
    assigned_drone: str = Field(description="The department to handle this step: 'ENGINEERING' or 'OPS'.")
    action: str = Field(description="A clear description of what needs to be done.")
    tool_to_use: str = Field(description="The exact name of the tool to use.")
    status: str = Field(default="PENDING", description="PENDING, SUCCESS, or FAILED")
    observation: str = Field(default="", description="The output or error from the drone's execution.")

class OrchestrationState(BaseModel):
    scratchpad: str = Field(description="Your detailed chain of thought. Explain exactly how you will break this down before writing the master plan.")
    original_request: str = Field(description="The user's exact original request.")
    master_plan: List[SubTask] = Field(min_length=1, description="The step-by-step plan to achieve the goal. THIS CANNOT BE EMPTY. You MUST generate at least one task.")
    current_step: int = Field(default=1)
    status: str = Field(default="PLANNING", description="PLANNING, EXECUTING, FAILED, COMPLETED")

class OrchestratorEngine:
    """
    The Manager's Clipboard (Chief of Staff). 
    Coordinates the "Split-Brain" architecture between the Architect (Planner) and specialized Drones (Executors).
    """
    def __init__(self):
        self.llm = LLM()

    def plan_and_execute(self, user_input: str) -> str:
        logger.info("Orchestrator: Generating Master Plan...")
        
        # 1. THE ARCHITECT PHASE
        architect_prompt = f"""
        You are the Principal Systems Architect (Chief of Staff).
        Analyze the following request and break it down into a step-by-step execution plan.
        
        AVAILABLE DRONES (Departments):
        - ENGINEERING: Use for writing Python code, modifying system files, or analyzing software architecture.
        - OPS: Use for searching the knowledge base, writing Markdown journals, summarizing text, or reading/modifying Obsidian notes.
        
        Available Tools for Drones:
        - search_knowledge (Search the internal codebase, playbooks, and Obsidian notes for context)
        - read_file (Read file contents)
        - list_directory (Explore folder structures)
        - write_file (Create or modify files)
        
        RULES:
        1. Keep steps atomic (e.g., Step 1: search_knowledge, Step 2: read_file, Step 3: write_file).
        2. Do NOT write code in the plan, just the actions the drone needs to take.
        3. Assign the correct Drone to each step based on the task domain.
        4. YOU MUST POPULATE THE 'master_plan' ARRAY. Do not return an empty list.
        """
        
        state = None
        max_retries = 3
        
        # Self-Healing Retry Loop
        for attempt in range(max_retries):
            try:
                state = self.llm.ask_structured(
                    system_prompt=architect_prompt, 
                    response_model=OrchestrationState,
                    user_input=user_input
                )
                if state and state.master_plan:
                    break
                logger.warning(f"Architect returned empty plan on attempt {attempt+1}")
            except Exception as e:
                logger.warning(f"Architect parsing failed on attempt {attempt+1}: {e}")
                
        # Final Failsafe
        if not state or not state.master_plan:
            return "‚ùå **Architect Error:** The LLM failed to generate a valid plan after 3 attempts. Please simplify the request."
            
        # Format the visual output for Mattermost
        output_log = "### üìã Chief of Staff's Master Plan\n"
        output_log += f"**Thoughts:** *{state.scratchpad}*\n\n"
        for step in state.master_plan:
            output_log += f"{step.step_number}. **[{step.assigned_drone.upper()}]** {step.action} (Tool: `{step.tool_to_use}`)\n"
            
        output_log += "\n### üöÄ Execution Log\n"
        
        # 2. THE DRONE EXECUTION PHASE
        for step in state.master_plan:
            output_log += f"\n**Executing Step {step.step_number} ({step.assigned_drone}):** {step.action}\n"
            logger.info(f"Orchestrator: Executing Step {step.step_number} via {step.assigned_drone}")
            
            # Build context from previous steps (The Manager's Clipboard)
            previous_context = ""
            for prev_step in state.master_plan:
                if prev_step.step_number < step.step_number and prev_step.observation:
                    previous_context += f"Step {prev_step.step_number} Result:\n{prev_step.observation}\n\n"
            
            # Formulate the localized context for the Drone
            execution_context = f"""
            YOUR OVERALL MISSION:
            {state.original_request}
            
            PREVIOUS CONTEXT (Results of prior steps):
            {previous_context if previous_context else "None (This is the first step)."}
            
            SPECIFIC STEP TO EXECUTE NOW:
            {step.action}
            
            You must use the '{step.tool_to_use}' tool. Generate the ACTION string now.
            """
            
            # Dynamic Drone Routing
            drone_type = step.assigned_drone.upper()
            if drone_type == "OPS":
                from cobalt_agent.brain.ops import OpsDepartment
                drone = OpsDepartment()
            else:
                # Default to Engineering for unknown or explicit ENGINEERING
                from cobalt_agent.brain.engineering import EngineeringDepartment
                drone = EngineeringDepartment()
                
            # Run the task through the unified ReAct loop
            result = drone.run(execution_context)
            
            step.observation = result
            output_log += f"> {result}\n"
            
            # Zero Trust Break
            if "Action paused" in result or "Proposal [" in result:
                output_log += "\n‚ö†Ô∏è **Execution paused. Awaiting Human-in-the-Loop Approval.**"
                state.status = "PAUSED_FOR_APPROVAL"
                break
                
            if "Error:" in result:
                output_log += "\n‚ùå **Step failed. Halting execution.**"
                state.status = "FAILED"
                break
                
        if state.status == "PLANNING": 
            state.status = "COMPLETED"
            output_log += "\n‚úÖ **Mission Accomplished.**"
            
        return output_log

========================================
FILE: src/cobalt_agent/core/proposals.py
========================================

from typing import Dict, Any, Optional, Callable
from pydantic import BaseModel, Field
import uuid
from datetime import datetime
import threading
import time
import re
from loguru import logger
from typing import TYPE_CHECKING

from cobalt_agent.config import get_config

if TYPE_CHECKING:
    from cobalt_agent.interfaces.mattermost import MattermostInterface

# --- PROPOSAL MODEL ---
class Proposal(BaseModel):
    """Standardized ticket for high-stakes AI actions."""
    task_id: str = Field(default_factory=lambda: str(uuid.uuid4())[:8])
    action: str = Field(description="The specific command or operation to be executed.")
    justification: str = Field(description="The agent's reasoning for why this action is necessary.")
    risk_assessment: str = Field(description="A summary of potential negative impacts (e.g., data loss, capital risk).")
    parameters: Dict[str, Any] = Field(default_factory=dict, description="Technical metadata required for execution.")
    timestamp: datetime = Field(default_factory=datetime.now)
    approved: bool = False
    approval_channel: Optional[str] = None
    approval_message_id: Optional[str] = None

    def format_for_mattermost(self) -> str:
        return (
            f"### üõ°Ô∏è ACTION PROPOSAL [{self.task_id}]\n"
            f"**Action:** `{self.action}`\n\n"
            f"**Justification:** {self.justification}\n"
            f"**Risk:** {self.risk_assessment}\n\n"
            f"### ‚ö†Ô∏è ACTION REQUIRED: Reply exactly with 'Approve {self.task_id}' to execute."
        )


# --- PROPOSAL ENGINE ---
class ProposalEngine:
    """
    The Proposal Engine enforces the Prime Directive by requiring human approval
    before executing high-stakes actions. It creates proposals, sends them to
    Mattermost for approval, and only executes approved actions.
    """
    # Shared state across all instances
    pending_proposals: Dict[str, Proposal] = {}
    callbacks: Dict[str, Callable[[Proposal], None]] = {}
    
    def __init__(self):
        self.config = get_config()
        self.approval_channel = self.config.mattermost.approval_channel
        self.approval_team = self.config.mattermost.approval_team
        self.mattermost: Optional[Any] = None
        self.approved_proposals: Dict[str, Proposal] = {}
        self._approval_callback: Optional[Callable[[Proposal], None]] = None
        self._monitoring = False
        self._monitor_thread: Optional[threading.Thread] = None
        
        logger.info(f"Proposal Engine initialized (Channel: {self.approval_channel})")
    
    def connect_mattermost(self) -> bool:
        """Connect to Mattermost for approval workflow."""
        if self.mattermost:
            return True
        
        # Lazy import to avoid circular dependency
        from cobalt_agent.interfaces.mattermost import MattermostInterface
        
        self.mattermost = MattermostInterface()
        connected = self.mattermost.connect()
        
        if connected:
            # Attach brain for message routing
            self.mattermost.brain = self._get_brain_for_approval_routing()
            logger.info("Proposal Engine: Mattermost connection established")
        
        return connected
    
    def _get_brain_for_approval_routing(self) -> Any:
        """
        Get the brain instance for approval routing.
        This is a stub - the actual brain should be passed in or connected externally.
        """
        # For now, return None - the brain will be attached by the main agent
        return None
    
    def create_proposal(
        self,
        action: str,
        justification: str,
        risk_assessment: str,
        parameters: Optional[Dict[str, Any]] = None
    ) -> Proposal:
        """
        Create a new proposal for a high-stakes action.
        
        Args:
            action: The specific command or operation to be executed
            justification: The agent's reasoning for why this action is necessary
            risk_assessment: A summary of potential negative impacts
            parameters: Technical metadata required for execution
            
        Returns:
            The created Proposal object
        """
        proposal = Proposal(
            action=action,
            justification=justification,
            risk_assessment=risk_assessment,
            parameters=parameters or {}
        )
        
        self.pending_proposals[proposal.task_id] = proposal
        logger.info(f"Proposal created: [{proposal.task_id}] {action[:50]}...")
        
        return proposal
    
    def send_proposal(self, proposal: Proposal) -> bool:
        """
        Send a proposal to Mattermost for approval.
        
        Args:
            proposal: The Proposal object to send
            
        Returns:
            True if proposal was sent successfully
        """
        if not self.mattermost:
            logger.error("Mattermost not connected. Cannot send proposal.")
            return False
        
        if not self.approval_channel:
            logger.error("Approval channel not configured.")
            return False
        
        message = proposal.format_for_mattermost()
        
        # Lazy import to avoid circular dependency
        from cobalt_agent.interfaces.mattermost import MattermostInterface
        
        # Get team ID first
        try:
            teams = self.mattermost.driver.teams.get_team_by_name(self.approval_team)
            if not teams:
                logger.error(f"Approval team not found: {self.approval_team}")
                return False
            
            team_id = teams["id"]
            
            # Get channel ID using team_id as parameter
            channel = self.mattermost.driver.channels.get_channel_by_name(team_id, self.approval_channel)
            if not channel:
                logger.error(f"Approval channel not found: {self.approval_channel} in team {self.approval_team}")
                return False
            
            channel_id = channel["id"]
            
            # Send the proposal message
            post = self.mattermost.driver.posts.create_post(
                options={
                    "channel_id": channel_id,
                    "message": message
                }
            )
            
            if post and "id" in post:
                proposal.approval_message_id = post["id"]
                proposal.approval_channel = channel_id
                logger.info(f"Proposal sent to Mattermost: [{proposal.task_id}]")
                return True
            else:
                logger.error("Failed to send proposal to Mattermost")
                return False
                
        except Exception as e:
            logger.error(f"Failed to send proposal: {e}")
            return False
    
    def handle_approval_response(self, message: str, channel_id: Optional[str] = None) -> Optional[str]:
        """
        Check if a message is an approval response for a pending proposal and return a formatted message.
        
        Args:
            message: The message text from Mattermost
            channel_id: Optional channel ID where the message was posted
            
        Returns:
            A formatted message string if this is a valid approval response, None otherwise
        """
        # Check if this is an approval message
        approval_pattern = r"approve\s+(\w{8})"
        match = re.search(approval_pattern, message.lower())
        
        if not match:
            # Check for reject pattern
            reject_pattern = r"reject\s+(\w{8})"
            reject_match = re.search(reject_pattern, message.lower())
            if reject_match:
                task_id = reject_match.group(1)
                return f"‚ùå Rejection received for task [{task_id}]. The action has been cancelled."
            return None
        
        task_id = match.group(1)
        
        # If channel_id is provided, validate it
        if channel_id and self.approval_channel and channel_id != self.approval_channel:
            return None
        
        # Look up the pending proposal
        if task_id in self.pending_proposals:
            proposal = self.pending_proposals.pop(task_id)
            proposal.approved = True
            self.approved_proposals[task_id] = proposal
            logger.info(f"Proposal approved: [{task_id}]")
            # Execute the stored callback
            if task_id in self.callbacks:
                try:
                    self.callbacks[task_id](proposal)
                    return f"‚úÖ Approval received for task [{task_id}]. Action executed successfully."
                except Exception as e:
                    logger.error(f"Callback execution failed: {e}")
                    return f"‚ùå Approval received, but execution failed: {e}"
            else:
                return f"‚ö†Ô∏è Approval received for [{task_id}], but no execution callback was found in memory."
        elif task_id in self.approved_proposals:
            return f"‚ÑπÔ∏è Proposal [{task_id}] was already approved."
        else:
            logger.warning(f"Approval for unknown task_id: {task_id}")
            return f"‚ö†Ô∏è No pending approval found for task [{task_id}]."
    
    def wait_for_approval(self, proposal: Proposal, timeout: int = 3600) -> bool:
        """
        Wait for a proposal to be approved (non-blocking with threading.Event).
        
        Args:
            proposal: The Proposal to wait for
            timeout: Maximum time to wait in seconds (default 1 hour)
            
        Returns:
            True if approved, False if timed out
        """
        # Use an event to signal when the proposal is approved or timeout occurs
        approval_event = threading.Event()
        
        def check_approval():
            start_time = time.time()
            while not approval_event.is_set():
                # Check if proposal was approved
                if proposal.task_id in self.approved_proposals:
                    approval_event.set()
                    return
                
                # Check for timeout
                if time.time() - start_time >= timeout:
                    # Remove from pending if timeout
                    if proposal.task_id in self.pending_proposals:
                        del self.pending_proposals[proposal.task_id]
                    logger.warning(f"Approval timeout for proposal: [{proposal.task_id}]")
                    return
                
                # Non-blocking wait using threading.Event
                if approval_event.wait(timeout=0.5):  # Check every 0.5 seconds
                    return
        
        # Start background thread to monitor approval
        monitor_thread = threading.Thread(target=check_approval, daemon=True)
        monitor_thread.start()
        
        # Wait for approval or timeout
        approval_event.wait()
        return proposal.task_id in self.approved_proposals
    
    def execute_approved(self, proposal: Proposal) -> bool:
        """
        Execute an approved proposal's action.
        
        Args:
            proposal: The approved Proposal to execute
            
        Returns:
            True if execution succeeded
        """
        if not proposal.approved:
            logger.error(f"Cannot execute unapproved proposal: [{proposal.task_id}]")
            return False
        
        try:
            # Execute the action (this would be implemented by the caller)
            action = proposal.action
            
            # For now, just log the action
            logger.info(f"Executing approved action: {action}")
            
            if self._approval_callback:
                self._approval_callback(proposal)
            
            return True
        except Exception as e:
            logger.error(f"Failed to execute approved action [{proposal.task_id}]: {e}")
            return False
    
    def set_approval_callback(self, task_id: str, callback: Callable[[Proposal], None]) -> None:
        """
        Set a callback function to be called when a proposal is approved.
        
        Args:
            task_id: The unique identifier for the task
            callback: Function that takes a Proposal and returns None
        """
        self.callbacks[task_id] = callback
        logger.info(f"Approval callback set for task [{task_id}]")
    
    def start_monitoring(self) -> None:
        """Start monitoring for approval responses in the background."""
        if self._monitoring:
            logger.warning("Monitoring already running")
            return
        
        self._monitoring = True
        self._monitor_thread = threading.Thread(target=self._monitor_approval_channel, daemon=True)
        self._monitor_thread.start()
        logger.info("Proposal Engine monitoring started")
    
    def _monitor_approval_channel(self) -> None:
        """Background thread to monitor the approval channel for approval responses."""
        # This would be implemented with the Mattermost WebSocket listener
        # For now, just a placeholder
        logger.info("Approval channel monitoring started (WebSocket listener attached to MattermostInterface)")
    
    def stop_monitoring(self) -> None:
        """Stop monitoring for approval responses."""
        self._monitoring = False
        if self._monitor_thread:
            self._monitor_thread.join(timeout=1)
        logger.info("Proposal Engine monitoring stopped")


# --- CONVENIENCE FUNCTION ---
def create_and_send_proposal(
    action: str,
    justification: str,
    risk_assessment: str,
    parameters: Optional[Dict[str, Any]] = None
) -> Optional[Proposal]:
    """
    Convenience function to create and send a proposal.
    
    Args:
        action: The specific command or operation to be executed
        justification: The agent's reasoning for why this action is necessary
        risk_assessment: A summary of potential negative impacts
        parameters: Technical metadata required for execution
        
    Returns:
        The created and sent Proposal if successful, None otherwise
    """
    engine = ProposalEngine()
    
    # Connect to Mattermost
    if not engine.connect_mattermost():
        logger.error("Failed to connect to Mattermost")
        return None
    
    # Create the proposal
    proposal = engine.create_proposal(
        action=action,
        justification=justification,
        risk_assessment=risk_assessment,
        parameters=parameters
    )
    
    # Send to Mattermost
    if not engine.send_proposal(proposal):
        logger.error("Failed to send proposal")
        return None
    
    return proposal

========================================
FILE: src/cobalt_agent/interfaces/cli.py
========================================

"""
Cobalt Agent - Interactive CLI Interface
Refactored: Centralized Routing + RAG (Retrieval Augmented Generation)
"""

from rich.console import Console
from rich.prompt import Prompt
from loguru import logger
from rich.markdown import Markdown

# Type hinting
from typing import Optional, TYPE_CHECKING, Any, List
if TYPE_CHECKING:
    from cobalt_agent.brain.cortex import Cortex

from cobalt_agent.tools.tool_manager import ToolManager

class CLI:
    """Interactive command-line interface for Cobalt Agent."""
    
    def __init__(self, memory_system, llm, system_prompt, tool_manager, cortex=None):
        self.console = Console()
        self.tool_manager = tool_manager
        self.memory = memory_system
        self.llm = llm
        self.system_prompt = system_prompt
        self.cortex = cortex 

        logger.info("CLI initialized with Brain connected")
    
    def start(self):
        """Start the interactive CLI loop."""
        self.console.print("\n[bold green]ü§ñ Cobalt Agent Interface[/bold green]")
        self.console.print(f"[dim]Model: {self.llm.model_name}[/dim]")
        self.console.print("[dim]Type 'exit' or 'quit' to leave[/dim]\n")
        
        while True:
            try:
                user_input = Prompt.ask("[bold cyan]Cobalt >[/]")
                user_input = user_input.strip()
                
                if not user_input: continue

                if user_input.lower() in ['exit', 'quit']:
                    self.console.print("[yellow]Shutting down Cobalt Agent...[/yellow]")
                    break
                
                # Save to Short-Term Memory immediately
                self.memory.add_log(user_input, source="User")

                # 1. CORTEX ROUTING (The Primary Brain)
                handled_by_cortex = False
                if self.cortex:
                    # Cortex decides: Tactical? Intel? Ops? Or None (General Chat)?
                    specialist_response = self.cortex.route(user_input)
                    
                    if specialist_response:
                        # Cortex returned a result (e.g., Raw Data or Note Status)
                        self.console.print(f"\n[bold purple]ü§ñ Cortex:[/bold purple]")
                        self.console.print(Markdown(specialist_response))
                        self.console.print()
                        
                        # Crucial: Log this to memory so the LLM "sees" it for follow-up analysis
                        self.memory.add_log(specialist_response, source="System")
                        handled_by_cortex = True
                
                # If Cortex handled it, we loop back to let user ask follow-up (e.g. "Analyze this")
                if handled_by_cortex: continue 
      	      	
                # 2. AUTONOMOUS CHAT (The Fallback / Analyst)
                # Handles "Analyze that", "Hi", or generic questions Cortex didn't claim.
                self._handle_chat(user_input)
                    
            except KeyboardInterrupt:
                self.console.print("\n[yellow]Interrupted. Shutting down...[/yellow]")
                break
            except Exception as e:
                logger.error(f"CLI error: {str(e)}", exc_info=True)
                self.console.print(f"[red]Error: {str(e)}[/red]")
    
    def _format_tool_output(self, output: Any) -> str:
        """Helper to convert Pydantic models/Lists to clean strings."""
        if isinstance(output, list):
            return "\n".join([str(item) for item in output])
        return str(output)

    def _retrieve_long_term_memory(self, query: str) -> str:
        """
        RAG HOOK: Searches the Postgres DB for relevant past context.
        """
        if not hasattr(self.memory, "search"):
            return ""

        try:
            self.console.print("[dim]üß† Recalling...[/dim]")
            
            # 1. Fetch MORE (10 instead of 3) to break through the "Echo Chamber"
            results = self.memory.search(query, limit=10)
            
            if not results:
                return ""
            
            # 2. Deduplicate & Format
            seen_content = set()
            unique_memories = []
            
            for mem in results:
                # Extract content safely
                if hasattr(mem, "content"):
                    content = mem.content
                    timestamp = getattr(mem, "timestamp", "Unknown")
                elif isinstance(mem, dict):
                    content = mem.get("content", "")
                    timestamp = mem.get("timestamp", "Unknown")
                else:
                    content = str(mem)
                    timestamp = "Unknown"
                
                # CLEANUP: Remove whitespace and skip if empty
                content = content.strip()
                if not content: continue
                
                # DEDUPLICATION: If we already saw this exact sentence, skip it.
                # This prevents "What is my favorite stock?" appearing 5 times.
                if content in seen_content:
                    continue
                
                # SELF-FILTER: Don't show the user's *current* question as a memory
                if content == query.strip():
                    continue

                seen_content.add(content)
                unique_memories.append((timestamp, content))
            
            # 3. Limit the final output to the top 5 UNIQUE results
            final_memories = unique_memories[:5]
            
            if not final_memories:
                return ""

            self.console.print(f"[dim green]Found {len(final_memories)} unique memories:[/dim green]")
            
            memory_block = "\n\n=== RELEVANT LONG-TERM MEMORY ===\n"
            for ts, text in final_memories:
                # Print preview for you
                clean_preview = text.replace("\n", " ")[:80]
                self.console.print(f"[dim]  - [{ts}] {clean_preview}...[/dim]")
                
                # Add to context
                memory_block += f"- [{ts}] {text}\n"
            
            return memory_block
            
        except Exception as e:
            logger.warning(f"Memory retrieval failed: {e}")
            return ""

    def _handle_chat(self, user_input: str):
        """Autonomous Agent Loop (ReAct Pattern) for general analysis."""
        self.console.print(f"[dim]Thinking...[/dim]")
        
        turn_history = [] 
        current_input = user_input
        MAX_TURNS = 5
        
        # --- STEP 1: RAG (Retrieval) ---
        # Fetch past memories relevant to this specific input
        long_term_context = self._retrieve_long_term_memory(user_input)
        
        # --- CRITICAL FIX: INJECT MEMORY INTO SYSTEM PROMPT ---
        # We modify the system prompt for THIS RUN ONLY.
        # This forces the LLM to treat the memory as an absolute rule/fact.
        run_specific_system_prompt = self.system_prompt
        if long_term_context:
            run_specific_system_prompt += f"\n\n{long_term_context}"
        
        for turn in range(MAX_TURNS):
            # 1. Get Short Term RAM
            short_term_context = self.memory.get_context()
            
            # Combine RAM + History (But NOT Long Term, that's in System Prompt now)
            full_history = str(short_term_context)
            if turn > 0:
                for t in turn_history:
                    full_history += f"\n{t['role']}: {t['content']}"
            
            # 2. Ask Brain
            response = self.llm.think(
                user_input=current_input,
                system_prompt=run_specific_system_prompt, # <--- The "Memory-Enhanced" Prompt
                memory_context=full_history
            )
            
            # 3. Check for ACTION (Tool Use by the LLM itself)
            if "ACTION:" in response:
                try:
                    lines = response.split('\n')
                    action_line = next(line for line in lines if "ACTION:" in line)
                    parts = action_line.replace("ACTION:", "").strip().split(" ", 1)
                    
                    tool_name = parts[0]
                    query = parts[1] if len(parts) > 1 else ""
                    
                    self.console.print(f"[bold yellow]‚ö° Auto-Tool:[/bold yellow] {tool_name} -> {query}")
                    self.memory.add_log(f"Agent Thought: {response}", source="Assistant")
                    
                    # Execute (tool_manager now returns strings)
                    result = self.tool_manager.execute_tool(tool_name.lower(), {"query": query})
                    
                    # Format observation (string handling)
                    if result.startswith("Error:"):
                        observation = f"System Observation: Error - {result}"
                        self.console.print(f"[red]{observation}[/red]")
                    else:
                        output_str = result
                        preview = output_str[:500] + "..." if len(output_str) > 500 else output_str
                        self.console.print(f"[dim cyan]{preview}[/dim cyan]") 
          	    	      	
                        observation = f"System Observation from {tool_name}: {output_str}"
                    
                    turn_history.append({"role": "assistant", "content": response})
                    turn_history.append({"role": "user", "content": observation})
                    
                    current_input = (
                        "(Observation provided above. Analyze this data STRICTLY according to the "
                        "protocols and formatting rules defined in your System Prompt. "
                        "Do not deviate from the agreed structure.)"
                    )
                    
                except Exception as e:
                    self.console.print(f"[red]Auto-Loop Error: {e}[/red]")
                    break
            else:
                self.memory.add_log(response, source="Assistant")
                self.console.print(f"\n[bold green]Cobalt:[/bold green]")
                self.console.print(Markdown(response))
                self.console.print()
                break

========================================
FILE: src/cobalt_agent/interfaces/mattermost.py
========================================

"""
Mattermost Communication Interface for Cobalt Agent
Provides a robust interface for sending and receiving messages via Mattermost.
"""

import asyncio
import json
import threading
import multiprocessing
from typing import Optional, Dict, Any, Callable, TYPE_CHECKING
if TYPE_CHECKING:
    from cobalt_agent.main import CobaltAgent
    from cobalt_agent.core.proposals import ProposalEngine, Proposal
from urllib.parse import urlparse

import websockets
from loguru import logger
from mattermostdriver import Driver

from cobalt_agent.config import get_config, MattermostConfig


class MattermostInterface:
    """
    Interface for Mattermost communication.
    
    Handles connection to Mattermost server, authentication,
    and message sending functionality.
    """
    
    def __init__(self, config: Optional[MattermostConfig] = None):
        self.proposal_engine: Optional[Any] = None
        """
        Initialize the Mattermost interface.
        
        Args:
            config: Optional MattermostConfig. If not provided, loads from global config.
        """
        self.config = config or get_config().mattermost
        self.driver: Optional[Driver] = None
        self.brain: Optional[Any] = None
        self.is_connected: bool = False
        
        logger.info(f"MattermostInterface initialized (URL: {self.config.url})")
    
    def connect(self) -> bool:
        """
        Connect to the Mattermost server and authenticate.
        
        Returns:
            True if connection and authentication succeeded, False otherwise.
        """
        if not self.config.url:
            logger.error("MATTERMOST_URL is not configured")
            return False
        
        if not self.config.token:
            logger.error("MATTERMOST_TOKEN is not configured")
            return False
        
        try:
            parsed = urlparse(self.config.url)
            driver_options = {
                "url": parsed.hostname,
                "scheme": parsed.scheme or "http",
                "port": parsed.port or 8065,
                "basepath": "/api/v4",
                "token": self.config.token,
            }
            
            logger.debug(f"Driver options: {driver_options}")
            
            self.driver = Driver(options=driver_options)
            
            # Attempt login
            user = self.driver.login()
            
            if user and "id" in user:
                self.is_connected = True
                logger.info(f"Successfully connected to Mattermost as user: {user.get('username', 'unknown')}")
                return True
            else:
                logger.error("Failed to authenticate with Mattermost")
                self.is_connected = False
                return False
                
        except Exception as e:
            logger.error(f"Failed to connect to Mattermost: {e}")
            self.is_connected = False
            return False
    
    def disconnect(self) -> None:
        """Disconnect from the Mattermost server."""
        if self.driver:
            try:
                self.driver.logout()
            except Exception as e:
                logger.warning(f"Error during logout: {e}")
        self.is_connected = False
        logger.info("Disconnected from Mattermost")
    
    def send_message(self, channel_name: str, team_name: str, message: str) -> bool:
        """
        Send a message to a Mattermost channel.
        
        Args:
            channel_name: Name of the channel (without #)
            team_name: Name of the team
            message: The message content to send
            
        Returns:
            True if message was sent successfully, False otherwise.
        """
        if not self.is_connected or not self.driver:
            logger.error("Not connected to Mattermost")
            return False
        
        try:
            # Get team ID
            teams = self.driver.teams.get_team_by_name(team_name)
            if not teams:
                logger.error(f"Team not found: {team_name}")
                return False
            
            team_id = teams["id"]
            
            # Get channel ID using team_id as parameter
            channel = self.driver.channels.get_channel_by_name(team_id, channel_name)
            if not channel:
                logger.error(f"Channel not found: {channel_name} in team {team_name}")
                return False
            
            channel_id = channel["id"]
            
            post = self.driver.posts.create_post(
                options={
                    "channel_id": channel_id,
                    "message": message
                }
            )
            
            if post and "id" in post:
                logger.info(f"Message sent to #{channel_name} in team {team_name}")
                return True
            else:
                logger.error("Failed to create post")
                return False
                
        except Exception as e:
            logger.error(f"Failed to send message: {e}")
            return False
    
    def send_message_to_channel_id(self, channel_id: str, message: str) -> bool:
        """
        Send a message directly to a channel using its ID.
        
        Args:
            channel_id: The Mattermost channel ID
            message: The message content to send
            
        Returns:
            True if message was sent successfully, False otherwise.
        """
        if not self.is_connected or not self.driver:
            logger.error("Not connected to Mattermost")
            return False
        
        try:
            post = self.driver.posts.create_post(
                options={
                    "channel_id": channel_id,
                    "message": message
                }
            )
            
            if post and "id" in post:
                logger.info(f"Message sent to channel {channel_id}")
                return True
            else:
                logger.error("Failed to create post")
                return False
                
        except Exception as e:
            logger.error(f"Failed to send message: {e}")
            return False
    
    def get_my_user_id(self) -> Optional[str]:
        """
        Get the current user's ID.
        
        Returns:
            User ID string if connected, None otherwise.
        """
        if not self.is_connected or not self.driver:
            return None
        
        try:
            user = self.driver.users.get_user("me")
            return user["id"] if user else None
        except Exception as e:
            logger.error(f"Failed to get user: {e}")
            return None
    
    async def _handle_mattermost_event(self, message: str) -> None:
        """
        Internal handler for Mattermost WebSocket events.
        
        Properly handles the Mattermost API quirk where event_data['data']['post']
        is passed as a stringified JSON object, NOT a parsed dictionary.
        
        Args:
            message: The event JSON string from Mattermost WebSocket
        """
        # Log raw payload for debugging
        logger.info(f"RAW WEBSOCKET PAYLOAD: {message}")
        
        try:
            event_data = json.loads(message)
            
            # Only process 'posted' events (new messages)
            if event_data.get("event") != "posted":
                return
            
            # Extract and parse the nested post data
            post_str = event_data.get("data", {}).get("post")
            if not post_str:
                return
            
            post_data = json.loads(post_str)
            
            user_id = post_data.get("user_id")
            channel_id = post_data.get("channel_id")
            text = post_data.get("message", "")
            
            # Ignore Mattermost system messages (joins, leaves, header updates)
            if post_data.get("type", "") != "":
                return
            
            # Ignore the bot's own messages to prevent infinite loops
            if user_id == self.get_my_user_id():
                return
            
            logger.info(f"Message received in channel {channel_id}: {text}")
            
            # === HITL APPROVAL INTERCEPTOR ===
            text_lower = text.strip().lower()
            if text_lower.startswith("approve") or text_lower.startswith("reject"):
                from cobalt_agent.core.proposals import ProposalEngine
                engine = ProposalEngine()
                
                # Handle the response and send the result back to the channel
                result_msg = engine.handle_approval_response(text)
                if result_msg:
                    # Reply in the approvals channel
                    self.send_message_to_channel_id(channel_id, result_msg)
                    
                    # CLOSE THE LOOP: Broadcast to town-square so the user knows the outcome
                    if "‚úÖ Approval received" in result_msg:
                        self.send_message("town-square", self.config.approval_team, "‚úÖ **Task Completed:** The pending action was approved and successfully executed.")
                    elif "‚ùå Rejection received" in result_msg:
                        self.send_message("town-square", self.config.approval_team, "‚ùå **Task Cancelled:** The pending action was rejected by an Admin.")
                return
            
            # Check for approval response first
            if self.proposal_engine:
                approved_proposal = self.proposal_engine.handle_approval_response(text, channel_id)
                if approved_proposal:
                    logger.info(f"Proposal approved: [{approved_proposal.task_id}]")
                    # Execute the approved action
                    self.proposal_engine.execute_approved(approved_proposal)
                    return  # Don't route to brain for approval responses
            
            # Route to the brain if attached - run LLM inference in background thread
            if hasattr(self, 'brain') and self.brain:
                logger.info("Routing message to Cortex in background thread...")
                
                # Import tool_manager for the tool loop
                from cobalt_agent.tools.tool_manager import ToolManager
                from cobalt_agent.memory import MemorySystem
                from cobalt_agent.config import get_config
                
                # Try to get memory from brain if available (for longer-term context)
                try:
                    memory = self.brain.memory if hasattr(self.brain, 'memory') else MemorySystem()
                except:
                    memory = MemorySystem()
                
                def think_and_reply():
                    try:
                        # Use 'route' method on Cortex for user input
                        response = self.brain.route(text)
                        if response:
                            # Specialized department response (TACTICAL, INTEL, OPS, etc.)
                            self.send_message_to_channel_id(channel_id, response)
                        else:
                            # DEFAULT route - use ReAct loop for tool execution
                            logger.info("DEFAULT route detected, using ReAct loop...")
                            # Use the agent's LLM with the correct system prompt
                            from cobalt_agent.config import get_config
                            config = get_config()
                            from cobalt_agent.prompt import PromptEngine
                            prompt_engine = PromptEngine(config.persona)
                            system_prompt = prompt_engine.build_system_prompt()
                            
                            # Initialize conversation history with user input
                            conversation_history = [
                                {"role": "user", "content": text}
                            ]
                            
                            # MAX_ITERATIONS to prevent infinite loops
                            MAX_ITERATIONS = 3
                            iteration = 0
                            final_answer = None
                            
                            while iteration < MAX_ITERATIONS:
                                iteration += 1
                                logger.info(f"ReAct iteration {iteration}/{MAX_ITERATIONS}")
                                
                                # Generate response from LLM using conversation history
                                response = self.brain.llm.generate_response(
                                    system_prompt=system_prompt,
                                    user_input=None,  # Already included in conversation history
                                    memory_context=conversation_history,
                                    search_context=""
                                )
                                
                                logger.info(f"LLM Response: {response}")
                                
                                # Check if response contains ACTION:
                                if "ACTION:" in response:
                                    # Parse the tool name and query
                                    logger.info("ACTION: detected, parsing tool command...")
                                    
                                    # Extract the ACTION line
                                    action_line = None
                                    for line in response.split('\n'):
                                        if 'ACTION:' in line:
                                            action_line = line
                                            break
                                    
                                    if action_line:
                                        # Parse "ACTION: tool_name query_string"
                                        action_parts = action_line.replace('ACTION:', '').strip().split(' ', 1)
                                        tool_name = action_parts[0].strip().lower()
                                        query = action_parts[1].strip() if len(action_parts) > 1 else ""
                                        
                                        # Fuzzy Match Hack: map "scrape" and "search" to "browser"
                                        if tool_name in ["scrape", "search"]:
                                            tool_name = "browser"
                                            logger.info(f"Fuzzy matched '{tool_name}' -> 'browser'")
                                        
                                        # Execute the tool
                                        tool_manager = ToolManager()
                                        tool_result = tool_manager.execute_tool(
                                            tool_name=tool_name,
                                            args={"query": query}
                                        )
                                        
                                        # Format the observation for LLM (tool_manager now returns strings)
                                        if tool_result.startswith("Error:"):
                                            observation = f"[Observation: Tool execution failed - {tool_result}]"
                                        else:
                                            observation = f"[Observation: {tool_result}]"
                                        
                                        # Append observation to conversation history
                                        conversation_history.append({
                                            "role": "assistant",
                                            "content": response
                                        })
                                        conversation_history.append({
                                            "role": "user",
                                            "content": observation
                                        })
                                        
                                        logger.info(f"Tool executed: {tool_name}, Observation: {observation}")
                                    else:
                                        # No valid ACTION line found, treat as final answer
                                        final_answer = response
                                        break
                                else:
                                    # No ACTION: found, this is the final conversational answer
                                    logger.info("No ACTION: detected, returning final answer")
                                    final_answer = response
                                    break
                            
                            # Send final answer to Mattermost
                            if final_answer:
                                # Update memory with assistant's response
                                memory.add_log(final_answer, source="Assistant")
                                self.send_message_to_channel_id(channel_id, final_answer)
                                logger.info("Final response sent to Mattermost")
                            else:
                                logger.warning("ReAct loop completed without final answer")
                    except Exception as e:
                        logger.error(f"think_and_reply error: {e}", exc_info=True)
                
                # Run the sync function in a background thread
                asyncio.create_task(asyncio.to_thread(think_and_reply))
            else:
                logger.warning("Brain is not attached to MattermostInterface! Cannot reply.")
                
        except Exception as e:
            logger.error(f"Error parsing Mattermost event: {e}", exc_info=True)
    
    def _handle_events(self, mm_driver: Driver) -> None:
        """
        Event handler for Mattermost WebSocket events.
        
        This method is called by the websocket when events are received.
        
        Args:
            mm_driver: The Mattermost driver instance (for accessing get_user_id, etc.)
        """
        # This is called for each event type from the websocket
        pass
    
    def _run_websocket_in_process(self, brain: "CobaltAgent", event_queue: "multiprocessing.Queue") -> None:
        """
        Run the Mattermost WebSocket in a separate process to avoid event loop conflicts.
        
        Args:
            brain: The CobaltAgent instance (not used directly, but for reference)
            event_queue: Queue for passing events to the main process
        """
        # Import here to ensure it runs in the new process context
        from mattermostdriver import Driver
        from loguru import logger
        
        # Reinitialize the driver in this process
        parsed = urlparse(self.config.url)
        driver_options = {
            "url": parsed.hostname,
            "scheme": parsed.scheme or "http",
            "port": parsed.port or 8065,
            "basepath": "/api/v4",
            "token": self.config.token,
        }
        
        driver = Driver(options=driver_options)
        driver.login()
        
        # Define the event handler for init_websocket
        def on_event(event: str, data: Dict[str, Any]) -> None:
            # Build the event dict from the event type and data
            event_dict = {"event": event, "data": data}
            # For now, just log to file since stdout might be redirected
            logger.info(f"Mattermost event: {event}")
            # Send to main process if needed
            try:
                event_queue.put(event_dict)
            except:
                pass
        
        try:
            # This runs its own event loop
            driver.init_websocket(on_event)
        except Exception as e:
            logger.error(f"WebSocket error: {e}")
        
        driver.logout()
    
    def start_listening(self, brain: "CobaltAgent") -> None:
        async def run_native_ws():
            # Format the URL properly for WebSockets
            base_url = self.config.url.rstrip('/')
            ws_url = base_url.replace('http://', 'ws://').replace('https://', 'wss://') + "/api/v4/websocket"
            
            logger.info(f"Connecting to native WebSocket engine: {ws_url}")
            
            headers = {"Authorization": f"Bearer {self.config.token}"}
            try:
                async with websockets.connect(ws_url, ping_interval=20, ping_timeout=20, additional_headers=headers) as ws:
                    logger.info("Connected and authenticated via HTTP headers. Listening for messages...")
                    
                    # Listen to the raw data stream forever
                    async for message in ws:
                        logger.info(f"RAW WEBSOCKET PAYLOAD: {message}")
                        await self._handle_mattermost_event(message)
            except Exception as e:
                logger.error(f"Native WebSocket connection dropped: {e}", exc_info=True)

        # Run the native engine in the main thread
        logger.info("Starting native WebSocket engine...")
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(run_native_ws())
        except KeyboardInterrupt:
            logger.info("Bot shut down manually.")

========================================
FILE: src/cobalt_agent/llm.py
========================================

"""
Cobalt Agent - LLM (The Brain)
Handles communication with AI providers via LiteLLM.
Unified interface supporting Chat, Direct Queries, and Structured Data extraction.
"""

import os
import json
from typing import List, Dict, Any, Optional, Type, TypeVar
from pydantic import BaseModel, Field, SecretStr, ValidationError
from loguru import logger
from litellm import completion

# Generic type for Pydantic models
T = TypeVar("T", bound=BaseModel)

class LLM(BaseModel):
    """
    The Brain of the agent. 
    Processes prompts and returns intelligent responses.
    """
    
    # Configuration
    role: str = Field("default", description="The role to use for model selection")
    api_key: Optional[SecretStr] = Field(default=None, description="API Key (optional if in env vars)")
    
    def __init__(self, **data: Any) -> None:
        super().__init__(**data)
        self._resolve_model_config()
        
    # Model name property
    @property
    def model_name(self) -> str:
        """Public property to access the resolved model name."""
        return self._model_name
    
    def switch_role(self, new_role: str) -> None:
        """
        Switch to a new role and re-resolve the model configuration.
        This allows hot-swapping between different models (e.g., Qwen 80B -> DeepSeek 70B).
        """
        self.role = new_role
        self._resolve_model_config()
        logger.info(f"Role switched to '{new_role}', model updated to: {self._model_name}")
    
    def _resolve_model_config(self) -> None:
        from cobalt_agent.config import load_config
        # Load the configuration object
        config = load_config()
        
        # Debugging: Print the config object to verify its attributes
        logger.debug(f"Config Object: {config.__dict__}")
        # 1. Resolve the Model Alias (Intent -> Alias)
        active_profile = config.active_profile
        
        model_alias = active_profile.get(self.role, active_profile.get("default"))

        # 2. Retrieve Model Config (Alias -> Config)
        if model_alias not in config.models:
            raise ValueError(f"Model alias '{model_alias}' not found in registry.")
            
        model_config = config.models[model_alias]
        
        # 3. Construct Model String
        if isinstance(model_config, dict):
            provider = model_config.get("provider")
            name = model_config.get("model_name")
            node_ref = model_config.get("node_ref")
            env_key_ref = model_config.get("env_key_ref")
        else:
            provider = model_config.provider
            name = model_config.model_name
            node_ref = getattr(model_config, "node_ref", None)
            env_key_ref = getattr(model_config, "env_key_ref", None)

        self._model_name = f"{provider}/{name}"

        # Store model config for later use in _call_provider
        self._model_config = model_config

        # 4. Resolve API Base (Local nodes need an IP, Cloud providers do not)
        if node_ref:
            nodes = config.network.nodes
            target_node = nodes.get(node_ref) if isinstance(nodes, dict) else getattr(nodes, node_ref, None)
            
            if not target_node:
                raise ValueError(f"Node reference '{node_ref}' not found in network topology.")
            
            if isinstance(target_node, dict):
                ip = target_node.get("ip")
                port = target_node.get("port")
                protocol = target_node.get("protocol", "http")
            else:
                ip = target_node.ip
                port = target_node.port
                protocol = getattr(target_node, "protocol", "http")

            self._api_base = f"{protocol}://{ip}:{port}"
        else:
            # Cloud providers (OpenAI, Gemini, OpenRouter) do not need an API base
            self._api_base = None

        # 5. Resolve API Key from Vault (RAM-locked secrets)
        if env_key_ref:
            keys = config.model_dump().get("keys", {})  # Access extra fields
            key_name = keys.get(env_key_ref) if isinstance(keys, dict) else getattr(keys, env_key_ref, None)
            
            if key_name and isinstance(keys, dict):
                env_var_name = keys.get(key_name)
                if env_var_name:
                    self.api_key = SecretStr(os.getenv(env_var_name, ""))
            elif key_name and not isinstance(keys, dict):
                # Handle object-style keys config
                env_var_name = getattr(keys, key_name, None)
                if env_var_name:
                    self.api_key = SecretStr(os.getenv(env_var_name, ""))
        
    def _call_provider(self, messages: List[Dict[str, str]]) -> str:
        """
        Internal helper to send messages to the provider via LiteLLM.
        Uses Zero-Trust security: API keys are resolved from RAM-locked vault.
        """
        try:
            # 1. Resolve API Key securely from RAM (Vault)
            from cobalt_agent.config import load_config
            config = load_config()
            
            # Access keys via model_dump() to handle extra fields
            keys = config.model_dump().get("keys", {})
            
            api_key = None
            if "env_key_ref" in self._model_config:
                key_name = self._model_config["env_key_ref"]  # e.g., "gemini"
                if key_name in keys:
                    env_var_name = keys[key_name]  # e.g., "GEMINI_API_KEY"
                    # env_var_name now contains the actual key name, e.g., "GEMINI_API_KEY"
                    # The value of that env var is stored in keys under env_var_name
                    api_key = keys.get(env_var_name)

            # 2. Prepare execution arguments
            kwargs = {
                "model": self._model_name,
                "messages": messages,
                "temperature": 0.7,
                "max_tokens": 4000
            }
            
            if self._api_base:
                kwargs["base_url"] = self._api_base
            if api_key:
                kwargs["api_key"] = api_key
                
            logger.debug(f"Routing LiteLLM request to exact model string: {kwargs['model']}")
                
            # 3. Execute request
            response = completion(**kwargs)
            
            if not response.choices or not response.choices[0].message:
                 raise ValueError("Empty response from provider")
                 
            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"LLM Call Failed: {str(e)}")
            raise e

    # --- 1. THE CHAT INTERFACE (For Main Loop) ---
    def generate_response(self,
                          system_prompt: Optional[str] = None,
                          user_input: Optional[str] = None,
                          memory_context: List[Dict] = None,
                          search_context: str = "") -> str:
        """
        Main conversational loop method. Handles history and context injection.
        """
        messages = []

        # A. System Prompt
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        # B. Memory Context
        if memory_context:
            for item in memory_context:
                # Case 1: Memory Log (Standard)
                if "source" in item:
                    role = "user" if item["source"] == "User" else "assistant"
                    messages.append({"role": role, "content": item["message"]})
                
                # Case 2: Tool Loop Message (Raw)
                elif "role" in item:
                    messages.append({"role": item["role"], "content": item["content"]})

        # C. Search Context (Legacy/Injection)
        if search_context:
             messages.append({
                "role": "user", 
                "content": f"Context Information:\n{search_context}"
            })

        # D. Current Input
        if user_input:
            messages.append({"role": "user", "content": user_input})

        try:
            response = self._call_provider(messages)
            logger.info(f"Cobalt, LLM model version: {self.model_name}")
            logger.info(f"Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst")
            return response
        except Exception as e:
            logger.error(f"LLM Call Failed: {str(e)}")
            raise e

    # --- 2. THE SKILL INTERFACE (For Tools & Research) ---
    def generate_response_skill(self, prompt: str) -> str:
        return self.generate_response(
            system_prompt=prompt,
            user_input=None,
            memory_context=None,
            search_context=""
        )

    def ask(self, 
            system_message: str,
            user_input: Optional[str] = None) -> str:
        """
        Direct one-off query. Used by skills like Research or Briefing.
        """
        messages = [
            {"role": "system", "content": system_message},
        ]

        if user_input:
            messages.append({"role": "user", "content": user_input})

        try:
            return self._call_provider(messages)
        except Exception as e:
            logger.error(f"Ask Failed: {str(e)}")
            raise e

    # --- 3. THE STRUCTURED INTERFACE (For Strict Data) ---
    def ask_structured(self, 
                       system_prompt: str, 
                       response_model: Type[T],
                       memory_context: List[Dict] = None,
                       search_context: str = "", 
                       user_input: Optional[str] = None) -> T:
        """
        Forces the LLM to output JSON conforming to a Pydantic model.
        Returns the instantiated Pydantic object.
        """
        # Get the schema from the model
        schema = response_model.model_json_schema()
        
        system_instruction = (
            f"You are a precise data output engine.\n"
            f"You MUST return ONLY valid JSON that matches this schema:\n"
            f"{json.dumps(schema, indent=2)}\n"
            f"Do not include markdown formatting (like ```json). Return raw JSON only."
        )

        messages = [
            {"role": "system", "content": system_instruction},
        ]

        if memory_context:
            for item in memory_context:
                # Case 1: Memory Log (Standard)
                if "source" in item:
                    role = "user" if item["source"] == "User" else "assistant"
                    messages.append({"role": role, "content": item["message"]})
                
                # Case 2: Tool Loop Message (Raw)
                elif "role" in item:
                    messages.append({"role": item["role"], "content": item["content"]})

        if search_context:
            messages.append({
                "role": "user", 
                "content": f"Context Information:\n{search_context}"
            })

        if user_input:
            messages.append({"role": "user", "content": user_input})

        try:
            raw_response = self._call_provider(messages)
            
            # Clean up potential markdown leakage
            cleaned_json = raw_response.replace("```json", "").replace("```", "").strip()
            
            # Parse and Validate
            return response_model.model_validate_json(cleaned_json)
            
        except ValidationError as e:
            logger.error(f"Structured Data Validation Failed: {e}")
            logger.debug(f"Raw Output: {raw_response}")
            raise ValueError(f"LLM failed to generate valid JSON: {e}")
        except Exception as e:
            logger.error(f"Structured Request Failed: {e}")
            raise e

========================================
FILE: src/cobalt_agent/main.py
========================================

"""
Cobalt Agent - Main Entry Point
Project Cobalt: Autonomous AI Chief of Staff & Trading System
"""

import sys
from loguru import logger
from datetime import datetime, timedelta

from cobalt_agent.config import load_config
from cobalt_agent.memory.postgres import PostgresMemory
from cobalt_agent.memory import MemorySystem  # Keep this as fallback
from cobalt_agent.persona import Persona
from cobalt_agent.interfaces.cli import CLI
from cobalt_agent.interfaces.mattermost import MattermostInterface
from cobalt_agent.llm import LLM
from cobalt_agent.prompt import PromptEngine
from cobalt_agent.tools.tool_manager import ToolManager
from cobalt_agent.brain.cortex import Cortex
from cobalt_agent.services.scheduler import CobaltScheduler
from cobalt_agent.core.proposals import ProposalEngine
from cobalt_agent.skills.productivity.briefing import MorningBriefing
from cobalt_agent.skills.research.deep_dive import DeepResearch

class CobaltAgent:
    def __init__(self):
        self.configure_logging()
        self.config = load_config()
        self.persona = Persona(self.config.persona)
        
        try:
            self.memory = PostgresMemory()
        except Exception as e:
            logger.warning(f"Database offline, falling back to local file: {e}")
            self.memory = MemorySystem()

        self.cortex = Cortex()

        logger.info("Cobalt Agent - System Initialized")
        logger.info(f"Python Version: {sys.version}")
        logger.info(f"Configuration Loaded: Debug Mode = {self.config.system.debug_mode}")

        # Initialize the Brain (LLM) with Intent-Based Routing
        self.llm = LLM(role="default")
        logger.info("Brain Initialized: Role-Based Routing Active (default)")

        # Initialize Tool Manager
        self.tool_manager = ToolManager()

        # Initialize Prompt Engine instead of static string
        self.prompt_engine = PromptEngine(self.config.persona)
        
        tools_list = self.tool_manager.get_tool_descriptions()
        system_prompt = self.prompt_engine.build_system_prompt(tools=tools_list)
        self.system_prompt = system_prompt

        # Log System Start to Memory
        self.memory.add_log("Cobalt Agent System Initialized", source="System")
        self.memory.add_log(f"Persona '{self.config.persona.name}' loaded", source="System")

        logger.info(f"Persona: {self.persona}")
        logger.info(f"Persona Roles: {', '.join(self.config.persona.roles)}")

        logger.info("=" * 80)
        logger.info("SYSTEM PROMPT:")
        logger.info("=" * 80)
        logger.info(f"\n{self.system_prompt}\n")
        logger.info("=" * 80)

        logger.info("Memory System online")

    def configure_logging(self):
        """Configure loguru logging with INFO level and file rotation."""
        # Remove default handler
        logger.remove()
        
        # Add console handler with INFO level
        logger.add(
            sys.stderr,
            level="INFO",
            format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
            colorize=True,
        )
        
        # Add file handler with rotation
        logger.add(
            "logs/agent_{time:YYYY-MM-DD}.log",
            level="INFO",
            format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
            rotation="00:00",  # Rotate daily at midnight
            retention="7 days",  # Keep logs for 7 days
        )
    def main(self):
        """Main entry point for Cobalt Agent."""
        self.configure_logging()
        
        briefing = MorningBriefing()
        researcher = DeepResearch() 
        
        # Start the Heartbeat (Scheduler)
        scheduler = CobaltScheduler()
        scheduler.start()

        logger.info("=" * 80)
        logger.info("Starting interactive CLI interface...")
        logger.info("=" * 80)

        cli = CLI(
            memory_system=self.memory, 
            llm=self.llm, 
            system_prompt=self.system_prompt,
            tool_manager=self.tool_manager,
            cortex=self.cortex
        )
  
        try:
            cli.start()
        except Exception as e:
            logger.error(f"Critical Error: {e}")
        finally:
            # Save memory to disk after exiting
            logger.info("Initiating graceful shutdown...")
            scheduler.shutdown()
            
            self.memory.add_log("CLI session ended", source="System")
        
            self.memory.save_memory()

    def process_input(self, text: str) -> str:
        """
        Process incoming text input and generate a response.
        Combines Cortex routing with autonomous chat fallback.
        
        Args:
            text: The incoming message text
            
        Returns:
            The response string
        """
        try:
            # 1. Try Cortex routing first (specialized departments)
            if self.cortex:
                specialist_response = self.cortex.route(text)
                if specialist_response:
                    logger.info(f"Cortex handled: {specialist_response[:100]}")
                    return specialist_response
            
            # 2. Fallback to autonomous chat (LLM)
            response = self.llm.generate_response(
                system_prompt=self.system_prompt,
                user_input=text,
                memory_context=[],
                search_context=""
            )
            logger.info(f"LLM response generated")
            return response
        except Exception as e:
            logger.error(f"Failed to process input: {e}")
            return f"Error processing your request: {e}"
    
    def send_message(self, message):
        """Send a message using the LLM."""
        try:
            response = self.llm.generate_response(
                system_prompt=self.system_prompt,
                user_input=message,
                memory_context=[],
                search_context=""
            )
            logger.info(f"Message sent: {message}")
            logger.info(f"Response received: {response}")
            return response
        except Exception as e:
            logger.error(f"Failed to send message: {e}")
    
    def start_mattermost_interface(self) -> None:
        """
        Start the Mattermost WebSocket listener instead of CLI.
        """
        mm_interface = MattermostInterface()
        
        try:
            if not mm_interface.connect():
                logger.error("Failed to connect to Mattermost. Exiting.")
                return
            
            # Initialize and attach Proposal Engine for HITL approval workflow
            self.proposal_engine = ProposalEngine()
            self.proposal_engine.connect_mattermost()
            mm_interface.proposal_engine = self.proposal_engine
            
            logger.info("=" * 80)
            logger.info("Cobalt Agent - Mattermost Interface Active")
            logger.info("HITL Proposal Engine - Active")
            logger.info("=" * 80)
            
            # Explicitly attach brain (cortex) to the interface before listening
            mm_interface.brain = self.cortex
            
            # Start listening for messages (blocking)
            mm_interface.start_listening(self)
        finally:
            if hasattr(mm_interface, 'disconnect'):
                mm_interface.disconnect()
            if hasattr(self, 'proposal_engine') and self.proposal_engine:
                self.proposal_engine.stop_monitoring()
            self.memory.add_log("Mattermost session ended", source="System")
            self.memory.save_memory()

if __name__ == "__main__":
    agent = CobaltAgent()
    
    # Start the Heartbeat (Scheduler) BEFORE the Mattermost interface
    scheduler = CobaltScheduler()
    scheduler.start()
    
    try:
        agent.start_mattermost_interface()
    finally:
        logger.info("Initiating graceful shutdown...")
        scheduler.shutdown()
        agent.memory.add_log("Agent shutdown complete", source="System")
        agent.memory.save_memory()


========================================
FILE: src/cobalt_agent/memory/base.py
========================================

"""
Memory Interface (The Contract)
Defines how Agents interact with memory, regardless of storage (JSON vs Postgres).
"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any

class MemoryProvider(ABC):
    """
    Abstract Base Class for Memory.
    Any memory system (JSON, SQL, Vector) MUST implement these methods.
    """

    @abstractmethod
    def add_log(self, message: str, source: str = "System", data: Dict = None):
        """Record an event or thought."""
        pass

    @abstractmethod
    def get_context(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Get recent conversation history (Short Term RAM)."""
        pass

    @abstractmethod
    def search(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        Find relevant memories based on meaning/content.
        (For JSON, this will be keyword search. For Postgres, Vector search.)
        """
        pass

========================================
FILE: src/cobalt_agent/memory/core.py
========================================

"""
Memory System Core (JSON Implementation)
Manages short-term (RAM) and long-term (Disk) memory for Cobalt Agent
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Any, Dict, List
from loguru import logger
from .base import MemoryProvider  # <--- IMPORT THE CONTRACT

class MemorySystem(MemoryProvider):  # <--- SIGN THE CONTRACT
    """
    Memory System for Cobalt Agent
    
    Manages:
    - Short-term memory: Last 10 interactions (RAM - Fast)
    - Long-term memory: Persistent storage in data/memory.json (Disk - Safe)
    """
    
    def __init__(self, memory_file: str = "data/memory.json"):
        self.memory_file = Path(memory_file)
        self.short_term: List[Dict[str, Any]] = [] 
        self.long_term: Dict[str, Any] = {"logs": []}
        self.load_memory()
        
    def add_log(self, message: str, source: str = "System", data: Dict = None) -> None:
        """Add a message to short-term memory AND long-term memory."""
        entry = {
            "timestamp": datetime.now().isoformat(),
            "source": source,
            "message": message,
            "data": data or {}
        }

        self.short_term.append(entry)
        
        # Keep only last 10 interactions in RAM
        if len(self.short_term) > 10:
            self.short_term.pop(0)
            
        self.long_term["logs"].append(entry)
        logger.debug(f"Memory added: [{source}] {message}")
        self.save_memory()

    def get_context(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Fast retrieval of short-term memory for AI prompts."""
        return self.short_term[-limit:]

    # <--- NEW METHOD: REQUIRED BY INTERFACE
    def search(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        Simple Keyword Search (Placeholder for Vector Search).
        Finds past logs that contain the query string.
        """
        results = []
        # Search backwards (newest first) to prioritize recent context
        for entry in reversed(self.long_term["logs"]):
            if query.lower() in entry["message"].lower():
                results.append(entry)
                if len(results) >= limit:
                    break
        return results

    def save_memory(self) -> None:
        """Save long-term memory to disk."""
        try:
            self.memory_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.memory_file, 'w', encoding='utf-8') as f:
                json.dump(self.long_term, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Failed to save memory: {e}")
            
    def load_memory(self) -> None:
        """Load long-term memory from disk."""
        try:
            if self.memory_file.exists():
                with open(self.memory_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        self.long_term = data
                        if "logs" not in self.long_term:
                            self.long_term["logs"] = []
                    else:
                        self.long_term = {"logs": []}

                    # Hydrate Short-Term RAM from Disk
                    self.short_term = self.long_term["logs"][-10:]
                logger.info(f"Memory loaded from {self.memory_file}")
            else:
                logger.info("Starting with empty memory")
                self.long_term = {"logs": []}
                self.short_term = []
        except Exception as e:
            logger.error(f"Failed to load memory: {e}")
            self.long_term = {"logs": []}
            self.short_term = []

========================================
FILE: src/cobalt_agent/memory/postgres.py
========================================

"""
Postgres Memory Adapter (The Hippocampus)
Hybrid: Combines Persistent Logging with Vector Embeddings for Semantic Search.

Context Signature Hashing:
- Computes deterministic SHA-256 hashes for page contexts
- Used for Fast Path cache lookups in Phase 3
- Hash is computed from URL, title, and visible text preview

Configuration Sources (highest to lowest priority):
1. Environment variables (POSTGRES_HOST, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD)
2. YAML config in configs/*.yaml
"""

import os
import json
import hashlib
from datetime import datetime
from html.parser import HTMLParser
from typing import List, Dict, Any, Optional
from loguru import logger

try:
    import psycopg
except ImportError:
    psycopg = None
    logger.warning("psycopg not installed, PostgresMemory will fail at runtime")

from litellm import embedding
from ..config import get_config
from .base import MemoryProvider


def compute_context_signature(url: str, title: str, visible_text: str) -> str:
    """
    Compute a deterministic SHA-256 hash for a page context.
    
    This function takes the page URL, title, and a preview of visible text,
    then computes a SHA-256 hash that serves as a unique signature for the
    context. This signature is used for Fast Path cache lookups in Phase 3.
    
    Args:
        url: The page URL
        title: The page title
        visible_text: A preview/summary of the visible text content
        
    Returns:
        A hex string SHA-256 hash of the context signature
        
    Example:
        >>> signature = compute_context_signature(
        ...     "https://example.com/page",
        ...     "Example Page",
        ...     "This is the visible content"
        ... )
        >>> print(signature)  # e.g., "a3f2b8c9..."
    """
    # Normalize inputs to ensure consistent hashing
    normalized_url = url.strip().lower()
    normalized_title = title.strip() if title else ""
    normalized_text = visible_text.strip() if visible_text else ""
    
    # Concatenate with a unique delimiter to prevent collisions
    context_string = f"{normalized_url}\x00{normalized_title}\x00{normalized_text}"
    
    # Compute SHA-256 hash
    hash_obj = hashlib.sha256(context_string.encode('utf-8'))
    return hash_obj.hexdigest()


def extract_visible_text(page_content: str, max_length: int = 500) -> str:
    """
    Extract visible text content from HTML for context signature.
    
    Args:
        page_content: Raw HTML content from the page
        max_length: Maximum length of returned text
        
    Returns:
        Extracted visible text, truncated to max_length
    """
    class TextExtractor(HTMLParser):
        def __init__(self):
            super().__init__()
            self.text_parts = []
            self.in_script_style = False
            
        def handle_starttag(self, tag, attrs):
            if tag.lower() in ('script', 'style'):
                self.in_script_style = True
                
        def handle_endtag(self, tag):
            if tag.lower() in ('script', 'style'):
                self.in_script_style = False
                
        def handle_data(self, data):
            if not self.in_script_style:
                self.text_parts.append(data.strip())
                
        def get_text(self) -> str:
            return ' '.join(filter(None, self.text_parts))
    
    try:
        parser = TextExtractor()
        parser.feed(page_content)
        text = parser.get_text()
        return text[:max_length]
    except Exception:
        # Fallback: simple text extraction
        import re
        # Remove HTML tags
        text = re.sub(r'<[^>]+>', ' ', page_content)
        # Normalize whitespace
        text = re.sub(r'\s+', ' ', text)
        return text[:max_length]


class PostgresMemory(MemoryProvider):
    def _get_conn(self):
        """Get a database connection."""
        return psycopg.connect(self.conn_str)
    
    def __init__(self):
        # 1. Load Credentials from config object
        config = get_config()
        postgres_config = config.postgres
        
        self.host = postgres_config.host
        self.port = postgres_config.port
        self.db = postgres_config.db
        self.user = postgres_config.user
        self.password = postgres_config.password or os.getenv("POSTGRES_PASSWORD", "cobalt_password")
        
        # Connection String (using config-based host for proper host-based execution)
        self.conn_str = f"postgresql://{self.user}:{self.password}@{self.host}:{self.port}/{self.db}"
        self.table_name = "memory_logs"
        
        # 2. Initialize DB (Auto-create vector table)
        self._init_db()
    
    def _init_db(self):
        """Initialize database connection and create tables."""
        try:
            with self._get_conn() as conn:
                # Enable Vector Extension
                conn.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                
                # Create Table with VECTOR Column (1536 dims for OpenAI)
                # We use 'content' instead of 'message' to standardize with RAG tools
                conn.execute(f"""
                    CREATE TABLE IF NOT EXISTS {self.table_name} (
                        id SERIAL PRIMARY KEY,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        source TEXT,
                        content TEXT,
                        embedding vector(1536), 
                        metadata JSONB DEFAULT '{{}}'::jsonb
                    );
                """)
                logger.info("üß† Connected to Postgres Memory (Vector Ready)")
        except Exception as e:
            logger.error(f"Failed to init DB: {e}")

    def _generate_embedding(self, text: str) -> List[float]:
        """Turns text into a list of numbers using LiteLLM."""
        try:
            text = text.replace("\n", " ")
            response = embedding(
                model="text-embedding-3-small",
                input=[text]
            )
            
            # ROBUST PARSING FIX: Handle both Object and Dict responses
            data_item = response.data[0]
            if isinstance(data_item, dict):
                return data_item['embedding']
            else:
                return data_item.embedding
                
        except Exception as e:
            logger.error(f"Embedding failed: {e}")
            return []

    def add_log(self, message: str, source: str = "System", data: Dict = None):
        """
        Saves a memory AND its vector representation.
        """
        # Generate Vector
        vector = self._generate_embedding(message)
        
        if not data:
            data = {}
            
        try:
            with self._get_conn() as conn:
                if vector:
                    conn.execute(
                        f"INSERT INTO {self.table_name} (source, content, embedding, metadata) VALUES (%s, %s, %s, %s)",
                        (source, message, str(vector), json.dumps(data))
                    )
                else:
                    # Fallback (save without vector if embedding fails)
                    conn.execute(
                        f"INSERT INTO {self.table_name} (source, content, metadata) VALUES (%s, %s, %s)",
                        (source, message, json.dumps(data))
                    )
        except Exception as e:
            logger.error(f"Failed to save memory: {e}")

    def get_context(self, limit: int = 10) -> str:
        """
        Get the most recent logs (Short Term RAM).
        Fetched from DB so it persists across restarts.
        """
        try:
            with self._get_conn() as conn:
                # We fetch the raw rows
                rows = conn.execute(f"""
                    SELECT timestamp, source, content 
                    FROM {self.table_name} 
                    ORDER BY timestamp DESC 
                    LIMIT %s
                """, (limit,)).fetchall()
                
                # Format into a chat-log string for the LLM
                context = ""
                # Reverse so it reads chronologically (Old -> New)
                for row in rows[::-1]:
                    ts = row[0].strftime("%H:%M") if hasattr(row[0], 'strftime') else str(row[0])
                    context += f"[{ts}] {row[1]}: {row[2]}\n"
                
                return context
        except Exception as e:
            logger.error(f"Failed to get context: {e}")
            return ""

    def search(self, query: str, limit: int = 5) -> List[Dict]:
        """
        Semantic Search: Finds memories mathematically similar to the query.
        """
        vector = self._generate_embedding(query)
        if not vector:
            return []

        try:
            with self._get_conn() as conn:
                # The <=> operator is "Cosine Distance" (Lower is better)
                results = conn.execute(f"""
                    SELECT timestamp, source, content, metadata, 
                           1 - (embedding <=> %s) as similarity
                    FROM {self.table_name}
                    WHERE embedding IS NOT NULL
                    ORDER BY embedding <=> %s
                    LIMIT %s;
                """, (str(vector), str(vector), limit)).fetchall()
                
                memories = []
                for row in results:
                    # Filter low relevance (Similarity < 0.3 is usually noise)
                    if row[4] < 0.3: 
                        continue
                        
                    memories.append({
                        "timestamp": row[0],
                        "source": row[1],
                        "content": row[2],
                        "metadata": row[3],
                        "score": row[4]
                    })
                
                return memories
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []
            
    def save_memory(self) -> None:
        """Postgres saves immediately, so this is a no-op."""
        pass

    def close(self) -> None:
        """Close the database connection (no-op for connection-per-operation pattern)."""
        # Since we create new connections for each operation via _get_conn(),
        # there's no persistent connection to close. This method exists for
        # API consistency with context manager patterns.
        pass

    def __enter__(self):
        """Context manager entry - returns self."""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit - calls close."""
        self.close()
        return False

========================================
FILE: src/cobalt_agent/persona.py
========================================

"""
Persona System for Cobalt Agent
Manages the AI agent's identity, roles, skills, and behavioral directives.
"""

from typing import List

from loguru import logger
from pydantic import BaseModel, Field


class PersonaConfig(BaseModel):
    """Configuration for Cobalt Agent persona."""

    name: str = Field(default="Cobalt", description="Agent name")
    roles: List[str] = Field(
        default_factory=list, description="List of roles the agent fulfills"
    )
    skills: List[str] = Field(
        default_factory=list, description="List of agent skills and capabilities"
    )
    tone: List[str] = Field(
        default_factory=list, description="Communication tone characteristics"
    )
    directives: List[str] = Field(
        default_factory=list, description="Core behavioral directives"
    )


class Persona:
    """
    Persona class that manages the AI agent's identity and generates system prompts.
    """

    def __init__(self, config: PersonaConfig):
        """
        Initialize the Persona with configuration.

        Args:
            config: PersonaConfig instance containing persona settings
        """
        self.config = config
        logger.info(f"Persona '{config.name}' initialized")

    def get_system_prompt(self) -> str:
        """
        Generate a comprehensive system prompt combining all persona attributes.
        Uses the system.core_identity prompt from config.yaml if available.

        Returns:
            str: Complete system instruction string for the AI agent
        """
        # Try to load from config first
        from cobalt_agent.config import get_config
        config = get_config()
        
        if config.prompts and config.prompts.system and config.prompts.system.core_identity:
            # Use config prompt with dynamic substitution
            prompt_template = config.prompts.system.core_identity
            prompt = prompt_template.format(
                name=self.config.name,
                roles="\n".join([f"  ‚Ä¢ {role}" for role in self.config.roles]) if self.config.roles else "No roles defined",
                skills="\n".join([f"  ‚Ä¢ {skill}" for skill in self.config.skills]) if self.config.skills else "No skills defined",
                tone=", ".join(self.config.tone) if self.config.tone else "professional",
                directives="\n".join([f"  ‚Ä¢ {directive}" for directive in self.config.directives]) if self.config.directives else "No directives defined"
            )
            logger.debug("System prompt loaded from config")
            return prompt
        
        # Fallback to original generation logic
        prompt_parts = []

        # Introduction
        prompt_parts.append(f"You are {self.config.name}, an advanced AI agent.")
        prompt_parts.append("")

        # Roles
        if self.config.roles:
            prompt_parts.append("YOUR ROLES:")
            for role in self.config.roles:
                prompt_parts.append(f"  ‚Ä¢ {role}")
            prompt_parts.append("")

        # Skills
        if self.config.skills:
            prompt_parts.append("YOUR SKILLS:")
            for skill in self.config.skills:
                prompt_parts.append(f"  ‚Ä¢ {skill}")
            prompt_parts.append("")

        # Communication Tone
        if self.config.tone:
            prompt_parts.append("COMMUNICATION STYLE:")
            tone_description = ", ".join(self.config.tone)
            prompt_parts.append(f"  Maintain a {tone_description} approach in all interactions.")
            prompt_parts.append("")

        # Core Directives
        if self.config.directives:
            prompt_parts.append("CORE DIRECTIVES:")
            for directive in self.config.directives:
                prompt_parts.append(f"  ‚Ä¢ {directive}")
            prompt_parts.append("")

        # Mission statement
        prompt_parts.append(
            "MISSION: Execute tasks with precision, leveraging your multidisciplinary expertise "
            "to deliver optimal outcomes while adhering to core directives."
        )

        system_prompt = "\n".join(prompt_parts)
        logger.debug("System prompt generated successfully (fallback)")

        return system_prompt

    def create_override(self, name: str, roles: list[str], directives: list[str]) -> "Persona":
        """
        Creates a new Persona instance with temporary overrides for Split-Brain agents.
        This strips away irrelevant global rules (like trading logic) for specialized tasks.
        
        Args:
            name: The new name for the override persona
            roles: List of roles for the override persona
            directives: List of directives for the override persona
            
        Returns:
            A new Persona instance with the specified overrides
        """
        # Create a deep copy of the underlying Pydantic model
        new_config = self.config.model_copy(deep=True)
        new_config.name = name
        new_config.roles = roles
        new_config.directives = directives
        return Persona(new_config)

    def __repr__(self) -> str:
        """String representation of the Persona."""
        return (
            f"Persona(name='{self.config.name}', "
            f"roles={len(self.config.roles)}, "
            f"skills={len(self.config.skills)})"
        )


========================================
FILE: src/cobalt_agent/prompt.py
========================================

"""
Cobalt Agent - Prompt Engine
Constructs dynamic system prompts based on context, tools, and time.
Refactored: Includes Memory Protocol & Temporal Gating.
"""

import datetime
from typing import List, Any
from cobalt_agent.config import PersonaConfig

class PromptEngine:
    """
    Generates the 'System Prompt' that tells the LLM how to behave.
    """
    
    def __init__(self, persona_config: PersonaConfig):
        self.persona = persona_config

    def build_system_prompt(self, tools: List[Any] = None) -> str:
        """
        Construct the full system prompt.
        
        Args:
            tools: List of tool objects available to the agent.
        """
        # 1. Identity & Role
        header = self._build_header()
        
        # 2. Operational Context (Time/Date)
        context = self._build_context()

        # 3. Memory Rules (NEW: Handles Recall & Stale Data)
        memory_rules = self._build_memory_protocol()
        
        # 4. Directives (Rules)
        directives = self._build_directives()
        
        # 5. Tool Capabilities (What it can do)
        tool_section = self._build_tool_descriptions(tools)
        
        # Combine everything
        return f"{header}\n\n{context}\n\n{memory_rules}\n\n{directives}\n\n{tool_section}"

    def _build_header(self) -> str:
        """
        Build the identity section of the system prompt.
        Includes: Identity, Roles, Tone, and Directives.
        """
        # Format roles
        roles_str = ", ".join(self.persona.roles)
        # Format tone
        tone_str = ", ".join(self.persona.tone)
        # Format directives as bullet points
        directives_str = "\n".join([f"- {d}" for d in self.persona.directives]) if self.persona.directives else "No specific directives defined."
        
        return (
            f"### IDENTITY\n"
            f"You are {self.persona.name}.\n"
            f"\n"
            f"### ROLES\n"
            f"Your roles are: {roles_str}.\n"
            f"\n"
            f"### OPERATIONAL DIRECTIVES\n"
            f"{directives_str}\n"
            f"\n"
            f"### TONE\n"
            f"Maintain a tone that is: {tone_str}."
        )

    def _build_context(self) -> str:
        now = datetime.datetime.now()
        return (
            f"### CURRENT CONTEXT\n"
            f"- Current Date/Time: {now.strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"- Operating System: Python Environment (CLI)\n"
            f"- User: Administrator"
        )

    def _build_memory_protocol(self) -> str:
        """
        Defines how to handle Long-Term Memory and Stale Data.
        Prevents the 'Bag Holder' scenario by expiring old market context.
        """
        return """
### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.
"""

    def _build_directives(self) -> str:
        # 1. Base Rules
        rules = [
            "You are an AUTONOMOUS AGENT. You are NOT a chat bot.",
            "You DO NOT have internal knowledge of real-time events.",
            "You MUST use tools to answer questions about the world.",
            # Strict Math Rules
            "STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.",
            "DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.",
            "Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation."
        ]
        
        if self.persona.directives:
            rules.extend(self.persona.directives)
            
        # 2. The Protocol (Simulated Dialogue)
        protocol = (
            "\n### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°\n"
            "To use a tool, you must output a single line starting with 'ACTION:'.\n"
            "Do not talk. Do not explain. JUST ACTION.\n\n"
            "### EXAMPLES OF CORRECT BEHAVIOR:\n"
            "User: What is the price of Apple?\n"
            "You: ACTION: finance AAPL\n"
            "System: [Observation: AAPL is $150]\n"
            "You: Apple is trading at $150.\n\n"
            "User: Find news about AI.\n"
            "You: ACTION: search AI news\n"
            "System: [Observation: AI is growing...]\n"
            "You: Recent news indicates AI is growing.\n\n"
            "### YOUR TURN:\n"
            "If I ask you a question that requires data, do not answer directly. START WITH ACTION:."
        )

        return "### DIRECTIVES\n" + "\n".join([f"- {r}" for r in rules]) + protocol

    def _build_tool_descriptions(self, tools) -> str:
        if not tools:
            return ""
            
        descriptions = []
        for tool in tools:
            # Use class name instead of raw memory address
            name = type(tool).__name__
            formatted_name = name.replace('Tool', '').lower()
            descriptions.append(f"- {name}: Use this tool for {formatted_name} tasks.")
        
        return "### AVAILABLE TOOLS\n" + "\n".join(descriptions)


========================================
FILE: src/cobalt_agent/security/vault.py
========================================

"""
Local Vault Manager - Just-In-Time (JIT) Secrets Manager.
AES-256 encrypted local credential storage with in-memory operations.
"""
import os
import json
from pathlib import Path
from typing import Dict, Optional, List
from loguru import logger
from cryptography.fernet import Fernet


class VaultManager:
    """
    In-memory Just-In-Time (JIT) Secrets Manager.
    Reads from an AES-256 encrypted local file. Secrets only exist in RAM.
    """
    
    def __init__(self, vault_path: str = "data/.cobalt_vault"):
        self.vault_path = Path(vault_path)
        self._secrets: Dict[str, str] = {}
        self._is_unlocked: bool = False
        
    def generate_master_key(self) -> str:
        """Generates a new AES-256 Fernet key. RUN ONCE."""
        return Fernet.generate_key().decode()

    def unlock(self, master_key: str) -> bool:
        """Decrypts the vault directly into RAM."""
        if not self.vault_path.exists():
            logger.warning("Vault file does not exist. Creating a new empty vault.")
            self._secrets = {}
            self._is_unlocked = True
            return True

        try:
            f = Fernet(master_key.encode())
            with open(self.vault_path, "rb") as file:
                encrypted_data = file.read()
            
            decrypted_data = f.decrypt(encrypted_data)
            self._secrets = json.loads(decrypted_data.decode())
            self._is_unlocked = True
            logger.info("üîê Vault successfully unlocked into memory.")
            return True
        except Exception as e:
            logger.error(f"Vault unlock failed (Invalid Key or Corrupt Data): {e}")
            self._is_unlocked = False
            return False

    def lock(self) -> None:
        """Wipes secrets from RAM."""
        self._secrets.clear()
        self._is_unlocked = False
        logger.info("üîí Vault locked. Secrets wiped from RAM.")

    def get_secret(self, key_name: str) -> Optional[str]:
        """JIT Secret retrieval."""
        if not self._is_unlocked:
            logger.error(f"Attempted to access secret '{key_name}' while vault is locked!")
            return None
        return self._secrets.get(key_name)

    def set_secret(self, master_key: str, key_name: str, secret_value: str) -> bool:
        """Encrypts and saves a new secret to the physical vault file."""
        if not self._is_unlocked:
            logger.error("Cannot add secret: Vault is locked.")
            return False
            
        self._secrets[key_name] = secret_value
        return self._save_vault(master_key)

    def list_secrets(self) -> List[str]:
        """Returns a list of all secret keys currently in the vault (names only)."""
        if not self._is_unlocked:
            logger.error("Cannot list secrets: Vault is locked.")
            return []
        return list(self._secrets.keys())

    def delete_secret(self, master_key: str, key_name: str) -> bool:
        """Deletes a secret from the vault and saves the updated vault."""
        if not self._is_unlocked:
            logger.error("Cannot delete secret: Vault is locked.")
            return False
            
        if key_name in self._secrets:
            del self._secrets[key_name]
            logger.info(f"Secret '{key_name}' removed from memory.")
            return self._save_vault(master_key)
        return False

    def _save_vault(self, master_key: str) -> bool:
        """Internal helper to encrypt and save the current state of RAM to disk."""
        try:
            f = Fernet(master_key.encode())
            encrypted_data = f.encrypt(json.dumps(self._secrets).encode())
            
            self.vault_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.vault_path, "wb") as file:
                file.write(encrypted_data)
                
            logger.debug("Vault successfully saved to disk.")
            return True
        except Exception as e:
            logger.error(f"Failed to encrypt and save vault: {e}")
            return False

========================================
FILE: src/cobalt_agent/services/scheduler.py
========================================

"""
Cobalt Scheduler Service
Background job scheduler for automated tasks like Morning Briefing.
"""
import os
from datetime import datetime
from apscheduler.schedulers.background import BackgroundScheduler
from loguru import logger
from cobalt_agent.llm import LLM
from cobalt_agent.config import get_config


class CobaltScheduler:
    """
    Background scheduler for automated tasks.
    HandlesMorning Briefing generation and delivery.
    """
    
    def __init__(self):
        self.scheduler = BackgroundScheduler()
        self.config = get_config()
        self._setup_jobs()

    def _setup_jobs(self):
        """Register all automated background tasks."""
        # Schedule Morning Briefing for 8:00 AM EST every weekday (Mon-Fri)
        self.scheduler.add_job(
            self.generate_morning_briefing,
            'cron',
            day_of_week='mon-fri',
            hour=8,
            minute=0,
            id='morning_briefing',
            replace_existing=True
        )
        logger.info("‚è±Ô∏è Scheduler: Morning Briefing job registered (Mon-Fri 08:00).")

    def start(self):
        """Start the background scheduler."""
        self.scheduler.start()
        logger.info("‚è±Ô∏è Cobalt Heartbeat (Scheduler) Online.")
        
        # --- TEST OVERRIDE: FIRE IMMEDIATELY ON BOOT ---
        #logger.info("üß™ Executing Immediate Test Override...")
        #self.generate_morning_briefing()
        # -----------------------------------------------

    def shutdown(self):
        """Shutdown the scheduler gracefully."""
        self.scheduler.shutdown()

    def generate_morning_briefing(self):
        """
        Runs the Gemini 3.1 Pro query and saves the output to the Obsidian Vault.
        """
        logger.info("‚òÄÔ∏è Running Automated Morning Briefing...")
        
        today_str = datetime.now().strftime("%B %d, %Y")
        
        # Load prompt from config
        prompt_template = self.config.prompts.scheduler.morning_briefing
        prompt = prompt_template.format(today_str=today_str)

        try:
            # Explicitly force the researcher profile (Gemini 3.1 Pro)
            research_llm = LLM(role="researcher")
            
            logger.info("Calling Gemini 3.1 Pro for market data...")
            report_content = research_llm.ask(
                system_message="You are a senior financial analyst and day trader. You have access to real-time data. Output strictly in the requested markdown format.",
                user_input=prompt
            )
            
            # Format the output filepath
            vault_path = self.config.system.obsidian_vault_path
            filename = f"Morning_Briefing_{datetime.now().strftime('%Y-%m-%d')}.md"
            filepath = os.path.join(vault_path, "0 - Inbox", filename)
            
            # Ensure directory exists
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            # Write the file directly
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(report_content)
                
            logger.info(f"‚úÖ Morning Briefing successfully written to {filepath}")
            
            # Broadcast to Mattermost to notify the user
            from cobalt_agent.interfaces.mattermost import MattermostInterface
            mm = MattermostInterface()
            mm.connect()
            mm.send_message("town-square", self.config.mattermost.approval_team, f"‚òÄÔ∏è **Morning Briefing Ready!** I have generated the pre-market analysis for {today_str} and saved it to your Inbox.")
            
        except Exception as e:
            logger.error(f"Failed to generate Morning Briefing: {e}")

========================================
FILE: src/cobalt_agent/skills/productivity/briefing.py
========================================

"""
The Morning Briefing Skill
Orchestrates Tools to create a daily digest.
Refactored to use Pydantic Models and LLM Synthesis.
"""
from datetime import datetime
from typing import List
from loguru import logger
from pydantic import BaseModel, Field

from cobalt_agent.config import load_config
from cobalt_agent.llm import LLM
from cobalt_agent.skills.productivity.scribe import Scribe
from cobalt_agent.tools.finance import FinanceTool
from cobalt_agent.tools.search import SearchTool

# --- PYDANTIC SCHEMA ---
class BriefingReport(BaseModel):
    """Structured format for the daily briefing."""
    executive_summary: str = Field(description="A concise 3-sentence summary of the overall market and news mood.")
    market_analysis: str = Field(description="A technical analysis of the provided stock data (Bullish/Bearish/Neutral).")
    top_headlines: List[str] = Field(description="A list of the 3-5 most critical news headlines found.")
    strategic_thought: str = Field(description="A single, provocative thought or question for the user based on today's events.")

# --- SKILL ---
class MorningBriefing:
    def __init__(self):
        # 1. Load Config & LLM
        config = load_config()
        # Handle model name attribute safely
        model_name = getattr(config.llm, "model_name", getattr(config.llm, "model", "gpt-4o"))
        
        self.llm = LLM(model_name=model_name)
        
        # 2. Initialize Tools
        self.scribe = Scribe()
        self.finance = FinanceTool()
        self.search = SearchTool()

    def _gather_data(self) -> str:
        """
        Runs tools to collect raw context for the LLM.
        """
        raw_data = []
        
        # A. Markets
        tickers = ["NVDA", "SPY", "BTC-USD"]
        raw_data.append("--- MARKET DATA ---")
        for t in tickers:
            try:
                data = self.finance.run(t)
                raw_data.append(f"{t}: {str(data)}")
            except Exception as e:
                logger.warning(f"Failed to fetch {t}: {e}")

        # B. News
        query = "top technology and finance news today"
        raw_data.append(f"\n--- NEWS SEARCH: '{query}' ---")
        try:
            results = self.search.run(query)
            if isinstance(results, list):
                raw_data.extend([str(item) for item in results])
            else:
                raw_data.append(str(results))
        except Exception as e:
            logger.warning(f"Failed to search news: {e}")

        return "\n".join(raw_data)

    def run(self):
        """Generates the daily report."""
        logger.debug("üå§Ô∏è Starting Morning Briefing generation...")
        
        # 1. Gather Data
        context_data = self._gather_data()
        
        # 2. Synthesize with LLM (The "Smart" Step)
        prompt = f"""
        You are a Chief of Staff. Review the raw market data and news below.
        Synthesize a structured Morning Briefing for me.
        
        RAW DATA:
        {context_data}
        """
        
        try:
            # Use the new ask_structured method from llm.py
            report: BriefingReport = self.llm.ask_structured(prompt, BriefingReport)
            
            # 3. Format as Markdown
            today = datetime.now().strftime("%Y-%m-%d")
            md_content = f"# üå§Ô∏è Morning Briefing: {today}\n"
            md_content += f"*Generated at: {datetime.now().strftime('%H:%M')}*\n\n"
            
            md_content += f"### üßê Executive Summary\n{report.executive_summary}\n\n"
            
            md_content += f"### üìà Market Pulse\n{report.market_analysis}\n\n"
            
            md_content += "### üì∞ Top Headlines\n"
            for news in report.top_headlines:
                md_content += f"- {news}\n"
                
            md_content += f"\n### üí° Strategic Thought\n> {report.strategic_thought}\n"

        except Exception as e:
            logger.error(f"Briefing synthesis failed: {e}")
            # Fallback if LLM fails
            md_content = f"# Briefing Failed\nCould not generate structured report.\n\nRaw Data:\n{context_data}"
            filename = f"Briefing_Failed_{datetime.now().strftime('%Y-%m-%d')}"

        # 4. Save to Obsidian
        filename = f"Briefing_{datetime.now().strftime('%Y-%m-%d')}"
        path = self.scribe.write_note(filename, md_content, folder="0 - Inbox")
        
        logger.info(f"‚úÖ Briefing saved to: {path}")
        return path

========================================
FILE: src/cobalt_agent/skills/productivity/scribe.py
========================================

"""
The Scribe Skill (Obsidian Integration)
Allows Cobalt to read, write, and search your "Second Brain".
Refactored to use Environment Variables for portability.
STRICT RULE: All automated writes go to '0 - Inbox'.
"""

import os
from pathlib import Path
from datetime import datetime
from typing import List, Optional
from loguru import logger

class Scribe:
    """
    Interface for interacting with an Obsidian Vault.
    """
    
    def __init__(self, vault_path: Optional[str] = None):
        """
        Initialize the Scribe.
        :param vault_path: Path to Obsidian vault. Defaults to env var OBSIDIAN_VAULT_PATH.
        """
        # 1. Try argument first, then environment variable
        path_str = vault_path or os.getenv("OBSIDIAN_VAULT_PATH")
        
        if not path_str:
             # Fallback for safety, but log a warning
            logger.warning("‚ö†Ô∏è OBSIDIAN_VAULT_PATH not set in .env. Defaulting to home/Documents/Think")
            path_str = str(Path.home() / "Documents" / "Think")

        self.vault_path = Path(path_str)

        if not self.vault_path.exists():
            logger.warning(f"‚ö†Ô∏è Obsidian Vault not found at {self.vault_path}. Scribe functions will fail.")

    def _resolve_path(self, filename: str) -> Path:
        """Helper to ensure file has .md extension and is inside the vault."""
        if not filename.endswith(".md"):
            filename += ".md"
        return self.vault_path / filename

    def write_note(self, filename: str, content: str, folder: str = "0 - Inbox") -> str:
        """
        Create or Overwrite a note.
        Defaults strictly to '0 - Inbox' unless overridden.
        """
        try:
            # Construct path (Vault / Folder / Filename)
            target_dir = self.vault_path / folder
            target_dir.mkdir(parents=True, exist_ok=True)
            
            clean_name = filename if filename.endswith(".md") else f"{filename}.md"
            file_path = target_dir / clean_name
            
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
            
            return f"‚úÖ Note saved: {folder}/{clean_name}"
        except Exception as e:
            logger.error(f"Failed to write note: {e}")
            return f"‚ùå Error writing note: {e}"

    def read_note(self, filename: str) -> str:
        """Read the content of a specific note."""
        try:
            # Try searching recursively if file not found in root
            found = list(self.vault_path.rglob(f"{filename if filename.endswith('.md') else filename + '.md'}"))
            
            if found:
                # Prioritize exact match if multiple found, otherwise take first
                file_path = found[0]
            else:
                 # Last ditch effort: check direct path
                file_path = self.vault_path / filename
                if not file_path.exists():
                    return f"‚ùå Note not found: {filename}"

            with open(file_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            return f"‚ùå Error reading note: {e}"

    def append_to_daily_note(self, content: str) -> str:
        """
        Appends text to today's Daily Log in '0 - Inbox'.
        """
        today = datetime.now().strftime("%Y-%m-%d")
        
        # STRICT REQUIREMENT: Inbox only
        daily_folder = "0 - Inbox"
        
        try:
            timestamp = datetime.now().strftime('%H:%M')
            header = f"\n\n### {timestamp} - Cobalt Log\n"
            full_entry = header + content
            
            target_dir = self.vault_path / daily_folder
            target_dir.mkdir(parents=True, exist_ok=True)
            
            # File format: Daily_Log_2026-02-10.md
            file_path = target_dir / f"Daily_Log_{today}.md"

            # Check if file exists to add title if new
            is_new = not file_path.exists()
            mode = "a" if not is_new else "w"

            with open(file_path, mode, encoding="utf-8") as f:
                if is_new:
                    f.write(f"# Daily Log: {today}\n")
                f.write(full_entry)
            
            return f"‚úÖ Logged to {daily_folder}/Daily_Log_{today}.md"
        except Exception as e:
            return f"‚ùå Failed to log to daily note: {e}"

    def search_vault(self, query: str, limit: int = 5) -> List[str]:
        """
        Semantic search (lite). Walks the vault and finds notes containing the keyword.
        """
        matches = []
        try:
            # Walk through all .md files
            for file_path in self.vault_path.rglob("*.md"):
                # Ignore system folders
                if any(part.startswith(".") for part in file_path.parts):
                    continue
                
                try:
                    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                        content = f.read()
                        if query.lower() in content.lower():
                            matches.append(file_path.name)
                            if len(matches) >= limit:
                                break
                except:
                    continue
            
            return matches if matches else ["No matching notes found."]
        except Exception as e:
            return [f"Error searching vault: {e}"]

========================================
FILE: src/cobalt_agent/skills/research/deep_dive.py
========================================

"""
Deep Research Agent
Implements a "Plan -> Search -> Analyze -> Report" loop.
Strictly uses Pydantic for type-safe LLM interactions.
"""
import json
from typing import List
from loguru import logger
from pydantic import BaseModel, Field, ValidationError

from cobalt_agent.llm import LLM
from cobalt_agent.config import load_config
from cobalt_agent.tools.search import SearchTool
from cobalt_agent.tools.browser import BrowserTool
from cobalt_agent.skills.productivity.scribe import Scribe

# --- PYDANTIC SCHEMAS ---
class ResearchPlan(BaseModel):
    """The strategy for researching a topic."""
    queries: List[str] = Field(
        description="A list of 3 specific, distinct search queries to investigate the topic from different angles."
    )

class ResearchReport(BaseModel):
    """The final synthesized report structure."""
    title: str = Field(description="A clear, professional title for the report.")
    executive_summary: str = Field(description="A high-level summary of the findings.")
    key_findings: List[str] = Field(description="A list of the most important technical or financial facts found.")
    strategic_outlook: str = Field(description="Forward-looking analysis or conclusion.")

# --- AGENT ---
class DeepResearch:
    def __init__(self):
        # 1. Load Global Config
        config = load_config()
        
        # 2. Extract Model Name
        if hasattr(config.llm, "model_name"):
            self.model_name = config.llm.model_name
        else:
            self.model_name = getattr(config.llm, "model", "gpt-4o")

        # 3. Initialize Components
        self.llm = LLM(model_name=self.model_name)
        self.search = SearchTool()
        self.browser = BrowserTool()
        self.scribe = Scribe()

    def run(self, topic: str):
        """
        Executes a multi-step research plan on a complex topic.
        """
        logger.info(f"üïµÔ∏è‚Äç‚ôÇÔ∏è Starting Deep Dive on: {topic} (Model: {self.model_name})")
        
        # --- PHASE 1: PLANNING ---
        logger.info("üß† Phase 1: Planning research strategy...")
        
        plan_prompt = f"Create a research plan for the topic: '{topic}'. Generate 3 distinct search queries."
        
        try:
            plan: ResearchPlan = self.llm.ask_structured(plan_prompt, ResearchPlan)
            queries = plan.queries
            logger.info(f"üìã Plan approved: {queries}")
        except Exception:
            logger.warning("Failed to generate structured plan. Falling back to defaults.")
            queries = [f"{topic} technology overview", f"{topic} market size", f"{topic} key players"]

        # --- PHASE 2: EXECUTION (The Loop) ---
        findings = []
        for q in queries:
            logger.info(f"üîç Executing Step: {q}")
            try:
                # Search returns List[SearchResult] objects now
                results = self.search.run(q)
                
                # Format the Pydantic objects into a readable string for the LLM
                formatted_results = ""
                for item in results:
                    formatted_results += f"Title: {item.title}\nURL: {item.href}\nSummary: {item.body}\n---\n"
                
                if not formatted_results:
                    formatted_results = "No results found."

                findings.append(f"### Query: {q}\n{formatted_results}\n")
                
            except Exception as e:
                logger.error(f"Search step failed for '{q}': {e}")

        # --- PHASE 3: SYNTHESIS ---
        logger.info("‚úçÔ∏è Phase 3: Synthesizing Final Report...")
        all_data = "\n".join(findings)
        
        synthesis_prompt = f"""
        Analyze these raw notes on '{topic}' and generate a final report.
        
        RAW NOTES:
        {all_data}
        """
        
        try:
            report: ResearchReport = self.llm.ask_structured(synthesis_prompt, ResearchReport)
            
            # Convert Pydantic model to Markdown for Obsidian
            md_content = f"# {report.title}\n\n"
            md_content += f"**Date:** Today\n\n"
            md_content += f"## Executive Summary\n{report.executive_summary}\n\n"
            md_content += "## Key Findings\n"
            for item in report.key_findings:
                md_content += f"- {item}\n"
            md_content += f"\n## Strategic Outlook\n{report.strategic_outlook}"
            
        except Exception as e:
            logger.error(f"Report synthesis failed: {e}")
            md_content = f"# Research Failed\nCould not generate structured report for {topic}.\n\nRaw Data:\n{all_data}"

        # --- PHASE 4: DELIVERY ---
        filename = f"Research_{topic.replace(' ', '_')}"
        path = self.scribe.write_note(filename, md_content, folder="0 - Inbox")
        
        return path

========================================
FILE: src/cobalt_agent/tools/aom.py
========================================

"""
AOM (Accessibility Object Model) Extractor Module
Extracts DOM tree via Chrome DevTools Protocol (CDP) and converts to compressed format.

This module uses Playwright's CDP session to call `dom.snapshotter.takeDomSnapshot()`
which provides a rich accessibility tree that can be converted to a compressed element
format with numeric IDs for stable referencing.

Features:
- CDP session management with Playwright
- DOM snapshot extraction
- Accessibility tree parsing to compressed dictionary format
- Ephemeral context management (no persistent storage state)
"""

import re
import hashlib
from typing import Optional
from playwright.sync_api import sync_playwright
from loguru import logger
from ..config import get_config


class SecurityViolation(Exception):
    """Exception raised when a URL fails domain whitelist validation."""
    pass


class AOMExtractor:
    """
    Extracts AOM (Accessibility Object Model) from web pages using CDP.
    
    Uses ephemeral browser contexts with no persistent storage state.
    Enforces domain whitelist for Zero-Trust security.
    """
    
    def __init__(self):
        """Initialize the AOM extractor with domain whitelist from config."""
        config = get_config()
        browser_config = config.browser
        self.allowed_domains: list[str] = (
            browser_config.allowed_domains if browser_config else ["example.com"]
        )
        self._extracted_tree: Optional[dict] = None
    
    def _validate_url(self, url: str) -> str:
        """
        Validate URL against the domain whitelist.
        
        File URLs (file:///) are always allowed for local file access.
        HTTP/HTTPS URLs are validated against the domain whitelist.
        
        Args:
            url: The URL to validate
            
        Returns:
            The validated URL
            
        Raises:
            SecurityViolation: If the domain is not in the allowed list
        """
        # File URLs are always allowed for local file access
        if url.startswith("file://"):
            return url
        
        # Extract domain from URL
        domain_pattern = r'https?://([^/]+)'
        match = re.search(domain_pattern, url)
        if not match:
            raise SecurityViolation(f"Invalid URL format: {url}")
        
        domain = match.group(1)
        
        # Remove port if present (e.g., example.com:8080 -> example.com)
        domain = domain.split(':')[0]
        
        # Check against whitelist
        if domain not in self.allowed_domains:
            raise SecurityViolation(
                f"Domain '{domain}' is not in the allowed domains list. "
                f"Allowed: {', '.join(self.allowed_domains)}"
            )
        
        logger.debug(f"URL validated: {domain} is in allowed list")
        return url
    
    def extract(self, url: str, timeout_ms: int = 15000) -> list[dict]:
        """
        Extract the DOM tree from a URL using CDP.
        
        Args:
            url: The URL to extract AOM from
            timeout_ms: Timeout in milliseconds (default 15000)
            
        Returns:
            List of compressed element dictionaries with:
            - id: int - Stable numeric ID
            - role: str - Accessibility role
            - name: str - Accessible name
            - state: dict - Actionable state (enabled, visible, editable)
            - aria: dict - Optional aria-* attributes
            - value: str - Optional value (for inputs)
            
        Raises:
            SecurityViolation: If domain is not whitelisted
            Exception: For browser/CDP errors
        """
        # Validate URL against whitelist
        validated_url = self._validate_url(url)
        
        logger.info(f"Extracting AOM from: {validated_url}")
        
        # Use ephemeral context (no storage state)
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            context = browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                          "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                storage_state={}  # Ephemeral - no persistent storage
            )
            page = context.new_page()
            
            try:
                # Navigate with timeout
                page.goto(validated_url, wait_until="domcontentloaded", timeout=timeout_ms)
                
                # Wait for dynamic content to settle
                page.wait_for_timeout(2000)
                
                # Get CDP session
                cdp_session = context.new_cdp_session(page)
                
                # Call DOMSnapshot.captureSnapshot to extract the DOM tree
                snapshot_result = cdp_session.send("DOMSnapshot.captureSnapshot", {
                    "computedStyles": [],
                    "includeDOMBindings": True
                })
                
                # Parse the snapshot into compressed format
                elements = self._parse_snapshot(snapshot_result)
                
                # Store the extracted tree for potential reuse
                self._extracted_tree = {
                    "url": validated_url,
                    "timestamp": __import__("time").time(),
                    "element_count": len(elements),
                    "elements": elements
                }
                
                browser.close()
                logger.info(f"Extracted {len(elements)} elements from {validated_url}")
                
                return elements
                
            except Exception as e:
                logger.exception(f"Failed to extract AOM from {validated_url}: {e}")
                browser.close()
                raise
    
    def _parse_snapshot(self, snapshot: dict) -> list[dict]:
        """
        Parse the DOM snapshot into compressed element format.
        
        Args:
            snapshot: The raw DOM snapshot from CDP
            
        Returns:
            List of compressed element dictionaries
        """
        if not snapshot:
            return []
        
        elements = []
        
        # DOM snapshot structure has nodes array and various metadata
        # Each node has id, role, name, attributes, etc.
        nodes = snapshot.get("nodes", [])
        document_strings = snapshot.get("strings", [])
        
        # Process each node in the snapshot
        for i, node in enumerate(nodes):
            element = self._process_node(node, document_strings)
            if element:
                elements.append(element)
        
        return elements
    
    def _process_node(self, node: list, strings: list[str]) -> Optional[dict]:
        """
        Process a single node from the DOM snapshot.
        
        Args:
            node: The node data (list format from CDP snapshot)
            strings: String table for node attributes
            
        Returns:
            Compressed element dictionary or None if invalid
        """
        if not node or len(node) < 2:
            return None
        
        try:
            # Extract node properties
            node_type = node[0] if len(node) > 0 else 0
            node_name_idx = node[1] if len(node) > 1 else -1
            node_value_idx = node[2] if len(node) > 2 else -1
            
            # Get string values from strings array
            node_name = strings[node_name_idx] if node_name_idx >= 0 else ""
            node_value = strings[node_value_idx] if node_value_idx >= 0 else ""
            
            # Determine role based on node type and name
            role = self._get_role(node_type, node_name)
            
            # Extract state (actionable properties)
            state = self._extract_state(node, strings)
            
            # Extract ARIA attributes
            aria = self._extract_aria(node, strings)
            
            # Extract value for inputs
            value = self._extract_value(node, strings, node_value)
            
            # Create compressed element
            element = {
                "id": self._generate_node_id(node, node_name),
                "role": role,
                "name": state.get("name", node_name),
                "state": state,
                "aria": aria,
                "value": value
            }
            
            # Only include non-empty elements
            if element["role"] and element["id"]:
                return element
            return None
            
        except Exception as e:
            logger.debug(f"Failed to process node: {e}")
            return None
    
    def _get_role(self, node_type: int, node_name: str) -> str:
        """
        Determine the accessibility role from node type and name.
        
        Args:
            node_type: The DOM node type (1=Element, 3=Text, 8=Comment, 9=Document)
            node_name: The node name/tag
            
        Returns:
            Accessibility role string
        """
        # Map common node types to accessibility roles
        role_map = {
            1: "generic",  # Element node - generic container
            3: "text",     # Text node
            8: "comment",  # Comment node
            9: "document", # Document node
        }
        
        # Default from type
        role = role_map.get(node_type, "generic")
        
        # Override with element-specific roles
        if node_type == 1:  # Element node
            node_lower = node_name.lower()
            element_roles = {
                "a": "link",
                "button": "button",
                "input": "input",
                "select": "combobox",
                "textarea": "textbox",
                "img": "image",
                "iframe": "iframe",
                "table": "table",
                "tr": "row",
                "td": "cell",
                "th": "columnheader",
                "h1": "heading",
                "h2": "heading",
                "h3": "heading",
                "h4": "heading",
                "h5": "heading",
                "h6": "heading",
                "li": "listitem",
                "ul": "list",
                "ol": "list",
                "form": "form",
                "header": "banner",
                "footer": "contentinfo",
                "nav": "navigation",
                "main": "main",
                "article": "article",
                "section": "region",
            }
            role = element_roles.get(node_lower, "generic")
        
        return role
    
    def _extract_state(self, node: list, strings: list[str]) -> dict:
        """
        Extract actionable state from node attributes.
        
        Args:
            node: The node data
            strings: String table
            
        Returns:
            State dictionary with enabled, visible, editable keys
        """
        state = {
            "enabled": True,
            "visible": True,
            "editable": False,
            "clickable": False,
            "name": ""
        }
        
        if len(node) < 4:
            return state
        
        # Attributes start at index 3
        attributes = node[3:]
        
        # Process attributes (every other item is key/value)
        for i in range(0, len(attributes), 2):
            if i + 1 >= len(attributes):
                break
            
            key_idx = attributes[i]
            value_idx = attributes[i + 1]
            
            if key_idx < 0 or value_idx < 0:
                continue
                
            key = strings[key_idx] if key_idx < len(strings) else ""
            value = strings[value_idx] if value_idx < len(strings) else ""
            
            # Check for disabled attribute
            if key.lower() == "disabled" and value.lower() in ("", "true"):
                state["enabled"] = False
            
            # Check for hidden attribute
            if key.lower() == "hidden" or key.lower() == "aria-hidden":
                state["visible"] = value.lower() not in ("true", "true")
            
            # Check for editable elements
            if key.lower() == "input" and value.lower() in ("text", "textarea", "password"):
                state["editable"] = True
            
            # Check for aria-readonly
            if key.lower() == "aria-readonly" and value.lower() == "true":
                state["editable"] = False
            
            # Check for name/accessibility name
            if key.lower() in ("aria-label", "aria-labelledby"):
                state["name"] = value
            
            # Check for clickability
            if key.lower() in ("onclick", "role") and value.lower() != "":
                state["clickable"] = True
        
        return state
    
    def _extract_aria(self, node: list, strings: list[str]) -> dict:
        """
        Extract ARIA attributes from node.
        
        Args:
            node: The node data
            strings: String table
            
        Returns:
            Dictionary of ARIA attributes
        """
        aria = {}
        
        if len(node) < 4:
            return aria
        
        attributes = node[3:]
        
        for i in range(0, len(attributes), 2):
            if i + 1 >= len(attributes):
                break
            
            key_idx = attributes[i]
            value_idx = attributes[i + 1]
            
            if key_idx < 0 or value_idx < 0:
                continue
            
            key = strings[key_idx] if key_idx < len(strings) else ""
            value = strings[value_idx] if value_idx < len(strings) else ""
            
            # Only include ARIA attributes
            if key.lower().startswith("aria-"):
                aria[key] = value
        
        return aria
    
    def _extract_value(self, node: list, strings: list[str], default: str = "") -> str:
        """
        Extract the value from an input element.
        
        Args:
            node: The node data
            strings: String table
            default: Default value if not found
            
        Returns:
            The element value
        """
        if len(node) < 4:
            return default
        
        attributes = node[3:]
        
        for i in range(0, len(attributes), 2):
            if i + 1 >= len(attributes):
                break
            
            key_idx = attributes[i]
            value_idx = attributes[i + 1]
            
            if key_idx < 0 or value_idx < 0:
                continue
            
            key = strings[key_idx] if key_idx < len(strings) else ""
            value = strings[value_idx] if value_idx < len(strings) else ""
            
            # Return value for input/textarea
            if key.lower() == "value":
                return value
        
        return default
    
    def _generate_node_id(self, node: list, node_name: str) -> int:
        """
        Generate a stable numeric ID for a node.
        
        Args:
            node: The node data
            node_name: The node name
            
        Returns:
            A deterministic integer ID
        """
        # Use node position in array as primary ID source
        # This provides stable numeric IDs across extracts
        return hash(f"{node_name}_{id(node)}") % (10**8)
    
    def get_extracted_tree(self) -> Optional[dict]:
        """Get the most recently extracted tree."""
        return self._extracted_tree
    
    def clear_cache(self) -> None:
        """Clear the cached extracted tree."""
        self._extracted_tree = None


def extract_aom(url: str) -> list[dict]:
    """
    Convenience function to extract AOM from a URL.
    
    Args:
        url: The URL to extract from
        
    Returns:
        List of compressed element dictionaries
    """
    extractor = AOMExtractor()
    return extractor.extract(url)


def is_url_allowed(url: str) -> bool:
    """
    Check if a URL is allowed by the domain whitelist.
    
    Args:
        url: The URL to check
        
    Returns:
        True if allowed, False otherwise
    """
    extractor = AOMExtractor()
    try:
        extractor._validate_url(url)
        return True
    except SecurityViolation:
        return False

========================================
FILE: src/cobalt_agent/tools/browser.py
========================================

"""
Browser Tool with Playwright
Visits a URL and extracts clean text content. Supports dynamic actions via JSON DSL.

Features:
- Headless Chromium browsing
- Form filling, clicks, and navigation
- JSON-based action sequence support
- Clean text extraction
- AOM ID-based element referencing
- Vault credential injection
"""
import json
from typing import Optional, Literal, Union, Dict, Any
from pydantic import BaseModel, Field, ValidationError, Discriminator, Tag
from loguru import logger
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError, ElementHandle

from .maps import Maps, get_maps
from ..security.vault import VaultManager
from ..config import get_config

# Define BrowserCommand class for backward compatibility
class BrowserCommand(BaseModel):
    """Pydantic model for browser tool command validation."""
    url: str = Field(default="", description="The URL to navigate to")
    actions: list = Field(default_factory=list, description="List of actions to perform")


class ClickAction(BaseModel):
    """Action to click on an element by its AOM ID."""
    action: Literal["click"] = "click"
    id: int


class TypeAction(BaseModel):
    """Action to type text into an element by its AOM ID."""
    action: Literal["type"] = "type"
    id: int
    text: str


class MapsAction(BaseModel):
    """Action to navigate to a URL and refresh the element map."""
    action: Literal["maps"] = "maps"
    url: str


class ExtractAction(BaseModel):
    """Action to extract AOM data from the current page."""
    action: Literal["extract"] = "extract"


class InjectCredentialsAction(BaseModel):
    """Action to inject credentials from Vault for authentication."""
    action: Literal["inject_credentials"] = "inject_credentials"
    vault_path: str


BrowserAction = Union[
    ClickAction,
    TypeAction,
    MapsAction,
    ExtractAction,
    InjectCredentialsAction
]


class WebPageContent(BaseModel):
    """Structured content from a visited webpage."""
    url: str = Field(description="The final URL after navigation.")
    title: str = Field(description="The page title.")
    content: str = Field(description="The cleaned text content of the page.")
    error: str = Field(default="", description="Error message if fetch failed.")

    def __str__(self):
        if self.error:
            return f"[Error reading {self.url}]: {self.error}"
        return f"### {self.title}\n{self.content[:4000]}.."


class BrowserTool:
    name = "browser"
    description = (
        "A full headless browser. You can pass a simple URL to scrape it, OR pass a JSON string to perform actions. "
        "JSON schema: {'url': '...', 'actions': [{'type': 'fill', 'selector': '...', 'text': '...'}, {'type': 'click', 'selector': '...'}]}"
    )

    def __init__(self):
        """Initialize the BrowserTool with Maps instance."""
        self._maps = get_maps()
        self._vault_manager: Optional[VaultManager] = None
        self._current_page = None

    def _parse_browser_action(self, raw_action: Dict[str, Any]) -> BrowserAction:
        """
        Parse a raw dictionary into a BrowserAction Pydantic model.
        
        Args:
            raw_action: Dictionary containing action data
            
        Returns:
            Parsed BrowserAction (one of the action types)
            
        Raises:
            ValidationError: If the action doesn't match any valid schema
        """
        # Determine action type from the 'action' field
        action_type = raw_action.get("action")
        
        if action_type == "click":
            return ClickAction(**raw_action)
        elif action_type == "type":
            return TypeAction(**raw_action)
        elif action_type == "maps":
            return MapsAction(**raw_action)
        elif action_type == "extract":
            return ExtractAction(**raw_action)
        elif action_type == "inject_credentials":
            return InjectCredentialsAction(**raw_action)
        else:
            from pydantic import ValidationError
            raise ValueError(f"Unknown action type: {action_type}")

    def _get_element_selector(self, element_id: int) -> Optional[str]:
        """
        Get the CSS selector for an element by its AOM ID.
        
        Args:
            element_id: The numeric AOM ID
            
        Returns:
            CSS selector string, or None if not found
        """
        element_ref = self._maps.get_element(element_id)
        if element_ref:
            return element_ref.get("selector")
        return None

    def _execute_click(self, element_id: int) -> str:
        """
        Execute a click action on an element by its AOM ID.
        
        Args:
            element_id: The numeric AOM ID
            
        Returns:
            Observation string describing the result
        """
        selector = self._get_element_selector(element_id)
        if not selector:
            return f"Error: Element ID {element_id} not found in current map"
        
        if not self._current_page:
            return f"Error: No page loaded"
        
        try:
            self._current_page.wait_for_selector(selector, timeout=5000)
            self._current_page.click(selector)
            return f"Successfully clicked element with ID {element_id} (selector: {selector})"
        except Exception as e:
            return f"Error clicking element ID {element_id}: {str(e)}"

    def _execute_type(self, element_id: int, text: str) -> str:
        """
        Execute a type action on an element by its AOM ID.
        
        Args:
            element_id: The numeric AOM ID
            text: Text to type
            
        Returns:
            Observation string describing the result
        """
        selector = self._get_element_selector(element_id)
        if not selector:
            return f"Error: Element ID {element_id} not found in current map"
        
        if not self._current_page:
            return f"Error: No page loaded"
        
        try:
            self._current_page.wait_for_selector(selector, timeout=5000)
            self._current_page.fill(selector, text)
            return f"Successfully typed '{text}' into element ID {element_id} (selector: {selector})"
        except Exception as e:
            return f"Error typing into element ID {element_id}: {str(e)}"

    def _execute_maps(self, url: str) -> str:
        """
        Execute a navigation action and refresh the element map.
        
        Args:
            url: URL to navigate to
            
        Returns:
            Observation string describing the result
        """
        if not self._current_page:
            return "Error: No page loaded"
        
        try:
            # Navigate to the new URL
            self._current_page.goto(url, wait_until="domcontentloaded", timeout=15000)
            self._current_page.wait_for_timeout(2000)
            
            # Refresh the maps with the new page
            self._maps.refresh_tree(self._current_page, url)
            
            title = self._current_page.title()
            return f"Navigated to {url}. Title: {title}. Maps tree refreshed."
        except Exception as e:
            return f"Error navigating to {url}: {str(e)}"

    def _execute_extract(self) -> str:
        """
        Execute an extract action to get AOM data from current page.
        
        Returns:
            Observation string with extracted element count
        """
        if not self._current_page:
            return "Error: No page loaded. Please navigate to a URL first."
        
        try:
            # Get the current page URL
            url = self._current_page.url
            
            # Use the AOMExtractor to get elements
            from .aom import AOMExtractor
            extractor = AOMExtractor()
            elements = extractor.extract(url)
            
            # Update maps with the new elements
            for element in elements:
                element_id = element.get("id")
                if element_id is None:
                    continue  # Skip elements without valid IDs
                role = element.get("role", "")
                name = element.get("name", "")
                
                # Create a simple selector based on role
                selector = self._generate_selector(element)
                
                if selector:
                    self._maps.add_element(element_id, selector)
            
            return f"Extracted {len(elements)} elements from current page."
        except Exception as e:
            return f"Error extracting AOM data: {str(e)}"

    def _execute_inject_credentials(self, vault_path: str) -> str:
        """
        Execute a credential injection action using VaultManager.
        
        Args:
            vault_path: Path/identifier for the credentials in the vault
            
        Returns:
            Observation string describing the result
        """
        # Get the vault manager from config
        try:
            config = get_config()
            vault_mgr = config.vault_manager
            
            if not vault_mgr:
                return "Error: VaultManager not initialized. Vault may be locked."
            
            if not vault_mgr._is_unlocked:
                return "Error: Vault is locked. Please unlock vault first."
            
            # Retrieve credentials from vault
            credentials = vault_mgr.get_secret(vault_path)
            
            if not credentials:
                return f"Error: No credentials found at path '{vault_path}'"
            
            # Parse credentials
            try:
                cred_dict = json.loads(credentials)
            except json.JSONDecodeError:
                # If not JSON, treat as a single secret value
                cred_dict = {"value": credentials}
            
            # Inject credentials into the page
            result = self._inject_credentials_to_page(cred_dict)
            
            # Note: credentials are NEVER returned in the observation
            return result
            
        except Exception as e:
            logger.exception(f"Failed to inject credentials: {e}")
            return f"Error injecting credentials: {str(e)}"

    def _inject_credentials_to_page(self, credentials: Dict[str, str]) -> str:
        """
        Inject credentials into the current page using Playwright.
        
        Args:
            credentials: Dictionary of credential key-value pairs
            
        Returns:
            Observation string describing injection results
        """
        if not self._current_page:
            return "Error: No page loaded. Cannot inject credentials."
        
        injected_count = 0
        
        # Try common credential field selectors
        for key, value in credentials.items():
            if not value:
                continue
                
            # Try various field selectors
            selectors_to_try = [
                f'input[name="{key}"]',
                f'input[id="{key}"]',
                f'input[placeholder*="{key}"]',
            ]
            
            for selector in selectors_to_try:
                try:
                    self._current_page.wait_for_selector(selector, timeout=2000)
                    self._current_page.fill(selector, value)
                    injected_count += 1
                    logger.debug(f"Injected credential '{key}' via selector: {selector}")
                    break  # Move to next credential once we find a matching field
                except Exception:
                    continue
        
        if injected_count > 0:
            return f"Successfully injected {injected_count} credential(s) into page fields."
        else:
            return "Note: No matching form fields found for injected credentials (credentials not returned)."

    def _generate_selector(self, element: Dict[str, Any]) -> Optional[str]:
        """
        Generate a CSS selector for an element based on its properties.
        
        Args:
            element: Element dictionary from AOM extraction
            
        Returns:
            CSS selector string, or None if not possible
        """
        role = element.get("role", "")
        name = element.get("name", "")
        aria = element.get("aria", {})
        
        # Try aria-label first (most specific)
        if "aria-label" in aria:
            return f'[aria-label="{aria["aria-label"]}"]'
        
        # Try name attribute
        if name:
            # Escape special characters in selector
            safe_name = name.replace('"', '\\"')
            return f'[aria-label="{safe_name}"], [placeholder="{safe_name}"]'
        
        # Try role-based selector
        role_selectors = {
            "button": "button",
            "link": "a",
            "input": "input",
            "textbox": "input[type='text'], textarea",
            "heading": "h1, h2, h3, h4, h5, h6",
        }
        
        if role in role_selectors:
            return role_selectors[role]
        
        return None

    def run(self, **kwargs) -> WebPageContent:
        """
        Executes a browsing session. Handles both simple URLs and JSON action sequences.
        
        Args:
            **kwargs: Either a 'query' string (URL) or 'url' and 'actions' parameters
        
        Returns:
            WebPageContent with the extracted data
        """
        # Try to parse input through Pydantic model for strict validation
        try:
            # Try to validate against BrowserCommand first
            if kwargs:
                try:
                    validated = BrowserCommand(**kwargs)
                    url = validated.url
                    actions = validated.actions
                except ValidationError:
                    # Fallback: check if there's a 'query' key with string value
                    query = kwargs.get("query", "")
                    if isinstance(query, str) and query.strip().startswith("{") and query.strip().endswith("}"):
                        command = json.loads(query)
                        url = command.get("url", "")
                        actions = command.get("actions", [])
                    else:
                        # Last resort: use query as URL directly
                        url = query if query else ""
                        actions = []
            else:
                url = ""
                actions = []
        except ValidationError as e:
            # Return error for invalid Pydantic validation
            return WebPageContent(url="unknown", title="Validation Error", content="", error=str(e))
        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse browser query as JSON: {e}")
            return WebPageContent(url="unknown", title="Parse Error", content="", error=f"Invalid JSON: {e}")
        
        # If url is empty at this point, try to get it from query parameter directly
        if not url:
            query = kwargs.get("query", "")
            if isinstance(query, str):
                url = query.strip()
            else:
                url = ""
        
        actions = []
        if isinstance(query, str) and query.strip().startswith("{") and query.strip().endswith("}"):
            try:
                command = json.loads(query)
                url = command.get("url", url)
                actions = command.get("actions", actions)
            except json.JSONDecodeError:
                logger.warning("Failed to parse browser query as JSON, treating as raw URL.")
        
        # Ensure URL has protocol
        if not url.startswith("http"):
            url = "https://" + url

        logger.info(f"üåê Playwright navigating to: {url}")

        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                context = browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
                )
                page = context.new_page()
                self._current_page = page
                
                # 1. Navigate
                page.goto(url, wait_until="domcontentloaded", timeout=15000)
                
                # 2. Refresh maps with the new page
                self._maps.refresh_tree(page, url)

                # 3. Process each action
                action_results = []
                
                for raw_action in actions:
                    try:
                        # Parse the raw action into a Pydantic model
                        action = self._parse_browser_action(raw_action)
                        logger.debug(f"Parsed action: {action}")
                        
                        # Execute based on action type
                        if isinstance(action, ClickAction):
                            result = self._execute_click(action.id)
                            action_results.append(result)
                            logger.debug(f"Click result: {result}")
                            
                        elif isinstance(action, TypeAction):
                            result = self._execute_type(action.id, action.text)
                            action_results.append(result)
                            logger.debug(f"Type result: {result}")
                            
                        elif isinstance(action, MapsAction):
                            result = self._execute_maps(action.url)
                            action_results.append(result)
                            logger.debug(f"Maps result: {result}")
                            
                        elif isinstance(action, ExtractAction):
                            result = self._execute_extract()
                            action_results.append(result)
                            logger.debug(f"Extract result: {result}")
                            
                        elif isinstance(action, InjectCredentialsAction):
                            result = self._execute_inject_credentials(action.vault_path)
                            action_results.append(result)
                            logger.debug(f"Inject credentials result: {result}")
                            
                    except ValidationError as e:
                        error_msg = f"Action validation error: {str(e)}"
                        action_results.append(error_msg)
                        logger.warning(error_msg)
                    except Exception as e:
                        error_msg = f"Error executing action: {str(e)}"
                        action_results.append(error_msg)
                        logger.exception(error_msg)

                # 4. Wait for any dynamic content to settle
                page.wait_for_timeout(2000)

                # 5. Extract Data
                title = page.title()
                
                # Strip out scripts and styles before getting text
                page.evaluate("""
                    document.querySelectorAll('script, style, nav, footer, header, iframe').forEach(el => el.remove());
                """)
                content = page.locator("body").inner_text()
                
                # Clean up whitespace
                clean_text = "\n".join([line.strip() for line in content.splitlines() if line.strip()])
                final_url = page.url

                browser.close()

                # Combine action results into observation
                observation = ""
                if action_results:
                    observation = "\n".join(action_results)
                
                return WebPageContent(
                    url=final_url,
                    title=title,
                    content=clean_text
                )

        except PlaywrightTimeoutError:
            return WebPageContent(url=url, title="Timeout", content="", error="Page load or action timed out.")
        except Exception as e:
            logger.exception(f"Playwright error: {e}")
            return WebPageContent(url=url, title="Error", content="", error=str(e))

========================================
FILE: src/cobalt_agent/tools/filesystem.py
========================================

"""
Filesystem Tools
Standard file operations for the Cobalt Agent.
Provides safe read, write, and directory listing capabilities.
"""
import json
import os
from typing import Dict, List, Any, Optional
from pydantic import BaseModel, Field, ValidationError
from loguru import logger
from pathlib import Path

from cobalt_agent.core.proposals import create_and_send_proposal, ProposalEngine
from cobalt_agent.config import get_config


class FileContent(BaseModel):
    """Structured content from a file read operation."""
    path: str = Field(description="The file path that was read.")
    content: str = Field(description="The file contents.")
    error: str = Field(default="", description="Error message if read failed.")

    def __str__(self):
        if self.error:
            return f"[Error reading {self.path}]: {self.error}"
        return f"File: {self.path}\nContent:\n{self.content[:4000]}..." if len(self.content) > 4000 else f"File: {self.path}\nContent:\n{self.content}"


class WriteResult(BaseModel):
    """Result of a file write operation."""
    path: str = Field(description="The file path that was written.")
    success: bool = Field(description="Whether the write succeeded.")
    error: str = Field(default="", description="Error message if write failed.")

    def __str__(self):
        if self.success:
            return f"Successfully wrote to {self.path}"
        return f"[Error writing {self.path}]: {self.error}"


class DirectoryListing(BaseModel):
    """Result of a directory listing operation."""
    path: str = Field(description="The directory path that was listed.")
    contents: List[Dict[str, Any]] = Field(description="List of files and directories.")
    error: str = Field(default="", description="Error message if listing failed.")

    def __str__(self):
        if self.error:
            return f"[Error listing {self.path}]: {self.error}"
        output = f"Directory: {self.path}\nContents:\n"
        for item in self.contents:
            item_type = item.get('type', 'unknown')
            item_name = item.get('name', 'unknown')
            output += f"  - [{item_type}] {item_name}\n"
        return output


class ReadFileInput(BaseModel):
    """Pydantic model for read_file tool input validation."""
    filepath: Optional[str] = Field(default=None, description="The file path to read")
    path: Optional[str] = Field(default=None, description="Alias for filepath")
    query: Optional[str] = Field(default=None, description="Alias for filepath")


class WriteFileInput(BaseModel):
    """Pydantic model for write_file tool input validation."""
    filepath: Optional[str] = Field(default=None, description="The file path to write")
    path: Optional[str] = Field(default=None, description="Alias for filepath")
    content: Optional[str] = Field(default=None, description="The content to write")


class ListDirectoryInput(BaseModel):
    """Pydantic model for list_directory tool input validation."""
    directory_path: Optional[str] = Field(default=None, description="The directory path to list")
    path: Optional[str] = Field(default=None, description="Alias for directory_path")
    query: Optional[str] = Field(default=None, description="Alias for directory_path")


class ReadFileTool:
    """Read the contents of a file."""
    name = "read_file"
    description = "Read the contents of a file. Use when you need to examine existing code or data. Pass the file path as the query parameter."

    def __init__(self):
        pass

    def run(self, query=None, **kwargs) -> FileContent:
        """
        Read a file and return its contents.
        Accepts either a filepath string directly or a JSON object with filepath key.
        """
        # Universal extraction
        data = query if query is not None else kwargs
        
        if isinstance(data, str):
            try:
                data = json.loads(data)
            except json.JSONDecodeError:
                # Return explicit error for invalid JSON so LLM can self-correct
                error_msg = "Observation: Invalid JSON format. Please use strict double quotes."
                return FileContent(path="unknown", content="", error=error_msg)
        
        path = ""
        if isinstance(data, dict):
            # Check common key names
            path = data.get("filepath", data.get("path", data.get("query", "")))
        elif isinstance(data, str):
            path = data.strip()
            
        if not path:
            return FileContent(path="unknown", content="", error=f"Missing filepath. Parsed data: {data}")
            
        logger.info(f"Reading file: {path}")
        
        try:
            path = os.path.normpath(path)
            if not os.path.exists(path):
                return FileContent(path=path, content="", error=f"File not found: {path}")
            if not os.path.isfile(path):
                return FileContent(path=path, content="", error=f"Not a file: {path}")
                
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()
            return FileContent(path=path, content=content)
            
        except Exception:
            logger.exception(f"Failed to read file {path}")
            return FileContent(path=path, content="", error="Failed to read file")


class WriteFileTool:
    """Modifies or creates a file."""
    name = "write_file"
    
    def run(self, query=None, **kwargs) -> str:
        filepath = None
        content = None
        
        # Universal extraction
        data = query if query is not None else kwargs
        
        if isinstance(data, str):
            try:
                data = json.loads(data)
            except json.JSONDecodeError as e:
                # Return explicit error for invalid JSON so LLM can self-correct
                error_msg = f"Observation: Invalid JSON format. Please use strict double quotes. Error: {e}"
                return error_msg
        
        if isinstance(data, dict):
            # Handle nested query dictionaries
            if "filepath" not in data and "query" in data:
                if isinstance(data["query"], dict):
                    data = data["query"]
                elif isinstance(data["query"], str):
                    try:
                        data = json.loads(data["query"])
                    except json.JSONDecodeError:
                        return "Observation: Invalid JSON format. Please use strict double quotes."

            filepath = data.get("filepath")
            content = data.get("content")

        if not filepath or content is None:
            logger.error(f"WriteFileTool missing fields. Parsed data: {data}")
            return f"Error: Missing filepath or content. Parsed data: {data}"

        # Resolve the path properly
        target_path = Path(filepath)
        
        # Get the base vault path from config
        config = get_config()
        base_path = Path(config.system.obsidian_vault_path)
        
        # CRITICAL: No hardcoded path forcing - accept the path as-is from the LLM
        # The caller must provide the full relative path within the vault
        
        # Path traversal protection: ensure resolved path is within vault
        resolved_target = target_path.resolve()
        resolved_base = base_path.resolve()
        
        if not resolved_target.is_relative_to(resolved_base):
            logger.error(f"Path traversal attempt blocked: {target_path} is outside vault {base_path}")
            raise PermissionError(f"Access denied: Path '{target_path}' is outside the Obsidian vault.")
        
        # Ensure the parent directory exists before writing
        target_path.parent.mkdir(parents=True, exist_ok=True)
        
        def execute_write(proposal_obj):
            try:
                with open(target_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Proposal Engine executed write to: {target_path} ({len(content)} bytes)")
            except Exception as e:
                logger.exception(f"Failed to physically write file {target_path}: {e}")
        
        try:
            proposal = create_and_send_proposal(
                action=f"Write {len(content)} bytes to {filepath}",
                justification="Agent requested file modification via WriteFileTool.",
                risk_assessment="HIGH"
            )
        except Exception as e:
            logger.exception(f"Proposal Engine crash: {e}")
            return f"Error: Proposal Engine crashed: {e}"
        
        if proposal:
            engine = ProposalEngine()
            engine.set_approval_callback(proposal.task_id, execute_write)
            engine.pending_proposals[proposal.task_id] = proposal
            return f"Action paused. Proposal [{proposal.task_id}] sent to Admin for approval in Mattermost."
        else:
            return "Error: Failed to generate Proposal Ticket. Mattermost connection failed."


class ListDirectoryTool:
    """List the contents of a directory."""
    name = "list_directory"
    description = "List the contents of a directory. Use when you need to explore the file structure. Pass the directory path as the query parameter."

    def __init__(self):
        pass

    def run(self, query=None, **kwargs) -> DirectoryListing:
        """
        List directory contents.
        Accepts either a directory_path string directly or a JSON object with directory_path key.
        """
        # Universal extraction
        data = query if query is not None else kwargs
        
        if isinstance(data, str):
            try:
                data = json.loads(data)
            except json.JSONDecodeError:
                # Return explicit error for invalid JSON so LLM can self-correct
                error_msg = "Observation: Invalid JSON format. Please use strict double quotes."
                return DirectoryListing(path="unknown", contents=[], error=error_msg)
        
        path = ""
        if isinstance(data, dict):
            path = data.get("directory_path", data.get("path", data.get("query", "")))
        elif isinstance(data, str):
            path = data.strip()
            
        if not path:
            return DirectoryListing(path="unknown", contents=[], error=f"Missing directory_path. Parsed data: {data}")
            
        logger.info(f"Listing directory: {path}")
        
        try:
            path = os.path.normpath(path)
            if not os.path.exists(path):
                return DirectoryListing(path=path, contents=[], error=f"Directory not found: {path}")
            if not os.path.isdir(path):
                return DirectoryListing(path=path, contents=[], error=f"Not a directory: {path}")
                
            contents = []
            for item in os.listdir(path):
                item_path = os.path.join(path, item)
                item_type = "dir" if os.path.isdir(item_path) else "file"
                contents.append({
                    'name': item,
                    'type': item_type
                })
            return DirectoryListing(path=path, contents=contents)
            
        except Exception:
            logger.exception(f"Failed to list directory {path}")
            return DirectoryListing(path=path, contents=[], error="Failed to list directory")

========================================
FILE: src/cobalt_agent/tools/finance.py
========================================

"""
Finance Tool
Returns structured market data with Technical Indicators.
Strictly implements ALL rules.yaml logic.
Fixed configuration access to handle nested dictionaries safely.
"""
import yfinance as yf
import pandas as pd
import numpy as np
from typing import Optional, Tuple, Any
from pydantic import BaseModel, Field
from loguru import logger
from cobalt_agent.config import load_config

# --- PYDANTIC MODEL ---
class MarketMetrics(BaseModel):
    """Structured financial data for a single asset."""
    ticker: str = Field(description="The stock symbol (e.g. AAPL).")
    price: float = Field(description="Current market price.")
    change_percent: float = Field(description="Daily percentage change.")
    volume: int = Field(description="Current trading volume.")
    
    # Momentum & Volatility
    rsi: float = Field(description="Relative Strength Index.")
    atr: float = Field(description="Average True Range.")
    rvol: float = Field(description="Relative Volume.")
    
    # Anchored VWAPs
    avwap_earnings: str = Field(description="VWAP from last earnings date.")
    avwap_high: str = Field(description="VWAP from 2-month Swing High.")
    avwap_low: str = Field(description="VWAP from 2-month Swing Low.")
    
    # Trend (SMAs)
    sma_10: str = Field(description="10-day SMA.")
    sma_20: str = Field(description="20-day SMA.")
    sma_50: str = Field(description="50-day SMA.")
    sma_100: str = Field(description="100-day SMA.")
    sma_200: str = Field(description="200-day SMA.")
    
    # Signals & Verification
    signal: str = Field("NEUTRAL", description="Computed technical signal.")
    alert_flags: str = Field("", description="Special alerts.")
    calculation_meta: str = Field(description="Debug string showing which rules were used.")

    def __str__(self):
        """Helper for readable string representation."""
        alerts = f" | ‚ö†Ô∏è {self.alert_flags}" if self.alert_flags else ""
        return (
            f"[{self.ticker}] ${self.price:.2f} ({self.change_percent:.2f}%) | "
            f"Signal: {self.signal}{alerts}\n"
            f"   ‚Ä¢ Rules Used: {self.calculation_meta}\n" 
            f"   ‚Ä¢ Momentum: RSI: {self.rsi:.1f} | RVOL: {self.rvol:.1f} | ATR: {self.atr:.2f}\n"
            f"   ‚Ä¢ Anchored VWAPs:\n"
            f"      - Earnings: {self.avwap_earnings}\n"
            f"      - Swing High: {self.avwap_high}\n"
            f"      - Swing Low:  {self.avwap_low}\n"
            f"   ‚Ä¢ SMAs: SMA10: {self.sma_10} | SMA20: {self.sma_20} | SMA50: {self.sma_50} | SMA200: {self.sma_200}"
        )

# --- TOOL ---
class FinanceTool:
    name = "finance"
    description = "Get current stock market data and technical indicators. Use for price queries, e.g., 'What is the price of AAPL?'"
    
    def __init__(self):
        self.system_config = load_config()
        # We access the raw dictionary or object safely
        self.rules = self.system_config.trading_rules

    def _get_rule(self, path: str, default: Any = None) -> Any:
        """
        Helper to safely access nested config rules whether they are 
        objects (dot notation) or dicts (bracket notation).
        Args:
            path: Dot-separated path e.g. "rsi.period"
        """
        try:
            current = self.rules
            for key in path.split('.'):
                if isinstance(current, dict):
                    current = current.get(key)
                else:
                    current = getattr(current, key)
                
                if current is None: return default
            return current
        except Exception:
            return default

    # --- INDICATOR CALCULATIONS ---
    def _calculate_rsi(self, data: pd.DataFrame, window: int) -> float:
        delta = data['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs)).iloc[-1]

    def _calculate_atr(self, data: pd.DataFrame, window: int) -> float:
        high_low = data['High'] - data['Low']
        high_close = np.abs(data['High'] - data['Close'].shift())
        low_close = np.abs(data['Low'] - data['Close'].shift())
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = np.max(ranges, axis=1)
        return true_range.rolling(window=window).mean().iloc[-1]

    def _calculate_rvol(self, data: pd.DataFrame, window: int = 20) -> float:
        avg_vol = data['Volume'].rolling(window=window).mean().iloc[-1]
        current_vol = data['Volume'].iloc[-1]
        if avg_vol == 0: return 0.0
        return current_vol / avg_vol

    def _calculate_avwap(self, data: pd.DataFrame, start_date: str) -> float:
        subset = data.loc[start_date:]
        if subset.empty: return 0.0
        v = subset['Volume'].values
        tp = (subset['High'] + subset['Low'] + subset['Close']) / 3
        return ((tp * v).cumsum() / v.cumsum()).iloc[-1]

    def _get_sma_data(self, data: pd.DataFrame, window: int) -> Tuple[float, str]:
        sma_series = data['Close'].rolling(window=window).mean()
        if len(sma_series) < 2 or pd.isna(sma_series.iloc[-1]): return (0.0, "N/A")
        current = sma_series.iloc[-1]
        previous = sma_series.iloc[-2]
        slope = "RISING" if current > previous else "FALLING"
        return current, slope

    def _get_last_earnings_date(self, ticker_obj) -> Optional[str]:
        try:
            earnings = ticker_obj.earnings_dates
            if earnings is None or earnings.empty: return None
            today = pd.Timestamp.now().tz_localize(earnings.index.dtype.tz)
            past_earnings = earnings[earnings.index < today]
            if past_earnings.empty: return None
            return past_earnings.index[0].strftime('%Y-%m-%d')
        except: return None

    # --- MAIN RUN METHOD ---
    def run(self, ticker: str) -> MarketMetrics:
        try:
            logger.debug(f"Fetching market data for: {ticker}")
            ticker = ticker.upper()
            stock = yf.Ticker(ticker)
            hist = stock.history(period="2y")
            
            if hist.empty:
                return MarketMetrics(
                    ticker=ticker, price=0.0, change_percent=0.0, volume=0, 
                    rsi=0, atr=0, rvol=0, avwap_earnings="N/A", avwap_high="N/A", avwap_low="N/A",
                    sma_10="N/A", sma_20="N/A", sma_50="N/A", sma_100="N/A", sma_200="N/A",
                    signal="NO DATA", calculation_meta="ERROR"
                )

            current_price = hist['Close'].iloc[-1]
            prev_price = hist['Close'].iloc[-2]
            change_pct = ((current_price - prev_price) / prev_price) * 100
            
            # --- 1. CONFIG PARAMETERS (Using Safe Access) ---
            # Using _get_rule helper to handle dict vs object mismatch
            rsi_period = self._get_rule("rsi.period", 14)
            rsi_overbought = self._get_rule("rsi.overbought", 70)
            rsi_oversold = self._get_rule("rsi.oversold", 30)
            
            atr_period = self._get_rule("atr.period", 14)
            atr_mult = self._get_rule("atr.expansion_multiplier", 5.0)
            
            ma_fast = self._get_rule("moving_averages.bullish_cross.fast", 10)
            ma_slow = self._get_rule("moving_averages.bullish_cross.slow", 20)
            
            rvol_alert = self._get_rule("momentum.rvol_alert_threshold", 3.0)

            # --- 2. CALCULATIONS ---
            rsi_val = self._calculate_rsi(hist, window=rsi_period)
            atr_val = self._calculate_atr(hist, window=atr_period)
            rvol_val = self._calculate_rvol(hist)

            # Anchored VWAPs
            last_earnings = self._get_last_earnings_date(stock)
            avwap_earn_str = "N/A"
            avwap_earn_val = 0.0
            if last_earnings:
                val = self._calculate_avwap(hist, last_earnings)
                avwap_earn_val = val
                dist = ((current_price - val) / val) * 100
                avwap_earn_str = f"${val:.2f} ({'ABOVE' if current_price > val else 'BELOW'} {abs(dist):.1f}%)"

            # Swing VWAPs
            recent_data = hist.tail(42)
            idx_max = recent_data['High'].idxmax()
            idx_min = recent_data['Low'].idxmin()
            
            val_high = self._calculate_avwap(hist, idx_max.strftime('%Y-%m-%d'))
            dist_high = ((current_price - val_high) / val_high) * 100
            avwap_high_str = f"${val_high:.2f} ({'ABOVE' if current_price > val_high else 'BELOW'} {abs(dist_high):.1f}%)"

            val_low = self._calculate_avwap(hist, idx_min.strftime('%Y-%m-%d'))
            dist_low = ((current_price - val_low) / val_low) * 100
            avwap_low_str = f"${val_low:.2f} ({'ABOVE' if current_price > val_low else 'BELOW'} {abs(dist_low):.1f}%)"

            # SMAs
            sma10_val, sma10_slope = self._get_sma_data(hist, 10)
            sma20_val, sma20_slope = self._get_sma_data(hist, 20)
            sma50_val, sma50_slope = self._get_sma_data(hist, 50)
            sma100_val, sma100_slope = self._get_sma_data(hist, 100)
            sma200_val, sma200_slope = self._get_sma_data(hist, 200)

            # --- 3. SIGNAL LOGIC ---
            signal = "NEUTRAL"
            alerts = []
            
            # A. RSI Checks
            if rsi_val > rsi_overbought: signal = f"OVERBOUGHT (> {rsi_overbought})"
            elif rsi_val < rsi_oversold: signal = f"OVERSOLD (< {rsi_oversold})"
            
            # B. Bullish Cross (Fast > Slow AND Both Rising)
            # Using configured periods for logic check (assuming 10/20 here matches variables)
            # Ideally we'd calculate dynamic SMAs based on config, but for now we hardcoded the 10/20 fetch above.
            elif (sma10_val > sma20_val) and (sma10_slope == "RISING") and (sma20_slope == "RISING"):
                 signal = f"BULLISH CROSS ({ma_fast}/{ma_slow} Rising)"
            
            # C. Trend (Earnings VWAP)
            elif avwap_earn_val > 0:
                if current_price > avwap_earn_val: signal = "BULLISH (Above Earnings VWAP)"
                else: signal = "BEARISH (Below Earnings VWAP)"

            # Alerts
            if rvol_val > rvol_alert: 
                alerts.append("RVOL ALERT")
            
            five_day_move = abs(current_price - hist['Close'].iloc[-6]) 
            if five_day_move > (atr_val * atr_mult):
                alerts.append("PARABOLIC MOVE")

            meta_string = f"RSI-{rsi_period} ({rsi_oversold}/{rsi_overbought}) | Cross-{ma_fast}/{ma_slow}"

            return MarketMetrics(
                ticker=ticker,
                price=round(current_price, 2),
                change_percent=round(change_pct, 2),
                volume=int(hist['Volume'].iloc[-1]),
                rsi=round(rsi_val, 1),
                atr=round(atr_val, 2),
                rvol=round(rvol_val, 2),
                avwap_earnings=avwap_earn_str,
                avwap_high=avwap_high_str,
                avwap_low=avwap_low_str,
                sma_10=f"${sma10_val:.2f} ({sma10_slope})",
                sma_20=f"${sma20_val:.2f} ({sma20_slope})",
                sma_50=f"${sma50_val:.2f} ({sma50_slope})",
                sma_100=f"${sma100_val:.2f} ({sma100_slope})",
                sma_200=f"${sma200_val:.2f} ({sma200_slope})",
                signal=signal,
                alert_flags=", ".join(alerts),
                calculation_meta=meta_string
            )

        except Exception as e:
            logger.error(f"Finance tool error for {ticker}: {e}")
            return MarketMetrics(
                ticker=ticker, price=0.0, change_percent=0.0, volume=0, 
                rsi=0, atr=0, rvol=0, avwap_earnings="Err", avwap_high="Err", avwap_low="Err",
                sma_10="N/A", sma_20="N/A", sma_50="N/A", sma_100="N/A", sma_200="N/A",
                signal="ERROR", calculation_meta="Error"
            )

========================================
FILE: src/cobalt_agent/tools/knowledge.py
========================================

from pydantic import BaseModel, Field
from typing import List, Any
from loguru import logger
from cobalt_agent.memory.postgres import PostgresMemory

class SearchResult(BaseModel):
    source: str
    content: str
    score: float

class KnowledgeSearchTool:
    name = "search_knowledge"
    description = "Search the agent's internal vector database (codebase, playbooks, and Obsidian vault) for semantic context. Pass a conceptual query string."

    def __init__(self):
        self.memory = PostgresMemory()

    def run(self, query=None, **kwargs) -> str:
        """Searches the vector DB and returns formatted results."""
        import json
        import ast
        
        # Universal extraction
        data = query if query is not None else kwargs
        
        if isinstance(data, str):
            try:
                data = json.loads(data)
            except Exception:
                try:
                    data = ast.literal_eval(data)
                except Exception:
                    pass

        search_query = ""
        if isinstance(data, dict):
            search_query = data.get("query", data.get("search", ""))
        elif isinstance(data, str):
            search_query = data.strip()
            
        if not search_query:
            return "Error: Missing search query."
            
        logger.info(f"üìö Searching Vector Knowledge Base for: '{search_query}'")
        
        try:
            results = self.memory.search(search_query, limit=5)
            if not results:
                return f"No relevant information found in the knowledge base for '{search_query}'."
                
            output = f"### Knowledge Base Results for '{search_query}':\n\n"
            for idx, res in enumerate(results, 1):
                # Retrieve the filepath/metadata if it was stored
                meta = res.get('metadata', {})
                filepath = meta.get('filepath', res.get('source', 'Unknown'))
                content = res.get('content', '').strip()
                score = res.get('score', 0.0)
                
                output += f"**Result {idx}** (Source: `{filepath}`, Relevance: {score:.2f})\n"
                output += f"```text\n{content}\n```\n\n"
                
            return output
            
        except Exception as e:
            logger.error(f"Knowledge search failed: {e}")
            return f"Error executing knowledge search: {e}"

========================================
FILE: src/cobalt_agent/tools/maps.py
========================================

"""
AOM Maps Module - Stateful Element Handle Mapping

This module provides a stateful mapping class that stores the relationship between
numeric IDs generated by the AOM extractor and the actual Playwright ElementHandle
or specific CDP node locator.

Features:
- Map numeric IDs to Playwright ElementHandle or CDP node locators
- Refresh tree upon navigation to prevent stale element reference errors
- Invalidate old IDs when the DOM changes
- Thread-safe access with locking
"""
from typing import Optional, Dict, Any
from playwright.sync_api import ElementHandle, Page
from loguru import logger
from copy import deepcopy


class Maps:
    """
    Stateful mapping between AOM numeric IDs and Playwright ElementHandles.
    
    This class maintains a cache of element IDs to their current ElementHandle
    or CDP node locator reference. It provides methods to:
    - Store element mappings
    - Retrieve elements by ID
    - Refresh mappings when the page changes
    - Invalidate stale references
    """
    
    def __init__(self):
        """Initialize the Maps cache with empty storage and no page reference."""
        self._element_cache: Dict[int, Dict[str, Any]] = {}
        self._current_url: Optional[str] = None
        self._page: Optional[Page] = None
        self._lock = None  # Can use threading.Lock for thread safety
        logger.debug("Maps instance initialized with empty cache")
    
    def _create_element_reference(self, element_id: int, selector: str) -> Dict[str, Any]:
        """
        Create a reference dictionary for an element.
        
        Args:
            element_id: The numeric ID from AOM extraction
            selector: The CSS selector to locate the element
            
        Returns:
            Dictionary containing element reference data
        """
        return {
            "id": element_id,
            "selector": selector,
            "created_at": __import__("time").time(),
            "valid": True
        }
    
    def add_element(self, element_id: int, selector: str, element: Optional[ElementHandle] = None) -> None:
        """
        Add or update an element mapping.
        
        Args:
            element_id: The numeric ID from AOM extraction
            selector: The CSS selector to locate the element
            element: Optional ElementHandle reference
        """
        if element_id in self._element_cache:
            logger.debug(f"Updating existing element mapping for ID {element_id}")
        else:
            logger.debug(f"Adding new element mapping for ID {element_id}")
        
        reference = self._create_element_reference(element_id, selector)
        
        # Store optional ElementHandle (as a marker - Playwright handles can't be serialized)
        if element:
            reference["has_handle"] = True
            # Note: We don't store the actual ElementHandle as it can't be pickled
            # and Playwright will invalidate it on page changes anyway
        else:
            reference["has_handle"] = False
        
        self._element_cache[element_id] = reference
    
    def get_element(self, element_id: int) -> Optional[Dict[str, Any]]:
        """
        Retrieve an element reference by its ID.
        
        Args:
            element_id: The numeric ID to look up
            
        Returns:
            Dictionary containing element reference data, or None if not found
        """
        element = self._element_cache.get(element_id)
        if element:
            if element.get("valid", False):
                return element
            else:
                logger.warning(f"Element ID {element_id} is marked as invalid")
        return None
    
    def remove_element(self, element_id: int) -> bool:
        """
        Remove an element from the cache.
        
        Args:
            element_id: The numeric ID to remove
            
        Returns:
            True if the element was removed, False if not found
        """
        if element_id in self._element_cache:
            del self._element_cache[element_id]
            logger.debug(f"Removed element ID {element_id} from cache")
            return True
        return False
    
    def refresh_tree(self, page: Page, new_url: Optional[str] = None) -> None:
        """
        Invalidate all cached elements and update the current URL.
        
        This should be called after navigation to prevent stale element reference errors.
        
        Args:
            page: The current Playwright Page object
            new_url: Optional new URL after navigation
        """
        logger.info("Refreshing Maps tree - invalidating all cached elements")
        
        # Invalidate all existing references
        for element_id in self._element_cache:
            self._element_cache[element_id]["valid"] = False
        
        # Update current URL
        if new_url:
            self._current_url = new_url
            logger.debug(f"Updated current URL to: {new_url}")
        else:
            try:
                self._current_url = page.url
                logger.debug(f"Current URL: {page.url}")
            except Exception as e:
                logger.warning(f"Failed to get current URL: {e}")
        
        self._page = page
    
    def clear(self) -> None:
        """Clear all cached elements."""
        logger.info("Clearing all element mappings from cache")
        self._element_cache.clear()
        self._current_url = None
        self._page = None
    
    def get_all_elements(self) -> Dict[int, Dict[str, Any]]:
        """
        Get all cached elements.
        
        Returns:
            Dictionary mapping element IDs to their reference data
        """
        return self._element_cache
    
    def is_valid_element(self, element_id: int) -> bool:
        """
        Check if an element ID is valid (exists and is marked valid).
        
        Args:
            element_id: The numeric ID to check
            
        Returns:
            True if the element exists and is valid, False otherwise
        """
        element = self._element_cache.get(element_id)
        if not element:
            return False
        return element.get("valid", False)
    
    def invalidate_all(self) -> None:
        """Mark all cached elements as invalid."""
        logger.info("Invalidating all cached elements")
        for element_id in self._element_cache:
            self._element_cache[element_id]["valid"] = False
    
    def get_current_url(self) -> Optional[str]:
        """
        Get the current URL being mapped.
        
        Returns:
            The current URL, or None if not set
        """
        return self._current_url
    
    def set_page(self, page: Page) -> None:
        """
        Set the current Playwright page for future operations.
        
        Args:
            page: The Playwright Page object
        """
        self._page = page
        logger.debug("Page reference updated in Maps")
    
    def get_page(self) -> Optional[Page]:
        """
        Get the current Playwright page reference.
        
        Returns:
            The current Page object, or None if not set
        """
        return self._page
    
    def find_element_by_selector(self, selector: str) -> Optional[Dict[str, Any]]:
        """
        Find an element by its CSS selector.
        
        Args:
            selector: The CSS selector to search for
            
        Returns:
            Dictionary containing element reference data, or None if not found
        """
        for element_id, reference in self._element_cache.items():
            if reference.get("selector") == selector:
                if reference.get("valid", False):
                    return reference
        return None


# Singleton instance for convenience
_maps_instance: Optional[Maps] = None


def get_maps() -> Maps:
    """
    Get the global Maps singleton instance.
    
    Returns:
        The Maps instance
    """
    global _maps_instance
    if _maps_instance is None:
        _maps_instance = Maps()
    return _maps_instance


def reset_maps() -> Maps:
    """
    Reset the global Maps instance (create new instance).
    
    Returns:
        A new Maps instance
    """
    global _maps_instance
    if _maps_instance is not None:
        _maps_instance.clear()
    _maps_instance = Maps()
    return _maps_instance


def refresh_maps_tree(page: Page, new_url: Optional[str] = None) -> None:
    """
    Convenience function to refresh the global Maps tree.
    
    Args:
        page: The current Playwright Page object
        new_url: Optional new URL after navigation
    """
    maps = get_maps()
    maps.refresh_tree(page, new_url)

========================================
FILE: src/cobalt_agent/tools/search.py
========================================

"""
Search Tool
Now returns strict Pydantic models instead of raw dictionaries.
Updated to use the new 'ddgs' package.
"""
from typing import List
from pydantic import BaseModel, Field
from loguru import logger
from ddgs import DDGS # <--- CHANGED THIS IMPORT

# --- PYDANTIC MODELS ---
class SearchResult(BaseModel):
    """A single search result item."""
    title: str = Field(description="The title of the search result.")
    href: str = Field(description="The URL link to the result.")
    body: str = Field(description="The snippet or summary text.")

# --- TOOL ---
class SearchTool:
    name = "search"
    description = "Search the internet for news, information, and general knowledge. Use for questions about current events, topics, or general queries."
    
    def __init__(self):
        pass

    def run(self, query: str, max_results: int = 5) -> List[SearchResult]:
        """
        Executes a search and returns a list of typed SearchResult objects.
        """
        try:
            logger.debug(f"Searching for: {query}")
            
            # 1. Execute Search
            # We use the context manager approach for safety
            with DDGS() as ddgs:
                # .text() returns a generator/iterator, so we cast to list
                results = list(ddgs.text(query, max_results=max_results))
            
            # 2. Convert to Pydantic Models
            structured_results = []
            for item in results:
                try:
                    # We map the raw dict keys to our model
                    structured_results.append(SearchResult(
                        title=item.get('title', 'No Title'),
                        href=item.get('href', '#'),
                        body=item.get('body', 'No description available.')
                    ))
                except Exception as e:
                    logger.warning(f"Skipping malformed search result: {e}")
            
            if not structured_results:
                 logger.warning(f"No results found for '{query}'")
                 return []
                 
            return structured_results

        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []

========================================
FILE: src/cobalt_agent/tools/test_script.py
========================================

print("Hello from the Forge")

========================================
FILE: src/cobalt_agent/tools/tool_manager.py
========================================

"""
Cobalt Agent - Tool Manager
Registry and execution engine for all agent capabilities.
"""

from typing import Dict, Any, List, Optional, Type
from loguru import logger
from pydantic import BaseModel, ValidationError
import json

# Import your tools
from cobalt_agent.tools.search import SearchTool
# Import Browser
from cobalt_agent.tools.browser import BrowserTool, BrowserCommand
# Import Finance
from cobalt_agent.tools.finance import FinanceTool
# Import Filesystem tools
from cobalt_agent.tools.filesystem import ReadFileTool, WriteFileTool, ListDirectoryTool
from cobalt_agent.tools.filesystem import ReadFileInput, WriteFileInput, ListDirectoryInput
# Import Knowledge Base
from cobalt_agent.tools.knowledge import KnowledgeSearchTool

class ToolResult(BaseModel):
    """Standardized output for any tool execution."""
    success: bool
    output: Any
    error: Optional[str] = None

class ToolManager:
    """
    Manages the registration and execution of tools.
    Allows the LLM to 'see' and 'use' functions.
    """
    
    def __init__(self):
        self.tools: Dict[str, Any] = {}
        self._register_core_tools()
        
    def _register_core_tools(self):
        """Register the default built-in tools."""
        # 1. Search Tool
        search = SearchTool()
        self.register_tool("search", search)

        # 2. Browser Tool (with Pydantic schema)
        browser = BrowserTool()
        self.register_tool("browser", browser, schema=BrowserCommand)
        
        # 3. Finance Tool
        finance = FinanceTool()
        self.register_tool("finance", finance)
        
        # 4. Filesystem Tools (with Pydantic schemas)
        self.register_tool("read_file", ReadFileTool(), schema=ReadFileInput)
        self.register_tool("write_file", WriteFileTool(), schema=WriteFileInput)
        self.register_tool("list_directory", ListDirectoryTool(), schema=ListDirectoryInput)
        
        # 5. Knowledge Base
        self.register_tool("search_knowledge", KnowledgeSearchTool())
        
    def register_tool(self, name: str, tool_instance: Any, schema: Optional[Type[BaseModel]] = None):
        """Add a new tool to the registry."""
        self.tools[name] = tool_instance
        self.tools[name + '_schema'] = schema  # Store schema separately
        logger.info(f"Tool registered: {name}")

    def get_tool_descriptions(self) -> List[Any]:
        """Return the list of tool objects for the Prompt Engine."""
        return list(self.tools.values())

    def execute_tool(self, name: str, args: Any) -> str:
        from loguru import logger
        logger.info(f"Executing tool: {name} with args: {args}")
        
        if name not in self.tools:
            return f"Error: Tool '{name}' not found."
            
        tool = self.tools[name]
        schema_key = name + '_schema'
        
        try:
            # Validate against Pydantic schema if available
            if schema_key in self.tools and self.tools[schema_key]:
                schema = self.tools[schema_key]
                try:
                    # If args is a dict, validate it against the schema
                    if isinstance(args, dict):
                        validated_args = schema(**args)
                        return tool.run(**validated_args.model_dump())
                    elif isinstance(args, str):
                        # Try to parse string as JSON first
                        try:
                            parsed_args = json.loads(args)
                            validated_args = schema(**parsed_args)
                            return tool.run(**validated_args.model_dump())
                        except json.JSONDecodeError:
                            # Return error for invalid JSON
                            return f"Observation: Invalid JSON format. Please use strict double quotes."
                except ValidationError as e:
                    # Return exact error message for LLM to self-correct
                    error_str = str(e)
                    logger.warning(f"Pydantic validation error for tool {name}: {error_str}")
                    return f"Error: {error_str}"
            
            # Fallback for tools without Pydantic schema
            if isinstance(args, dict):
                return tool.run(**args)
            else:
                return tool.run(args)
        except json.JSONDecodeError as e:
            return f"Observation: Invalid JSON format. Please use strict double quotes."
        except TypeError as e:
            # Fallback for legacy tools that strictly only accept a single positional 'query' string
            logger.warning(f"Tool {name} rejected kwargs, falling back to positional: {e}")
            if isinstance(args, dict):
                if "query" in args:
                    return tool.run(args["query"])
                elif len(args) == 1:
                    return tool.run(list(args.values())[0])
                else:
                    return tool.run(str(args))
            return tool.run(str(args))
        except Exception as e:
            logger.error(f"Error executing tool {name}: {str(e)}")
            return f"Error executing tool {name}: {str(e)}"


========================================
FILE: src/cobalt_agent.egg-info/SOURCES.txt
========================================

README.md
pyproject.toml
src/cobalt_agent/__init__.py
src/cobalt_agent/config.py
src/cobalt_agent/llm.py
src/cobalt_agent/main.py
src/cobalt_agent/persona.py
src/cobalt_agent/prompt.py
src/cobalt_agent.egg-info/PKG-INFO
src/cobalt_agent.egg-info/SOURCES.txt
src/cobalt_agent.egg-info/dependency_links.txt
src/cobalt_agent.egg-info/requires.txt
src/cobalt_agent.egg-info/top_level.txt
src/cobalt_agent/brain/cortex.py
src/cobalt_agent/brain/playbook.py
src/cobalt_agent/brain/strategy.py
src/cobalt_agent/brain/tactical.py
src/cobalt_agent/brain/strategies/__init__.py
src/cobalt_agent/brain/strategies/second_day_play.py
src/cobalt_agent/core/__init__.py
src/cobalt_agent/core/proposals.py
src/cobalt_agent/core/scheduler.py
src/cobalt_agent/interfaces/__init__.py
src/cobalt_agent/interfaces/cli.py
src/cobalt_agent/interfaces/mattermost.py
src/cobalt_agent/memory/__init__.py
src/cobalt_agent/memory/base.py
src/cobalt_agent/memory/core.py
src/cobalt_agent/memory/postgres.py
src/cobalt_agent/skills/productivity/briefing.py
src/cobalt_agent/skills/productivity/scribe.py
src/cobalt_agent/skills/research/deep_dive.py
src/cobalt_agent/tools/__init__.py
src/cobalt_agent/tools/browser.py
src/cobalt_agent/tools/finance.py
src/cobalt_agent/tools/search.py
src/cobalt_agent/tools/tool_manager.py
tests/test_brain_connection.py
tests/test_config_override.py
tests/test_logic_lab.py
tests/test_memory_integration.py
tests/test_role_switch.py
tests/test_scribe.py
tests/test_strategies.py

========================================
FILE: src/cobalt_agent.egg-info/dependency_links.txt
========================================




========================================
FILE: src/cobalt_agent.egg-info/requires.txt
========================================

pydantic>=2.0.0
pydantic-ai>=0.0.1
litellm>=1.0.0
openai>=1.0.0
pandas>=2.2.0
pandas-ta-classic
ta-lib>=0.4.0
mplfinance>=0.12.0
aiohttp>=3.9.0
mattermostdriver>=7.0
google-api-python-client>=2.0
gitpython>=3.1.0
schedule>=1.2.0
beautifulsoup4>=4.12.0
playwright>=1.40.0
fastapi>=0.100.0
uvicorn>=0.20.0
redis>=5.0.0
asyncpg>=0.29.0
sqlalchemy>=2.0.0
loguru>=0.7.0
python-dotenv>=1.0.0
pyyaml>=6.0.0
pyotp>=2.9.0
qrcode>=7.4.0
bcrypt>=4.0.0
passlib>=1.7.0
ddgs>=9.10.0
rich>=14.3.2
requests>=2.32.5
yfinance>=1.1.0
psycopg[binary]>=3.3.2
pgvector>=0.4.2
apscheduler>=3.11.2
cryptography>=46.0.4


========================================
FILE: src/cobalt_agent.egg-info/top_level.txt
========================================

cobalt_agent


========================================
FILE: tests/conftest.py
========================================

"""
Pytest Configuration
Allows tests to import modules from the main directory and loads Environment Variables.
"""
import sys
import os
import pytest
from dotenv import load_dotenv

# 1. LOAD SECRETS (Crucial Step)
# This forces the test runner to read your .env file
load_dotenv()

# 2. ADD SOURCE CODE TO PATH
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

@pytest.fixture
def temp_vault_path():
    """Create a temporary vault file path for testing (file doesn't exist initially)."""
    import tempfile
    from pathlib import Path
    
    with tempfile.NamedTemporaryFile(suffix='.vault', delete=False) as f:
        path = f.name
    
    # Delete the file so it doesn't exist when tests run
    Path(path).unlink(missing_ok=True)
    
    yield path
    
    # Cleanup after test
    Path(path).unlink(missing_ok=True)


@pytest.fixture
def mock_config():
    """Provides a standard mock configuration for tests."""
    return {
        "strategies": {
            "second_day_play": {
                "active": True,
                "scoring": {
                    "base_score": 50,
                    "high_rvol_threshold": 3.0,
                    "high_rvol_points": 20, 
                    "base_rvol_points": 10,
                    "gap_up_points": 5,
                    "live_rvol_multiplier": 5.0,
                    "spy_correlation_weight": 10.0,
                    "resistance_penalty": -20.0,
                    "time_decay_per_min": -0.5
                }
            }
        }
    }


========================================
FILE: tests/test_browser_actions.py
========================================

"""
Tests for Browser Actions and Pydantic Schema Validation.

This module tests:
1. Pydantic BrowserAction schema validation
2. Strict rejection of invalid actions or missing fields
3. Vault credential injection with mocked VaultManager
4. Credential security (credentials not leaked in output)
"""
import pytest
from unittest.mock import Mock, patch, MagicMock
from pydantic import ValidationError

from src.cobalt_agent.tools.browser import (
    BrowserAction,
    ClickAction,
    TypeAction,
    MapsAction,
    ExtractAction,
    InjectCredentialsAction,
    BrowserTool,
    WebPageContent
)
from src.cobalt_agent.security.vault import VaultManager
from src.cobalt_agent.tools.maps import Maps


class TestPydanticSchemaValidation:
    """Test Pydantic BrowserAction schema validation."""
    
    def test_click_action_valid(self):
        """Test ClickAction with valid data."""
        action = ClickAction(id=123)
        assert action.action == "click"
        assert action.id == 123
    
    def test_type_action_valid(self):
        """Test TypeAction with valid data."""
        action = TypeAction(id=456, text="Hello World")
        assert action.action == "type"
        assert action.id == 456
        assert action.text == "Hello World"
    
    def test_maps_action_valid(self):
        """Test MapsAction with valid data."""
        action = MapsAction(url="https://example.com")
        assert action.action == "maps"
        assert action.url == "https://example.com"
    
    def test_extract_action_valid(self):
        """Test ExtractAction with valid data."""
        action = ExtractAction()
        assert action.action == "extract"
    
    def test_inject_credentials_action_valid(self):
        """Test InjectCredentialsAction with valid data."""
        action = InjectCredentialsAction(vault_path="path/to/creds")
        assert action.action == "inject_credentials"
        assert action.vault_path == "path/to/creds"
    
    def test_click_action_rejects_string_id(self):
        """Test that ClickAction rejects string IDs (strict typing)."""
        with pytest.raises(ValidationError) as exc_info:
            ClickAction(id="not-a-number")
        assert "Input should be a valid integer" in str(exc_info.value)
    
    def test_type_action_rejects_missing_text(self):
        """Test that TypeAction requires text field."""
        # text is required, id is required
        with pytest.raises(ValidationError) as exc_info:
            TypeAction(id=123)
        assert "Field required" in str(exc_info.value) or "missing required" in str(exc_info.value).lower()
    
    def test_maps_action_rejects_missing_url(self):
        """Test that MapsAction requires url field."""
        with pytest.raises(ValidationError) as exc_info:
            MapsAction()
        assert "Field required" in str(exc_info.value) or "missing required" in str(exc_info.value).lower()
    
    def test_click_action_rejects_missing_id(self):
        """Test that ClickAction requires id field."""
        with pytest.raises(ValidationError) as exc_info:
            ClickAction()
        assert "Field required" in str(exc_info.value) or "missing required" in str(exc_info.value).lower()
    
    def test_inject_credentials_action_rejects_missing_vault_path(self):
        """Test that InjectCredentialsAction requires vault_path field."""
        with pytest.raises(ValidationError) as exc_info:
            InjectCredentialsAction()
        assert "Field required" in str(exc_info.value) or "missing required" in str(exc_info.value).lower()
    
    def test_invalid_action_type_raises_validation_error(self):
        """Test that invalid action types raise ValidationError."""
        with pytest.raises(ValidationError):
            ClickAction(id=123, action="invalid_action")
    
    def test_browser_action_union_accepts_valid_actions(self):
        """Test BrowserAction union accepts all valid action types."""
        from typing import get_args
        
        actions = [
            ClickAction(id=1),
            TypeAction(id=2, text="test"),
            MapsAction(url="https://test.com"),
            ExtractAction(),
            InjectCredentialsAction(vault_path="path")
        ]
        
        for action in actions:
            # This should not raise - just use the action directly since it's already validated
            assert action.action == action.action
            # The union validation happens when parsing raw dicts, not when creating models


class TestVaultCredentialInjection:
    """Test Vault credential injection functionality."""
    
    def test_inject_credentials_success(self):
        """Test successful credential injection from vault."""
        with patch('src.cobalt_agent.tools.browser.get_config') as mock_get_config:
            # Setup mocks
            mock_config = Mock()
            mock_vault = Mock(spec=VaultManager)
            
            # Set up vault unlocked
            mock_vault._is_unlocked = True
            # Return JSON credentials
            mock_vault.get_secret.return_value = '{"username": "testuser", "password": "testpass123"}'
            
            mock_config.vault_manager = mock_vault
            mock_get_config.return_value = mock_config
            
            # Create browser tool with mocked page
            tool = BrowserTool()
            
            # Mock the current page
            mock_page = Mock()
            tool._current_page = mock_page
            
            # Execute the credential injection
            result = tool._execute_inject_credentials("test/creds")
            
            # Verify vault was called
            mock_vault.get_secret.assert_called_once_with("test/creds")
            
            # Verify page.fill was called for credentials
            assert mock_page.fill.call_count >= 2
            
            # Verify result doesn't contain actual password
            assert "testpass123" not in result
            assert "testuser" not in result
    
    def test_inject_credentials_vault_locked(self):
        """Test that locked vault returns error."""
        with patch('src.cobalt_agent.tools.browser.get_config') as mock_get_config:
            mock_config = Mock()
            mock_vault = Mock(spec=VaultManager)
            mock_vault._is_unlocked = False
            mock_config.vault_manager = mock_vault
            mock_get_config.return_value = mock_config
            
            tool = BrowserTool()
            result = tool._execute_inject_credentials("test/creds")
            
            assert "Vault is locked" in result
    
    def test_inject_credentials_no_vault_manager(self):
        """Test that missing vault manager returns error."""
        with patch('src.cobalt_agent.tools.browser.get_config') as mock_get_config:
            mock_config = Mock()
            mock_config.vault_manager = None
            mock_get_config.return_value = mock_config
            
            tool = BrowserTool()
            result = tool._execute_inject_credentials("test/creds")
            
            assert "VaultManager not initialized" in result
    
    def test_inject_credentials_no_credentials_in_vault(self):
        """Test that missing credentials in vault returns error."""
        with patch('src.cobalt_agent.tools.browser.get_config') as mock_get_config:
            mock_config = Mock()
            mock_vault = Mock(spec=VaultManager)
            mock_vault._is_unlocked = True
            mock_vault.get_secret.return_value = None  # No credentials found
            mock_config.vault_manager = mock_vault
            mock_get_config.return_value = mock_config
            
            tool = BrowserTool()
            result = tool._execute_inject_credentials("test/creds")
            
            assert "No credentials found" in result
    
    def test_inject_credentials_no_page_loaded(self):
        """Test that no page loaded returns error."""
        with patch('src.cobalt_agent.tools.browser.get_config') as mock_get_config:
            # Set up mocks before creating tool
            mock_config = Mock()
            mock_vault = Mock(spec=VaultManager)
            mock_vault._is_unlocked = True
            mock_vault.get_secret.return_value = '{"username": "test"}'
            mock_config.vault_manager = mock_vault
            mock_get_config.return_value = mock_config
            
            tool = BrowserTool()
            result = tool._execute_inject_credentials("test/creds")
            
            # When page is None, the config loading happens first
            # Since we mock get_config, this should pass and return page not loaded error
            assert "Error" in result or "VaultManager not initialized" in result
    
    def test_inject_credentials_password_not_leaked(self):
        """Test that password is never in the observation string."""
        with patch('src.cobalt_agent.tools.browser.get_config') as mock_get_config:
            mock_config = Mock()
            mock_vault = Mock(spec=VaultManager)
            mock_vault._is_unlocked = True
            
            # Return credentials that look like a real password
            mock_vault.get_secret.return_value = '{"password": "SuperSecret123!@#"}'
            
            mock_config.vault_manager = mock_vault
            mock_get_config.return_value = mock_config
            
            tool = BrowserTool()
            mock_page = Mock()
            tool._current_page = mock_page
            
            result = tool._execute_inject_credentials("test/creds")
            
            # The password must NOT appear in the result
            assert "SuperSecret123!@#" not in result
            assert "SuperSecret" not in result
    
    def test_inject_credentials_uses_playwright_fill(self):
        """Test that credentials are injected using Playwright fill."""
        with patch('src.cobalt_agent.tools.browser.get_config') as mock_get_config:
            mock_config = Mock()
            mock_vault = Mock(spec=VaultManager)
            mock_vault._is_unlocked = True
            mock_vault.get_secret.return_value = '{"api_key": "my-api-key-12345"}'
            
            mock_config.vault_manager = mock_vault
            mock_get_config.return_value = mock_config
            
            tool = BrowserTool()
            mock_page = Mock()
            tool._current_page = mock_page
            
            result = tool._execute_inject_credentials("test/creds")
            
            # Verify fill was called
            mock_page.fill.assert_called()
            
            # Get the fill calls
            calls = mock_page.fill.call_args_list
            
            # Verify the password was passed to fill (but we can't check the value in result)
            found_fill = False
            for call in calls:
                if call[0][0] == 'input[name="api_key"]' or call[0][0] == 'input[id="api_key"]':
                    found_fill = True
                    break
            
            assert found_fill, "fill should have been called for api_key field"


class TestBrowserActionParsing:
    """Test BrowserTool action parsing functionality."""
    
    def test_parse_click_action(self):
        """Test parsing a click action."""
        tool = BrowserTool()
        raw_action = {"action": "click", "id": 123}
        
        action = tool._parse_browser_action(raw_action)
        
        assert isinstance(action, ClickAction)
        assert action.action == "click"
        assert action.id == 123
    
    def test_parse_type_action(self):
        """Test parsing a type action."""
        tool = BrowserTool()
        raw_action = {"action": "type", "id": 456, "text": "Hello"}
        
        action = tool._parse_browser_action(raw_action)
        
        assert isinstance(action, TypeAction)
        assert action.action == "type"
        assert action.id == 456
        assert action.text == "Hello"
    
    def test_parse_invalid_action_raises_error(self):
        """Test that invalid action type raises error."""
        tool = BrowserTool()
        raw_action = {"action": "unknown_action", "id": 123}
        
        with pytest.raises(ValueError):
            tool._parse_browser_action(raw_action)
    
    def test_parse_click_action_with_extra_field(self):
        """Test parsing click action with extra field."""
        tool = BrowserTool()
        raw_action = {"action": "click", "id": 123, "extra": "should be ignored"}
        
        action = tool._parse_browser_action(raw_action)
        
        assert isinstance(action, ClickAction)
        assert action.id == 123
    
    def test_parse_action_missing_required_field(self):
        """Test that missing required fields raise ValidationError."""
        tool = BrowserTool()
        raw_action = {"action": "click"}  # Missing id
        
        with pytest.raises(ValidationError):
            tool._parse_browser_action(raw_action)


if __name__ == "__main__":
    pytest.main([__file__, "-v"])

========================================
FILE: tests/test_browser_aom.py
========================================

"""
Tests for AOM (Accessibility Object Model) Extractor.

This module tests:
1. URL domain whitelist validation
2. DOM snapshot extraction from example.com
3. Compressed element format generation
4. SecurityViolation raised for non-whitelisted domains
"""

import pytest
import tempfile
import os
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from src.cobalt_agent.tools.aom import AOMExtractor, SecurityViolation, extract_aom, is_url_allowed


class TestDomainWhitelist:
    """Test domain whitelist validation."""
    
    def test_allowed_domain_passes(self):
        """Test that whitelisted domains are accepted."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config:
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com", "test.com"]
            mock_get_config.return_value = mock_config
            
            extractor = AOMExtractor()
            
            # example.com should always be allowed as default
            assert is_url_allowed("https://example.com")
            assert is_url_allowed("http://example.com")
            assert is_url_allowed("https://example.com/page")
    
    def test_malicious_domain_raises_security_violation(self):
        """Test that non-whitelisted domains raise SecurityViolation."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config:
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com", "test.com"]
            mock_get_config.return_value = mock_config
            
            extractor = AOMExtractor()
            
            with pytest.raises(SecurityViolation) as exc_info:
                extractor._validate_url("https://malicious-domain.com")
            
            assert "malicious-domain.com" in str(exc_info.value)
            assert "not in the allowed domains list" in str(exc_info.value)
    
    def test_trailing_path_does_not_affect_whitelist(self):
        """Test that paths don't affect domain whitelist."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config:
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com", "test.com"]
            mock_get_config.return_value = mock_config
            
            extractor = AOMExtractor()
            
            # Should pass - example.com is whitelisted
            result = extractor._validate_url("https://example.com/some/path")
            assert "example.com" in result
    
    def test_port_is_stripped_correctly(self):
        """Test that ports are stripped from domain before validation."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config:
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com", "test.com"]
            mock_get_config.return_value = mock_config
            
            extractor = AOMExtractor()
            
            # Should pass - port is stripped, domain is checked
            result = extractor._validate_url("https://example.com:8080/page")
            assert result == "https://example.com:8080/page"
    
    def test_config_domains_are_loaded(self):
        """Test that config-defined domains are loaded."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config:
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com", "test.com", "mydomain.org"]
            mock_get_config.return_value = mock_config
            
            extractor = AOMExtractor()
            
            # Should include example.com as minimum
            assert len(extractor.allowed_domains) >= 1
            assert "example.com" in extractor.allowed_domains


class TestAOMExtraction:
    """Test AOM extraction functionality."""
    
    def test_extract_returns_list(self):
        """Test that extract returns a list of elements."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            # Mock the browser and page
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            # Create a mock snapshot result
            mock_snapshot = {
                "nodes": [
                    [1, 0, 1, 2, 3, 4],  # Element node
                ],
                "strings": ["html", "body", "onclick", "clickHandler"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            elements = extractor.extract("https://example.com")
            
            assert isinstance(elements, list)
            assert len(elements) > 0
    
    def test_element_has_required_fields(self):
        """Test that each element has required fields."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            # Mock the browser and page
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            # Create a mock snapshot result with proper node structure
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1, 2, 3, 4, 5],  # Element node with attributes
                ],
                "strings": ["html", "body", "role", "button", "aria-label", "Test Button"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            elements = extractor.extract("https://example.com")
            
            for element in elements:
                assert "id" in element
                assert "role" in element
                assert "name" in element
                assert "state" in element
                assert "aria" in element
                assert "value" in element
    
    def test_element_has_numeric_id(self):
        """Test that element IDs are numeric."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1, 2, 3],
                ],
                "strings": ["div", "id", "test"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            elements = extractor.extract("https://example.com")
            
            for element in elements:
                assert isinstance(element["id"], int), f"Expected int, got {type(element['id'])}"
                assert element["id"] >= 0, "ID should be non-negative"
    
    def test_element_has_role(self):
        """Test that elements have accessibility roles."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1],  # Element with no attributes
                ],
                "strings": ["button"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            elements = extractor.extract("https://example.com")
            
            for element in elements:
                assert element["role"] is not None
                assert element["role"] != ""
                assert isinstance(element["role"], str)
    
    def test_state_has_actionable_properties(self):
        """Test that state has enabled, visible, editable."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1, 2, 3, 4, 5],  # Element with attributes
                ],
                "strings": ["button", "role", "button", "aria-label", "Click Me"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            elements = extractor.extract("https://example.com")
            
            for element in elements:
                state = element["state"]
                assert "enabled" in state
                assert "visible" in state
                assert "editable" in state
                assert isinstance(state["enabled"], bool)
                assert isinstance(state["visible"], bool)
    
    def test_aria_is_dict(self):
        """Test that aria attributes are returned as dict."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1, 2, 3, 4, 5],  # Element with ARIA
                ],
                "strings": ["button", "aria-label", "Click Me", "aria-hidden", "false"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            elements = extractor.extract("https://example.com")
            
            for element in elements:
                aria = element["aria"]
                assert isinstance(aria, dict)
    
    def test_value_is_string(self):
        """Test that value is a string."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1, 2, 3, 4, 5],  # Element with value
                ],
                "strings": ["input", "value", "test value"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            elements = extractor.extract("https://example.com")
            
            for element in elements:
                value = element["value"]
                assert isinstance(value, str)


class TestLocalFileExtraction:
    """Test extraction from local HTML files."""
    
    def test_extract_from_local_file(self, tmp_path: Path):
        """Test extracting from a local HTML file."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            # Mock the browser and page
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1],
                ],
                "strings": ["div"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            file_url = "file:///test/test.html"
            elements = extractor.extract(file_url)
            
            assert isinstance(elements, list)
            assert len(elements) > 0
    
    def test_local_file_contains_expected_roles(self, tmp_path: Path):
        """Test that local file extraction has expected roles."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1],  # div
                    [1, 1, -1, 2, 3],  # h1
                ],
                "strings": ["div", "h1", "role", "heading"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            file_url = "file:///test/test.html"
            elements = extractor.extract(file_url)
            
            roles = [e["role"] for e in elements]
            
            # Should contain heading role
            assert "heading" in roles


class TestExtractAOMFunction:
    """Test the convenience extract_aom function."""
    
    def test_extract_aom_function(self):
        """Test extract_aom convenience function."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1],
                ],
                "strings": ["div"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            elements = extract_aom("https://example.com")
            
            assert isinstance(elements, list)
            assert len(elements) > 0
    
    def test_extract_aom_validates_url(self):
        """Test that extract_aom validates URL."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config:
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            with pytest.raises(SecurityViolation):
                extract_aom("https://malicious-domain.com")


class TestEdgeCases:
    """Test edge cases and error handling."""
    
    def test_empty_url_raises_error(self):
        """Test that empty URL raises SecurityViolation."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config:
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            extractor = AOMExtractor()
            
            with pytest.raises(SecurityViolation):
                extractor._validate_url("")
    
    def test_invalid_url_format(self):
        """Test that invalid URL format raises error."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config:
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            extractor = AOMExtractor()
            
            with pytest.raises(SecurityViolation):
                extractor._validate_url("not-a-url")
    
    def test_subdomain_validation(self):
        """Test subdomain validation."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config:
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            extractor = AOMExtractor()
            
            # Subdomain of whitelisted domain should fail
            # (unless explicitly added to whitelist)
            with pytest.raises(SecurityViolation):
                extractor._validate_url("https://sub.example.com")
    
    def test_get_extracted_tree(self):
        """Test getting extracted tree from cache."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1],
                ],
                "strings": ["div"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            
            elements = extractor.extract("https://example.com")
            
            tree = extractor.get_extracted_tree()
            
            assert tree is not None
            assert "url" in tree
            assert "timestamp" in tree
            assert "element_count" in tree
            assert "elements" in tree
            assert tree["element_count"] == len(elements)
    
    def test_clear_cache(self):
        """Test clearing the cache."""
        with patch('src.cobalt_agent.tools.aom.get_config') as mock_get_config, \
             patch('src.cobalt_agent.tools.aom.sync_playwright') as mock_playwright:
            
            mock_config = Mock()
            mock_config.browser = Mock()
            mock_config.browser.allowed_domains = ["example.com"]
            mock_get_config.return_value = mock_config
            
            mock_browser = Mock()
            mock_context = Mock()
            mock_page = Mock()
            mock_cdp_session = Mock()
            
            mock_snapshot = {
                "nodes": [
                    [1, 0, -1],
                ],
                "strings": ["div"]
            }
            
            mock_cdp_session.send.return_value = mock_snapshot
            mock_context.new_cdp_session.return_value = mock_cdp_session
            mock_browser.new_context.return_value = mock_context
            mock_context.new_page.return_value = mock_page
            mock_playwright.return_value.__enter__.return_value.chromium.launch.return_value = mock_browser
            
            extractor = AOMExtractor()
            
            extractor.extract("https://example.com")
            
            extractor.clear_cache()
            
            assert extractor.get_extracted_tree() is None


if __name__ == "__main__":
    pytest.main([__file__, "-v"])

========================================
FILE: tests/test_cortex.py
========================================

"""
Cortex Router Tests
Tests keyword routing (Fast-path vs Orchestrator) and domain classification.
"""
from unittest.mock import patch, MagicMock
import pytest

from cobalt_agent.brain.cortex import Cortex, DomainDecision


class TestCortexRouting:
    """Test suite for Cortex router."""
    
    @pytest.fixture
    def mock_config(self):
        """Create a mock config with departments and cortex_routing rules."""
        mock = MagicMock()
        mock.departments = {
            "TACTICAL": {"active": True, "description": "Trading operations"},
            "INTEL": {"active": True, "description": "Research and news"},
            "OPS": {"active": True, "description": "Operations and Scribe"},
            "ENGINEERING": {"active": True, "description": "Code work"},
            "DEFAULT": {"active": True, "description": "General chat"}
        }
        # Add cortex_routing rules for fast-path keywords
        mock.rules = MagicMock()
        # Make cortex_routing return a simple object with keyword lists
        cortex_routing = MagicMock()
        cortex_routing.orchestrator_keywords = [
            "engineering", "directory", "file", "codebase", "src/", "list the", 
            "research", "summarize", "ops", "read", "write", "search", "prd"
        ]
        cortex_routing.high_risk_keywords = [
            "delete", "move", "remove", "format", "execute", "kill", "reorganize"
        ]
        mock.rules.cortex_routing = cortex_routing
        return mock
    
    @pytest.fixture
    def mock_llm_instance(self, mock_config):
        """Create a mock LLM instance."""
        mock_llm = MagicMock()
        mock_llm.ask_structured.return_value = DomainDecision(
            domain_name="ENGINEERING",
            reasoning="Code work",
            task_parameters="test"
        )
        return mock_llm
    
    @pytest.fixture
    def cortex_instance(self, mock_config, mock_llm_instance):
        """Create a Cortex instance with mocked config and LLM."""
        with patch("cobalt_agent.brain.cortex.load_config", return_value=mock_config):
            with patch("cobalt_agent.brain.cortex.LLM", return_value=mock_llm_instance):
                cortex = Cortex()
                # Store the mock LLM for later use
                cortex._mock_llm = mock_llm_instance
                return cortex
    
    def test_orchestrator_fast_path_engineering_keyword(self, cortex_instance):
        """Test that 'write' keyword triggers Orchestrator fast-path (code work indicator)."""
        # This test verifies the fast-path routing works
        # The input should trigger fast-path, so we check OrchestratorEngine is called
        with patch("cobalt_agent.core.orchestrator.OrchestratorEngine") as mock_orch:
            mock_orch_instance = MagicMock()
            mock_orch_instance.plan_and_execute.return_value = "Orchestrator executed"
            mock_orch.return_value = mock_orch_instance
            
            result = cortex_instance.route("Please write the new module")
            
            # The fast-path should trigger OrchestratorEngine
            mock_orch.assert_called_once()
            mock_orch_instance.plan_and_execute.assert_called_once_with(
                "Please write the new module"
            )
            assert result == "Orchestrator executed"
    
    def test_orchestrator_fast_path_file_keyword(self, cortex_instance):
        """Test that 'file' keyword triggers Orchestrator fast-path."""
        with patch("cobalt_agent.core.orchestrator.OrchestratorEngine") as mock_orch:
            mock_orch_instance = MagicMock()
            mock_orch_instance.plan_and_execute.return_value = "File operation done"
            mock_orch.return_value = mock_orch_instance
            
            result = cortex_instance.route("Write a file in src/")
            
            mock_orch.assert_called_once()
            assert result == "File operation done"
    
    def test_orchestrator_fast_path_directory_keyword(self, cortex_instance):
        """Test that 'directory' keyword triggers Orchestrator fast-path."""
        with patch("cobalt_agent.core.orchestrator.OrchestratorEngine") as mock_orch:
            mock_orch_instance = MagicMock()
            mock_orch_instance.plan_and_execute.return_value = "Directory listing"
            mock_orch.return_value = mock_orch_instance
            
            result = cortex_instance.route("List the contents of the src directory")
            
            mock_orch.assert_called_once()
            assert result == "Directory listing"
    
    def test_orchestrator_fast_path_list_the_keyword(self, cortex_instance):
        """Test that 'list the' keyword triggers Orchestrator fast-path."""
        with patch("cobalt_agent.core.orchestrator.OrchestratorEngine") as mock_orch:
            mock_orch_instance = MagicMock()
            mock_orch_instance.plan_and_execute.return_value = "Listing completed"
            mock_orch.return_value = mock_orch_instance
            
            result = cortex_instance.route("List the files in the directory")
            
            mock_orch.assert_called_once()
            assert result == "Listing completed"
    
    def test_orchestrator_fast_path_codebase_keyword(self, cortex_instance):
        """Test that 'codebase' keyword triggers Orchestrator fast-path."""
        with patch("cobalt_agent.core.orchestrator.OrchestratorEngine") as mock_orch:
            mock_orch_instance = MagicMock()
            mock_orch_instance.plan_and_execute.return_value = "Code analysis"
            mock_orch.return_value = mock_orch_instance
            
            result = cortex_instance.route("Analyze the codebase structure")
            
            mock_orch.assert_called_once()
            assert result == "Code analysis"
    
    def test_web_search_fast_path_http_url(self, cortex_instance):
        """Test that HTTP URL triggers web search fast-path (returns None)."""
        result = cortex_instance.route("Visit https://example.com")
        # Should return None (handled in main chat loop)
        assert result is None
    
    def test_web_search_fast_path_browser_keyword(self, cortex_instance):
        """Test that 'browser' keyword triggers web search fast-path (returns None)."""
        result = cortex_instance.route("Use browser to scrape the page")
        assert result is None
    
    def test_tactical_routing(self, cortex_instance):
        """Test TACTICAL domain routing for trading queries."""
        # Set up the mock LLM to return TACTICAL decision
        cortex_instance._mock_llm.ask_structured.return_value = DomainDecision(
            domain_name="TACTICAL",
            reasoning="Stock price query",
            task_parameters="NVDA"
        )
        
        with patch("cobalt_agent.brain.tactical.Strategos") as mock_strategos:
            mock_dept = MagicMock()
            mock_dept.run.return_value = "NVDA is trading at $123"
            mock_strategos.return_value = mock_dept
            
            result = cortex_instance.route("What is the current price of NVDA?")
            
            # Verify Strategos was instantiated and run was called
            mock_strategos.assert_called_once()
            mock_dept.run.assert_called_once_with("NVDA")
            assert "NVDA" in result
    
    def test_engineering_routing(self, cortex_instance):
        """Test ENGINEERING domain routing for code work."""
        # Set up the mock LLM to return ENGINEERING decision
        cortex_instance._mock_llm.ask_structured.return_value = DomainDecision(
            domain_name="ENGINEERING",
            reasoning="Code work request",
            task_parameters="Review this function"
        )
        
        with patch("cobalt_agent.brain.engineering.EngineeringDepartment") as mock_eng:
            mock_dept = MagicMock()
            mock_dept.run.return_value = "Code reviewed successfully"
            mock_eng.return_value = mock_dept
            
            # Use a query that does NOT trigger fast-path (avoid: write, fix, update, etc.)
            result = cortex_instance.route("Review this Python function for bugs")
            
            mock_eng.assert_called_once()
            mock_dept.run.assert_called_once()
            assert result == "Code reviewed successfully"
    
    def test_ops_routing(self, cortex_instance):
        """Test OPS domain routing for operations tasks."""
        # Set up the mock LLM to return OPS decision
        cortex_instance._mock_llm.ask_structured.return_value = DomainDecision(
            domain_name="OPS",
            reasoning="Scribe task",
            task_parameters="Log this entry"
        )

        with patch("cobalt_agent.skills.productivity.scribe.Scribe") as mock_scribe:
            mock_scribe_instance = MagicMock()
            mock_scribe_instance.append_to_daily_note.return_value = "Entry logged"
            mock_scribe.return_value = mock_scribe_instance
            
            # Use a query that does NOT trigger fast-path (avoid: save, note, etc.)
            result = cortex_instance.route("Log this entry to my journal")

            mock_scribe_instance.append_to_daily_note.assert_called_once()
            assert result == "Entry logged"

    def test_ops_routing_with_save(self, cortex_instance):
        """Test OPS domain routing with save note action."""
        # Set up the mock LLM to return OPS decision
        cortex_instance._mock_llm.ask_structured.return_value = DomainDecision(
            domain_name="OPS",
            reasoning="Scribe task",
            task_parameters="Note content"
        )

        with patch("cobalt_agent.skills.productivity.scribe.Scribe") as mock_scribe:
            mock_scribe_instance = MagicMock()
            mock_scribe_instance.write_note.return_value = "Note saved"
            mock_scribe.return_value = mock_scribe_instance

            # Use a query that does NOT trigger fast-path (avoid: write, file, directory, etc.)
            # and contains "save" to trigger write_note
            result = cortex_instance.route("Save the project notes for later review")

            # The write_note should be called when "save" is in the prompt
            mock_scribe_instance.write_note.assert_called_once()
            assert result == "Note saved"

    def test_ops_routing_with_search(self, cortex_instance):
        """Test OPS domain routing with search action."""
        # Set up the mock LLM to return OPS decision
        cortex_instance._mock_llm.ask_structured.return_value = DomainDecision(
            domain_name="OPS",
            reasoning="Search task",
            task_parameters="medical billing"
        )

        with patch("cobalt_agent.skills.productivity.scribe.Scribe") as mock_scribe:
            mock_scribe_instance = MagicMock()
            mock_scribe_instance.search_vault.return_value = ["Note 1", "Note 2"]
            mock_scribe.return_value = mock_scribe_instance

            # Use a query that contains "find" to trigger search (but NOT trigger fast-path)
            # "find" is in orchestrator_keywords but "find the" should work
            result = cortex_instance.route("Find the vault records for medical billing")

            mock_scribe_instance.search_vault.assert_called_once_with("medical billing")
            assert "Found these notes" in result
    
    def test_default_routing_for_general_queries(self, cortex_instance):
        """Test DEFAULT routing for general conversation."""
        # Set up the mock LLM to return DEFAULT decision
        cortex_instance._mock_llm.ask_structured.return_value = DomainDecision(
            domain_name="DEFAULT",
            reasoning="General chat",
            task_parameters="chat"
        )
        
        result = cortex_instance.route("Hi, how are you today?")
        
        # Should return None (handled in main chat loop)
        assert result is None
    
    def test_intel_routing(self, cortex_instance):
        """Test INTEL domain routing for research queries."""
        # Set up the mock LLM to return INTEL decision
        cortex_instance._mock_llm.ask_structured.return_value = DomainDecision(
            domain_name="INTEL",
            reasoning="Research query",
            task_parameters="Latest AI developments"
        )
        
        with patch("cobalt_agent.skills.research.deep_dive.DeepResearch") as mock_research:
            mock_research_instance = MagicMock()
            mock_research_instance.run.return_value = "Research summary"
            mock_research.return_value = mock_research_instance
            
            result = cortex_instance.route("What are the latest AI developments?")
            
            mock_research.assert_called_once()
            mock_research_instance.run.assert_called_once_with("Latest AI developments")
            assert result == "Research summary"
    
    def test_high_risk_detection(self, cortex_instance):
        """Test that high-risk actions trigger proposal generation."""
        with patch.object(cortex_instance, '_generate_proposal') as mock_proposal:
            mock_proposal.return_value = "Proposal generated"

            # Use a query that does NOT trigger fast-path (avoid: write, execute, reorganize, etc.)
            # and DOES contain high-risk keywords for proposal trigger
            # "move" is a high-risk keyword, but NOT in orchestrator_keywords
            result = cortex_instance.route("Move the database to a new server")

            mock_proposal.assert_called_once()
            assert "Proposal" in result or "BLOCKED" in result
    
    def test_classification_error_handling(self, cortex_instance):
        """Test fallback when classification fails."""
        # Make the LLM raise an exception
        cortex_instance._mock_llm.ask_structured.side_effect = Exception("Classification failed")
        
        # Use a query that does NOT trigger fast-path
        # Avoid: engineering, file, directory, codebase, list the, research, read, write, search, prd
        # Avoid: http://, https://, browser, scrape, search, summarize the top
        result = cortex_instance.route("Analyze the market structure")
        
        # Should fallback to FOUNDATION domain when classification fails, which returns None
        assert result is None


========================================
FILE: tests/test_llm.py
========================================

"""
LLM Tests
Tests for the LLM (Language Model) class with proper mocking of external API calls.
"""
from unittest.mock import patch, MagicMock
import pytest

from cobalt_agent.llm import LLM


class TestLLM:
    """Test suite for LLM class."""
    
    @pytest.fixture
    def mock_config(self):
        """Mock configuration to return test data."""
        config = MagicMock()
        config.active_profile = {
            "default": "test-model"
        }
        config.models = {
            "test-model": {
                "provider": "openai",
                "model_name": "gpt-4",
                "env_key_ref": "OPENAI_API_KEY"
            }
        }
        config.network = MagicMock(nodes={})
        config.model_dump.return_value = {
            "keys": {
                "OPENAI_API_KEY": "TEST_API_KEY"
            }
        }
        return config
    
    def test_llm_initialization_with_default_role(self, mock_config):
        """Test LLM initialization with default role."""
        with patch("cobalt_agent.config.load_config") as mock_load:
            mock_load.return_value = mock_config
            
            llm = LLM(role="default")
            
            assert llm.role == "default"
            assert llm.model_name == "openai/gpt-4"
    
    def test_llm_initialization_with_custom_role(self, mock_config):
        """Test LLM initialization with a custom role."""
        mock_config.active_profile = {
            "custom_role": "custom-model"
        }
        mock_config.models = {
            "custom-model": {
                "provider": "anthropic",
                "model_name": "claude-3",
                "env_key_ref": "ANTHROPIC_API_KEY"
            }
        }
        
        with patch("cobalt_agent.config.load_config") as mock_load:
            mock_load.return_value = mock_config
            
            llm = LLM(role="custom_role")
            
            assert llm.role == "custom_role"
            assert llm.model_name == "anthropic/claude-3"
    
    def test_switch_role_updates_model(self, mock_config):
        """Test that switch_role properly updates the model."""
        with patch("cobalt_agent.config.load_config") as mock_load:
            mock_load.return_value = mock_config
            
            llm = LLM(role="default")
            initial_model = llm.model_name
            
            mock_config.active_profile = {
                "default": "test-model",
                "strategist": "strategist-model"
            }
            mock_config.models = {
                "test-model": {
                    "provider": "openai",
                    "model_name": "gpt-4"
                },
                "strategist-model": {
                    "provider": "anthropic",
                    "model_name": "claude-3"
                }
            }
            
            llm.switch_role("strategist")
            
            assert llm.role == "strategist"
            assert llm.model_name == "anthropic/claude-3"
    
    def test_generate_response_calls_completion(self, mock_config):
        """Test that generate_response properly calls the LLM provider."""
        with patch("cobalt_agent.config.load_config") as mock_load:
            mock_load.return_value = mock_config
            
            llm = LLM(role="default")
            
            with patch("cobalt_agent.llm.completion") as mock_completion:
                mock_response = MagicMock()
                mock_response.choices = [MagicMock()]
                mock_response.choices[0].message = MagicMock()
                mock_response.choices[0].message.content = "Test response"
                mock_completion.return_value = mock_response
                
                result = llm.generate_response(
                    system_prompt="You are a helpful assistant",
                    user_input="Hello"
                )
                
                assert result == "Test response"
                mock_completion.assert_called_once()
    
    def test_ask_method_calls_completion(self, mock_config):
        """Test that ask method calls completion with proper messages."""
        with patch("cobalt_agent.config.load_config") as mock_load:
            mock_load.return_value = mock_config
            
            llm = LLM(role="default")
            
            with patch("cobalt_agent.llm.completion") as mock_completion:
                mock_response = MagicMock()
                mock_response.choices = [MagicMock()]
                mock_response.choices[0].message = MagicMock()
                mock_response.choices[0].message.content = "Direct answer"
                mock_completion.return_value = mock_response
                
                result = llm.ask("System prompt", "User input")
                
                assert result == "Direct answer"
                
                # Verify the messages were passed correctly
                call_kwargs = mock_completion.call_args[1]
                messages = call_kwargs["messages"]
                assert messages[0]["role"] == "system"
                assert messages[0]["content"] == "System prompt"
                assert messages[1]["role"] == "user"
                assert messages[1]["content"] == "User input"
    
    def test_ask_structured_returns_pydantic_model(self, mock_config):
        """Test that ask_structured returns a validated Pydantic model."""
        from pydantic import BaseModel, Field
        
        class TestModel(BaseModel):
            name: str
            value: int
        
        with patch("cobalt_agent.config.load_config") as mock_load:
            mock_load.return_value = mock_config
            
            llm = LLM(role="default")
            
            with patch("cobalt_agent.llm.completion") as mock_completion:
                mock_response = MagicMock()
                mock_response.choices = [MagicMock()]
                mock_response.choices[0].message = MagicMock()
                # Return raw JSON as the LLM would
                mock_response.choices[0].message.content = '{"name": "test", "value": 42}'
                mock_completion.return_value = mock_response
                
                result = llm.ask_structured("Test prompt", TestModel)
                
                assert isinstance(result, TestModel)
                assert result.name == "test"
                assert result.value == 42
    
    def test_llm_api_base_resolved_for_local_model(self):
        """Test that API base is correctly resolved for local models."""
        config = MagicMock()
        config.active_profile = {
            "local-model": "local-model"
        }
        config.models = {
            "local-model": {
                "provider": "ollama",
                "model_name": "llama2",
                "node_ref": "local-node"
            }
        }
        config.network.nodes = {
            "local-node": {
                "ip": "192.168.1.100",
                "port": 11434,
                "protocol": "http"
            }
        }
        config.model_dump.return_value = {
            "keys": {}
        }
        
        with patch("cobalt_agent.config.load_config") as mock_load:
            mock_load.return_value = config
            
            llm = LLM(role="local-model")
            
            assert llm._api_base == "http://192.168.1.100:11434"
    
    def test_llm_no_api_base_for_cloud_model(self, mock_config):
        """Test that API base is None for cloud models."""
        with patch("cobalt_agent.config.load_config") as mock_load:
            mock_load.return_value = mock_config
            
            llm = LLM(role="default")
            
            assert llm._api_base is None

========================================
FILE: tests/test_orchestrator.py
========================================

"""
Orchestrator Engine Tests
Tests the OrchestratorEngine with mocked LLM returns for plan generation and Drone execution.
"""
from unittest.mock import patch, MagicMock, PropertyMock
import pytest
from pydantic import BaseModel, Field
from typing import List

from cobalt_agent.core.orchestrator import OrchestratorEngine, SubTask, OrchestrationState


# Note: These are test-specific models, not prefixed with 'Test' to avoid pytest collection warnings
class MockSubTask(BaseModel):
    """Test SubTask model with different assigned drones."""
    step_number: int
    assigned_drone: str
    action: str
    tool_to_use: str
    status: str = "PENDING"
    observation: str = ""


class MockOrchestrationState(BaseModel):
    """Test state with mock data."""
    scratchpad: str
    original_request: str
    master_plan: List[MockSubTask]
    current_step: int = 1
    status: str = "PLANNING"


class TestOrchestratorEngineClass:
    """Test suite for OrchestratorEngine."""
    
    @pytest.fixture
    def mock_orchestrator(self):
        """Create an OrchestratorEngine instance."""
        return OrchestratorEngine()
    
    @pytest.fixture
    def mock_plan_state(self):
        """Create a mock OrchestrationState with valid plan."""
        return OrchestrationState(
            scratchpad="I will analyze the request and break it down into steps.",
            original_request="Create a test file",
            master_plan=[
                SubTask(
                    step_number=1,
                    assigned_drone="ENGINEERING",
                    action="Create test file",
                    tool_to_use="write_file",
                    status="PENDING"
                )
            ],
            current_step=1,
            status="PLANNING"
        )
    
    @patch("cobalt_agent.core.orchestrator.LLM")
    def test_plan_and_execute_creates_plan(self, mock_llm_class, mock_plan_state):
        """Test that plan_and_execute generates a valid plan."""
        # Configure the mock LLM to return our mock state
        mock_llm_instance = MagicMock()
        mock_llm_instance.ask_structured.return_value = mock_plan_state
        mock_llm_class.return_value = mock_llm_instance
        
        orchestrator = OrchestratorEngine()
        
        result = orchestrator.plan_and_execute("Create a test file")
        
        # Verify LLM was called with structured interface
        mock_llm_instance.ask_structured.assert_called_once()
        call_kwargs = mock_llm_instance.ask_structured.call_args[1]
        assert call_kwargs["response_model"] == OrchestrationState
        assert "ARCHITECT" in call_kwargs["system_prompt"].upper()
    
    @patch("cobalt_agent.core.orchestrator.LLM")
    @patch("cobalt_agent.brain.engineering.EngineeringDepartment")
    def test_plan_and_execute_creates_engineering_drone(self, mock_eng_class, mock_llm_class, mock_plan_state):
        """Test that ENGINEERING drone is instantiated for ENGINEERING tasks."""
        # Configure the mock LLM to return our mock state
        mock_llm_instance = MagicMock()
        mock_llm_instance.ask_structured.return_value = mock_plan_state
        mock_llm_class.return_value = mock_llm_instance
        
        # Configure the Engineering drone mock
        mock_drone_instance = MagicMock()
        mock_drone_instance.run.return_value = "File created successfully"
        mock_eng_class.return_value = mock_drone_instance
        
        orchestrator = OrchestratorEngine()
        result = orchestrator.plan_and_execute("Write Python code")
        
        # Verify Engineering drone was instantiated
        mock_eng_class.assert_called_once()
    
    @patch("cobalt_agent.core.orchestrator.LLM")
    @patch("cobalt_agent.brain.ops.OpsDepartment")
    def test_plan_and_execute_creates_ops_drone(self, mock_ops_class, mock_llm_class):
        """Test that OPS drone is instantiated for OPS tasks."""
        # Create a plan with OPS assigned
        ops_state = OrchestrationState(
            scratchpad="I will search and summarize.",
            original_request="Find information",
            master_plan=[
                SubTask(
                    step_number=1,
                    assigned_drone="OPS",
                    action="Search knowledge base",
                    tool_to_use="search_knowledge",
                    status="PENDING"
                )
            ],
            current_step=1,
            status="PLANNING"
        )
        
        # Configure the mock LLM
        mock_llm_instance = MagicMock()
        mock_llm_instance.ask_structured.return_value = ops_state
        mock_llm_class.return_value = mock_llm_instance
        
        # Configure the OPS drone mock
        mock_drone_instance = MagicMock()
        mock_drone_instance.run.return_value = "Information found"
        mock_ops_class.return_value = mock_drone_instance
        
        orchestrator = OrchestratorEngine()
        result = orchestrator.plan_and_execute("Find information")
        
        # Verify Ops drone was instantiated
        mock_ops_class.assert_called_once()
    
    @patch("cobalt_agent.core.orchestrator.LLM")
    def test_plan_and_execute_handles_empty_plan(self, mock_llm_class):
        """Test that empty plans are handled with a failsafe error."""
        # Configure the mock LLM to raise exception (simulating empty plan handling)
        mock_llm_instance = MagicMock()
        mock_llm_instance.ask_structured.side_effect = Exception("Parsing failed - empty plan")
        mock_llm_class.return_value = mock_llm_instance
        
        orchestrator = OrchestratorEngine()
        result = orchestrator.plan_and_execute("Test request")
        
        # Verify error message for empty plan
        assert "Architect Error" in result
        assert "failed to generate a valid plan" in result.lower()
    
    @patch("cobalt_agent.core.orchestrator.LLM")
    def test_plan_and_execute_executes_all_steps(self, mock_llm_class, mock_plan_state):
        """Test that all steps in the plan are executed."""
        # Create a plan with multiple steps
        multi_step_state = OrchestrationState(
            scratchpad="Execute multiple steps.",
            original_request="Complete multi-step task",
            master_plan=[
                SubTask(
                    step_number=1,
                    assigned_drone="ENGINEERING",
                    action="Step 1",
                    tool_to_use="read_file",
                    status="PENDING",
                    observation=""
                ),
                SubTask(
                    step_number=2,
                    assigned_drone="OPS",
                    action="Step 2",
                    tool_to_use="write_file",
                    status="PENDING",
                    observation=""
                ),
                SubTask(
                    step_number=3,
                    assigned_drone="ENGINEERING",
                    action="Step 3",
                    tool_to_use="list_directory",
                    status="PENDING",
                    observation=""
                )
            ],
            current_step=1,
            status="PLANNING"
        )
        
        mock_llm_instance = MagicMock()
        mock_llm_instance.ask_structured.return_value = multi_step_state
        mock_llm_class.return_value = mock_llm_instance
        
        orchestrator = OrchestratorEngine()
        result = orchestrator.plan_and_execute("Multi-step task")
        
        # Verify execution output contains all steps
        assert "Step 1" in result
        assert "Step 2" in result
        assert "Step 3" in result
    
    @patch("cobalt_agent.core.orchestrator.LLM")
    @patch("cobalt_agent.brain.engineering.EngineeringDepartment")
    def test_plan_and_execute_stops_on_error(self, mock_eng_class, mock_llm_class):
        """Test that execution stops when a step fails."""
        error_state = OrchestrationState(
            scratchpad="Stop on error.",
            original_request="Error task",
            master_plan=[
                SubTask(
                    step_number=1,
                    assigned_drone="ENGINEERING",
                    action="Working step",
                    tool_to_use="read_file",
                    status="PENDING",
                    observation=""
                ),
                SubTask(
                    step_number=2,
                    assigned_drone="ENGINEERING",
                    action="Should not execute",
                    tool_to_use="write_file",
                    status="PENDING",
                    observation=""
                )
            ],
            current_step=1,
            status="PLANNING"
        )
        
        mock_llm_instance = MagicMock()
        mock_llm_instance.ask_structured.return_value = error_state
        mock_llm_class.return_value = mock_llm_instance
        
        # Make first step return error
        mock_drone_instance = MagicMock()
        mock_drone_instance.run.return_value = "Error: Something went wrong"
        mock_eng_class.return_value = mock_drone_instance
        
        orchestrator = OrchestratorEngine()
        result = orchestrator.plan_and_execute("Error task")
        
        # Verify error handling - check for error indicator in output
        assert "Error:" in result
        # Verify execution stopped (check for failure message in output)
        assert "Halting execution" in result
    
    @patch("cobalt_agent.core.orchestrator.LLM")
    @patch("cobalt_agent.brain.engineering.EngineeringDepartment")
    def test_plan_and_execute_handles_zero_trust_pause(self, mock_eng_class, mock_llm_class):
        """Test that Zero-Trust pause is handled correctly."""
        pause_state = OrchestrationState(
            scratchpad="Pause for approval.",
            original_request="Pause task",
            master_plan=[
                SubTask(
                    step_number=1,
                    assigned_drone="ENGINEERING",
                    action="Pause step",
                    tool_to_use="write_file",
                    status="PENDING",
                    observation=""
                )
            ],
            current_step=1,
            status="PLANNING"
        )
        
        mock_llm_instance = MagicMock()
        mock_llm_instance.ask_structured.return_value = pause_state
        mock_llm_class.return_value = mock_llm_instance
        
        mock_drone_instance = MagicMock()
        mock_drone_instance.run.return_value = "Action paused. Proposal sent"
        mock_eng_class.return_value = mock_drone_instance
        
        orchestrator = OrchestratorEngine()
        result = orchestrator.plan_and_execute("Pause task")
        
        # Verify Zero-Trust pause message
        assert "Action paused" in result
        assert "HUMAN-IN-THE-LOOP APPROVAL" in result.upper()

========================================
FILE: tests/test_scheduler.py
========================================

"""
Scheduler Tests
Tests that the APScheduler registers cron jobs correctly.
"""
import pytest
from unittest.mock import patch, MagicMock, call
from datetime import datetime, time


class TestCobaltScheduler:
    """Test suite for CobaltScheduler."""
    
    @patch("cobalt_agent.services.scheduler.BackgroundScheduler")
    @patch("cobalt_agent.services.scheduler.get_config")
    def test_scheduler_registers_morning_briefing_job(self, mock_get_config, mock_scheduler_class):
        """Test that Morning Briefing job is registered with correct cron schedule."""
        # Mock the config
        mock_config = MagicMock()
        mock_config.system.obsidian_vault_path = "/test/vault"
        mock_get_config.return_value = mock_config
        
        # Mock the scheduler
        mock_scheduler = MagicMock()
        mock_scheduler_class.return_value = mock_scheduler
        
        # Import and instantiate scheduler
        from cobalt_agent.services.scheduler import CobaltScheduler
        
        scheduler = CobaltScheduler()
        
        # Verify scheduler was created
        mock_scheduler_class.assert_called_once()
        
        # Verify the job was added with correct parameters
        mock_scheduler.add_job.assert_called_once()
        
        # Get the call arguments - call_args is (args, kwargs) tuple
        call_args = mock_scheduler.add_job.call_args
        args = call_args[0]
        kwargs = call_args[1] if len(call_args) > 1 else {}
        
        # First positional arg should be the function
        assert args[0] == scheduler.generate_morning_briefing
        # Second positional arg is the trigger type
        assert args[1] == "cron"
        assert kwargs.get("day_of_week") == "mon-fri"
        assert kwargs.get("hour") == 8
        assert kwargs.get("minute") == 0
        assert kwargs.get("id") == "morning_briefing"
        assert kwargs.get("replace_existing") is True
    
    @patch("cobalt_agent.services.scheduler.BackgroundScheduler")
    @patch("cobalt_agent.services.scheduler.get_config")
    def test_scheduler_start_method(self, mock_get_config, mock_scheduler_class):
        """Test that start() method starts the scheduler."""
        # Mock the config
        mock_config = MagicMock()
        mock_config.system.obsidian_vault_path = "/test/vault"
        mock_get_config.return_value = mock_config
        
        # Mock the scheduler
        mock_scheduler = MagicMock()
        mock_scheduler_class.return_value = mock_scheduler
        
        from cobalt_agent.services.scheduler import CobaltScheduler
        
        scheduler = CobaltScheduler()
        scheduler.start()
        
        # Verify scheduler.start() was called
        mock_scheduler.start.assert_called_once()
    
    @patch("cobalt_agent.services.scheduler.BackgroundScheduler")
    @patch("cobalt_agent.services.scheduler.get_config")
    def test_scheduler_shutdown_method(self, mock_get_config, mock_scheduler_class):
        """Test that shutdown() method shuts down the scheduler."""
        # Mock the config
        mock_config = MagicMock()
        mock_config.system.obsidian_vault_path = "/test/vault"
        mock_get_config.return_value = mock_config
        
        # Mock the scheduler
        mock_scheduler = MagicMock()
        mock_scheduler_class.return_value = mock_scheduler
        
        from cobalt_agent.services.scheduler import CobaltScheduler
        
        scheduler = CobaltScheduler()
        scheduler.shutdown()
        
        # Verify scheduler.shutdown() was called
        mock_scheduler.shutdown.assert_called_once()
    
    @patch("cobalt_agent.services.scheduler.BackgroundScheduler")
    @patch("cobalt_agent.services.scheduler.get_config")
    @patch("cobalt_agent.services.scheduler.LLM")
    @patch("cobalt_agent.services.scheduler.os")
    @patch("cobalt_agent.services.scheduler.open", create=True)
    def test_generate_morning_briefing(self, mock_open, mock_os, mock_llm_class, mock_get_config, mock_scheduler_class):
        """Test that generate_morning_briefing generates and saves the briefing."""
        # Mock the config
        mock_config = MagicMock()
        mock_config.system.obsidian_vault_path = "/test/vault"
        mock_get_config.return_value = mock_config
        
        # Mock the scheduler
        mock_scheduler = MagicMock()
        mock_scheduler_class.return_value = mock_scheduler
        
        # Mock the LLM
        mock_llm_instance = MagicMock()
        mock_llm_instance.ask.return_value = "Market Analysis\n\nSummary: Buy stocks"
        mock_llm_class.return_value = mock_llm_instance
        
        from cobalt_agent.services.scheduler import CobaltScheduler
        
        scheduler = CobaltScheduler()
        scheduler.generate_morning_briefing()
        
        # Verify LLM was called
        mock_llm_instance.ask.assert_called_once()
        
        # Verify os.makedirs was called to create directory
        mock_os.makedirs.assert_called_once()
        
        # Verify file was opened for writing
        mock_open.assert_called_once()
        
        # Verify write was called
        write_call = mock_open.return_value.__enter__.return_value.write
        write_call.assert_called_once()
    
    @patch("cobalt_agent.services.scheduler.BackgroundScheduler")
    @patch("cobalt_agent.services.scheduler.get_config")
    def test_scheduler_has_correct_job_count(self, mock_get_config, mock_scheduler_class):
        """Test that scheduler has exactly one job registered."""
        # Mock the config
        mock_config = MagicMock()
        mock_config.system.obsidian_vault_path = "/test/vault"
        mock_get_config.return_value = mock_config
        
        # Mock the scheduler
        mock_scheduler = MagicMock()
        mock_scheduler_class.return_value = mock_scheduler
        
        from cobalt_agent.services.scheduler import CobaltScheduler
        
        scheduler = CobaltScheduler()
        
        # Only one job should be registered (morning_briefing)
        mock_scheduler.add_job.assert_called_once()
    
    @patch("cobalt_agent.services.scheduler.BackgroundScheduler")
    @patch("cobalt_agent.services.scheduler.get_config")
    def test_scheduler_replaces_existing_job(self, mock_get_config, mock_scheduler_class):
        """Test that jobs are set to replace_existing=True."""
        # Mock the config
        mock_config = MagicMock()
        mock_config.system.obsidian_vault_path = "/test/vault"
        mock_get_config.return_value = mock_config
        
        # Mock the scheduler
        mock_scheduler = MagicMock()
        mock_scheduler_class.return_value = mock_scheduler
        
        from cobalt_agent.services.scheduler import CobaltScheduler
        
        scheduler = CobaltScheduler()
        
        # Get the call arguments
        call_kwargs = mock_scheduler.add_job.call_args[1]
        
        # Verify replace_existing is True
        assert call_kwargs["replace_existing"] is True

========================================
FILE: tests/test_scribe.py
========================================

"""
Scribe Skill Tests
Verifies that notes are written to the correct location using environment variables.
"""
import os
import pytest
from cobalt_agent.skills.productivity.scribe import Scribe

def test_scribe_initialization(tmp_path):
    """Test if Scribe accepts a direct path."""
    scribe = Scribe(vault_path=str(tmp_path))
    assert scribe.vault_path == tmp_path

def test_scribe_env_var_fallback(monkeypatch, tmp_path):
    """
    Test if Scribe falls back to the Environment Variable if no path is given.
    """
    monkeypatch.setenv("OBSIDIAN_VAULT_PATH", str(tmp_path))
    scribe = Scribe()
    assert scribe.vault_path == tmp_path

def test_write_note(tmp_path):
    """Test actually writing a file to a fake vault."""
    scribe = Scribe(vault_path=str(tmp_path))
    
    filename = "test_note"
    content = "# Hello World"
    folder = "0 - Inbox"
    
    result = scribe.write_note(filename, content, folder)
    
    expected_file = tmp_path / folder / "test_note.md"
    assert expected_file.exists()
    assert expected_file.read_text(encoding="utf-8") == content
    assert "‚úÖ Note saved" in result

========================================
FILE: tests/test_strategies.py
========================================

"""
Strategy Test Suite
Verifies that trading logic respects the configuration rules.
"""
import pytest
from cobalt_agent.brain.strategies.second_day_play import SecondDayPlay

# --- FIXTURES (Reusable Data) ---

@pytest.fixture
def mock_config():
    """Simulates the data from strategies.yaml"""
    return {
        "name": "Second Day Play",
        "parameters": {
            "min_rvol": 1.5,
            "gap_percentage": 2.0
        },
        "scoring": {
            "base_score": 50,
            "high_rvol_threshold": 3.0,
            "high_rvol_points": 20, # Custom value for test to verify logic
            "base_rvol_points": 10,
            "gap_up_points": 5
        }
    }

@pytest.fixture
def mock_nvda_data():
    """A perfect setup: High Volume, Gap Up."""
    return {
        "yesterday_close": 140.00,
        "yesterday_volume": 50_000_000,
        "average_volume": 10_000_000, # RVOL = 5.0 (High)
        "today_open": 141.50,         # Gap Up
        "pre_market_high": 142.00
    }

@pytest.fixture
def mock_weak_data():
    """A failed setup: Low Volume."""
    return {
        "yesterday_close": 50.00,
        "yesterday_volume": 1_200_000,
        "average_volume": 1_000_000,  # RVOL = 1.2 (Fail)
        "today_open": 50.50,
        "pre_market_high": 51.00
    }

# --- TESTS ---

def test_second_day_play_initialization(mock_config):
    """Does the strategy load the config correctly?"""
    strategy = SecondDayPlay(mock_config)
    assert strategy.params["min_rvol"] == 1.5
    assert strategy.scoring["high_rvol_points"] == 20

def test_valid_setup_scoring(mock_config, mock_nvda_data):
    """
    Test Math:
    Base (50) + High RVOL (20) + Gap Up (5) = 75
    """
    strategy = SecondDayPlay(mock_config)
    result = strategy.analyze("NVDA", mock_nvda_data)
    
    assert result["status"] == "ACTIVE_WATCH"
    assert result["scoring_engine"]["base_score"] == 75
    assert result["zones"]["entry"] == 142.05

def test_rejection_logic(mock_config, mock_weak_data):
    """Ensure weak stocks are rejected."""
    strategy = SecondDayPlay(mock_config)
    result = strategy.analyze("WEAK", mock_weak_data)
    
    assert result["status"] == "REJECTED"
    assert "Low Relative Volume" in result["reason"]

========================================
FILE: tests/test_vault.py
========================================

"""
Vault Manager Tests
Tests AES-256 encryption, decryption, and locking functionality.
"""
import os
import json
import tempfile
import pytest
from pathlib import Path

from cobalt_agent.security.vault import VaultManager


@pytest.fixture
def temp_vault_path():
    """Create a temporary vault file path for testing (file doesn't exist initially)."""
    with tempfile.NamedTemporaryFile(suffix='.vault', delete=False) as f:
        path = f.name
    
    # Delete the file so it doesn't exist when tests run
    Path(path).unlink(missing_ok=True)
    
    yield path
    
    # Cleanup after test
    Path(path).unlink(missing_ok=True)


@pytest.fixture
def vault_manager(temp_vault_path):
    """Create a VaultManager instance."""
    return VaultManager(temp_vault_path)


@pytest.fixture
def master_key():
    """Generate a valid Fernet key for testing."""
    from cryptography.fernet import Fernet
    return Fernet.generate_key().decode()


class TestVaultManager:
    """Test suite for VaultManager."""
    
    def test_generate_master_key(self, vault_manager):
        """Test that generate_master_key produces a valid Fernet key."""
        key = vault_manager.generate_master_key()
        # Verify it's a valid Fernet key format (base64 encoded)
        assert isinstance(key, str)
        assert len(key) == 44  # Base64 encoded 32-byte key
    
    def test_unlock_empty_vault(self, vault_manager, master_key):
        """Test unlocking a non-existent vault creates an empty vault."""
        result = vault_manager.unlock(master_key)
        assert result is True
        assert vault_manager._is_unlocked is True
        assert vault_manager._secrets == {}
    
    def test_unlock_existing_vault(self, vault_manager, master_key, temp_vault_path):
        """Test unlocking an existing encrypted vault."""
        # First unlock to create the vault
        vault_manager.unlock(master_key)
        
        # Add a secret
        vault_manager.set_secret(master_key, "test_key", "test_value")
        
        # Lock the vault
        vault_manager.lock()
        assert vault_manager._is_unlocked is False
        
        # Create new vault manager instance
        new_vault = VaultManager(temp_vault_path)
        
        # Unlock with same key
        result = new_vault.unlock(master_key)
        assert result is True
        assert new_vault._is_unlocked is True
        assert new_vault.get_secret("test_key") == "test_value"
    
    def test_unlock_with_invalid_key(self, vault_manager, temp_vault_path, master_key):
        """Test that unlocking with an invalid key fails."""
        # Create vault with valid key
        vault_manager.unlock(master_key)
        vault_manager.set_secret(master_key, "test_key", "test_value")
        vault_manager.lock()
        
        # Try to unlock with invalid key
        invalid_key = "invalid_key_that_will_not_work"
        result = vault_manager.unlock(invalid_key)
        assert result is False
        assert vault_manager._is_unlocked is False
    
    def test_set_and_get_secret(self, vault_manager, master_key):
        """Test setting and retrieving a secret."""
        vault_manager.unlock(master_key)
        
        result = vault_manager.set_secret(master_key, "api_key", "secret123")
        assert result is True
        
        secret = vault_manager.get_secret("api_key")
        assert secret == "secret123"
    
    def test_get_secret_from_locked_vault(self, vault_manager, master_key):
        """Test that getting a secret from locked vault returns None."""
        vault_manager.unlock(master_key)
        vault_manager.set_secret(master_key, "api_key", "secret123")
        vault_manager.lock()
        
        secret = vault_manager.get_secret("api_key")
        assert secret is None
    
    def test_list_secrets(self, vault_manager, master_key):
        """Test listing all secret keys."""
        vault_manager.unlock(master_key)
        
        vault_manager.set_secret(master_key, "key1", "value1")
        vault_manager.set_secret(master_key, "key2", "value2")
        vault_manager.set_secret(master_key, "key3", "value3")
        
        secrets = vault_manager.list_secrets()
        assert "key1" in secrets
        assert "key2" in secrets
        assert "key3" in secrets
        assert len(secrets) == 3
    
    def test_list_secrets_from_locked_vault(self, vault_manager, master_key):
        """Test that listing secrets from locked vault returns empty list."""
        vault_manager.unlock(master_key)
        vault_manager.set_secret(master_key, "key1", "value1")
        vault_manager.lock()
        
        secrets = vault_manager.list_secrets()
        assert secrets == []
    
    def test_delete_secret(self, vault_manager, master_key):
        """Test deleting a secret."""
        vault_manager.unlock(master_key)
        
        vault_manager.set_secret(master_key, "key_to_delete", "value123")
        assert vault_manager.get_secret("key_to_delete") == "value123"
        
        result = vault_manager.delete_secret(master_key, "key_to_delete")
        assert result is True
        assert vault_manager.get_secret("key_to_delete") is None
    
    def test_delete_secret_from_locked_vault(self, vault_manager, master_key):
        """Test that deleting from locked vault fails."""
        vault_manager.unlock(master_key)
        vault_manager.set_secret(master_key, "key1", "value1")
        vault_manager.lock()
        
        result = vault_manager.delete_secret(master_key, "key1")
        assert result is False
    
    def test_lock_wipes_secrets(self, vault_manager, master_key):
        """Test that lock() properly wipes secrets from memory."""
        vault_manager.unlock(master_key)
        vault_manager.set_secret(master_key, "key1", "value1")
        vault_manager.set_secret(master_key, "key2", "value2")
        
        # Verify secrets are in memory
        assert vault_manager.get_secret("key1") == "value1"
        assert vault_manager.get_secret("key2") == "value2"
        
        # Lock the vault
        vault_manager.lock()
        
        # Verify secrets are cleared
        assert vault_manager.get_secret("key1") is None
        assert vault_manager.get_secret("key2") is None
        assert vault_manager._is_unlocked is False
    
    def test_persistence_across_instances(self, vault_manager, master_key, temp_vault_path):
        """Test that secrets persist to disk and can be loaded by new instance."""
        vault_manager.unlock(master_key)
        vault_manager.set_secret(master_key, "persist_key", "persist_value")
        vault_manager.lock()
        
        # Create new instance pointing to same vault
        new_vault = VaultManager(temp_vault_path)
        new_vault.unlock(master_key)
        
        assert new_vault.get_secret("persist_key") == "persist_value"
    
    def test_set_secret_while_locked(self, vault_manager, master_key):
        """Test that setting a secret while locked fails."""
        vault_manager.unlock(master_key)
        vault_manager.lock()
        
        result = vault_manager.set_secret(master_key, "new_key", "new_value")
        assert result is False
        assert vault_manager.get_secret("new_key") is None