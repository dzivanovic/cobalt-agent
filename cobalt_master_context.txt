PROJECT DIRECTORY STRUCTURE
================================================================================

cobalt/
configs/
    config.yaml
    rules.yaml
    strategies.yaml
data/
    postgres/
        base/
            1/
            16384/
            4/
            5/
        global/
        pg_commit_ts/
        pg_dynshmem/
        pg_logical/
            mappings/
            snapshots/
        pg_multixact/
            members/
            offsets/
        pg_notify/
        pg_replslot/
        pg_serial/
        pg_snapshots/
        pg_stat/
        pg_stat_tmp/
        pg_subtrans/
        pg_tblspc/
        pg_twophase/
        pg_wal/
            archive_status/
        pg_xact/
dev_utils/
    brain_scan.py
    create_missing_tasks.py
    create_prd.py
    generate_constitution.py
    generate_context.py
    manage_vault.py
    reset_memory_table.py
    update_board.py
    wipe_memory.py
docs/
    0 - Inbox/
        Briefing_2026-02-24.md
        Briefing_2026-02-25.md
    0 - Projects/
        Cobalt/
            00 - Master Plan/
                ADR/
                    ADR-001 Hybrid Compute Strategy.md
                    ADR-002 Cobalt-Ion Distributed Protocol.md
                    ADR-003 Python-First Architecture.md
                    ADR-004 Zero Trust Security.md
                    ADR-005 Agentic RAG.md
                    ADR-006 Prime Directive and HITL.md
                    ADR-007 HITL Proposal Engine.md
                    ADR-008 JIT Secrets Vault.md
                    ADR-009 Headless Browser Strategy.md
                Developer Docs/
                    brain_scan.md
                    browser.md
                    cli.md
                    config.md
                    cortex.md
                    create_missing_tasks.md
                    create_prd.md
                    finance.md
                    generate_constitution.md
                    generate_context.md
                    llm.md
                    main.md
                    mattermost.md
                    memory_base.md
                    memory_core.md
                    playbook.md
                    postgres.md
                    prompt.md
                    proposals.md
                    reset_memory_table.md
                    search.md
                    second_day_play.md
                    strategy.md
                    tactical.md
                    tool_manager.md
                    update_board.md
                    vault.md
                    wipe_memory.md
                ARCHITECTURE_ASSESSMENT.md
            90 - Project Management/
                Requirements/
                    PRD-001 Cobalt-Ion Tactical HUD.md
                    PRD-002 Mattermost HITL Proposal Engine.md
                    PRD-003 Zero Trust Docker Sandbox.md
                    PRD-004 Cortex LLM Switchboard Router.md
                    PRD-005 Voice Architecture.md
                    PRD-006 Dynamic Browser Automation.md
                User Stories/
                    Story-001_Initial_Brainstorm.md
            Tasks/
                01 System Prep.md
                02 Architecture Setup.md
                03 Dependency Management.md
                04 Verification.md
                05 Hello World.md
                06 Core Config.md
                07 Memory System.md
                08 Persona Logic.md
                09 Interface Layer.md
                10 Tool Manager.md
                11 Prompt Engine.md
                12 Browser Capabilities.md
                13 Trading Engine.md
                14 Autonomous Loop.md
                15 Memory Interface.md
                16 Postgres Adapter.md
                17 Cortex Dispatcher.md
                18 Scribe Skill (Obsidian).md
                19 Scheduler & Cron.md
                20 Multi-Agent Orchestration.md
                21 (Morning Briefing).md
                22 Mac Studio Deployment.md
                23 Strategos Agent Setup.md
                24 Playbook Registry.md
                25 Strategy Interface.md
                26 Second Day Play Impl.md
                27 Backtest Engine.md
                28 Ops Medical Stub.md
                29 Privacy Guardrails.md
                30 Ion Core Architecture.md
                31 Cobalt-Ion Bridge.md
                32 HUD Widgets & Overlay.md
                33 Mattermost C2 Integration.md
                34 Automated Trade Journaling.md
                35 Untethering Tailscale VSCode.md
                36 Feature Proposal Engine.md
                37 Feature Docker Sandbox.md
                38 Refactor Switchboard Router.md
                39 Tool Playwright Browser.md
                40 Tool LastPass Integration.md
            Cobalt Project Board.base
logs/
    agent_2026-02-18.log
    agent_2026-02-22.log
    agent_2026-02-24.log
    agent_2026-02-25.log
    cobalt_agent_2026-02-15.log
    mattermost_session.log
src/
    cobalt_agent/
        brain/
            strategies/
                second_day_play.py
            cortex.py
            engineering.py
            playbook.py
            strategy.py
            tactical.py
        core/
            proposals.py
            scheduler.py
        interfaces/
            cli.py
            mattermost.py
        memory/
            base.py
            core.py
            postgres.py
        security/
            vault.py
        skills/
            productivity/
                briefing.py
                scribe.py
            research/
                deep_dive.py
        tools/
            browser.py
            finance.py
            search.py
            tool_manager.py
        config.py
        llm.py
        main.py
        persona.py
        prompt.py
    cobalt_agent.egg-info/
        SOURCES.txt
        dependency_links.txt
        requires.txt
        top_level.txt
tests/
    conftest.py
    test_brain_connection.py
    test_config_override.py
    test_logic_lab.py
    test_memory_integration.py
    test_role_switch.py
    test_scribe.py
    test_strategies.py
README.md
docker-compose.yml
pyproject.toml

========================================
FILE: README.md
========================================



========================================
FILE: configs/config.yaml
========================================

# Project Cobalt Configuration File

system:
  debug_mode: true
  version: "0.5.0"
  obsidian_vault_path: /Users/cobalt/cobalt/docs

# 1. NETWORK TOPOLOGY (Hardware Abstraction)
network:
  nodes:
    cortex:
      role: primary_inference
      ip: "100.70.206.126"
      port: 11434
      protocol: http
    edge_mobile:
      role: client
      ip: localhost
      port: 8080
    edge_dev:
      role: hot_spare
      ip: localhost
      port: 8081
    station_trading:
      role: execution
      ip: localhost
      port: 8082

# 2. CREDENTIALS
keys:
  openai: "OPENAI_API_KEY"
  anthropic: "ANTHROPIC_API_KEY"
  gemini: "GEMINI_API_KEY"
  openrouter: "OPENROUTER_API_KEY"

# 3. UNIVERSAL MODEL REGISTRY (2026 Edition)
models:
  # --- LOCAL ---
  local_coder_32b:
    provider: "ollama"
    model_name: "qwen2.5-coder:32b"
    node_ref: "cortex"
    context: 32768
  local_strategist_r1:
    provider: "ollama"
    model_name: "deepseek-r1:70b"
    node_ref: "cortex"
    context: 16384
  local_bleeding_edge:
    provider: "ollama"
    model_name: "qwen3-coder-next"
    node_ref: "cortex"
    context: 65536

  # --- CLOUD BLEEDING EDGE ---
  cloud_gpt5_2:
    provider: "openai"
    model_name: "gpt-5.2" 
    env_key_ref: "openai"
  cloud_claude_4_6_opus:
    provider: "openrouter"
    model_name: "anthropic/claude-4.6-opus"
    env_key_ref: "openrouter"
  cloud_claude_4_6_sonnet:
    provider: "openrouter"
    model_name: "anthropic/claude-4.6-sonnet"
    env_key_ref: "openrouter"
  cloud_gemini_2_5_pro:
    provider: "gemini"
    model_name: "gemini/gemini-2.5-pro"
    env_key_ref: "gemini"
  cloud_gemini_2.5_flash:
    provider: "gemini"
    model_name: "gemini/gemini-2.5-flash"
    env_key_ref: "gemini"

# 4. ACTIVE SWITCHBOARD
active_profile:
  default: "local_bleeding_edge"
  coder: "local_bleeding_edge"
  architect: "local_bleeding_edge"
  strategist: "local_strategist_r1"
  researcher: "cloud_gemini_2.5_pro"
  fast_chat: "local_coder_32b"

mattermost:
  approval_channel: "cobalt-approvals"
  approval_team: "cobalt-team"

persona:
  name: "Cobalt"
  roles:
    - "Chief of Staff to Dejan"
    - "Principal Systems Architect"
    - "Zero-Trust Automation Engine"
  skills:
    - "Infrastructure and Workflow Automation"
    - "Zero-Trust Security Analysis"
    - "Documentation as Code (Obsidian Vault Integration)"
    - "Systematic Problem Solving and Triage"
  tone:
    - "Hyper-competent and authoritative"
    - "Analytical and unshakeable"
    - "Extremely concise (high signal, zero noise)"
    - "Professional (strictly avoid chatty filler, apologies, and sycophancy)"
  directives:
    - "PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework."
    - "PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization."
    - "ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands."
    - "DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented."
    - "BREVITY: Deliver answers directly. Eliminate introductory filler."
    - "FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions."
    - "TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only."

# COBALT ORGANIZATIONAL CHART
# Defines the active Departments and their mission statements.
departments:
  TACTICAL:
    description: "Capital Allocation, Trading Strategies, Market Data, Risk Management, 'Stocks in Play'."
    active: true
  INTEL:
    description: "Deep Research, News Briefings, Information Retrieval, Macro Analysis."
    active: true
  GROWTH:
    description: "Project Management, Skill Acquisition, Real Estate, Solar/Homestead Planning."
    active: true
  OPS:
    description: "Medical Admin (Billing/Coding), Journaling (Scribe), Scheduling."
    active: true
  ENGINEERING:
    description: "Writing new code, fixing tools, system upgrades."
    active: true
  DEFAULT:
    description: "General chat, web research, web browsing, article summarization. Use for queries that don't fit other domains."
    active: true


========================================
FILE: configs/rules.yaml
========================================

# Cobalt Trading Rules & Thresholds
# ROOT KEY: trading_rules (Distinguishes these from coding rules or behavioral rules)

trading_rules:
  momentum:
    rvol_alert_threshold: 3.0   # Trigger "MOMENTUM ALERT" if RVOL > 3.0
    rvol_strong_threshold: 1.5  # Consider it "strong volume" above this

  moving_averages:
    bullish_cross:
      fast: 10
      slow: 20
      logic: "rising" # Check if slopes are positive

  rsi:
    period: 20
    overbought: 80
    oversold: 20

  atr:
    period: 14
    expansion_multiplier: 5.0   # 5x ATR in 5 days = Parabolic
    extension_multiplier: 3.0   # 3x ATR = Extended

========================================
FILE: configs/strategies.yaml
========================================

# COBALT STRATEGY PLAYBOOK
# Defines the specific setups, risk rules, and entry criteria for the Tactical Department.

strategies:
  second_day_play:
    name: "Second Day Play"
    active: true
    direction: "BOTH" # Long or Short
    description: "Continuation play for stocks with strong Day 1 momentum."
    
    # EXISTING FILTERS (Preserved)
    time_window:
      start: "09:30"
      end: "10:30" # "Trade trigger before 10:30 am EST"
    filters:
      min_atr: 1.0 # "Range of more than 1 ATR"
      day1_close_zone: 0.20 # "Upper 20% or lower 20%"
      max_gap: 0.33 # "Gap up of less than 1/3 of the range from day 1"
      min_rvol_day1: 1.5 # "Traded more than average RVOL"
      
      # COMPLEX VARIABLES (Optional)
      liquidity:
        min_average_daily_volume: 1000000
        min_price: 2.00
      correlation:
        check_sector: true
        check_spy: true

    execution:
      entry_trigger: "candle_close_above_prior_high"
      stop_buffer: 0.02 # "$0.02 below the low"
      target_multiplier: 2.0 # "Target twice the height of day 1 range"

    # NEW SCORING BLOCK (Added for Logic Lab & Ion)
    scoring:
      # The base score if all hard filters are met
      base_score: 50
      
      # Relative Volume (RVOL) Logic
      high_rvol_threshold: 3.0
      high_rvol_points: 10
      base_rvol_points: 10 # Points for just meeting min_rvol
      
      # Price Action Logic
      gap_up_points: 10
      
      # Ion (Real-Time) Modifiers - Instructions for the Windows HUD
      live_rvol_multiplier: 5.0
      spy_correlation_weight: 10.0
      resistance_penalty: -20.0
      time_decay_per_min: -0.5

  fashionably_late_scalp:
    name: "Fashionably Late Scalp"
    active: false
    direction: "BOTH"
    time_window:
      start: "10:00"
      end: "13:30" # Morning + Mid-Day
    filters:
      trend_indicator: "9EMA"
      baseline_indicator: "VWAP"
      min_volume_ratio: 1.0 # "Volume bars during convergence > divergence"
    execution:
      entry_trigger: "cross_9ema_vwap"
      stop_rule: "measured_move_third" # "1/3 distance from VWAP to Low"
      target_rule: "measured_move_1x" # "1 measured move above cross"

  second_chance_scalp:
    name: "Second Chance Scalp"
    active: false
    direction: "BOTH"
    time_window:
      start: "09:59"
      end: "16:00" # All day
    filters:
      pattern: "break_retest"
      volume_break: "high"
      volume_retest: "low" # "Low-volume retest"
    execution:
      entry_trigger: "candle_close_above_prior"
      stop_buffer: 0.02 # "$0.02 below turn candle"
      exit_strategy: "half_and_trail"

========================================
FILE: dev_utils/brain_scan.py
========================================

"""
Brain Scan v2 - Deep Diagnostic
Checks Schema, Content, and Embedding Health.
"""
import os
import psycopg
from dotenv import load_dotenv

load_dotenv()

DB_HOST = os.getenv("POSTGRES_HOST", "localhost")
DB_NAME = os.getenv("POSTGRES_DB", "cobalt_memory")
DB_USER = os.getenv("POSTGRES_USER", "postgres")
DB_PASS = os.getenv("POSTGRES_PASSWORD", "cobalt_password")

def scan():
    conn_str = f"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:5432/{DB_NAME}"
    
    try:
        with psycopg.connect(conn_str) as conn:
            print(f"üî¨ Scanning Database: {DB_NAME}")
            
            # 1. GET TABLE INFO
            table_name = 'memory_logs'
            columns = conn.execute(f"""
                SELECT column_name, data_type 
                FROM information_schema.columns 
                WHERE table_name = '{table_name}';
            """).fetchall()
            
            print(f"\nüìã Schema for '{table_name}':")
            has_vector = False
            for col in columns:
                print(f"   - {col[0]} ({col[1]})")
                if 'vector' in col[1] or 'embedding' in col[0]:
                    has_vector = True
            
            if not has_vector:
                print("\n‚ùå CRITICAL: No VECTOR column found! Semantic search is impossible.")
            
            # 2. CHECK CONTENT (Last 20 items)
            print(f"\nüìú Recent Memories (Last 20):")
            # We explicitly ask for embedding status
            query = f"""
                SELECT id, source, content, 
                       (embedding IS NOT NULL) as has_vector 
                FROM {table_name} 
                ORDER BY timestamp DESC LIMIT 20;
            """
            
            try:
                rows = conn.execute(query).fetchall()
            except Exception as e:
                # Fallback if 'embedding' column doesn't exist
                print(f"‚ö†Ô∏è Query failed (likely missing column): {e}")
                rows = conn.execute(f"SELECT id, source, content FROM {table_name} ORDER BY timestamp DESC LIMIT 20").fetchall()

            found_tsla = False
            for row in rows:
                id_val = row[0]
                source = row[1]
                content = row[2][:60].replace("\n", " ") # Truncate for display
                
                # Check vector status if we grabbed it
                vector_status = "‚úÖ" if (len(row) > 3 and row[3]) else "‚ùå NULL"
                
                print(f"   [{id_val}] {vector_status} | {source}: {content}...")
                
                if "TSLA" in content:
                    found_tsla = True

            print("\n--- DIAGNOSIS ---")
            if not found_tsla:
                print("‚ùå 'TSLA' memory NOT FOUND in database. The Write failed.")
            else:
                print("‚úÖ 'TSLA' memory FOUND.")
                
    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    scan()

========================================
FILE: dev_utils/create_missing_tasks.py
========================================

"""
Cobalt Task Generator
Creates the missing Phase 4 (Ion) and Phase 5 (Ops) tasks on the Project Board.
"""
import os
import sys
import importlib.util
from datetime import datetime

# --- 1. ROBUST SCRIBE LOADER (The "Smoking Gun" Fix) ---
# This works because 'uv run' executes from the Project Root.
current_dir = os.getcwd()
scribe_path = os.path.join(current_dir, "cobalt_agent", "skills", "productivity", "scribe.py")

print(f"üîç Loading Scribe from: {scribe_path}")

try:
    if not os.path.exists(scribe_path):
        raise FileNotFoundError(f"File not found at {scribe_path}")

    # Load module directly by file path (bypassing package issues)
    spec = importlib.util.spec_from_file_location("scribe_module", scribe_path)
    scribe_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(scribe_module)
    
    Scribe = scribe_module.Scribe
    print("‚úÖ Scribe Class Loaded Successfully.")
except Exception as e:
    print(f"‚ùå Failed to load Scribe: {e}")
    sys.exit(1)

# Initialize
scribe = Scribe()
current_date = datetime.now().strftime("%Y-%m-%d")

# --- 2. DEFINE TASKS ---

tasks = {
    "30 Ion Core Architecture.md": f"""---
status: To Do
priority: P1 (High)
module: Interface
phase: 4 (Ion HUD)
complexity: L
tags: [cobalt, task, ion]
created: {current_date}
---

# 30 Ion Core Architecture

## Objective
Establish the foundational Python application for the **Windows HUD**.

## Requirements
* [ ] Create `ion_agent/` directory structure on Windows.
* [ ] Initialize a **PyQt6** application loop.
* [ ] Implement a **Transparent Overlay Window** (Click-through capable).
* [ ] Create a system tray icon for background management.
* [ ] Ensure it can run alongside TradeStation without stealing focus.

## Technical Notes
* Use `PyQt6.QtCore.Qt.WindowType.FramelessWindowHint`.
* Must handle high-DPI scaling (4K monitors).
""",

    "31 Cobalt-Ion Bridge.md": f"""---
status: To Do
priority: P0 (Critical)
module: Core
phase: 4 (Ion HUD)
complexity: M
tags: [cobalt, task, network]
created: {current_date}
---

# 31 Cobalt-Ion Bridge

## Objective
Create the low-latency communication link between **Cobalt (Mac)** and **Ion (Windows)**.

## Requirements
* [ ] Implement **ZeroMQ (ZMQ)** PUB/SUB pattern.
* [ ] **Publisher:** Cobalt (Mac) broadcasting strategy signals.
* [ ] **Subscriber:** Ion (Windows) listening for HUD updates.
* [ ] Define the JSON payload schema (Ticker, Action, Confidence, Price).
* [ ] Secure the connection over **Tailscale IP**.

## Technical Notes
* Latency target: < 50ms.
* Use `zmq.asyncio` for non-blocking I/O.
""",

    "32 HUD Widgets & Overlay.md": f"""---
status: To Do
priority: P1 (High)
module: Interface
phase: 4 (Ion HUD)
complexity: M
tags: [cobalt, task, ui]
created: {current_date}
---

# 32 HUD Widgets & Overlay

## Objective
Build the specific visual components that appear on the screen.

## Requirements
* [ ] **Confidence Gauge:** A visual bar/dial showing Model Confidence (0-100%).
* [ ] **Signal Box:** A "BUY/SELL" indicator that flashes on trigger.
* [ ] **Trade Log:** A small scrolling list of recent fills.
* [ ] **P&L Ticker:** Real-time session P&L display.

## Design
* "Dark Mode" aesthetic (Cyberpunk/High-Contrast).
* Green = Long, Red = Short.
""",

    "33 Mattermost C2 Integration.md": f"""---
status: To Do
priority: P1 (High)
module: Ops
phase: 5 (Ops)
complexity: M
tags: [cobalt, task, chat]
created: {current_date}
---

# 33 Mattermost C2 Integration

## Objective
Connect Cobalt to the "Red Phone" (Mattermost) for remote command and control.

## Requirements
* [ ] Create a Mattermost Bot Account ("Cobalt").
* [ ] Implement **Incoming Webhooks** for alerts (Trade Signals).
* [ ] Implement **Outgoing Webhooks** (or Slash Commands) for user commands.
* [ ] **Kill Switch:** Create a command `/cobalt stop` that halts all trading instantly.
* [ ] **Approval Flow:** Interactive buttons for "Approve Trade?" messages.
""",

    "34 Automated Trade Journaling.md": f"""---
status: To Do
priority: P2 (Normal)
module: Skills
phase: 5 (Ops)
complexity: S
tags: [cobalt, task, journaling]
created: {current_date}
---

# 34 Automated Trade Journaling

## Objective
Remove manual data entry by having Cobalt write its own trade logs.

## Requirements
* [ ] Capture execution details (Entry, Exit, Size, P&L).
* [ ] Capture "Why?" (The Strategy Logic snapshot at moment of trade).
* [ ] Format as a Markdown table.
* [ ] Append to the **Daily Note** in Obsidian via Scribe.

## Format
| Time | Ticker | Side | P&L | Strategy | Confidence |
|------|--------|------|-----|----------|------------|
"""
}

# --- 3. EXECUTE WRITE ---
print(f"üìù Creating {len(tasks)} missing tasks in '0 - Projects/Cobalt/Tasks'...")

target_folder = "0 - Projects/Cobalt/Tasks"

for filename, content in tasks.items():
    try:
        # Scribe.write_note(filename, content, folder)
        result = scribe.write_note(filename=filename, content=content, folder=target_folder)
        print(f"‚úÖ Created: {filename}")
    except Exception as e:
        print(f"‚ùå Failed: {filename} | Error: {e}")

print("\nüèÅ Board Updated. Run 'update_board.py' (or refresh Obsidian) to see changes.")

========================================
FILE: dev_utils/create_prd.py
========================================

"""
Cobalt Requirements Generator
Creates the PRD-001 based on the 'Strategic Pause' conversation.
"""
import os
import sys
import importlib.util
from datetime import datetime

# --- LOAD SCRIBE ---
current_dir = os.getcwd()
scribe_path = os.path.join(current_dir, "cobalt_agent", "skills", "productivity", "scribe.py")

try:
    if not os.path.exists(scribe_path):
        raise FileNotFoundError(f"File not found at {scribe_path}")
    
    spec = importlib.util.spec_from_file_location("scribe_module", scribe_path)
    scribe_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(scribe_module)
    Scribe = scribe_module.Scribe
    print("‚úÖ Scribe Class Loaded Successfully.")
except Exception as e:
    print(f"‚ùå Failed to load Scribe: {e}")
    sys.exit(1)

scribe = Scribe()
current_date = datetime.now().strftime("%Y-%m-%d")

# --- PRD CONTENT ---

prd_content = f"""---
status: Approved
priority: P0
module: Core
tags: [cobalt, requirements, prd, ion]
created: {current_date}
---

# PRD-001: Cobalt-Ion Tactical HUD

## 1. Executive Summary
**The Vision:** Build a "Co-Pilot" system for manual day trading.
**The Problem:** Professional trading requires processing dozens of variables (RVOL, Levels, Tape, News) in real-time. Humans are slow and emotional.
**The Solution:** A "Heads-Up Display" (HUD) that acts as a real-time **Confidence Gauge**. It calculates the mathematical "Expected Value" (EV) of a trade 10x/second, allowing the trader to execute with conviction.

## 2. Core Philosophy
1.  **Not an Auto-Trader:** The system NEVER executes trades autonomously. It observes, calculates, and suggests. The user pulls the trigger.
2.  **Distributed Brain:** * **Mac Studio (Cobalt):** The Strategist. Slow, deep thinking. Analysis of Context & Catalysts.
    * **Windows PC (Ion):** The Calculator. Fast, reactive math. Visualizing the HUD.
3.  **Python-First:** Both components run on Python (PyQt6 for Windows HUD) to ensure speed of development and shared logic.

## 3. User Stories

### Story A: The "Morning Briefing" (Context)
**As a** Trader,
**I want** Cobalt to scan the market for "In Play" stocks and identify the specific *Strategies* (from my Playbook) that apply to them (e.g., "NVDA is an Earnings Gap"),
**So that** I start the day with a curated list of opportunities, not just raw tickers.

### Story B: The "Formula Injection" (Handoff)
**As a** System Architect,
**I want** Cobalt to send a "Math Package" (JSON) to Ion containing the specific *Weights and Variables* for the day (e.g., "For NVDA, Gap Fill is +10 points, Resistance at $145 is -20 points"),
**So that** Ion can run the math locally without latency, acting as a "dumb calculator" for Cobalt's "smart rules."

### Story C: The "Tactical Engagement" (The HUD)
**As a** Trader executing a trade,
**I want** a visual Gauge (0-100) that updates in real-time based on Price, Volume, and Time,
**So that** I can intuitively see if the trade is degrading (Score dropping) or improving (Score rising) without doing mental math.
* *Example:* "I am long NVDA. Volume dries up -> Score drops 10 points -> Gauge turns Yellow -> I trim my position."

## 4. Functional Requirements

### 4.1 The Scoring Engine (Dynamic EV)
The Score (0-100) is calculated as:
$$ Score = Base + Fuel - Friction - Decay $$
* **Base:** Static score from the Daily Setup (e.g., "A+ Setup" = 60).
* **Fuel (Momentum):** Live modifiers (e.g., `RVOL > 2.0` adds +10).
* **Friction (Risk):** Proximity to Resistance (e.g., `Dist < $0.10` subtracts -20).
* **Decay (Time):** Penalty for stalling (e.g., `-1 point` per minute of chop).

### 4.2 The "Math Package" Protocol
Cobalt must send a JSON payload to Ion containing:
* `Ticker`: Symbol (e.g., "NVDA").
* `Strategies`: List of active setups (e.g., ["GapAndGo", "BellaFade"]).
* `Zones`: Key Price Levels (Entry, Stop, Target).
* `Coefficients`: The weights for the Scoring Engine.

### 4.3 The Multi-Strategy Capability
The system must support **Conflicting Strategies** simultaneously.
* *Scenario:* NVDA gaps up.
* *HUD State:* Ion displays *two* potential scores:
    1.  **Long Score:** For the "Gap & Go" breakout.
    2.  **Short Score:** For the "Extension Fade" reversal.

## 5. Technical Constraints
* **Language:** Python 3.11+.
* **GUI Framework:** PyQt6 (Windows) for transparent overlays.
* **Communication:** ZeroMQ (ZMQ) over Tailscale LAN.
* **Data Source:** TradeStation API (connected locally on Windows).
* **Latency Target:** < 50ms from Tick to HUD Update.

## 6. Future Extensibility
* **Discord Integration:** Manual scraping of trader sentiment to adjust "Base Scores."
* **Journaling:** Automated logging of *why* a score was high/low at the moment of execution.
"""

# --- EXECUTE ---
print("üìù Generating PRD-001 based on Strategic Conversation...")

try:
    folder = "0 - Projects/Cobalt/90 - Project Management/Requirements"
    filename = "PRD-001 Cobalt-Ion Tactical HUD.md"
    
    scribe.write_note(filename=filename, content=prd_content, folder=folder)
    print(f"‚úÖ Successfully Created: {folder}/{filename}")

except Exception as e:
    print(f"‚ùå Failed to create PRD: {e}")

========================================
FILE: dev_utils/generate_constitution.py
========================================

"""
Cobalt Constitution Generator (Master Version)
Contains:
1. Dashboard (The Root)
2. System Manifest (5 Depts, Coach Role, Hardware Stack)
3. Security Architecture (Zero Trust, Vault, JIT)
4. ADRs (Distributed Protocol, Python-First)
5. Project Management (Roadmap, Backlog)
"""
import os
import sys
import importlib.util
from datetime import datetime

# --- 1. ROBUST SCRIBE LOADER ---
current_dir = os.getcwd()
scribe_path = os.path.join(current_dir, "cobalt_agent", "skills", "productivity", "scribe.py")

try:
    if not os.path.exists(scribe_path):
        raise FileNotFoundError(f"File not found at {scribe_path}")
    
    spec = importlib.util.spec_from_file_location("scribe_module", scribe_path)
    scribe_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(scribe_module)
    Scribe = scribe_module.Scribe
    print("‚úÖ Scribe Class Loaded Successfully.")
except Exception as e:
    print(f"‚ùå Failed to load Scribe: {e}")
    sys.exit(1)

scribe = Scribe()
current_date = datetime.now().strftime("%Y-%m-%d")

# --- 2. FRONTMATTER DEFINITIONS ---

arch_frontmatter = f"""---
status: Done
priority: P0 (Critical)
module: Ops
phase: 1 (Foundation)
complexity: M
tags: [cobalt, architecture, documentation]
created: {current_date}
---
"""

pm_frontmatter = f"""---
status: In Progress
priority: P1 (High)
module: Ops
phase: 3 (Capabilities)
complexity: S
tags: [cobalt, planning, roadmap]
created: {current_date}
---
"""

dashboard_frontmatter = f"""---
status: In Progress
priority: P0 (Critical)
module: Core
phase: 1 (Foundation)
complexity: L
tags: [cobalt, root, dashboard]
created: {current_date}
---
"""

# --- 3. THE CONSTITUTION CONTENT ---

files_to_create = {
    
    # ---------------------------------------------------------
    # THE DASHBOARD (Updated with all ADRs)
    # ---------------------------------------------------------
    "0 - Projects/Cobalt/00 Cobalt Master Plan.md": f"""{dashboard_frontmatter}
# Cobalt Command Center

## 1. Strategy & Ops (Level 1)
* [[System Manifest]] - The Stack, Hierarchy, and Roles.
* [[Security Architecture]] - Zero Trust, JIT Access, and Kill-Switches.
* [[ADR-001 Cobalt-Ion Distributed Protocol]] - Architecture Decisions.
* [[ADR-002 Hybrid AI Compute]] - Local vs. Cloud Model Strategy.
* [[ADR-003 Python-First Architecture]] - Ion HUD Technology Stack.

## 2. Project Management (Level 2)
* [[Roadmap]] - The Strategic Phases (Q1/Q2 Goals).
* [[Backlog]] - Future ideas and holding pen.

## 3. Execution (Level 3)
![[Cobalt Project Board]]
""",

    # ---------------------------------------------------------
    # LEVEL 1: MASTER PLAN
    # ---------------------------------------------------------

    "0 - Projects/Cobalt/00 - Master Plan/System Manifest.md": f"""{arch_frontmatter}
# Cobalt System Manifest

## 1. The Vision
**Cobalt** is a distributed, semi-autonomous trading system acting as a "Chief of Staff."
**Dejan** is the CEO and final decision-maker.

## 2. The Hierarchy

### Level 1: The CEO (Dejan)
* **Role:** The Decision Maker.
* **Responsibilities:**
    * Setting Strategic Goals.
    * Final Approval on "High Risk" Actions.
    * Risk Control Override.

### Level 2: Cobalt (The Chief of Staff & Performance Coach)
* **Role:** The Brain & The Mirror.
* **Responsibilities:**
    * **Orchestration:** Directing the 5 Departments below.
    * **Coaching:** Reviewing Scribe's journals to provide psychological feedback.
    * **Gatekeeping:** Protecting the CEO from noise and emotional trading.
    * **Memory:** Maintaining the context of all projects and trades.

### Level 3: The Departments (The Workforce)
* **Strategos (Tactical)**
    * Market Analysis & Technical Indicators.
    * Quant Logic & Strategy Generation.
    * Pattern Recognition Engine.
* **Ion (Interface)**
    * Windows HUD Overlay (PyQt6).
    * TradeStation Execution Bridge.
    * Real-time Data Visualization.
* **Scribe (Ops)**
    * Documentation & Knowledge Management.
    * Automated Journaling & Logging.
    * Project Management (Kanban Updates).
* **Sentinel (Risk)**
    * Position Sizing Logic.
    * "Kill Switch" Enforcement.
    * Compliance & Privacy Guardrails.
* **Scout (Research)**
    * Data Gathering (FinanceTool).
    * Sentiment Analysis (News/Social).
    * Web Browsing & Due Diligence.

## 3. The Hardware Stack

* **The Brain (Mac Studio M2 Ultra)**
    * **Specs:** 96GB RAM, 2TB SSD.
    * **Role:** Central Compute Node.
    * **Workload:** Hosts DeepSeek-R1 (Local LLM), Postgres DB, and Core Logic.

* **The Engine (Windows Workstation)**
    * **Role:** Dedicated Execution Environment.
    * **Workload:** Runs TradeStation Platform and Ion Agent (HUD).
    * **Constraint:** Zero-latency link to Mac via Tailscale.

* **The Console (Lenovo X1 Carbon)**
    * **Role:** Primary Development Interface.
    * **Workload:** VSCode (Remote SSH), Task Management, Ops Control.
    * **Security:** Biometric Access required for code changes.

* **The Red Phone (Mobile iOS/Android)**
    * **Role:** Command & Control (C2).
    * **Workload:** Mattermost Alerts ("Trade Signal"), MFA "Kill Switch" Approvals.
    * **Access:** Emergency System Shutdown.

## 4. The Software Stack
* **Core Intelligence (Cobalt):**
    * **Language:** Python 3.11+
    * **Models:** DeepSeek-R1 (Thinking), OpenAI o3-mini (Speed), Gemini 1.5 Pro (Architect).
    * **Memory:** PostgreSQL (Vector + Relational), Obsidian (Markdown).

* **Departmental Stacks:**
    * **Strategos:** `pandas`, `numpy`, `ta-lib` (Technical Analysis).
    * **Ion:** `PyQt6` (GUI), `pyzmq` (Networking), `EasyLanguage` (TradeStation).
    * **Scribe:** `obsidian-api`, `jinja2` (Templating).
    * **Sentinel:** `pydantic` (Data Validation), `cryptography` (Security).
    * **Scout:** `playwright` (Browsing), `beautifulsoup4` (Scraping).
""",

    "0 - Projects/Cobalt/00 - Master Plan/Security Architecture.md": f"""{arch_frontmatter}
# Cobalt Security Architecture (Zero Trust)

## 1. Core Philosophy: "Assume Breach"
We operate under the assumption that the network is compromised. Trust is never granted implicitly based on location (LAN) or device ownership.
* **Verify Explicitly:** Always authenticate and authorize based on all available data points.
* **Use Least Privilege:** Limit user access with Just-In-Time and Just-Enough-Access (JIT/JEA).
* **Assume Breach:** Minimize blast radius and segment access.

## 2. Identity & Access Management (IAM)
* **The Identity Provider:** Tailscale is the root of trust for *Device Identity*.
* **MFA Protocol:** Critical actions (Trade > $X, System Config Changes) require out-of-band verification via Mattermost (Mobile).
* **Service-to-Service Auth:**
    * Components (e.g., Mac -> Windows) must authenticate via **mTLS** or **Signed JWTs**.
    * `Ion` will reject commands from `Cobalt` that are not cryptographically signed by `Sentinel`.

## 3. Secrets Management (The Vault)
* **No Hardcoded Keys:** API Keys (TradeStation, OpenAI) are NEVER stored in plain text code or environment variables.
* **The Cobalt Vault:**
    * Secrets are stored in an encrypted local keystore (AES-256).
    * **Injection:** Secrets are loaded into memory *only* at runtime process initialization.
    * **Rotation:** Keys are rotated regularly.

## 4. Just-In-Time (JIT) Execution
* **Standing Privileges:** `Ion` (The Executor) has **Read-Only** access to the broker by default.
* **The Token Flow:**
    1.  `Strategos` spots a trade.
    2.  `Sentinel` validates risk checks.
    3.  `Sentinel` issues a **One-Time Execution Token (OTET)**.
    4.  `Ion` uses the OTET to unlock the "Execute" function for *that specific trade only*.
    5.  Token expires immediately after execution or timeout (500ms).

## 5. Network Micro-Segmentation
* **The Airlock:**
    * `Scout` (Research/Web Scraper) is isolated in a "Dirty" VLAN/Container.
    * `Scout` CANNOT talk to `Ion` (Execution) or `Sentinel` (Risk).
    * `Scout` can only write to a sanitized "Drop Zone" in the Database.
* **Tailscale ACLs:**
    * **Mac Studio:** Can talk to Windows (Port 5555 Only).
    * **Windows:** Can talk to Mac Studio (Postgres Port Only).
    * **External:** All inbound traffic blocked.
""",

    # ---------------------------------------------------------
    # ADRs
    # ---------------------------------------------------------

    "0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-001 Cobalt-Ion Distributed Protocol.md": f"""{arch_frontmatter}
# ADR-001: The Cobalt-Ion Distributed Architecture
## Status: ACCEPTED
## Decision
We use a **Distributed Actor Model**:
* **Cobalt (Mac):** Generates the "Strategy Math" (Scoring Profile).
* **Ion (Windows):** Runs the "Math" 10x/sec against live data to paint the HUD.
* **Protocol:** JSON payloads over Tailscale LAN.
""",

    "0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-002 Hybrid AI Compute.md": f"""{arch_frontmatter}
# ADR-002: Hybrid AI Compute Strategy
## Status: ACCEPTED
## Decision
* **DeepSeek-R1 (Local 70B):** Used for "Morning Prep" and deep reasoning. Zero data leakage.
* **OpenAI o3-mini (Cloud):** Used for fast, non-sensitive pattern recognition during the day.
* **Gemini 1.5 Pro (Cloud):** Used as the System Architect and Code Generator (Massive Context).
""",

    "0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-003 Python-First Architecture.md": f"""{arch_frontmatter}
# ADR-003: Python-First Architecture
## Status: ACCEPTED
## Decision
We will use **Python (PyQt6)** for the Ion HUD.
* **Reasoning:** Modern Python is fast enough for human-speed trading (HUD updates). It simplifies the codebase (one language for Brain and HUD) and allows code sharing (Pydantic models).
""",

    # ---------------------------------------------------------
    # LEVEL 2: PROJECT MANAGEMENT
    # ---------------------------------------------------------

    "0 - Projects/Cobalt/90 - Project Management/Roadmap.md": f"""{pm_frontmatter}
# Cobalt Strategic Roadmap

## Phase 1: The Core (Completed) ‚úÖ
* Basic Agent Setup (Hello World).
* Configuration System (YAML).
* Logging & Tooling.

## Phase 2: The Brain (Completed) ‚úÖ
* Memory System (Postgres).
* Scribe Tool (Obsidian Integration).
* DeepSeek Local Model Integration.

## Phase 3: The Tactical Department (Active) üöß
* **Feature:** Data Feeds (FinanceTool).
* **Feature:** Strategy Playbook (YAML -> Python).
* **Feature:** Backtester (Validating Strategies).

## Phase 4: The Ion HUD (Next) üìÖ
* **Epic:** Build Python/PyQt Overlay for Windows.
* **Epic:** Establish Socket/ZMQ Link between Mac and Windows.
* **Epic:** Zero Trust Security Implementation (JIT/Vault).

## Phase 5: The Ops Department (Future) üîÆ
* **Epic:** Mattermost Chat Integration.
* **Epic:** Automated Journaling.
""",

    "0 - Projects/Cobalt/90 - Project Management/Backlog.md": f"""{pm_frontmatter}
# Cobalt Product Backlog
## Unscheduled Ideas
* [ ] Integrate Discord scraping for sentiment analysis.
* [ ] Build "Ion Voice" for audio alerts.
* [ ] Research "Mean Reversion" strategy implementation.
"""
}

# --- 4. EXECUTE WRITE ---

print("üìù Scribe initializing Cobalt Constitution...")

for full_path, content in files_to_create.items():
    try:
        # Resolve Folder/Filename
        path_str = str(full_path)
        last_slash = path_str.rfind("/")
        
        if last_slash == -1:
            print(f"‚ùå Invalid path format: {full_path}")
            continue
            
        folder = path_str[:last_slash]
        filename = path_str[last_slash+1:]
        
        # Write
        result = scribe.write_note(filename=filename, content=content, folder=folder)
        print(f"‚úÖ Generated: {full_path}")
        
    except Exception as e:
        print(f"‚ùå Failed: {full_path} | Error: {e}")

print("\nüèÅ Cobalt Constitution generated.")

========================================
FILE: dev_utils/generate_context.py
========================================

#!/usr/bin/env python3
"""
Script to generate a master context file for architectural review.
Generates cobalt_master_context.txt with directory tree and file contents.
"""

import os
from pathlib import Path

# Exclusions: files/dirs starting with . or __, plus venv and uv.lock
EXCLUDED_PREFIXES = ('.', '__')
EXCLUDED_NAMES = {'venv', 'uv.lock'}

# Inclusions: allowed file extensions
ALLOWED_EXTENSIONS = {'.py', '.md', '.yaml', '.yml', '.toml', '.log', '.txt', '.base'}


def is_excluded(path: Path, base: Path) -> bool:
    """Check if a path should be excluded based on naming rules."""
    rel_path = path.relative_to(base)
    
    # Check each component of the path
    for part in rel_path.parts:
        if part.startswith(EXCLUDED_PREFIXES) or part in EXCLUDED_NAMES:
            return True
    
    # Check for uv.lock file specifically
    if path.name == 'uv.lock':
        return True
    
    return False


def get_file_extension(file_path: Path) -> str:
    """Get the file extension."""
    return file_path.suffix.lower()


def should_process_file(file_path: Path) -> bool:
    """Check if a file should be processed based on its extension."""
    return get_file_extension(file_path) in ALLOWED_EXTENSIONS


def read_file_content(file_path: Path) -> str:
    """Read file content. For .log files, only read last 200 lines."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
            if get_file_extension(file_path) == '.log':
                # For log files, only read last 200 lines
                lines = f.readlines()
                return ''.join(lines[-200:])
            else:
                return f.read()
    except Exception as e:
        return f"[Error reading file: {e}]"


def generate_directory_tree(base_path: Path, indent: str = '') -> str:
    """Generate a text-based directory tree, respecting exclusions."""
    tree_lines = []
    tree_lines.append(f"{base_path.name}/")
    
    def walk_directory(path: Path, prefix: str):
        try:
            # Get all entries, sorted
            entries = sorted(path.iterdir(), key=lambda x: (x.is_file(), x.name))
            
            for entry in entries:
                rel_path = entry.relative_to(base_path)
                
                # Skip excluded paths
                if is_excluded(entry, base_path):
                    continue
                
                if entry.is_dir():
                    tree_lines.append(f"{prefix}{entry.name}/")
                    walk_directory(entry, prefix + "    ")
                else:
                    # Check if file should be processed
                    if should_process_file(entry):
                        tree_lines.append(f"{prefix}{entry.name}")
        except PermissionError:
            tree_lines.append(f"{prefix}[Permission denied]")
    
    walk_directory(base_path, '')
    return '\n'.join(tree_lines)


def collect_files(base_path: Path) -> list:
    """Collect all files that should be processed."""
    files = []
    
    for root, dirs, filenames in os.walk(base_path):
        root_path = Path(root)
        
        # Filter out excluded directories
        dirs[:] = [d for d in dirs if not is_excluded(root_path / d, base_path)]
        
        for filename in filenames:
            file_path = root_path / filename
            
            # Skip excluded paths
            if is_excluded(file_path, base_path):
                continue
            
            # Check if file should be processed
            if should_process_file(file_path):
                files.append(file_path)
    
    return sorted(files)


def main():
    base_path = Path.cwd()
    output_file = base_path / 'cobalt_master_context.txt'
    
    print(f"Generating context file for: {base_path}")
    
    # Generate directory tree
    print("Generating directory tree...")
    tree_content = generate_directory_tree(base_path)
    
    # Collect files to process
    print("Collecting files...")
    files = collect_files(base_path)
    print(f"Found {len(files)} files to process")
    
    # Write to output file
    print(f"Writing to {output_file}...")
    with open(output_file, 'w', encoding='utf-8') as out_f:
        # Write directory tree as first section
        out_f.write("PROJECT DIRECTORY STRUCTURE\n")
        out_f.write("=" * 80 + "\n\n")
        out_f.write(tree_content)
        
        # Process each file
        for file_path in files:
            rel_path = file_path.relative_to(base_path)
            print(f"Processing: {rel_path}")
            
            content = read_file_content(file_path)
            
            out_f.write(f"\n\n========================================\n")
            out_f.write(f"FILE: {rel_path}\n")
            out_f.write(f"========================================\n\n")
            out_f.write(content)
    
    print(f"\nContext file generated: {output_file}")
    print(f"Total files processed: {len(files)}")


if __name__ == '__main__':
    main()

========================================
FILE: dev_utils/manage_vault.py
========================================

import sys
import os
from pathlib import Path
from rich.console import Console
from rich.prompt import Prompt

# Add project root to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "src")))
from cobalt_agent.security.vault import VaultManager

console = Console()

def main():
    console.print("\n[bold blue]üõ°Ô∏è Cobalt Local Vault Manager[/bold blue]")
    vault = VaultManager()
    
    # Check if Master Key is in environment for ease of use during dev
    master_key = os.getenv("COBALT_MASTER_KEY")
    
    if not master_key:
        action = Prompt.ask("No COBALT_MASTER_KEY found in environment. Generate a new one?", choices=["y", "n"], default="y")
        if action == "y":
            new_key = vault.generate_master_key()
            console.print(f"\n[bold red]!!! CRITICAL: SAVE THIS KEY IN YOUR PASSWORD MANAGER !!![/bold red]")
            console.print(f"[bold green]export COBALT_MASTER_KEY='{new_key}'[/bold green]\n")
            console.print("Run this export command in your terminal, then run this script again.")
            return
        else:
            console.print("Exiting. You must set COBALT_MASTER_KEY to use the vault.")
            return

    if not vault.unlock(master_key):
        console.print("[red]Failed to unlock vault. Check your Master Key.[/red]")
        return
        
    while True:
        console.print("\n[bold cyan]--- Vault Menu ---[/bold cyan]")
        console.print("[1] List All Secret Names")
        console.print("[2] Retrieve a Secret")
        console.print("[3] Add/Update a Secret (String or JSON)")
        console.print("[4] Delete a Secret")
        console.print("[5] Exit and Lock Vault")
        
        choice = Prompt.ask("Choose an action", choices=["1", "2", "3", "4", "5"])
        
        if choice == "1":
            keys = vault.list_secrets()
            if keys:
                console.print("\n[bold green]Stored Keys:[/bold green]")
                for k in keys:
                    console.print(f" - {k}")
            else:
                console.print("[yellow]Vault is empty.[/yellow]")
                
        elif choice == "2":
            key_name = Prompt.ask("Enter Secret Name to retrieve")
            val = vault.get_secret(key_name)
            if val:
                console.print(f"\n[bold green]{key_name}:[/bold green]\n{val}")
            else:
                console.print(f"[red]Secret '{key_name}' not found.[/red]")
                
        elif choice == "3":
            key_name = Prompt.ask("Enter Secret Name (e.g., BROKER_CREDS)")
            console.print("[dim]Note: You can paste a flat string OR a JSON string like {\"url\":\"...\", \"user\":\"...\", \"pass\":\"...\"}[/dim]")
            secret_value = Prompt.ask("Enter Secret Value", password=True)
            if vault.set_secret(master_key, key_name, secret_value):
                console.print(f"[green]Successfully saved '{key_name}'[/green]")
                
        elif choice == "4":
            key_name = Prompt.ask("Enter Secret Name to delete")
            confirm = Prompt.ask(f"Are you sure you want to delete '{key_name}'?", choices=["y", "n"])
            if confirm == "y":
                if vault.delete_secret(master_key, key_name):
                    console.print(f"[green]Deleted '{key_name}'.[/green]")
                else:
                    console.print(f"[red]Failed to delete '{key_name}'.[/red]")
                    
        elif choice == "5":
            vault.lock()
            console.print("[bold blue]Vault locked. Goodbye.[/bold blue]")
            break

if __name__ == "__main__":
    main()

========================================
FILE: dev_utils/reset_memory_table.py
========================================

import os
import psycopg
from dotenv import load_dotenv

load_dotenv()

def reset_table():
    host = os.getenv("POSTGRES_HOST", "localhost")
    db = os.getenv("POSTGRES_DB", "cobalt_memory")
    user = os.getenv("POSTGRES_USER", "postgres")
    password = os.getenv("POSTGRES_PASSWORD", "cobalt_password")
    
    conn_str = f"postgresql://{user}:{password}@{host}:5432/{db}"
    
    try:
        with psycopg.connect(conn_str, autocommit=True) as conn:
            print(f"üîå Connecting to {db}...")
            # Drop the table that has the wrong schema
            conn.execute("DROP TABLE IF EXISTS memory_logs;")
            print("üí• Table 'memory_logs' destroyed successfully.")
            
    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    reset_table()

========================================
FILE: dev_utils/update_board.py
========================================

"""
Script to populate the Obsidian Project Board with Phase 4 & 5 tasks.
Uses the Scribe tool to ensure correct formatting.
"""
import sys
import os

# Add project root to path so we can import the cobalt_agent package
# This assumes dev_utils/ is one level deep in the project root
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from cobalt_agent.skills.productivity.scribe import Scribe

def create_task(id_num, title, priority, module, complexity, description):
    scribe = Scribe()
    # Format: "23 Strategos Agent Setup"
    filename = f"{id_num} {title}"
    
    # Frontmatter for your Kanban Board (Obsidian Canvas/Dataview compatible)
    content = f"""---
status: To Do
priority: {priority}
module: {module}
complexity: {complexity}
tags:
  - cobalt/task
created: 2026-02-10
---

# {title}

## Objective
{description}

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script
"""
    # Save to 0 - Inbox (You can drag them to your board later)
    result = scribe.write_note(filename, content, folder="0 - Inbox")
    print(result)

if __name__ == "__main__":
    print("üöÄ Generating Phase 4 & 5 Tasks...")
    
    # --- PHASE 4: TACTICAL (STRATEGOS) ---
    create_task("23", "Strategos Agent Setup", "P0", "Tactical", "M", 
                "Create the 'Strategos' class. This manages the Playbook and Risk, replacing the basic FinanceTool wrapper.")
    
    create_task("24", "Playbook Registry", "P1", "Tactical", "S", 
                "Create 'strategies.yaml' to define rules for Second Day Play and Fashionably Late Scalp.")
    
    create_task("25", "Strategy Interface", "P1", "Tactical", "M", 
                "Define the abstract Python class for a Strategy (check_entry, check_stop, calculate_probability).")
    
    create_task("26", "Second Day Play Impl", "P1", "Tactical", "L", 
                "Implement the specific logic from the SMB PDF: Day 1 Trend, Day 2 Open, RVOL checks.")
    
    create_task("27", "Backtest Engine", "P2", "Tactical", "XL", 
                "Create the engine that runs a Strategy against 90 days of historical minute-data.")

    # --- PHASE 5: OPS (STEWARD) ---
    create_task("28", "Ops Medical Stub", "P2", "Ops", "S", 
                "Create the Steward Agent shell to handle future medical billing tasks.")
    
    create_task("29", "Privacy Guardrails", "P0", "Ops", "M", 
                "Implement PII stripping to ensure no patient data ever hits the LLM.")

    print("\n‚úÖ Done! Check your Obsidian '0 - Inbox' folder.")

========================================
FILE: dev_utils/wipe_memory.py
========================================

"""
Wipe Memory Script (Smart Version)
Finds ANY table in the public schema and wipes it.
"""
import os
import psycopg
from dotenv import load_dotenv

load_dotenv()

# Load credentials from .env
DB_HOST = os.getenv("POSTGRES_HOST", "localhost")
DB_NAME = os.getenv("POSTGRES_DB", "cobalt_memory")
DB_USER = os.getenv("POSTGRES_USER", "postgres")
DB_PASS = os.getenv("POSTGRES_PASSWORD", "cobalt_password")

def wipe():
    print(f"üîå Connecting to database: {DB_NAME}...")
    conn_str = f"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:5432/{DB_NAME}"
    
    try:
        with psycopg.connect(conn_str, autocommit=True) as conn:
            # 1. Find the table name automatically
            res = conn.execute("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public';
            """).fetchall()
            
            if not res:
                print("‚ö†Ô∏è  No tables found in 'public' schema. Database is truly empty.")
                return

            # 2. Loop through and wipe them
            for row in res:
                table_name = row[0]
                print(f"üßπ Wiping table: {table_name}...")
                conn.execute(f"TRUNCATE TABLE {table_name};")
            
            print("‚ú® All memory tables wiped clean.")
            
    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    wipe()

========================================
FILE: docker-compose.yml
========================================

services:
  db:
    profiles: ["core"]
    image: pgvector/pgvector:pg16
    container_name: cobalt_memory
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    restart: always
    networks:
      - cobalt_net

  pgadmin:
    image: dpage/pgadmin4
    container_name: cobalt_viewer
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD}
    ports:
      - "18080:80"
    restart: always
    networks:
      - cobalt_net
    depends_on:
      - db

  mattermost:
    profiles: ["core"]
    image: mattermost/mattermost-enterprise-edition:latest
    platform: linux/amd64
    ports:
      - "8065:8065"
    environment:
      MM_SQLSETTINGS_DRIVERNAME: postgres
      MM_SQLSETTINGS_DATASOURCE: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}?sslmode=disable&connect_timeout=10
    depends_on:
      - db
    volumes:
      - mattermost_config:/mattermost/config
      - mattermost_data:/mattermost/data
    restart: unless-stopped
    networks:
      - cobalt_net

networks:
  cobalt_net:
    driver: bridge

volumes:
  mattermost_config:
  mattermost_data:


========================================
FILE: docs/0 - Inbox/Briefing_2026-02-24.md
========================================

# üå§Ô∏è Morning Briefing: 2026-02-24
*Generated at: 08:00*

### üßê Executive Summary
Markets showed mixed sentiment amid mixed economic signals, with tech stocks rallying on AI breakthrough news while energy sector lagged due to falling crude prices. Investor caution persisted ahead of the Fed's upcoming meeting, balancing optimism over earnings season with concerns about persistent inflation. Overall mood leaned cautiously optimistic with increased volatility in mid-cap sectors.

### üìà Market Pulse
Bullish on tech and AI-related equities; Bearish on energy and utilities; Neutral on financials pending rate clarity.

### üì∞ Top Headlines
- Tech Giant Announces Breakthrough in On-Device AI Model Efficiency
- Crude Oil Prices Drop 4.2% Amid Record US Inventory Build
- Fed Chair Signals Patience on Rate Cuts Despite Inflation Cooling
- FDA Approves First Gene Therapy for Rare Blood Disorder
- Auto Sales Fall 3.1% in Q2, Reflecting Consumer Caution

### üí° Strategic Thought
> If AI-driven productivity gains are real and accelerating, why are valuations in the sector still pricing in near-perfect execution‚Äîwhat if the market underestimates execution risk over innovation hype?


========================================
FILE: docs/0 - Inbox/Briefing_2026-02-25.md
========================================

# üå§Ô∏è Morning Briefing: 2026-02-25
*Generated at: 08:00*

### üßê Executive Summary
Markets opened with cautious optimism amid mixed economic indicators, as inflation data slightly beat expectations while labor market remains resilient. Sentiment was buoyed by strong tech earnings but tempered by geopolitical tensions and Fed commentary reinforcing a higher-for-longer rate outlook. Investors shifted toward defensive sectors while tech and energy led gains.

### üìà Market Pulse
Bullish ‚Äî The S&P 500 closed near its daily high on strong volume, with the 50-day MA crossing above the 200-day MA (golden cross), and RSI stabilizing above 50. Support levels at 4,700 held firmly, and sector rotation shows increasing momentum in tech and industrials.

### üì∞ Top Headlines
- Fed Chair Powell Signals Rates May Stay High Through 2024 Amid Sticky Inflation
- Tech Earnings Beat Expectations: Apple and Microsoft Report Strong Quarterly Growth
- Oil Prices Surge 3% on Middle East Escalation and OPEC+ Production Cuts
- Labor Department Reports Unemployment Rate Holds at 3.7%, Wages Rise 4.1% YoY
- SEC Proposes New Rules on AI Disclosure for Public Companies

### üí° Strategic Thought
> If the Fed‚Äôs 'higher for longer' narrative is now fully priced in, are we witnessing the last golden cross before a potential Q4 correction‚Äîespecially if inflation data unexpectedly re-accelerates?


========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-001 Hybrid Compute Strategy.md
========================================

---
title: "ADR-001 Hybrid Compute Strategy"
status: Active 
priority: P0
module: [Architecture]
phase: 1
complexity: M
tags: [cobalt, architecture, documentation, adr]
created: 2026-02-23
---

# ADR-001: Hybrid Compute Strategy

## Status: ACCEPTED

## Decision

We implement a **Hybrid Compute Strategy** with two distinct LLM paths:

### Dayshift (Fast Path)
- **Model**: Local 8B + Qwen 3 Coder
- **Use Cases**:
  - Chat interactions
  - Tool invocation routing
  - Simple queries
  - Real-time decision support
- **Characteristics**:
  - Low latency (< 2 seconds)
  - High throughput
  - Cost-effective for frequent requests

### Nightshift (Deep Reasoning Path)
- **Model**: DeepSeek 70B
- **Use Cases**:
  - Strategy backtesting
  - Complex market analysis
  - Multi-step reasoning tasks
  - Risk assessment calculations
- **Characteristics**:
  - High cognitive capability
  - Long context window
  - Higher latency acceptable for depth

## Architecture

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   User      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ   ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
              ‚îÇ  Cortex      ‚îÇ
              ‚îÇ  Router      ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ   ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Dayshift‚îÇ                     ‚îÇ Nightshift ‚îÇ
‚îÇ 8B +   ‚îÇ                     ‚îÇ DeepSeek   ‚îÇ
‚îÇ Qwen 3 ‚îÇ                     ‚îÇ   70B      ‚îÇ
‚îÇ (Fast) ‚îÇ                     ‚îÇ  (Deep)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Implementation Details

### Router Logic
1. **Fast Exit**: Check message length and complexity
   - < 4 words or contains "?" ‚Üí Dayshift
   - Contains "STRATEGY", "ANALYZE", "BACKTEST" ‚Üí Nightshift
   - Default: Use LLM classification

2. **Load Balancing**:
   - Monitor Dayshift queue latency
   - Overflow to Nightshift if Dayshift is busy

### Model Selection Criteria
| Criterion | Dayshift | Nightshift |
|-----------|----------|------------|
| Latency | < 2s | < 10s |
| Cost | $/token | $/token |
| Context | 128k | 128k+ |
| Reasoning | Low | High |

## Trade-offs

| Option | Pros | Cons |
|--------|------|------|
| Single Fast Model | Low latency | Poor deep reasoning, high cost |
| Single Deep Model | Excellent reasoning | Slow, expensive |
| Hybrid (Chosen) | Best of both | More complex routing |

## Next Steps

1. Implement Cortex router with LLM classification
2. Add queuing system for Nightshift requests
3. Add metrics dashboard for model usage
4. Implement fallback logic for model failures

## References

- [Qwen 3 Coder Documentation](https://qwenlm.github.io/)
- [DeepSeek API Documentation](https://api-docs.deepseek.com/)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-002 Cobalt-Ion Distributed Protocol.md
========================================

---
title: "ADR-002 Cobalt-Ion Distributed Protocol"
status: Active 
priority: P0
module: [Architecture]
phase: 1
complexity: M
tags: [cobalt, architecture, documentation, adr]
created: 2026-02-23
---

# ADR-002: Cobalt-Ion Distributed Protocol

## Status: ACCEPTED

## Decision

We implement a **Distributed Actor Model** using high-speed message brokers:

### Components

#### Cobalt (Mac - Python)
- **Role**: Chief of Staff, Router, Decision Maker
- **Technologies**: Python, FastAPI, Redis Pub/Sub, ZeroMQ
- **Responsibilities**:
  - LLM integration
  - Department routing
  - Tool orchestration
  - Memory management
  - Strategy execution

#### Ion (Windows - Rust)
- **Role**: Visualization, UI, Real-time Updates
- **Technologies**: Rust, Redis Pub/Sub, ZeroMQ
- **Responsibilities**:
  - Chart rendering
  - Order entry UI
  - Real-time price updates
  - Alert notifications
  - Human interaction

### Communication Protocol

**Format**: JSON payloads over message brokers

**Channels**:
```
cobalt‚Üíion:routing       Cortex ‚Üí Ion: Route user input
cobalt‚Üíion:execute       Cortex ‚Üí Ion: Execute tool
ion‚Üícobalt:notification  Ion ‚Üí Cortex: User action
ion‚Üícobalt:heartbeat     Ion ‚Üí Cortex: Health check
```

## Architecture

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    Mac        ‚îÇ
                    ‚îÇ   Cobalt      ‚îÇ
                    ‚îÇ   (Python)    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ   ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Message Broker    ‚îÇ
              ‚îÇ   (Redis/ZeroMQ)    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ   ‚îÇ      ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ   ‚îî‚îÄ‚îê    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Ion    ‚îÇ  ‚îÇ Ion    ‚îÇ  ‚îÇ ‚îÇ  Ion   ‚îÇ
‚îÇ (Rust) ‚îÇ  ‚îÇ (Rust) ‚îÇ  ‚îÇ ‚îÇ (Rust) ‚îÇ
‚îÇ Windows‚îÇ  ‚îÇ Windows‚îÇ  ‚îÇ ‚îÇ Windows‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ   Redis    ‚îÇ
                  ‚îÇ  Pub/Sub   ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Implementation Details

### Cobalt (Python) - Publisher/Subscriber
```python
import redis
import json

class CobaltBroker:
    def __init__(self):
        self.redis = redis.Redis(host='localhost', port=6379)
        self.channel = 'cobalt/ion'
    
    def publish_routing(self, data: dict) -> None:
        self.redis.publish(self.channel, json.dumps({
            'type': 'routing',
            'payload': data
        }))
    
    def subscribe_notifications(self, callback):
        pubsub = self.redis.pubsub()
        pubsub.subscribe('ion/cobalt')
        for message in pubsub.listen():
            callback(message)
```

### Ion (Rust) - Subscriber/Publisher
```rust
use redis::{Connection, Commands};

struct IonBroker {
    conn: Connection,
    channel: String,
}

impl IonBroker {
    fn new() -> Self {
        let conn = redis::Connection::connect("redis://localhost:6379").unwrap();
        IonBroker {
            conn,
            channel: "ion/cobalt".to_string(),
        }
    }
    
    fn subscribe(&mut self) {
        self.conn.subscribe(&"cobalt/ion").unwrap();
    }
    
    fn publish(&mut self, data: &str) {
        self.conn.publish("ion/cobalt", data).unwrap();
    }
}
```

## Trade-offs

| Option | Pros | Cons |
|--------|------|------|
| REST API | Simple, HTTP compatible | High latency, synchronous |
| Message Brokers (Chosen) | Low latency, async, scalable | More complex setup |

## Next Steps

1. Implement Redis Pub/Sub in Python Cortex
2. Implement ZeroMQ bindings in Rust Ion
3. Create message schemas
4. Add reconnection logic

## References

- [Redis Pub/Sub Documentation](https://redis.io/docs/manual/pubsub/)
- [ZeroMQ Documentation](https://zeromq.org/documentation/)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-003 Python-First Architecture.md
========================================

---
title: "ADR-003 Python-First Architecture"
status: Active 
priority: P0
module: [Architecture]
phase: 1
complexity: M
tags: [cobalt, architecture, documentation, adr]
created: 2026-02-23
---

# ADR-003: Python-First Architecture

## Status: ACCEPTED

## Decision

We will use **Python (FastAPI)** for the Cobalt agent and **Rust** for the Ion HUD client.

* **Cobalt (Mac)**: Python FastAPI for the core agent system (orchestration, LLM integration, routing, tool execution)
* **Ion (Windows)**: Rust for the real-time trading visualization and UI
* **Reasoning**: Python provides the fastest development velocity and best LLM integration ecosystem. Rust provides safe, high-performance UI rendering.

## Architecture

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    Mac        ‚îÇ
                    ‚îÇ   Cobalt      ‚îÇ
                    ‚îÇ   (Python)    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ   ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Message Broker    ‚îÇ
              ‚îÇ   (Redis/ZeroMQ)    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ   ‚îÇ      ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ   ‚îî‚îÄ‚îê    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Ion    ‚îÇ  ‚îÇ Ion    ‚îÇ  ‚îÇ ‚îÇ  Ion   ‚îÇ
‚îÇ (Rust) ‚îÇ  ‚îÇ (Rust) ‚îÇ  ‚îÇ ‚îÇ (Rust) ‚îÇ
‚îÇ Windows‚îÇ  ‚îÇ Windows‚îÇ  ‚îÇ ‚îÇ Windows‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ   Redis    ‚îÇ
                  ‚îÇ  Pub/Sub   ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Implementation Details

### Cobalt (Python)
- FastAPI for HTTP endpoints
- LangChain for LLM integration
- Pydantic for data validation
- Redis/ZeroMQ for IPC with Ion

### Ion (Windows - Rust)
- tauri or egui for GUI
- High-performance rendering
- Windows API access for system integration
- Redis/ZeroMQ client for communication

## Trade-offs

| Option | Pros | Cons |
|--------|------|------|
| Single Language | Simpler tooling | Limited technology choice |
| Multi-Language (Chosen) | Best of both worlds | IPC complexity |

## Next Steps

1. Implement FastAPI endpoints in Python Cobalt
2. Create Rust Ion client library
3. Add message queue for reliability
4. Implement health check/heartbeat mechanism

## References

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Rust GUI Documentation](https://github.com/egui-rs/egui)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-004 Zero Trust Security.md
========================================

---
title: "ADR-004 Zero Trust Security"
status: Active 
priority: P0
module: [Security]
phase: 1
complexity: M
tags: [cobalt, security, architecture, documentation, adr]
created: 2026-02-23
---

# ADR-004: Zero Trust Security

## Status: ACCEPTED

## Decision

We implement a **Zero Trust Security Model** with three layers:

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Human-In-The-Loop ‚îÇ
                    ‚îÇ  Proposal Engine   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Docker Seccomp       ‚îÇ
                    ‚îÇ  Sandbox              ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  LastPass JIT         ‚îÇ
                    ‚îÇ  Credential Manager   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Layer 1: Human-In-The-Loop (HITL) Proposal Engine

### Overview
All high-risk operations require human approval before execution.

### Approval Flow
```
1. Agent proposes action
   ‚îú‚îÄ Trade execution
   ‚îú‚îÄ Code execution
   ‚îî‚îÄ Credential access

2. Generate approval request (Pydantic model)
   ‚îú‚îÄ Action type
   ‚îú‚îÄ Parameters
   ‚îú‚îÄ Risk assessment
   ‚îî‚îÄ Justification

3. Wait for human approval (via Mattermost/CLI)
   ‚îú‚îÄ Timeout: 5 minutes
   ‚îî‚îÄ Auto-reject if no response

4. Execute only if approved
```

### Pydantic Models
```python
class ApprovalRequest(BaseModel):
    request_id: str
    action_type: str  # "TRADE", "CODE_EXEC", "CREDENTIAL_ACCESS"
    parameters: Dict[str, Any]
    risk_level: str   # "LOW", "MEDIUM", "HIGH"
    justification: str
    timestamp: datetime

class ApprovalResponse(BaseModel):
    approved: bool
    approver: str
    timestamp: datetime
    comments: Optional[str]
```

## Layer 2: Docker Seccomp Sandboxes

### Overview
All code execution runs in isolated Docker containers with strict seccomp profiles.

### Container Configuration
```yaml
security_opt:
  - seccomp:./seccomp/profile.json
  - no-new-privileges:true

read_only: true

network_mode: none

privileged: false

user: "1000:1000"
```

### Seccomp Profile
- Only allows: `read`, `write`, `open`, `close`, `stat`, `fstat`
- Blocks: `socket`, `connect`, `execve`, `ptrace`
- Allows network only for specific tools (browser, search)

## Layer 3: LastPass JIT Credential Management

### Overview
Credentials are retrieved just-in-time, never stored in plaintext.

### JIT Flow
```
1. Agent requests credential access
2. LastPass API called with:
   ‚îú‚îÄ User authentication
   ‚îú‚îÄ Justification (for audit)
   ‚îî‚îÄ TTL (time-to-live)

3. LastPass returns temporary credential
   ‚îú‚îÄ Valid for 5 minutes
   ‚îú‚îÄ Single-use or limited uses
   ‚îî‚îÄ Audit log created

4. Credential used and discarded
   ‚îú‚îÄ Credential deleted from memory
   ‚îî‚îÄ Audit log updated
```

### API Integration
```python
class LastPassClient:
    def get_credential(self, vault_id: str, justification: str) -> Credential:
        response = requests.post(
            f"{self.api_url}/jit-credential",
            json={
                "vault_id": vault_id,
                "justification": justification,
                "ttl_minutes": 5
            }
        )
        return Credential.parse(response.json())
```

## Implementation Details

### Approval Engine
- Runs as separate module in Cortex
- Uses Mattermost as approval interface
- Tracks approval status in memory

### Docker Sandbox
- Uses `docker-py` SDK
- Creates containers on-demand
- Cleans up after execution

### JIT Credential Manager
- LastPass API integration
- Credential caching (short-term)
- Automatic cleanup

## Trade-offs

| Option | Pros | Cons |
|--------|------|------|
| No Sandbox | Fast | Security risk |
| Full Sandbox (Chosen) | Secure | Slightly slower, complexity |

## Next Steps

1. Implement Pydantic approval models
2. Create Mattermost approval UI
3. Build Docker sandbox runner
4. Integrate LastPass JIT API

## References

- [Docker Seccomp Documentation](https://docs.docker.com/engine/security/seccomp/)
- [LastPass API Documentation](https://developer.lastpass.com/)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-005 Agentic RAG.md
========================================

---
title: "ADR-005 Agentic RAG"
status: Active 
priority: P0
module: [Architecture]
phase: 1
complexity: M
tags: [cobalt, architecture, documentation, adr]
created: 2026-02-23
---

# ADR-005: Agentic RAG - Memory as a Tool

## Status: ACCEPTED

## Decision

We implement an **Agentic RAG (Retrieval-Augmented Generation)** system using **Memory as a Tool** rather than passive context injection.

### Architecture
```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   User Query ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
                        ‚îÇ       ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
              ‚îÇ   Query     ‚îÇ   ‚îÇ
              ‚îÇ   Encoder   ‚îÇ   ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                  ‚îÇ ‚îÇ ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ           ‚îÇ        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Postgres  ‚îÇ ‚îÇVector‚îÇ ‚îÇ  Agentic‚îÇ
‚îÇ   pgvector ‚îÇ ‚îÇSearch‚îÇ ‚îÇ  RAG    ‚îÇ
‚îÇ  (Storage) ‚îÇ ‚îÇEngine‚îÇ ‚îÇ  Tool   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ           ‚îÇ        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Generated        ‚îÇ
        ‚îÇ   Response         ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Components

#### 1. Postgres/pgvector Database
- Stores all conversation logs with vector embeddings
- Uses cosine similarity for search
- Indexes on timestamp and source

#### 2. Vector Search Engine
- Converts query to embedding
- Retrieves similar memories by semantic similarity
- Applies temporal and relevance filters

#### 3. Agentic RAG Tool
- Memory retrieval as a callable tool
- Context-aware query routing
- Dynamic memory injection into prompts

### Memory Rules
| Rule Type | Behavior |
|-----------|----------|
| **PREFERENCE** | Keep forever (e.g., "I like TSLA") |
| **MARKET CONTEXT** | Expire after 24 hours |
| **SESSION** | Expire after conversation ends |

## Implementation Details

### Database Schema
```sql
CREATE TABLE memory_logs (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    source VARCHAR(255),
    message TEXT,
    data JSONB,
    embedding VECTOR(768)
);

CREATE INDEX idx_memory_embedding ON memory_logs 
USING ivfflat (embedding vector_cosine_ops);
```

### Python Interface
```python
class AgenticRAG:
    def __init__(self, db_url: str):
        self.engine = create_engine(db_url)
        self.session = Session()
    
    def store_memory(self, message: str, source: str, data: dict):
        embedding = self._generate_embedding(message)
        self.session.add(MemoryLog(
            message=message,
            source=source,
            data=data,
            embedding=embedding
        ))
        self.session.commit()
    
    def search_memories(self, query: str, limit: int = 10) -> List[Dict]:
        query_embedding = self._generate_embedding(query)
        results = self.session.execute(
            """
            SELECT message, source, data, 
                   1 - (embedding <=> :query_embedding) as similarity
            FROM memory_logs
            WHERE timestamp > NOW() - INTERVAL '24 hours'
            ORDER BY similarity DESC
            LIMIT :limit
            """,
            {"query_embedding": query_embedding, "limit": limit}
        )
        return results.fetchall()
```

### Memory Filter Rules
```python
def filter_memories(memories: List[Dict], context: Dict) -> List[Dict]:
    # Remove stale memories
    filtered = [m for m in memories 
                if not _is_stale(m, context)]
    
    # Apply relevance threshold
    return [m for m in filtered if m['similarity'] > 0.5]
```

## Trade-offs

| Option | Pros | Cons |
|--------|------|------|
| Keyword Search | Fast | Poor semantic understanding |
| Full RAG (Chosen) | High quality retrieval | Requires vector storage |

## Next Steps

1. Set up Postgres with pgvector extension
2. Implement embedding generation
3. Create memory filter rules engine
4. Integrate RAG into PromptEngine

## References

- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Retrieval-Augmented Generation Paper](https://arxiv.org/abs/2005.11401)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-006 Prime Directive and HITL.md
========================================

---
title: "ADR-006 Prime Directive and HITL"
status: Active
priority: P0
module: [Architecture, Security]
phase: 2
complexity: M
tags: [cobalt, architecture, documentation, adr, security]
created: 2026-02-23
---

# ADR-006: Prime Directive and Human-In-The-Loop (HITL) Core Personality

## Status: ACCEPTED

## Decision
We are explicitly binding the Cobalt Agent's personality to a "Zero Trust" and "Proposal Engine" framework via configuration-as-code (`config.yaml`). Cobalt will operate under a strict Prime Directive: it cannot execute destructive, financial, or system-altering commands autonomously. 

## Context
Previously, Cobalt's directives were generic ("Protect capital", "Analyze data"). To achieve enterprise-grade security, the system prompt must fundamentally restrict the agent's autonomy at the personality level, forcing it to generate a "proposal" for the human operator rather than taking unilateral action.

## Implementation Details
1.  **Configuration Driven:** The Prime Directive is injected via the `persona.directives` list in `config.yaml`.
2.  **Prompt Engine Integration:** The existing `prompt.py` will automatically parse these new directives and construct the system prompt.
3.  **The Proposal Engine Hook:** The agent is explicitly instructed to draft proposals and await cryptographic authorization for high-stakes tasks.

## Trade-offs
| Option | Pros | Cons |
|--------|------|------|
| Hardcoded Python Logic | Unbreakable | Violates decoupled architecture |
| Config-Driven (Chosen) | Flexible, maintains separation of concerns | Relies on LLM adherence to prompt |

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-007 HITL Proposal Engine.md
========================================

---
title: "ADR-007 HITL Proposal Engine"
status: Active
priority: P0
module: [Cortex, Security]
phase: 3
complexity: L
tags: [cobalt, architecture, security, hitl]
created: 2026-02-23
---

# ADR-007: Human-in-the-Loop (HITL) Proposal Engine

## Status: ACCEPTED

## Decision
We will implement a standardized `Proposal` Pydantic model that the Cortex must generate for any "High-Stakes" action. A high-stakes action is defined as any command that modifies the file system, executes code, or initiates a financial transaction.

## Context
The current routing logic in `cortex.py` is susceptible to keyword misclassification (e.g., mistaking "NVIDIA files" for a "TACTICAL" trading query). By forcing a "Proposal" step, the agent must pause, summarize the risk, and await a cryptographic token (or manual 'YES' in the short term) before proceeding.

## Implementation Details
1. **Middleware Layer**: A new validation step in `cortex.py` that checks the "Risk Level" of a classified task.
2. **Standardized Model**: All proposals will include:
   - `task_id`: Unique identifier.
   - `action`: The raw command to be executed.
   - `justification`: Why the agent thinks this is necessary.
   - `risk_assessment`: A summary of what could go wrong (e.g., "Permanent data loss").
3. **Approval Flow**: The agent will post the proposal to Mattermost and wait for the user to respond with "Approve [task_id]".

## Next Steps
- Define the `Proposal` model in a new `src/cobalt_agent/core/proposals.py` file.
- Update `cortex.py` to utilize this model for any non-read-only tasks.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-008 JIT Secrets Vault.md
========================================

---
title: "ADR-008 JIT Secrets Vault"
status: Active
priority: P0
module: [Security, Core]
phase: 4
complexity: M
tags: [cobalt, architecture, security, secrets]
created: 2026-02-24
---

# ADR-008: Just-In-Time (JIT) Secrets Architecture

## Status: ACCEPTED

## Decision
We will transition away from static `.env` files for high-privilege API keys (e.g., TradeStation, OpenAI). Instead, we will implement a local, encrypted "Vault" service. The Cobalt Agent will request credentials "Just-In-Time" at runtime, hold them in RAM only for the duration of the execution context, and never log or write them to disk.

## Context
While the `.env` file is excluded from Git, storing static, long-lived credentials on the hard drive represents a single point of failure. By moving to a Vault architecture, we ensure that if the Cobalt script is hijacked, the attacker only gains access to an isolated process, not the master keys to the financial or cloud infrastructure.

## Implementation Details
1. **The Vault Daemon:** A highly restricted, independent process running on the Mac Studio that holds the encrypted keys.
2. **The Request Protocol:** Cobalt's `config.py` will be modified to request keys via an internal socket/API rather than reading `os.getenv`.
3. **RAM Only:** Credentials will be explicitly scrubbed from Pydantic models when serialized, ensuring they never leak into the Postgres Memory database.

## Trade-offs
| Option | Pros | Cons |
|--------|------|------|
| HashiCorp Vault | Industry standard | Overkill/too heavy for local node |
| Local Encrypted Daemon | Lightweight, fast | Requires custom implementation |

*Decision:* We will build a lightweight Local Encrypted Daemon specifically tuned for the Cobalt architecture.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ADR/ADR-009 Headless Browser Strategy.md
========================================

---
title: "ADR-009 Headless Browser Strategy"
status: Active
priority: P1
module: [Architecture, Tools]
phase: 5
complexity: M
tags: [cobalt, architecture, documentation, adr, playwright]
created: 2026-02-25
---

# ADR-009: Headless Browser Strategy (Playwright)

## Status: ACCEPTED

## Decision
We will deprecate the use of `requests` + `BeautifulSoup` for the primary `BrowserTool` and adopt **Microsoft Playwright** (`playwright-python`) using a synchronous, headless Chromium instance. We will also implement a JSON-based DSL (Domain Specific Language) allowing the LLM to dictate browser actions (clicks, fills).

## Context
The legacy scraping approach failed on Single Page Applications (SPAs) and sites requiring basic interaction (closing modals, logging in). To make Cobalt a true Chief of Staff, it requires the ability to drive a browser session. 

## Implementation Details
1. **Engine:** Playwright Chromium (Headless).
2. **Input Parsing:** The `run` method will attempt to parse the LLM's query as JSON. If it fails, it gracefully falls back to treating the query as a raw URL.
3. **Action Loop:** Iterates through a defined `actions` array (e.g., `[{"type": "fill", "selector": "#username", "text": "admin"}]`) and executes them sequentially using Playwright's built-in auto-waiting mechanisms.

## Trade-offs
| Option | Pros | Cons |
|--------|------|
| Requests/BS4 | Extremely fast, lightweight | Cannot run JS, cannot interact |
| Selenium | Industry standard, wide support | Heavy, brittle waiting logic |
| Playwright (Chosen) | Excellent auto-waiting, fast, modern | Requires downloading Chromium binaries |

*Decision:* Playwright's native auto-waiting (waiting for elements to be actionable before clicking) makes it vastly superior for LLM-driven execution, as the LLM cannot natively "see" if an element has rendered yet.

## Files Changed
- `src/cobalt_agent/tools/browser.py` - Complete rewrite using Playwright

## Dependencies Added
- `playwright` (via `uv add playwright`)
- `chromium` browser binaries (via `uv run playwright install chromium`)

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/ARCHITECTURE_ASSESSMENT.md
========================================

---
title: "Project Cobalt Architecture Assessment"
status: Active
priority: P0
module: [Architecture]
phase: 1
complexity: L
tags: [cobalt, architecture, master_plan]
created: 2026-02-23
---

# ARCHITECTURE ASSESSMENT: Project Cobalt
**Date:** February 2026
**Status:** Alpha / Proof of Concept
**Focus:** Enterprise-Grade Autonomous Trading & Chief of Staff System

## 1. Executive Summary
Project Cobalt has successfully established its "Nervous System" and "Memory." The core event loop is decoupled, allowing asynchronous communication via Mattermost, while the brain utilizes a robust LiteLLM abstraction layer mapped to local and cloud models. The architecture strictly enforces type-safety via Pydantic and relies on configuration-as-code (YAML) for strategy and system parameters. 

## 2. Current Strengths (The Foundation)
* **Decoupled C2 Interface:** The `mattermost.py` implementation successfully uses `asyncio.to_thread` to maintain a persistent WebSocket connection without blocking the primary LLM inference loop.
* **Agentic RAG Foundation:** `postgres.py` successfully utilizes `pgvector` to store both textual logs and high-dimensional semantic embeddings, creating a persistent "Hippocampus" that can be queried conceptually.
* **Config-Driven Playbooks:** The `Playbook` and `SecondDayPlay` modules load dynamic scoring weights from `strategies.yaml`, avoiding hardcoded logic and enabling future autonomous modification.
* **LLM Abstraction:** The `llm.py` module elegantly wraps `litellm`, exposing a strict `ask_structured` method that guarantees JSON/Pydantic compliance for complex agent reasoning.

## 3. Technical Debt & Immediate Gaps
* **Routing Brittleness:** The current `cortex.py` and `mattermost.py` routing relies on hardcoded keyword bypasses (e.g., `if "?" in text`). This must be replaced with a localized "Switchboard" LLM router.
* **Missing Execution Hands:** The system currently lacks a sandboxed Code Execution Tool (Docker/Seccomp) to safely run Python scripts.
* **Missing "Touch" (Playwright):** Browser capability is currently limited to raw text scraping. A Playwright-based tool is required for dynamic web interaction and complex scraping.
* **Missing Secrets Management:** Integration with a Vault/LastPass API is required to facilitate Just-In-Time (JIT) credential injection without hardcoding keys.
* **Proposal Engine:** There is no standardized Pydantic schema for the AI to request "Google Auth" permission before executing a high-risk task.

## 4. Target State Architecture
* **The MoA (Mixture of Agents) Engine:**
    * **Dayshift:** Lightning-fast local models (e.g., Qwen-Coder) handling chat, tool routing, and basic operations.
    * **Nightshift:** Heavyweight local reasoning models (DeepSeek 70B) utilized for asynchronous strategy backtesting and complex data analysis.
    * **Cloud Escalation:** High-tier models (Gemini 3.1 / Opus) used only when local sandbox attempts fail gracefully.
* **The Execution Split (Cobalt/Ion):** Python acts as the strategic orchestrator (Cobalt), dispatching mathematical configurations to a hyper-fast Windows execution client (Ion).
* **Zero Trust (ZTA):** All system modifications and external actions proposed by Cobalt are halted at a Privilege Boundary, requiring asynchronous Human-in-the-Loop (HITL) cryptographic approval.

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/brain_scan.md
========================================

---
title: "Brain Scan Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[postgres]]"
location: "dev_utils/brain_scan.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Brain Scan Script

**Location:** `dev_utils/brain_scan.py`

## Overview

Brain Scan is a diagnostic tool that performs a comprehensive health check on the PostgreSQL memory database. It verifies schema integrity, checks for vector embeddings, and confirms content storage.

## Usage

```bash
python dev_utils/brain_scan.py
```

Or with uv:

```bash
uv run python dev_utils/brain_scan.py
```

## Behavior

The script connects to the PostgreSQL database and performs the following checks:

### 1. Schema Verification
- Lists all columns in the `memory_logs` table
- Identifies if a `vector` or `embedding` column exists
- Reports if semantic search is possible

### 2. Content Audit
- Retrieves the last 20 memory entries
- Shows embedding status for each record
- Verifies specific content (e.g., "TSLA") exists in the database

### 3. Diagnosis Report
Outputs a summary with:
- **Schema Health**: Whether vector columns exist
- **Content Status**: Whether expected content is present
- **Embedding Status**: Whether embeddings are populated

## Example Output

```
üî¨ Scanning Database: cobalt_memory

üìã Schema for 'memory_logs':
   - id (integer)
   - timestamp (timestamp without time zone)
   - source (text)
   - content (text)
   - embedding (vector)

--- DIAGNOSIS ---
‚úÖ 'TSLA' memory FOUND.
```

## Destructive Warnings

‚ö†Ô∏è **This is a READ-ONLY diagnostic script** - it does not modify the database. However, if the `embedding` column does not exist, semantic search will be impossible, and you may need to run an embedding generation script.

## Dependencies

- `psycopg` - PostgreSQL client library
- `python-dotenv` - Environment variable loading

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/browser.md
========================================

---
title: "Browser Tool Documentation"
status: Active
module: Tool
type: Class
dependencies:
  - "[[tool_manager]]"
location: "src/cobalt_agent/tools/browser.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Browser Tool Module

**Location:** `src/cobalt_agent/tools/browser.py`

## Overview

Browser Tool visits URLs and extracts clean text content. Returns structured Pydantic models.

## Class: `WebPageContent` (Pydantic Model)

Structured content from a visited webpage.

### Fields

| Field | Type | Description |
|--|--|--|
| `url` | `str` | The source URL |
| `title` | `str` | The page title |
| `content` | `str` | The cleaned text content |
| `error` | `str` | Error message if fetch failed (default: "") |

### Methods

#### `__str__() -> str`
Returns a summary string for LLM consumption. Truncates content to 4000 characters.

---

## Class: `BrowserTool`

Fetches and cleans text from URLs.

### Attributes

| Attribute | Value |
|--|--|
| `name` | `"browser"` |
| `description` | `"Visit a webpage and extract its content. Use for reading articles, documents, or online content."` |
| `headers` | User-Agent header for requests |

### Methods

#### `run(url: str) -> WebPageContent`

Fetches and cleans text from a URL.

**Parameters:**
- `url`: The URL to visit

**Returns:** `WebPageContent` with title, content, or error

**Workflow:**
1. Fetch page with requests and User-Agent header
2. Parse HTML with BeautifulSoup
3. Extract title and clean text (remove scripts, styles, nav, footer)
4. Return structured WebPageContent

**Error Handling:**
- Returns WebPageContent with error field populated on exception
- Timeout: 10 seconds

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/cli.md
========================================

---
title: "CLI Interface Documentation"
status: Active
module: Interface
type: Class
dependencies:
  - "[[main]]"
  - "[[memory_core]]"
  - "[[tool_manager]]"
  - "[[cortex]]"
location: "src/cobalt_agent/interfaces/cli.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# CLI Interface Module

**Location:** `src/cobalt_agent/interfaces/cli.py`

## Overview

Interactive Command-Line Interface for Cobalt Agent with centralized routing and RAG (Retrieval Augmented Generation).

## Class: `CLI`

Interactive command-line interface for Cobalt Agent.

### Constructor

```python
CLI(memory_system, llm, system_prompt, tool_manager, cortex=None)
```

**Parameters:**
- `memory_system`: Memory system for storing conversation history
- `llm`: LLM instance for inference
- `system_prompt`: System prompt for the agent
- `tool_manager`: ToolManager instance for tool execution
- `cortex`: Optional Cortex instance for routing

### Methods

#### `start()`
Start the interactive CLI loop. Displays agent info and prompts for user input.

#### `_handle_chat(user_input: str)`
Autonomous Agent Loop (ReAct Pattern) for general analysis.

1. Retrieve long-term memory (RAG)
2. Inject memory into system prompt
3. Run LLM with tool execution loop (max 5 turns)
4. Handle tool calls and observations

#### `_retrieve_long_term_memory(query: str) -> str`
Fetches relevant past memories from the memory system for RAG.

**Parameters:**
- `query`: User query to search for relevant memories

**Returns:** Formatted string of top 5 unique memories

#### `_format_tool_output(output: Any) -> str`
Helper to convert Pydantic models/Lists to clean strings.

---

## Features

- **Centralized Routing**: Delegates to Cortex for specialized tasks
- **RAG Integration**: Retrieves relevant long-term memory for context
- **Auto-Tool**: LLM can trigger tool calls automatically
- **Memory Management**: Maintains short-term RAM (10 entries) and long-term storage

---

## Usage

```python
from cobalt_agent.interfaces.cli import CLI

cli = CLI(memory_system, llm, system_prompt, tool_manager, cortex)
cli.start()

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/config.md
========================================

---
title: "Configuration Management Documentation"
status: Active
module: Core
type: Class
dependencies:
  - "[[persona]]"
location: "src/cobalt_agent/config.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Configuration Management

## Overview
The Configuration Management system provides type-safe, multi-source configuration for the Cobalt Agent using Pydantic Settings and YAML files. It supports environment variable overrides and dynamic config loading.

## Core Components

### Configuration Loading Priority
1. **Environment Variables** (highest priority) - Strictly for node/Docker specific data like `POSTGRES_HOST`, `NODE_ID`, etc.
2. **Secure Vault** (dynamically injected) - API keys and tokens injected from the VaultManager at runtime
3. **YAML Configuration Files** (configs/*.yaml) - Static configuration like `trading_rules`, `persona`, etc.
4. **Default Values** (lowest priority)

### Environment Variable Mapping
- Simple fields: `UPPER_CASE` converts to `lower_case_with_underscores`
- Nested fields: `POSTGRES_HOST` maps to `postgres.host` via `env_nested_delimiter="_"`

## Classes

### `CobaltSettings` (Main Configuration Class)
The primary configuration class that loads from YAML and environment variables.

**Configuration Source (in priority order):**
1. `.env` file and OS environment variables (for node-specific values)
2. Secure Vault (AES-256 encrypted, injected at runtime via `COBALT_MASTER_KEY`)
3. `configs/config.yaml` and other YAML files (static configuration)
4. Default values defined in Pydantic models

**Attributes:**
- `system`: System-level configuration
- `llm`: LLM provider settings
- `persona`: Agent personality and behavior
- `trading_rules`: Trading strategy parameters
- `postgres`: PostgreSQL database settings
- `mattermost`: Mattermost communication settings

### `SystemConfig`
System-level configuration settings.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `debug_mode` | `bool` | `False` | Enable debug logging |
| `version` | `str` | `"0.1.0"` | Application version |
| `obsidian_vault_path` | `str` | `"/default/obsidian/vault/path"` | Path to Obsidian vault |

### `LLMConfig`
LLM provider configuration.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `model_name` | `str` | `"gemini/gemini-1.5-pro"` | Model identifier |
| `api_key` | `Optional[str]` | `None` | API key for provider |

### `PersonaConfig`
Agent persona configuration.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `name` | `str` | `"Cobalt"` | Agent name |
| `roles` | `list[str]` | `[]` | Agent roles |
| `skills` | `list[str]` | `[]` | Agent capabilities |
| `tone` | `list[str]` | `[]` | Communication tone |
| `directives` | `list[str]` | `[]` | Core behavioral rules |

### `PostgresConfig`
PostgreSQL database connection settings.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `host` | `str` | `"localhost"` | Database host |
| `port` | `int` | `5432` | Database port |
| `db` | `str` | `"cobalt_memory"` | Database name |
| `user` | `str` | `"postgres"` | Database user |
| `password` | `Optional[str]` | `None` | Database password |

### `MattermostConfig`
Mattermost communication settings.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `url` | `Optional[str]` | `None` | Mattermost URL |
| `token` | `Optional[str] | `None` | Authentication token |
| `scheme` | `str` | `"http"` | URL scheme |
| `port` | `int` | `8065` | Port number |

## Functions

### `load_config(config_dir: Optional[Path | str] = None) -> CobaltSettings`
Load configuration from YAML files and merge with environment variables.

**Parameters:**
- `config_dir`: Path to configuration directory (default: `configs/`)

**Returns:**
- `CobaltSettings`: Loaded configuration

### `get_config() -> CobaltSettings`
Convenience function to get singleton configuration.

**Returns:**
- `CobaltSettings`: Current configuration

### `get_current_node_role() -> Optional[str]`
Determine the role of the current node based on network configuration.

**Returns:**
- `str`: Node role if found, otherwise `None`

## Configuration File Structure

### `configs/config.yaml`
Main configuration file with the following sections:

```yaml
system:
  debug_mode: false
  version: "0.1.0"
  obsidian_vault_path: "/path/to/vault"

llm:
  model_name: "gemini/gemini-1.5-pro"
  api_key: "${LLM_API_KEY}"

persona:
  name: "Cobalt"
  roles:
    - "Market Analyst"
    - "Trading Assistant"
  tone:
    - "Professional"
    - "Analytical"
  directives:
    - "Use tools for real-time data"
    - "Trust tool results over assumptions"

postgres:
  host: "localhost"
  port: 5432
  db: "cobalt_memory"

mattermost:
  url: "https://mattermost.example.com"
  token: "${MATTERMOST_TOKEN}"
```

## Error Handling
- Invalid YAML files are logged and skipped
- Missing configuration files use defaults
- Environment variable parsing errors are logged
- Configuration validation errors are caught and reported

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/cortex.md
========================================

---
title: "Cortex Documentation"
status: Active
module: Brain
type: Orchestrator
dependencies:
  - "[[main]]"
  - "[[tactical]]"
  - "[[llm]]"
  - "[[prompt]]"
location: "src/cobalt_agent/main.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Cortex (The Chief of Staff)

## Overview
Cortex is the central routing and coordination agent for the Cobalt system. It acts as the "Chief of Staff" that routes user requests to the appropriate specialized department (Tactical, Intel, Ops, Engineering) based on the user's intent.

### Zero Trust Architecture
Under the Prime Directive (ADR-006), Cortex implements a **High-Risk Intercept** pattern that enforces Human-in-the-Loop (HITL) approval for any high-stakes actions before execution. This ensures Zero Trust: no destructive, financial, or system-altering commands execute without explicit human approval.

## Class: `Cortex`

### Constructor
```python
def __init__(self)
```
Initializes Cortex with configuration from `config.yaml`, loads departments, and initializes the LLM instance.

### Key Attributes
- `config`: Loaded configuration from `configs/config.yaml`
- `departments`: Dictionary of active departments from config
- `llm`: LLM instance for classification and routing decisions

### Main Methods

#### `route(user_input: str) -> Optional[str]`
Routes user input to the appropriate department handler.

**Logic:**
1. Fast exit for simple greetings (< 4 words, "hi")
2. Direct bypass for questions (? or keywords: price, what)
3. Classify domain using LLM
4. Route to department handler (Tactical, Intel, Ops, Engineering, Foundation)

**Returns:**
- String response from department handler, or `None` for general chat (Foundation)

#### `_classify_domain(user_input: str) -> DomainDecision`
Uses LLM to classify user input into a domain and extract task parameters.

**Returns:** `DomainDecision` Pydantic model with:
- `domain_name`: The department name (e.g., "TACTICAL", "OPS")
- `reasoning`: Why this domain was selected
- `task_parameters`: The action item or query

### Department Handlers

#### `_run_tactical(params: str) -> str`
Routes to `Strategos` for trading and market data tasks.

**Handles:**
- Stock price queries (extracts ticker symbol)
- Strategy queries (when "STRATEGY" or "PLAYBOOK" is mentioned)

#### `_run_intel(params: str) -> str`
Routes to Research/Briefing skills.

**Handles:**
- "briefing" ‚Üí `MorningBriefing().run()`
- Other ‚Üí `DeepResearch().run(params)`

#### `_run_ops(params: str, original_input: str) -> str`
Routes to Scribe (Operations/Scribe) for logging, saving, and searching.

**Handles:**
- "log"/"journal" ‚Üí Append to daily note
- "save"/"note" ‚Üí Create new note
- "search"/"find" ‚Üí Search vault
- "medical"/"billing" ‚Üí Placeholder for future Steward logic

### `_generate_proposal(user_input: str) -> str`
Generates a Proposal using LLM synthesis for high-risk actions.

**Purpose:**
The Prime Directive FORBIDS autonomous execution of high-risk actions. This method:
1. Detects high-risk keywords in user input
2. Calls LLM to synthesize a structured JSON proposal
3. Extracts JSON using regex and instantiates Proposal
4. Returns formatted proposal for Mattermost display

**LLM Prompt:**
```python
prompt = f"""
[SECURITY PROTOCOL: PRIME DIRECTIVE]
High-risk action detected: "{user_input}"

You are the Chief of Staff. You are FORBIDDEN from executing this autonomously.
Generate a JSON response explaining the risk.

OUTPUT FORMAT:
{{
  "action": "Summary of what was requested",
  "justification": "Why the user wants this",
  "risk_assessment": "Blunt warning about data loss or system instability"
}}

OUTPUT ONLY JSON. NO EXTRA TEXT.
"""
```

**Regex Extraction Mechanism:**
```python
# Extract JSON block from LLM response
match = re.search(r'\{.*\}', raw_response, re.DOTALL)
if not match:
    raise ValueError("No JSON block found in LLM response.")
data = json.loads(match.group(0))
```

**Parameters:**
- `user_input`: The original user request containing high-risk keywords

**Returns:**
- Formatted Markdown string with proposal details
- Returns error message if Proposal Engine fails

**Error Handling:**
```python
except Exception as e:
    logger.error(f"Proposal Generation Failed: {e} | Raw Output: {raw_response}")
    return (
        f"### üõ°Ô∏è SECURITY INTERCEPT\n"
        f"**Action Blocked:** Administrative system change.\n\n"
        f"**Reason:** The Proposal Engine could not validate the risk assessment. "
        f"Execution is denied by default per the Prime Directive."
    )
```

## High-Risk Intercept (Zero Trust Enforcement)

### Overview
The High-Risk Intercept is a middleware layer that enforces the Prime Directive by intercepting high-risk actions and routing them through the Proposal Engine before execution. This ensures all destructive, financial, or system-altering commands require explicit human approval.

The Cortex module implements this by detecting high-risk keywords in user input and generating a Proposal using LLM synthesis with structured JSON extraction.

### Intercept Logic Flow
```
1. route(user_input) receives request
   ‚Üì
2. Classify domain using LLM (_classify_domain)
   ‚Üì
3. Check for high-risk keywords in original input
   ‚Üì
4. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ High-Risk Keyword Found ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                                                ‚Üì
5. Call _generate_proposal(user_input)            Bypass (Low-Risk)
   ‚Üì                                                ‚Üì
6. LLM generates JSON with:                      Route to department
   - action: Summary of requested operation
   - justification: Why user wants this
   - risk_assessment: Potential impacts
   ‚Üì
7. Regex extraction: r'\{.*\}' (raw_response, re.DOTALL)
   ‚Üì
8. Instantiate Proposal (task_id auto-generates)
   ‚Üì
9. Return proposal.format_for_mattermost()
   ‚Üì
10. User sees proposal in Mattermost approval channel
   ‚Üì
11. User responds with "Approve [task_id]"
   ‚Üì
12. MattermostInterface detects via regex: r"approve\s+(\w{8})"
   ‚Üì
13. ProposalEngine moves to approved list
   ‚Üì
14. Execute approved action via callback
```

### High-Risk Detection Criteria
Tasks are classified as high-risk if user input contains any of these keywords:
- `delete`, `move`, `remove`, `format`, `execute`, `kill`, `reorganize`

**Case-insensitive detection** in `_generate_proposal()`:
```python
high_risk_keywords = ['delete', 'move', 'remove', 'format', 'execute', 'kill', 'reorganize']
is_high_risk = any(word in user_input.lower() for word in high_risk_keywords)
```

### Integration with ProposalEngine
```python
from cobalt_agent.core.proposals import ProposalEngine

# In route() method:
if is_high_risk(decision.domain_name, decision.task_parameters):
    engine = ProposalEngine()
    engine.connect_mattermost()
    
    proposal = engine.create_proposal(
        action=get_command(decision),
        justification=decision.reasoning,
        risk_assessment="Potential financial loss or data modification"
    )
    
    engine.send_proposal(proposal)
    engine.wait_for_approval(proposal)
    engine.execute_approved(proposal)
else:
    # Route directly to department
    return self._route_to_department(decision)
```

### Approval Response Handling
When a user responds with "Approve [task_id]":
1. MattermostInterface detects the message via WebSocket
2. `handle_approval_response()` validates the pattern and task_id
3. ProposalEngine moves proposal from pending to approved
4. Approved callback executes the action

### Security Guarantees
- **No autonomous execution**: All high-risk actions require explicit approval
- **Audit trail**: All proposals are logged with timestamps
- **Channel validation**: Approval must occur in designated channel only
- **Token validation**: 8-character task_id ensures approval matches correct proposal

## Domain Routing Logic

| Domain | Purpose | Parameters |
|--------|---------|------------|
| `TACTICAL` | Trading & Market Data | Ticker symbol or "STRATEGY" |
| `INTEL` | Research & News | Search topic |
| `OPS` | Operations & Logging | Task parameters |
| `ENGINEERING` | Engineering | TODO - Not implemented |
| `FOUNDATION` | General Chat | "chat" |

## Configuration
Departments are loaded from `config.yaml` under the `departments` section. Only departments marked as `active: true` are considered for routing.

## Example Flow
```
User: "What is the price of AAPL?"
‚Üí LLM classifies: domain="TACTICAL", params="AAPL"
‚Üí _run_tactical("AAPL")
‚Üí Strategos().run("AAPL")
‚Üí Returns market data
```

```
User: "What's new in AI?"
‚Üí LLM classifies: domain="INTEL", params="AI"
‚Üí _run_intel("AI")
‚Üí DeepResearch().run("AI")
‚Üí Returns search results

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/create_missing_tasks.md
========================================

---
title: "Create Missing Tasks Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[scribe]]"
location: "dev_utils/create_missing_tasks.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Create Missing Tasks Script

**Location:** `dev_utils/create_missing_tasks.py`

## Overview

Create Missing Tasks generates Phase 4 (Ion) and Phase 5 (Ops) task files in the Obsidian Project Board. It creates markdown files with proper frontmatter for use with Dataview plugins.

## Usage

```bash
python dev_utils/create_missing_tasks.py
```

Or with uv:

```bash
uv run python dev_utils/create_missing_tasks.py
```

## Behavior

The script performs the following actions:

1. **Dynamically loads** the Scribe class from `cobalt_agent/skills/productivity/scribe.py`
2. **Creates** 5 task files in the `0 - Projects/Cobalt/Tasks` folder:
   - 30 Ion Core Architecture.md
   - 31 Cobalt-Ion Bridge.md
   - 32 HUD Widgets & Overlay.md
   - 33 Mattermost C2 Integration.md
   - 34 Automated Trade Journaling.md

Each task file contains:
- Status, priority, module, phase, complexity, tags
- Objective and requirements sections

## Output Files

| Filename | Phase | Priority | Description |
|--|--|--|--|
| 30 Ion Core Architecture.md | Phase 4 | P1 | Windows HUD Python application |
| 31 Cobalt-Ion Bridge.md | Phase 4 | P0 | ZeroMQ communication between Mac and Windows |
| 32 HUD Widgets & Overlay.md | Phase 4 | P1 | Visual components for the HUD |
| 33 Mattermost C2 Integration.md | Phase 5 | P1 | Remote command and control |
| 34 Automated Trade Journaling.md | Phase 5 | P2 | Trade log entry automation |

## Destructive Warnings

‚ö†Ô∏è **This script creates new files** - it does not modify existing ones. Ensure the target folder (`0 - Projects/Cobalt/Tasks`) exists in your Obsidian vault.

## Dependencies

- `importlib.util` - Dynamic module loading
- `datetime` - Date generation for frontmatter

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/create_prd.md
========================================

---
title: "Create PRD Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[scribe]]"
location: "dev_utils/create_prd.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Create PRD Script

**Location:** `dev_utils/create_prd.py`

## Overview

Create PRD generates the PRD-001 document based on the "Strategic Pause" conversation. It creates a comprehensive Product Requirements Document for the Cobalt-Ion Tactical HUD project.

## Usage

```bash
python dev_utils/create_prd.py
```

Or with uv:

```bash
uv run python dev_utils/create_prd.py
```

## Behavior

The script performs the following actions:

1. **Loads** the Scribe class dynamically from `cobalt_agent/skills/productivity/scribe.py`
2. **Generates** the PRD-001 content including:
   - Executive Summary
   - Core Philosophy (Distributed Brain, Python-First)
   - User Stories (Morning Briefing, Formula Injection, Tactical Engagement)
   - Functional Requirements (Scoring Engine, Math Package, Multi-Strategy)
   - Technical Constraints (Python, PyQt6, ZeroMQ, TradeStation API)
   - Future Extensibility (Discord, Journaling)
3. **Writes** the file to `0 - Projects/Cobalt/90 - Project Management/Requirements/`

## Output

Creates: `PRD-001 Cobalt-Ion Tactical HUD.md` in the Requirements folder.

## PRD Summary

### The Vision
Build a "Co-Pilot" system for manual day trading with a real-time Confidence Gauge.

### Core Philosophy
1. **Not an Auto-Trader** - System never executes trades autonomously
2. **Distributed Brain** - Mac (Cobalt) for strategy, Windows (Ion) for HUD math
3. **Python-First** - Shared logic between components

### Scoring Engine Formula
```
Score = Base + Fuel - Friction - Decay
```

## Destructive Warnings

‚ö†Ô∏è **This script creates new files** - it does not modify existing ones. Ensure the target folder exists in your Obsidian vault.

## Dependencies

- `importlib.util` - Dynamic module loading
- `datetime` - Date generation for frontmatter

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/finance.md
========================================

---
title: "Finance Tool Documentation"
status: Active
module: Tool
type: Class
dependencies:
  - "[[tool_manager]]"
  - "[[config]]"
location: "src/cobalt_agent/tools/finance.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Finance Tool Module

**Location:** `src/cobalt_agent/tools/finance.py`

## Overview

Finance Tool returns structured market data with Technical Indicators. Implements all rules from `rules.yaml`.

## Class: `MarketMetrics` (Pydantic Model)

Structured financial data for a single asset.

### Fields

| Field | Type | Description |
|--|--|--|
| `ticker` | `str` | The stock symbol (e.g. AAPL) |
| `price` | `float` | Current market price |
| `change_percent` | `float` | Daily percentage change |
| `volume` | `int` | Current trading volume |
| `rsi` | `float` | Relative Strength Index |
| `atr` | `float` | Average True Range |
| `rvol` | `float` | Relative Volume |
| `avwap_earnings` | `str` | VWAP from last earnings date |
| `avwap_high` | `str` | VWAP from 2-month Swing High |
| `avwap_low` | `str` | VWAP from 2-month Swing Low |
| `sma_10` | `str` | 10-day SMA with slope |
| `sma_20` | `str` | 20-day SMA with slope |
| `sma_50` | `str` | 50-day SMA with slope |
| `sma_100` | `str` | 100-day SMA with slope |
| `sma_200` | `str` | 200-day SMA with slope |
| `signal` | `str` | Computed technical signal |
| `alert_flags` | `str` | Special alerts |
| `calculation_meta` | `str` | Debug string showing which rules were used |

### Methods

#### `__str__() -> str`
Returns a human-readable string representation with formatted output.

---

## Class: `FinanceTool`

Fetches market data and calculates technical indicators.

### Attributes

| Attribute | Value |
|--|--|
| `name` | `"finance"` |
| `description` | `"Get current stock market data and technical indicators. Use for price queries, e.g., 'What is the price of AAPL?'"` |
| `system_config` | Loaded config object |
| `rules` | Trading rules from config |

### Methods

#### `run(ticker: str) -> MarketMetrics`

Fetches market data and returns structured metrics.

**Parameters:**
- `ticker`: Stock symbol (e.g., AAPL)

**Returns:** `MarketMetrics` with all calculated indicators

**Workflow:**
1. Load 2-year historical data via yfinance
2. Calculate RSI, ATR, RVOL
3. Compute Anchored VWAPs (earnings, swing high, swing low)
4. Calculate SMAs with slope detection
5. Apply signal logic from rules.yaml
6. Return structured metrics

#### `_get_rule(path: str, default: Any = None) -> Any`

Safely access nested config rules (handles dict or object notation).

#### `_calculate_rsi(data, window: int) -> float`

Calculates Relative Strength Index.

#### `_calculate_atr(data, window: int) -> float`

Calculates Average True Range.

#### `_calculate_rvol(data, window: int) -> float`

Calculates Relative Volume against 20-day average.

#### `_calculate_avwap(data, start_date: str) -> float`

Calculates Anchored VWAP from a specific date.

#### `_get_sma_data(data, window: int) -> Tuple[float, str]`

Returns SMA value and slope direction ("RISING" or "FALLING").

#### `_get_last_earnings_date(ticker_obj) -> Optional[str]`

Gets the most recent past earnings date.

### Signal Logic

1. **Overbought/ Oversold**: RSI > 70 or RSI < 30
2. **Bullish Cross**: Fast SMA > Slow SMA AND both rising
3. **Trend**: Price above/below earnings VWAP
4. **Default**: NEUTRAL

### Alerts

- **RVOL ALERT**: Relative volume > 3.0
- **PARABOLIC MOVE**: 5-day move > 5x ATR

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/generate_constitution.md
========================================

---
title: "Generate Constitution Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[scribe]]"
location: "dev_utils/generate_constitution.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Generate Constitution Script

**Location:** `dev_utils/generate_constitution.py`

## Overview

Generate Constitution creates the Cobalt Constitution - a comprehensive set of architecture documentation, ADRs, and project management files. This script generates the foundational documentation structure for the entire Cobalt project.

## Usage

```bash
python dev_utils/generate_constitution.py
```

Or with uv:

```bash
uv run python dev_utils/generate_constitution.py
```

## ‚ö†Ô∏è Destructive Warning

üö® **THIS SCRIPT DELETES AND CREATES FILES** - It creates the entire Constitution document structure. Run only once during initial setup or when explicitly updating the Constitution.

## Behavior

The script generates the following files in the Obsidian vault:

### Level 1: Master Plan
1. **Dashboard** (`00 Cobalt Master Plan.md`) - Root navigation document
2. **System Manifest** (`00 - Master Plan/System Manifest.md`) - Stack, hierarchy, and roles
3. **Security Architecture** (`00 - Master Plan/Security Architecture.md`) - Zero Trust, JIT, Kill-Switches

### Level 2: ADRs
4. **ADR-001** - Distributed Protocol (Mac/Windows architecture)
5. **ADR-002** - Hybrid AI Compute (Local vs Cloud models)
6. **ADR-003** - Python-First Architecture (PyQt6 for Ion HUD)

### Level 3: Project Management
7. **Roadmap** - Strategic phases (Q1/Q2 goals)
8. **Backlog** - Future ideas and placeholders

## Output Files Structure

```
0 - Projects/Cobalt/
‚îú‚îÄ‚îÄ 00 Cobalt Master Plan.md           (Dashboard)
‚îú‚îÄ‚îÄ 00 - Master Plan/
‚îÇ   ‚îú‚îÄ‚îÄ System Manifest.md
‚îÇ   ‚îî‚îÄ‚îÄ Security Architecture.md
‚îú‚îÄ‚îÄ 00 - Master Plan/ADR/
‚îÇ   ‚îú‚îÄ‚îÄ ADR-001 Cobalt-Ion Distributed Protocol.md
‚îÇ   ‚îú‚îÄ‚îÄ ADR-002 Hybrid AI Compute.md
‚îÇ   ‚îî‚îÄ‚îÄ ADR-003 Python-First Architecture.md
‚îî‚îÄ‚îÄ 90 - Project Management/
    ‚îú‚îÄ‚îÄ Roadmap.md
    ‚îî‚îÄ‚îÄ Backlog.md
```

## System Manifest Overview

### The Hierarchy
- **Level 1: CEO (Dejan)** - Final decision maker
- **Level 2: Cobalt (Chief of Staff)** - Orchestration and coaching
- **Level 3: Departments** - Strategos, Ion, Scribe, Sentinel, Scout

### The Hardware Stack
- **Brain (Mac Studio M2 Ultra)** - Central compute node
- **Engine (Windows Workstation)** - Execution environment
- **Console (Lenovo X1 Carbon)** - Development interface
- **Red Phone (Mobile)** - Command & Control

## Dependencies

- `importlib.util` - Dynamic module loading
- `datetime` - Date generation for frontmatter

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/generate_context.md
========================================

---
title: "Generate Context Documentation"
status: Active
module: Utility
type: Script
dependencies: []
location: "dev_utils/generate_context.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Generate Context Script

**Location:** `dev_utils/generate_context.py`

## Overview

Generate Context is a utility script that generates a master context file (`cobalt_master_context.txt`) for architectural review. It walks the project directory, collects relevant files, and outputs a single file containing the directory tree and file contents.

## Usage

Run the script from the project root:

```bash
python dev_utils/generate_context.py
```

Or with uv:

```bash
uv run python dev_utils/generate_context.py
```

## Behavior

### Exclusions

The script automatically excludes:
- Files/directories starting with `.` or `__`
- `venv` directory
- `uv.lock` file

### Inclusions

The script processes files with the following extensions:
- `.py` (Python)
- `.md` (Markdown)
- `.yaml` / `.yml` (YAML)
- `.toml` (TOML)
- `.log` (Log files - last 200 lines only)
- `.txt` (Text files)

### Output

The script generates `cobalt_master_context.txt` containing:
1. **Directory Tree**: Text-based representation of the project structure
2. **File Contents**: All processed files with their full content

## Use Cases

- **Architectural Review**: Provides a complete snapshot of the codebase for review
- **Context Generation**: Creates a consolidated file for LLM analysis
- **Documentation**: Serves as a baseline for project documentation

## Notes

- Log files are automatically truncated to the last 200 lines to manage file size
- Files that cannot be read (permissions, binary) will show an error message

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/llm.md
========================================

---
title: "LLM Interface Documentation"
status: Active
module: Brain
type: Class
dependencies:
  - "[[main]]"
  - "[[prompt]]"
location: "src/cobalt_agent/llm.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# LLM (Language Model) Interface

## Overview
The LLM interface provides unified access to large language models through a single API. It supports multiple providers including Gemini and handles model configuration, prompting, and response parsing.

## Class: `LLM`

### Constructor
```python
def __init__(self, config: LLMConfig)
```
Initializes the LLM with provider configuration.

**Parameters:**
- `config`: `LLMConfig` instance containing model name and API key

### Key Attributes
- `config`: LLM configuration
- `model_name`: The model identifier (e.g., "gemini/gemini-1.5-pro")
- `api_key`: Provider API key

### Main Methods

#### `generate(prompt: str, temperature: float = 0.7, max_tokens: int = 2048) -> str`
Generates text from the LLM based on the provided prompt.

**Parameters:**
- `prompt`: The input prompt text
- `temperature`: Controls randomness (0.0 to 1.0)
- `max_tokens`: Maximum tokens in the response

**Returns:**
- `str`: Generated response from the model

#### `_call_gemini(prompt: str, temperature: float, max_tokens: int) -> str`
Internal method to call the Gemini API.

**Parameters:**
- `prompt`: The input prompt
- `temperature`: Temperature setting
- `max_tokens`: Maximum tokens

**Returns:**
- Generated response from Gemini

### Internal Methods

#### `_get_provider() -> str`
Determines the LLM provider from the model name.

**Returns:**
- Provider name (e.g., "gemini")

#### `_parse_model_name(full_name: str) -> Tuple[str, str]`
Splits full model name into provider and model parts.

**Returns:**
- Tuple of (provider, model_name)

## Configuration

### Model Name Format
The model name follows the format `provider/model-name`:
- `gemini/gemini-1.5-pro`
- `gemini/gemini-2.0-flash`

### Environment Variables
- `LLM_API_KEY`: API key for the LLM provider

## Error Handling
- Missing API keys raise configuration errors
- Network failures are caught and logged
- Invalid responses are handled gracefully

## Future Enhancements
- Support for additional LLM providers
- Streaming responses
- Token usage tracking
- Rate limit handling

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/main.md
========================================

---
title: "Main Entry Point Documentation"
status: Active
module: Core
type: Class
dependencies:
  - "[[llm]]"
  - "[[memory_core]]"
  - "[[cortex]]"
  - "[[cli]]"
  - "[[mattermost]]"
location: "src/cobalt_agent/main.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Main Entry Point

## Overview
The main module serves as the entry point for the Cobalt Agent application. It initializes the system, loads configuration, and starts the agent's main loop or interactive interface.

## Class: `CobaltAgent`

### Constructor
```python
def __init__(self)
```
Initializes the Cobalt Agent with all components.

### Key Components

#### Core System
- `config`: Global configuration from `configs/config.yaml`
- `llm`: LLM instance for reasoning
- `cortex`: Chief of Staff for routing requests to departments
- `memory`: Memory system for storing and retrieving conversation history

#### Departments
- `Tactical`: Market data and trading strategies (Strategos)
- `Intel`: Research and news analysis
- `Ops`: Logging and documentation (Scribe)
- `Engineering`: Development tools and utilities

#### Interfaces
- `CLI`: Command-line interface
- `Mattermost`: Real-time chat integration

### Main Methods

#### `run() -> None`
Starts the main agent loop.

**Behavior:**
- Loads configuration
- Initializes all components
- Starts interactive loop or service

#### `route(user_input: str) -> Optional[str]`
Convenience method to route input through Cortex.

**Parameters:**
- `user_input`: User's message or command

**Returns:**
- Response from the appropriate department

## Command-Line Interface

### Usage
```bash
python -m cobalt_agent
# or
uv run python -m cobalt_agent
```

### Options
- `--debug`: Enable debug logging
- `--config-dir`: Specify custom configuration directory

## Environment Setup

### Required Variables
- `LLM_API_KEY`: API key for the LLM provider
- `MATTERMOST_TOKEN`: (Optional) Token for Mattermost integration

### Configuration Files
- `configs/config.yaml`: Main configuration
- `configs/strategies.yaml`: Trading strategy parameters
- `configs/rules.yaml`: Business rules and overrides

## Startup Flow
1. Load `.env` file
2. Load YAML configuration files
3. Initialize LLM
4. Initialize Memory System
5. Initialize Cortex (Chief of Staff)
6. Register Departments
7. Register Tools
8. Start CLI or Mattermost listener

## Error Handling
- Missing configuration defaults to safe values
- LLM connection failures are logged and retried
- Department initialization failures are logged
- Agent continues with partial functionality when possible

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/mattermost.md
========================================

---
title: "Mattermost Interface Documentation"
status: Active
module: Interface
type: Class
dependencies:
  - "[[main]]"
  - "[[cortex]]"
  - "[[llm]]"
location: "src/cobalt_agent/interfaces/mattermost.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Mattermost Interface

## Overview
The Mattermost Interface provides real-time communication capabilities for the Cobalt Agent. It enables the agent to listen for messages in Mattermost channels and respond using the Brain's routing and LLM capabilities.

### Zero Trust Integration
The interface integrates with the Proposal Engine to handle **Approval Responses** for high-stakes actions. When users respond with "Approve [task_id]" in the approval channel, the interface detects the response, validates the task_id, and triggers execution of the approved action.

## Class: `MattermostInterface`

### Constructor
```python
def __init__(self, config: Optional[MattermostConfig] = None)
```
Initializes the interface with configuration. If no config is provided, loads from global config.

**Parameters:**
- `config`: Optional `MattermostConfig` instance

### Key Attributes
- `config`: Mattermost configuration (URL, token)
- `driver`: Mattermost driver instance
- `brain`: Reference to the CobaltAgent/Cortex for message processing
- `is_connected`: Boolean indicating connection status

### Main Methods

#### `connect() -> bool`
Establishes connection to the Mattermost server and authenticates.

**Returns:**
- `True` if connection and authentication succeeded
- `False` otherwise

**Configuration Sources:**
1. Environment variables: `MATTERMOST_URL`, `MATTERMOST_TOKEN`
2. YAML config: `configs/config.yaml`

#### `disconnect() -> None`
Logs out from Mattermost and disconnects from the server.

#### `send_message(channel_name: str, team_name: str, message: str) -> bool`
Sends a message to a specific channel.

**Parameters:**
- `channel_name`: Name of the channel (without #)
- `team_name`: Name of the team
- `message`: Message content to send

**Returns:**
- `True` if message sent successfully
- `False` otherwise

#### `send_message_to_channel_id(channel_id: str, message: str) -> bool`
Directly sends a message to a channel using its ID.

**Parameters:**
- `channel_id`: Mattermost channel ID
- `message`: Message content

#### `get_my_user_id() -> Optional[str]`
Returns the current user's Mattermost ID.

### WebSocket Integration

#### `start_listening(brain: "CobaltAgent") -> None`
Starts the WebSocket listener in the main thread to receive incoming messages.

**Features:**
- Connects to Mattermost WebSocket API
- Processes incoming messages
- Routes to Brain for inference
- Sends responses back to channel

**Message Flow:**
1. WebSocket receives "posted" event
2. Extract post data (user_id, channel_id, message)
3. Ignore bot's own messages
4. Route to `brain.route()` or generate conversational response
5. Send response to channel

### Internal Methods

#### `_handle_mattermost_event(message: str) -> None`
Processes incoming WebSocket events.

**Handles:**
- Event parsing and validation
- Post data extraction from JSON
- Message routing to Brain
- Conversational response generation

#### `_handle_events(mm_driver: Driver) -> None`
Event handler callback for Mattermost events.

#### `_run_websocket_in_process(brain: "CobaltAgent", event_queue: "multiprocessing.Queue") -> None`
Runs the WebSocket listener in a separate process to avoid event loop conflicts.

### Approval Response Handling

#### Overview
The MattermostInterface detects and processes **Approval Responses** for high-stakes actions. When users respond with "Approve [task_id]" in the approval channel, the interface validates the response using regex and triggers the Proposal Engine to execute the approved action.

**Key Integration Points:**
- `MattermostInterface` receives WebSocket events
- `proposal_engine.handle_approval_response()` validates approval pattern and task_id
- `proposal_engine.execute_approved()` executes the approved action

#### Approval Pattern Regex
```python
approval_pattern = r"approve\s+(\w{8})"
```

**Pattern Components:**
- `approve`: Literal text (case-insensitive)
- `\s+`: One or more whitespace characters
- `(\w{8})`: Capture group for exactly 8 word characters (task_id)

**Example Matches:**
| Input | Extracted Task ID | Match? |
|-------|-------------------|--------|
| `approve abc12345` | `abc12345` | ‚úÖ Yes |
| `Approve ABC12345` | `ABC12345` | ‚úÖ Yes |
| `approved xyz98765` | `xyz98765` | ‚úÖ Yes |
| `APPROVE 12345678` | `12345678` | ‚úÖ Yes |
| `approve abc123` | `N/A` | ‚ùå No (wrong length) |
| `Deny abc12345` | `N/A` | ‚ùå No (wrong keyword) |

#### Approval Response Processing Flow
```
1. WebSocket receives "posted" event with message
   ‚Üì
2. _handle_mattermost_event() extracts message text and channel_id
   ‚Üì
3. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ proposal_engine attached? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ                                            ‚Üì
   ‚îÇ                                     No engine ‚Üí skip
   ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Yes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                         ‚Üì
4. Call proposal_engine.handle_approval_response(text, channel_id)
   ‚Üì
5. Regex pattern matching checks for approval pattern
   ‚Üì
6. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Match ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                             ‚Üì
7. Extract task_id (8-char ID)  No match ‚Üí route to brain
   ‚Üì
8. Validate channel matches approval_channel config
   ‚Üì
9. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Valid ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                             ‚Üì
10. Look up task_id in pending_proposals  Invalid channel ‚Üí route to brain
   ‚Üì
11. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Found ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                             ‚Üì
12. Remove from pending, add to approved  Unknown task_id ‚Üí route to brain
   ‚Üì
13. Set proposal.approved = True
   ‚Üì
14. Log approval event
   ‚Üì
15. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ approval_callback set? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ                                         ‚Üì
   ‚îÇ                                  No callback ‚Üí done
   ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Yes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                         ‚Üì
16. Execute approved action   Execute callback with proposal
   ‚Üì
17. Return to message loop
```

#### Integration with ProposalEngine

**Connection Setup:**
```python
from cobalt_agent.core.proposals import ProposalEngine

# In main.py or initialization:
engine = ProposalEngine()
engine.connect_mattermost()
engine.start_monitoring()

# Attach engine to MattermostInterface:
mm_interface.proposal_engine = engine
mm_interface.brain = cobalt_agent.cortex
```

**Message Processing Priority:**
1. **Approval responses** (highest priority) - processed first
2. **Brain routing** - for non-approval messages

**Flow when approval detected:**
```python
# In _handle_mattermost_event():
if self.proposal_engine:
    approved_proposal = self.proposal_engine.handle_approval_response(text, channel_id)
    if approved_proposal:
        # Execute the approved action
        self.proposal_engine.execute_approved(approved_proposal)
        return  # Don't route to brain for approval responses

# Only reach here if not an approval response
if self.brain:
    response = self.brain.route(text)
    self.send_message_to_channel_id(channel_id, response)
```

#### The `handle_approval_response()` Method

**Location:** `ProposalEngine` (not `MattermostInterface`)

**Signature:**
```python
def handle_approval_response(self, message: str, channel_id: str) -> Optional[Proposal]
```

**Behavior:**
1. Regex extracts task_id from message
2. Validates channel matches approval_channel config
3. Looks up task_id in pending_proposals
4. If found: removes from pending, adds to approved, sets approved=True
5. Returns the approved Proposal (or None if not an approval)

**Returns:**
- `Proposal` object if this is a valid approval response
- `None` if message doesn't match approval pattern or task_id not found

#### Error Handling

**Common failure cases:**
- **No approval engine attached**: Message routes to brain normally
- **Channel mismatch**: Approval ignored, message routes to brain
- **Unknown task_id**: Warning logged, message routes to brain
- **Regex no match**: Message routes to brain normally

## Integration with Brain

The Mattermost interface requires a Brain (Cortex) attachment to process messages:

```python
mm_interface.brain = cobalt_agent.cortex
```

When a message is received:
1. `cortex.route(text)` attempts to match to a department
2. If matched, department response is sent
3. If not matched, LLM generates conversational response

## Configuration Example
```yaml
mattermost:
  url: "https://mattermost.example.com"
  token: "${MATTERMOST_TOKEN}"
  scheme: "https"
  port: 443

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/memory_base.md
========================================

---
title: "Memory Base Documentation"
status: Active
module: Memory
type: Class
dependencies:
  - "[[memory_core]]"
  - "[[postgres]]"
location: "src/cobalt_agent/memory/base.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Memory Base Module

**Location:** `src/cobalt_agent/memory/base.py`

## Overview

Memory Interface (The Contract) defines how Agents interact with memory, regardless of storage implementation (JSON vs Postgres).

## Class: `MemoryProvider` (ABC)

Abstract Base Class for Memory. Any memory system (JSON, SQL, Vector) MUST implement these methods.

### Methods

#### `add_log(message: str, source: str = "System", data: Dict = None) -> None`
Record an event or thought.

**Parameters:**
- `message`: The memory content
- `source`: Origin of the memory (default: "System")
- `data`: Optional dictionary of additional data

#### `get_context(limit: int = 10) -> List[Dict[str, Any]]`
Get recent conversation history (Short Term RAM).

**Parameters:**
- `limit`: Maximum number of recent interactions to retrieve

**Returns:** List of memory entries

#### `search(query: str, limit: int = 5) -> List[Dict[str, Any]]`
Find relevant memories based on meaning/content.

**Parameters:**
- `query`: Search query string
- `limit`: Maximum number of results to return

**Returns:** List of matching memory entries

**Notes:**
- For JSON storage: Uses keyword search
- For Postgres: Uses vector search

---

## Implementation Pattern

Any memory provider must inherit from `MemoryProvider`:

```python
from cobalt_agent.memory.base import MemoryProvider

class MyMemoryProvider(MemoryProvider):
    def add_log(self, message, source="System", data=None):
        # Implementation here
        pass
    
    def get_context(self, limit=10):
        # Implementation here
        return []
    
    def search(self, query, limit=5):
        # Implementation here
        return []

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/memory_core.md
========================================

---
title: "Memory Core Documentation"
status: Active
module: Memory
type: Class
dependencies:
  - "[[memory_base]]"
  - "[[postgres]]"
location: "src/cobalt_agent/memory/core.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Memory Core Module

**Location:** `src/cobalt_agent/memory/core.py`

## Overview

Memory System Core (JSON Implementation) manages short-term (RAM) and long-term (Disk) memory for the Cobalt Agent.

## Class: `MemorySystem`

Manages:
- Short-term memory: Last 10 interactions (RAM - Fast)
- Long-term memory: Persistent storage in `data/memory.json` (Disk - Safe)

Implements the `MemoryProvider` interface from `base.py`.

### Constructor

```python
MemorySystem(memory_file: str = "data/memory.json")
```

**Parameters:**
- `memory_file`: Path to the memory JSON file.

### Attributes

- `memory_file`: Path to the memory storage file
- `short_term`: List of last 10 interactions (RAM)
- `long_term`: Dictionary containing all historical logs (Disk)

### Methods

#### `add_log(message: str, source: str = "System", data: Dict = None) -> None`
Add a message to both short-term and long-term memory.

**Parameters:**
- `message`: The memory content
- `source`: Origin of the memory (default: "System")
- `data`: Optional dictionary of additional data

Automatically saves to disk and maintains RAM limit of 10 entries.

#### `get_context(limit: int = 10) -> List[Dict[str, Any]]`
Fast retrieval of short-term memory for AI prompts.

**Parameters:**
- `limit`: Number of recent interactions to retrieve

**Returns:** List of memory entries sorted by timestamp.

#### `search(query: str, limit: int = 5) -> List[Dict[str, Any]]`
Simple keyword search through long-term memory.

**Parameters:**
- `query`: Search string to match against memory messages
- `limit`: Maximum number of results

**Returns:** List of matching memory entries (newest first).

#### `save_memory() -> None`
Save long-term memory to disk.

#### `load_memory() -> None`
Load long-term memory from disk and hydrate short-term RAM.

---

## Memory Entry Format

```python
{
    "timestamp": "2026-02-22T23:00:00",
    "source": "System",
    "message": "Strategy scan completed",
    "data": {"strategy": "second_day_play", "score": 75}
}

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/playbook.md
========================================

---
title: "Playbook Module Documentation"
status: Active
module: Brain
type: Orchestrator
dependencies:
  - "[[strategy]]"
  - "[[tactical]]"
  - "[[config]]"
  - "[[second_day_play]]"
location: "src/cobalt_agent/brain/playbook.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Playbook Module

## Overview

The Playbook Registry loads trading strategies and parameters from `configs/strategies.yaml` and executes strategy logic against market data.

## Class: `Playbook`

Manages active trading strategies and their parameters.

### Constructor

```python
Playbook(config_path: str = "configs/strategies.yaml")
```

Initializes the playbook with strategy configurations from a YAML file.

### Methods

#### `_load_config(path_str: str) -> Dict[str, Any]`
Loads the YAML configuration file and returns strategy parameters.

#### `_initialize_strategies()`
Hydrates strategy classes with their configurations by mapping YAML keys to Python classes.

#### `get_strategy(name: str)`
Returns the strategy instance by name.

#### `list_strategies() -> str`
Returns a formatted string list of ACTIVE (loaded) strategies with their configurations.

#### `run_all(market_data: Dict[str, Any]) -> str`
Runs ALL strategies against incoming market data and returns a summary string of scoring profiles.

### Example Output

```
üìú **Active Playbook:**
- **SecondDayPlay**: LONG (09:30-11:00)
   ‚Ä¢ Score: 75/100 (High)
   ‚Ä¢ Logic: Positive relative volume and gap up pattern
   ‚Ä¢ HUD Config: 3 dynamic rules active
```

---

## Related Files

- `strategy.py` - Abstract base class for all strategies
- `tactical.py` - Strategos agent that orchestrates playbook execution
- `strategies/` - Individual strategy implementations

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/postgres.md
========================================

---
title: "Memory Postgres Documentation"
status: Active
module: Memory
type: Class
dependencies:
  - "[[memory_base]]"
  - "[[memory_core]]"
  - "[[config]]"
location: "src/cobalt_agent/memory/postgres.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Postgres Memory Module

**Location:** `src/cobalt_agent/memory/postgres.py`

## Overview

Postgres Memory Adapter (The Hippocampus) provides persistent memory with vector embeddings for semantic search. Combines database persistence with AI-powered similarity search.

## Class: `PostgresMemory`

Implements `MemoryProvider` interface from `base.py`.

### Constructor

```python
PostgresMemory()
```

Initializes database connection and auto-creates tables. Loads credentials from:
1. Environment variables: `POSTGRES_HOST`, `POSTGRES_DB`, `POSTGRES_USER`, `POSTGRES_PASSWORD`
2. YAML config in `configs/*.yaml`

### Methods

#### `add_log(message: str, source: str = "System", data: Dict = None) -> None`
Saves a memory AND its vector embedding to Postgres.

**Parameters:**
- `message`: Memory content to store
- `source`: Origin of the memory (default: "System")
- `data`: Optional dictionary for metadata

**Workflow:**
1. Generate vector embedding using LiteLLM (`text-embedding-3-small`)
2. Insert into database with content, embedding, and metadata

#### `get_context(limit: int = 10) -> str`
Retrieve recent logs (Short Term RAM) from database.

**Parameters:**
- `limit`: Number of recent entries to retrieve

**Returns:** Formatted chat-log string (chronological order)

#### `search(query: str, limit: int = 5) -> List[Dict]`
Semantic search - finds memories similar to the query using vector cosine distance.

**Parameters:**
- `query`: Search query string
- `limit`: Maximum number of results

**Returns:** List of matching memories with similarity scores (filtering out scores < 0.3)

### Attributes

| Attribute | Description |
|--|--|
| `conn_str` | PostgreSQL connection string |
| `table_name` | Table name: "memory_logs" |
| `host`, `port`, `db`, `user`, `password` | Database connection credentials |

### Database Schema

| Column | Type | Description |
|--|--|--|
| `id` | SERIAL PRIMARY KEY | Unique identifier |
| `timestamp` | TIMESTAMP | Auto-generated |
| `source` | TEXT | Origin of the memory |
| `content` | TEXT | Memory content |
| `embedding` | vector(1536) | OpenAI embedding vector |
| `metadata` | JSONB | Additional data |

### Features

- **Hybrid Storage**: Combines persistent logging with vector search
- **Vector Search**: Uses Postgres `vector` extension for semantic similarity
- **Fallback**: Saves without vector if embedding fails
- **Context Retrieval**: Returns chronologically sorted short-term memory

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/prompt.md
========================================

---
title: "Prompt Engine Documentation"
status: Active
module: Brain
type: Class
dependencies:
  - "[[main]]"
  - "[[persona]]"
  - "[[llm]]"
location: "src/cobalt_agent/prompt.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Prompt Engine

## Overview
The Prompt Engine constructs dynamic system prompts for the LLM based on context, tools, and temporal information. It ensures the agent maintains proper behavior, memory protocol, and tool usage guidelines.

## Class: `PromptEngine`

### Constructor
```python
def __init__(self, persona_config: PersonaConfig)
```
Initializes the Prompt Engine with persona configuration.

**Parameters:**
- `persona_config`: `PersonaConfig` instance containing agent identity and directives

### Main Methods

#### `build_system_prompt(tools: List[Any] = None) -> str`
Constructs the complete system prompt by combining all components.

**Parameters:**
- `tools`: Optional list of tool objects available to the agent

**Returns:**
- `str`: Complete system prompt

**Components:**
1. Identity & Role (Header)
2. Operational Context (Time/Date)
3. Memory Protocol
4. Directives (Rules)
5. Tool Capabilities

## Prompt Components

### 1. Header (`_build_header()`)
Contains agent identity information:
- Agent name
- Roles
- Directives
- Tone

**Format:**
```
### IDENTITY
You are {name}.

### ROLES
Your roles are: {roles}.

### OPERATIONAL DIRECTIVES
{directives}

### TONE
Maintain a tone that is: {tone}.
```

### 2. Context (`_build_context()`)
Provides temporal and environmental context:
- Current date/time
- Operating system
- User identity

### 3. Memory Protocol (`_build_memory_protocol()`)
Defines rules for memory recall and stale data handling:
- **PREFERENCE** memories: Keep forever (e.g., "I like TSLA")
- **MARKET CONTEXT** memories: Expire after 24 hours
- Instructions to use memory when available

### 4. Directives (`_build_directives()`)
Core operating rules:
- Agent is autonomous (not a chat bot)
- Must use tools for real-time data
- Strict data adherence (no hallucination)
- Tool usage format (ACTION: syntax)

### 5. Tool Descriptions (`_build_tool_descriptions()`)
Lists available tools with their capabilities for the LLM.

## Tool Usage Protocol

### Action Format
The agent must use the `ACTION:` prefix when invoking tools:

```
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.
```

### Key Rules
1. **No internal knowledge**: Cannot answer without tools
2. **Start with ACTION:** When data is needed
3. **Trust tool results**: Use provided values, don't interpret
4. **Strict data adherence**: Reference exact periods from tool data (e.g., "RSI (20)", not "RSI (14)")

## Configuration Integration
The Prompt Engine uses `PersonaConfig` from the global configuration system, ensuring consistency across the agent's behavior and documentation.

## Example Output
```python
engine = PromptEngine(persona_config)
prompt = engine.build_system_prompt(tools=[search_tool, finance_tool])
print(prompt)
# Full system prompt for LLM

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/proposals.md
========================================

---
title: "Proposal Engine Documentation"
status: Active
module: Core
type: Engine
dependencies:
  - "[[mattermost]]"
  - "[[main]]"
  - "[[cortex]]"
  - "[[config]]"
location: "src/cobalt_agent/core/proposals.py"
tags: [cobalt, dev_docs, hitl, security]
created: 2026-02-23
---

# Proposal Engine (Zero Trust Architecture)

## Overview
The Proposal Engine enforces the Prime Directive by requiring human approval before executing high-stakes actions. It implements a standardized `Proposal` model for all destructive, financial, or system-altering commands, ensuring Zero Trust architecture through Human-in-the-Loop (HITL) validation.

### Zero Trust Principles
- **No Autonomous Execution**: No high-stakes action executes without explicit approval
- **Standardized Proposals**: All proposals follow a consistent format for review
- **Explicit Approval Flow**: Approval must be provided via Mattermost channel response
- **Cryptographic Token**: Task IDs provide unique, verifiable authorization tokens

## LLM Synthesis with Regex Extraction

### Overview
The Cortex module generates proposals using LLM synthesis with structured JSON extraction. When high-risk keywords are detected, the system calls an LLM to synthesize a proposal with action, justification, and risk_assessment fields.

### Regex Extraction Mechanism
```python
# Extract JSON block from LLM response
match = re.search(r'\{.*\}', raw_response, re.DOTALL)
if not match:
    raise ValueError("No JSON block found in LLM response.")
data = json.loads(match.group(0))
```

**Pattern Components:**
- `r'\{.*\}'`: Regex to match JSON object from start `{` to end `}`
- `re.DOTALL`: Allows `.` to match newlines (multi-line JSON)
- Extracts the first valid JSON block from LLM response

### LLM Prompt Format
```python
prompt = f"""
[SECURITY PROTOCOL: PRIME DIRECTIVE]
High-risk action detected: "{user_input}"

You are the Chief of Staff. You are FORBIDDEN from executing this autonomously.
Generate a JSON response explaining the risk.

OUTPUT FORMAT:
{{
  "action": "Summary of what was requested",
  "justification": "Why the user wants this",
  "risk_assessment": "Blunt warning about data loss or system instability"
}}

OUTPUT ONLY JSON. NO EXTRA TEXT.
"""
```

### JSON Output Schema
| Field | Type | Description |
|-------|------|-------------|
| `action` | `str` | Summary of the requested operation |
| `justification` | `str` | User's reasoning for the action |
| `risk_assessment` | `str` | Potential impacts or negative consequences |

### Error Handling
- **No JSON block found**: Returns security intercept message
- **Invalid JSON**: Logs error and returns rejection message
- **Missing fields**: Uses defaults for missing fields

### Example Flow
```
1. User input: "Delete the old log files"
   ‚Üì
2. Cortex.route() detects high-risk keyword "delete"
   ‚Üì
3. Calls _generate_proposal() with user input
   ‚Üì
4. LLM generates JSON response:
   {
     "action": "Delete old log files",
     "justification": "User wants to clean up logs",
     "risk_assessment": "Could affect audit trail if logs are needed later"
   }
   ‚Üì
5. Regex extracts JSON block using r'\{.*\}'
   ‚Üì
6. Instantiate Proposal with extracted fields
   ‚Üì
7. Return formatted proposal for Mattermost display
```

## Class: `Proposal`

### Constructor
```python
def __init__(
    task_id: str = Field(default_factory=lambda: str(uuid.uuid4())[:8])
    action: str = Field(description="The specific command or operation to be executed.")
    justification: str = Field(description="The agent's reasoning for why this action is necessary.")
    risk_assessment: str = Field(description="A summary of potential negative impacts.")
    parameters: Dict[str, Any] = Field(default_factory=dict)
    timestamp: datetime = Field(default_factory=datetime.now)
    approved: bool = False
    approval_channel: Optional[str] = None
    approval_message_id: Optional[str] = None
)
```

### Key Attributes

| Field | Type | Description |
|-------|------|-------------|
| `task_id` | `str` | Unique 8-character identifier for approval matching |
| `action` | `str` | The raw command to be executed |
| `justification` | `str` | Agent's reasoning for the action |
| `risk_assessment` | `str` | Summary of potential negative impacts |
| `parameters` | `Dict[str, Any]` | Technical metadata for execution |
| `timestamp` | `datetime` | When proposal was created |
| `approved` | `bool` | Whether this proposal has been approved |
| `approval_channel` | `Optional[str]` | Mattermost channel for approval |
| `approval_message_id` | `Optional[str]` | Mattermost post ID for tracking |

### Methods

#### `format_for_mattermost() -> str`
Formats the proposal for display in Mattermost approval channel.

**Output Format:**
```markdown
### üõ°Ô∏è ACTION PROPOSAL [task_id]
**Action:** `command`
**Justification:** agent reasoning
**Risk:** potential impacts

---
‚ö†Ô∏è *This action is paused per the Prime Directive. Reply with 'Approve [task_id]' to proceed.*
```

## Class: `ProposalEngine`

### Constructor
```python
def __init__(self)
```
Initializes the Proposal Engine with configuration from `config.yaml`.

**Key Initialization Steps:**
1. Loads approval channel and team from config
2. Initializes empty proposal dictionaries
3. Logs connection details

### Key Attributes

| Attribute | Type | Description |
|-----------|------|-------------|
| `config` | `CobaltSettings` | Global configuration |
| `approval_channel` | `str` | Mattermost channel for approval messages |
| `approval_team` | `str` | Team containing approval channel |
| `mattermost` | `Optional[MattermostInterface]` | Mattermost connection instance |
| `approved_proposals` | `Dict[str, Proposal]` | Successfully approved proposals |
| `pending_proposals` | `Dict[str, Proposal]` | Waiting for approval |
| `_approval_callback` | `Optional[Callable]` | Callback for approved proposals |
| `_monitoring` | `bool` | Whether background monitoring is active |

### Main Methods

#### `connect_mattermost() -> bool`
Establishes connection to Mattermost for approval workflow.

**Returns:**
- `True` if connection and authentication succeeded
- `False` otherwise

**Behavior:**
- Creates `MattermostInterface` instance
- Attempts to connect and authenticate
- Attaches brain for message routing
- Logs connection status

#### `create_proposal(
    action: str,
    justification: str,
    risk_assessment: str,
    parameters: Optional[Dict] = None
) -> Proposal`
Creates a new proposal for a high-stakes action.

**Parameters:**
- `action`: The specific command to execute
- `justification`: Agent's reasoning for necessity
- `risk_assessment`: Summary of potential negative impacts
- `parameters`: Technical metadata for execution

**Returns:**
- Created `Proposal` object
- Added to `pending_proposals` dictionary

**Behavior:**
- Generates unique 8-character task_id
- Creates and stores proposal in pending queue
- Logs proposal creation

#### `send_proposal(proposal: Proposal) -> bool`
Sends a proposal to Mattermost for human review.

**Parameters:**
- `proposal`: The `Proposal` object to send

**Returns:**
- `True` if proposal was sent successfully
- `False` otherwise

**Behavior:**
1. Validates Mattermost connection
2. Retrieves team ID by name
3. Retrieves channel ID using team_id
4. Creates Mattermost post with formatted proposal
5. Stores approval_message_id in proposal
6. Logs success/failure

**Error Cases:**
- No Mattermost connection
- Approval channel not configured
- Team or channel not found

#### `handle_approval_response(message: str, channel_id: str) -> Optional[Proposal]`
Checks if a message is an approval response for a pending proposal.

**Parameters:**
- `message`: The message text from Mattermost
- `channel_id`: The channel ID where the message was posted

**Returns:**
- `Proposal` if this is a valid approval response
- `None` if not an approval or task_id not found

**Approval Pattern:**
- Regex: `approve\s+(\w{8})` (case-insensitive)
- Must match 8-character task_id
- Must be in approval channel

**Behavior:**
1. Extracts task_id from message using regex
2. Validates channel is approval channel
3. Looks up pending proposal by task_id
4. Moves proposal from pending to approved
5. Sets `approved = True`

#### `wait_for_approval(proposal: Proposal, timeout: int = 3600) -> bool`
Waits for a proposal to be approved (polling mode).

**Parameters:**
- `proposal`: The `Proposal` to wait for
- `timeout`: Maximum wait time in seconds (default: 1 hour)

**Returns:**
- `True` if approved within timeout
- `False` if timeout reached

**Behavior:**
- Polls every 5 seconds
- Checks `approved_proposals` dictionary
- Removes from pending on timeout

#### `execute_approved(proposal: Proposal) -> bool`
Executes an approved proposal's action.

**Parameters:**
- `proposal`: The approved `Proposal` to execute

**Returns:**
- `True` if execution succeeded
- `False` otherwise

**Behavior:**
1. Validates proposal is approved
2. Logs execution start
3. Calls approval callback if set
4. Handles execution errors

#### `set_approval_callback(callback: Callable[[Proposal], None]) -> None`
Sets a callback function for approved proposals.

**Parameters:**
- `callback`: Function that takes a `Proposal` and returns `None`

**Usage:**
```python
def on_approval(proposal: Proposal):
    engine.execute_approved(proposal)

engine.set_approval_callback(on_approval)
```

#### `start_monitoring() -> None`
Starts background monitoring for approval responses.

**Behavior:**
- Creates daemon thread for monitoring
- Calls `_monitor_approval_channel()`

#### `_monitor_approval_channel() -> None`
Background thread to monitor approval channel for responses.

**Implementation Note:**
- WebSocket listener is attached to `MattermostInterface`
- This method serves as monitoring entry point

#### `stop_monitoring() -> None`
Stops background monitoring for approval responses.

**Behavior:**
- Sets monitoring flag to False
- Waits for thread to join
- Logs monitoring stop

## Convenience Functions

### `create_and_send_proposal(...) -> Optional[Proposal]`
Convenience function to create and send a proposal in one call.

**Parameters:**
- `action`: The specific command to execute
- `justification`: Agent's reasoning
- `risk_assessment`: Potential negative impacts
- `parameters`: Technical metadata

**Returns:**
- `Proposal` if successful
- `None` if connection or send fails

**Behavior:**
1. Creates new `ProposalEngine` instance
2. Connects to Mattermost
3. Creates the proposal
4. Sends to Mattermost

## Zero Trust Workflow

### Standard Approval Flow
```
1. Agent identifies high-stakes action
   ‚Üì
2. Creates Proposal with task_id, action, justification, risk
   ‚Üì
3. Sends to Mattermost approval channel
   ‚Üì
4. User sees proposal and responds with "Approve [task_id]"
   ‚Üì
5. MattermostInterface detects approval response
   ‚Üì
6. ProposalEngine validates and moves to approved list
   ‚Üì
7. Callback executes the approved action
   ‚Üì
8. Action completes
```

### High-Risk Intercept (Cortex Integration)
The Cortex module intercepts classified tasks and routes them through the Proposal Engine before any department execution:

```
Cortex.route() ‚Üí Classifies Task
                ‚Üì
        Is it high-risk?
                ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Yes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚Üì              ‚Üì
    No              ProposalEngine.create_proposal()
        ‚Üì              ‚Üì
    Route to      ProposalEngine.send_proposal()
    Department    ‚Üì
        ‚Üì              ‚Üì
    Execute    Wait for Approval
                            ‚Üì
                    ProposalEngine.execute_approved()
                            ‚Üì
                        Execute Action
```

## Configuration

### Mattermost Settings
```yaml
mattermost:
  url: "https://mattermost.example.com"
  token: "${MATTERMOST_TOKEN}"
  approval_channel: "approvals"  # Channel for proposals
  approval_team: "cobalt-team"   # Team containing approval channel
```

### Human Intervention Triggers
The following actions require proposal approval:
- File system modifications
- Financial transactions
- System command execution
- Configuration changes
- Any destructive operation

## Security Considerations

1. **Task ID Format**: 8-character UUID prefix balances uniqueness with manual entry feasibility
2. **Channel Validation**: Approval must occur in designated channel only
3. **Regex Matching**: Case-insensitive pattern matching for user convenience
4. **No Auto-Approval**: All high-stakes actions require explicit human approval
5. **Logging**: All proposal lifecycle events are logged for audit trail

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/reset_memory_table.md
========================================

---
title: "Reset Memory Table Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[postgres]]"
location: "dev_utils/reset_memory_table.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Reset Memory Table Script

**Location:** `dev_utils/reset_memory_table.py`

## Overview

Reset Memory Table drops the `memory_logs` table from the PostgreSQL database. Use this when the schema is incorrect and needs to be recreated from scratch.

## Usage

```bash
python dev_utils/reset_memory_table.py
```

Or with uv:

```bash
uv run python dev_utils/reset_memory_table.py
```

## ‚ö†Ô∏è Destructive Warning

üö® **THIS SCRIPT DELETES THE ENTIRE memory_logs TABLE** - All data in the table will be permanently lost. This action cannot be undone.

**Before running:**
1. Ensure you have a database backup
2. Verify the table name (`memory_logs`)
3. Confirm this is the correct table to reset

## Behavior

The script performs the following actions:

1. Connects to PostgreSQL using credentials from `.env` or environment variables
2. Drops the `memory_logs` table if it exists
3. Prints confirmation of successful deletion

## Environment Variables

| Variable | Default | Description |
|--|--|--|
| `POSTGRES_HOST` | `localhost` | Database host |
| `POSTGRES_DB` | `cobalt_memory` | Database name |
| `POSTGRES_USER` | `postgres` | Database user |
| `POSTGRES_PASSWORD` | `cobalt_password` | Database password |

## Typical Use Case

This script is used when:
- The database schema has been incorrectly initialized
- A schema migration has failed
- You need to start fresh with a new schema

**After running:**
1. Run the schema creation script to rebuild the table
2. Re-run any necessary data seeding scripts

## Dependencies

- `psycopg` - PostgreSQL client library
- `python-dotenv` - Environment variable loading

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/search.md
========================================

---
title: "Search Tool Documentation"
status: Active
module: Tool
type: Class
dependencies:
  - "[[tool_manager]]"
location: "src/cobalt_agent/tools/search.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Search Tool Module

**Location:** `src/cobalt_agent/tools/search.py`

## Overview

Search Tool provides internet search functionality using the `ddgs` package. Returns strict Pydantic models instead of raw dictionaries.

## Class: `SearchResult` (Pydantic Model)

A single search result item.

### Fields

| Field | Type | Description |
|-------|------|---------|
| `title` | `str` | The title of the search result |
| `href` | `str` | The URL link to the result |
| `body` | `str` | The snippet or summary text |

---

## Class: `SearchTool`

Executes internet searches and returns structured results.

### Attributes

| Attribute | Value |
|--|--|
| `name` | `"search"` |
| `description` | `"Search the internet for news, information, and general knowledge. Use for questions about current events, topics, or general queries."` |

### Methods

#### `run(query: str, max_results: int = 5) -> List[SearchResult]`

Executes a search and returns a list of typed SearchResult objects.

**Parameters:**
- `query`: Search query string
- `max_results`: Maximum number of results to return (default: 5)

**Returns:** List of SearchResult objects

**Workflow:**
1. Execute search using DDGS context manager
2. Convert raw results to Pydantic models
3. Handle malformed results gracefully
4. Return empty list on failure

### Usage Example

```python
tool = SearchTool()
results = tool.run(" Cobalt AI agent", max_results=3)
for result in results:
    print(f"{result.title}: {result.href}")

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/second_day_play.md
========================================

---
title: "Second Day Play Strategy Documentation"
status: Active
module: Strategy
type: Class
dependencies:
  - "[[playbook]]"
  - "[[strategy]]"
  - "[[config]]"
location: "src/cobalt_agent/brain/strategies/second_day_play.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Second Day Play Strategy

**Location:** `src/cobalt_agent/brain/strategies/second_day_play.py`

## Overview

Second Day Play is a day trading strategy that identifies high-probability setups based on the second day of a breakout pattern. It dynamically loads scoring rules and thresholds from `strategies.yaml`.

## Class: `SecondDayPlay`

Analyzes market data and returns a Scoring Profile (JSON) for potential trades.

### Constructor

```python
SecondDayPlay(config: dict = None)
```

**Parameters:**
- `config`: Configuration dictionary containing `parameters`, `scoring`, and strategy metadata.

### Attributes

- `params`: Dictionary of trading parameters (RVOL thresholds, price zones)
- `scoring`: Dictionary of scoring modifiers and points
- `name`: Strategy name
- `version`: Strategy version (1.1)

---

## Scoring Engine

The strategy calculates a dynamic score based on:

### RVOL Modifiers
- **High RVOL Threshold** (default: 3.0): Adds points for exceptional volume
- **Base RVOL Points** (default: 10): Points for meeting minimum volume requirement
- **Live RVOL Multiplier** (default: 5.0): Applied during market hours
- **Base Score** (default: 50): Starting point before modifiers

### Gap Modifiers
- **Gap Up Points** (default: 10): Applied when price gaps up at open

### abort_conditions
List of price/volume conditions that trigger immediate exit:
- Price drops below stop loss
- Volume run rate falls below 50% of expected

---

## Output Structure

```python
{
    "timestamp": "2026-02-22T16:30:00",
    "ticker": "NVDA",
    "strategy": "SecondDayPlay",
    "status": "ACTIVE_WATCH",  # or "REJECTED"
    "direction": "LONG",
    "zones": {
        "entry": 165.50,
        "stop": 162.30,
        "target": 171.10,
        "risk_per_share": 3.20
    },
    "scoring_engine": {
        "base_score": 75,
        "modifiers": {
            "live_rvol_multiplier": 5.0,
            "spy_correlation_weight": 10.0,
            "resistance_penalty": -20.0,
            "time_decay_per_min": -0.5
        }
    },
    "abort_conditions": ["price < 162.30", "volume_run_rate < 50%"]
}

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/strategy.md
========================================

---
title: "Strategy Interface Documentation"
status: Active
module: Strategy
type: Class
dependencies:
  - "[[playbook]]"
  - "[[second_day_play]]"
location: "src/cobalt_agent/brain/strategy.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Strategy Module

## Overview

The Strategy Interface defines the contract that all trading strategies must implement. This enforces a standard structure for the Backtester and Live Engine.

## Class: `Strategy` (ABC)

Abstract Base Class for all Cobalt Strategies.

### Constructor

```python
Strategy(config: Dict[str, Any])
```

Initializes a strategy with specific parameters from `strategies.yaml`.

**Parameters:**
- `config`: Dictionary containing strategy parameters including `name`, `time_window`, and other configuration data.

### Methods

#### `analyze(market_data: Any) -> Dict[str, Any]`
**Abstract Method** - Core logic that must be implemented by all strategies.

**Parameters:**
- `market_data`: A clean object containing Price, Volume, VWAP, etc.

**Returns:**
Dictionary containing:
- `signal`: 'BUY', 'SELL', or 'WAIT'
- `confidence`: 0.0 to 1.0 (The 'T-Shirt Size')
- `stop_loss`: Price level
- `target`: Price level
- `reason`: Text explanation

#### `check_time_window(current_time_str: str = None) -> bool`
Helper method that checks if trading is allowed within the configured time window.

**Parameters:**
- `current_time_str`: Optional time string in HH:MM format (defaults to current time).

**Returns:**
`True` if within the configured time window, `False` otherwise.

---

## Strategy Structure

All strategies must implement the `analyze()` method and return a consistent structure:

```python
{
    "signal": "BUY|SELL|WAIT",
    "confidence": 0.75,
    "stop_loss": 145.50,
    "target": 160.00,
    "reason": "Positive momentum and volume surge detected"
}
```

---

## Related Files

- `playbook.py` - Orchestrates strategy execution
- `tactical.py` - Strategos agent that uses strategies
- `strategies/second_day_play.py` - Example strategy implementation

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/tactical.md
========================================

---
title: "Tactical Module Documentation"
status: Active
module: Brain
type: Class
dependencies:
  - "[[tactical]]"
  - "[[playbook]]"
  - "[[finance]]"
location: "src/cobalt_agent/brain/tactical.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Tactical Module

## Overview

The Strategos Agent (Tactical Department Head) is responsible for:
1. Market Data Retrieval (FinanceTool)
2. Strategy Execution (Playbook)

## Class: `Strategos`

The Quantitative Trading Engine. Routes raw data requests or executes full strategy scans.

### Constructor

```python
Strategos()
```

Initializes Strategos with:
- `finance`: FinanceTool instance for market data retrieval
- `playbook`: Playbook instance for strategy execution

Logs the number of loaded strategies on initialization.

### Methods

#### `run(task: str) -> str`
Main entry point for the Tactical Department.

**Parameters:**
- `task`: The ticker symbol (e.g., 'NVDA') or a specific command.

**Returns:**
A combined intelligence report containing market data and strategy scan results.

**Workflow:**
1. Cleans input (extracts ticker symbol)
2. Retrieves raw market data via FinanceTool
3. Converts data to dictionary format
4. Runs all active strategies via Playbook
5. Returns combined intelligence

**Special Commands:**
- `"STRATEGY"` or `"PLAYBOOK"`: Returns list of active strategies instead of analysis

### Example Output

```
FinanceData(ticker='NVDA', price=165.50, volume=50000000)
[‚öîÔ∏è Strategy Scan]
**second_day_play** [ACTIVE_WATCH]
   ‚Ä¢ Score: 75/100 (High)
   ‚Ä¢ Logic: Positive relative volume and gap up pattern
   ‚Ä¢ HUD Config: 3 dynamic rules active

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/tool_manager.md
========================================

---
title: "Tool Manager Documentation"
status: Active
module: Core
type: Orchestrator
dependencies:
  - "[[search]]"
  - "[[browser]]"
  - "[[finance]]"
location: "src/cobalt_agent/tools/tool_manager.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Tool Manager Module

## Overview

Cobalt Agent - Tool Manager is a registry and execution engine for all agent capabilities.

## Class: `ToolResult` (Pydantic Model)

Standardized output for any tool execution.

### Fields

| Field | Type | Description |
|-------|------|-------------|
| `success` | `bool` | Whether the tool execution succeeded |
| `output` | `Any` | The result output from the tool |
| `error` | `Optional[str]` | Error message if execution failed |

---

## Class: `ToolManager`

Manages the registration and execution of tools. Allows the LLM to 'see' and 'use' functions.

### Constructor

```python
ToolManager()
```

Initializes the tool manager and registers core tools:
1. SearchTool
2. BrowserTool
3. FinanceTool

### Methods

#### `register_tool(name: str, tool_instance: Any) -> None`
Add a new tool to the registry.

**Parameters:**
- `name`: Unique identifier for the tool
- `tool_instance`: Instance of the tool (must have a `run()` method)

#### `get_tool_descriptions() -> List[Any]`
Return the list of tool objects for the Prompt Engine.

#### `execute_tool(tool_name: str, args: Dict[str, Any]) -> ToolResult`
Execute a registered tool by name.

**Parameters:**
- `tool_name`: The name of the tool (e.g., 'search')
- `args`: Dictionary of arguments for the tool

**Returns:** `ToolResult` with success status, output, and optional error message.

### Tool Execution Logic

1. Extract query from args (supports 'query', 'q', or first value)
2. Check if tool exists
3. Call tool's `run()` method
4. Return standardized result

---

## Tool Registry

| Name | Class | Description |
|------|-------|-------------|
| `search` | SearchTool | Internet search for information |
| `browser` | BrowserTool | Web page content retrieval |
| `finance` | FinanceTool | Market data retrieval |

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/update_board.md
========================================

---
title: "Update Board Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[scribe]]"
location: "dev_utils/update_board.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Update Board Script

**Location:** `dev_utils/update_board.py`

## Overview

Update Board populates the Obsidian Project Board with Phase 4 & 5 tasks. It creates markdown files with proper frontmatter for use with Dataview plugins or Kanban views.

## Usage

```bash
python dev_utils/update_board.py
```

Or with uv:

```bash
uv run python dev_utils/update_board.py
```

## ‚ö†Ô∏è Destructive Warning

‚ö†Ô∏è **This script creates new files** - it does not modify existing ones. However, if run multiple times, it may create duplicate task files. Check the `0 - Inbox` folder before running.

## Behavior

The script performs the following actions:

1. **Imports** the Scribe class from `cobalt_agent.skills.productivity.scribe`
2. **Calls** `create_task()` for each Phase 4 & 5 task
3. **Saves** each task to the `0 - Inbox` folder in your Obsidian vault

## Output Files

| ID | Title | Priority | Module | Complexity |
|--|--|--|--|--|
| 23 | Strategos Agent Setup | P0 | Tactical | M |
| 24 | Playbook Registry | P1 | Tactical | S |
| 25 | Strategy Interface | P1 | Tactical | M |
| 26 | Second Day Play Impl | P1 | Tactical | L |
| 27 | Backtest Engine | P2 | Tactical | XL |
| 28 | Ops Medical Stub | P2 | Ops | S |
| 29 | Privacy Guardrails | P0 | Ops | M |

## Task File Format

Each task file contains:
- Status: `To Do`
- Priority: `P0` (Critical) through `P2` (Normal)
- Module: `Tactical` or `Ops`
- Complexity: `S`, `M`, `L`, or `XL`
- Acceptance criteria: Code implemented and verified

## Dependencies

- `cobalt_agent.skills.productivity.scribe` - Obsidian integration
- `sys`, `os` - Path handling

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/vault.md
========================================

---
title: "Vault Manager Documentation"
status: Active
module: Security
type: Class
dependencies:
  - "[[config]]"
  - "[[mattermost]]"
location: "src/cobalt_agent/security/vault.py"
tags: [cobalt, dev_docs, security]
created: 2026-02-24
---

# Vault Manager (Zero Trust Secrets Manager)

## Overview
The Vault Manager is a Just-In-Time (JIT) secrets manager that provides secure storage and retrieval of API keys, tokens, and credentials. It uses AES-256 encryption with **RAM-only decryption** - secrets exist only in memory during active use and are never exposed in plaintext on disk.

### Core Features
- **AES-256 Fernet encryption** for secure at-rest storage
- **RAM-only decryption** - secrets exist only in memory when vault is unlocked
- **Automatic injection** - secrets are injected into `os.environ` and config schema at runtime
- **Flat strings and JSON support** - handles both simple keys and grouped credentials
- **Manual key rotation** via `COBALT_MASTER_KEY` environment variable

---

## Class: `VaultManager`

### Constructor
```python
def __init__(self, vault_path: str = "data/.cobalt_vault")
```
Initializes the vault manager with the specified vault file path.

**Parameters:**
- `vault_path`: Path to the encrypted vault file (default: `"data/.cobalt_vault"`)

### Key Attributes
- `vault_path`: Path to the encrypted vault file on disk
- `_secrets`: Dictionary storing decrypted secrets in RAM (only populated when unlocked)
- `_is_unlocked`: Boolean indicating whether the vault is currently decrypted

### Main Methods

#### `generate_master_key() -> str`
Generates a new AES-256 Fernet key. Run this once to create your master key.

**Returns:**
- `str`: A new Fernet key for encrypting/decrypting the vault

**Usage:**
```bash
export COBALT_MASTER_KEY="your-generated-key-here"
```

#### `unlock(master_key: str) -> bool`
Decrypts the vault file into RAM. This is the only way to access secrets.

**Parameters:**
- `master_key`: The AES-256 Fernet key to decrypt the vault

**Returns:**
- `True` if decryption succeeded
- `False` if the key was invalid or data was corrupt

**Behavior:**
- Loads the encrypted vault file from disk
- Decrypts the contents using Fernet
- Stores decrypted JSON in `_secrets` dictionary
- Sets `_is_unlocked = True`
- Logs success or failure

#### `lock() -> None`
Wipes secrets from RAM and locks the vault.

**Behavior:**
- Clears the `_secrets` dictionary
- Sets `_is_unlocked = False`
- Logs the lock event

#### `get_secret(key_name: str) -> Optional[str]`
Retrieves a secret from the unlocked vault.

**Parameters:**
- `key_name`: The name of the secret to retrieve

**Returns:**
- The secret value if found and vault is unlocked
- `None` if vault is locked or key not found

#### `set_secret(master_key: str, key_name: str, secret_value: str) -> bool`
Adds or updates a secret in the vault.

**Parameters:**
- `master_key`: The encryption key (must have vault unlocked first)
- `key_name`: The name of the secret (e.g., `OPENAI_API_KEY`)
- `secret_value`: The secret value to store

**Returns:**
- `True` if the secret was saved successfully
- `False` if vault is locked or save failed

**Behavior:**
- Stores the secret in RAM
- Encrypts and saves the entire vault to disk

#### `list_secrets() -> List[str]`
Lists all secret keys currently in the vault.

**Returns:**
- List of secret names if vault is unlocked
- Empty list if vault is locked

#### `delete_secret(master_key: str, key_name: str) -> bool`
Removes a secret from the vault and updates the vault file.

**Parameters:**
- `master_key`: The encryption key
- `key_name`: The name of the secret to delete

**Returns:**
- `True` if the secret was deleted
- `False` if vault is locked or key not found

---

## CLI Utility: `manage_vault.py`

### Overview
The `manage_vault.py` script provides an interactive command-line interface for managing the vault. It requires the `COBALT_MASTER_KEY` environment variable to be set.

### Location
```
dev_utils/manage_vault.py
```

### Requirements
- **Mandatory**: `COBALT_MASTER_KEY` environment variable must be set
- **Optional**: If not set, the script will offer to generate a new key

### Usage
```bash
# Set the master key first (REQUIRED)
export COBALT_MASTER_KEY="your-fernet-key-here"

# Run the management script
python dev_utils/manage_vault.py
```

### Interactive Menu
When run, the script presents the following options:

1. **List All Secret Names** - Shows all keys currently stored in the vault
2. **Retrieve a Secret** - Displays the value of a specified secret
3. **Add/Update a Secret** - Store a new secret (supports flat strings or JSON)
4. **Delete a Secret** - Remove a secret from the vault
5. **Exit and Lock Vault** - Save changes and lock the vault

### Secret Value Formats

The CLI supports both flat strings and JSON strings for different use cases:

| Format | Example | Use Case |
|--------|---------|----------|
| Flat String | `sk-proj-abc123...` | Simple API keys (OPENAI_API_KEY, GEMINI_API_KEY) |
| JSON String | `{"url":"...", "user":"...", "pass":"..."}` | Grouped credentials (MATTERMOST_CREDS) |

### Error Handling
- **No Master Key**: Script generates a new key and prompts user to save it
- **Invalid Key**: Error message displayed, script exits
- **Corrupt Vault**: Warning logged, empty vault created

---

## Configuration Integration

### Loading Priority (Highest to Lowest)
1. **Environment Variables** - Strictly for node/Docker specific data (POSTGRES_HOST, etc.)
2. **Secure Vault** - API keys and tokens injected dynamically at runtime
3. **YAML Configuration Files** - Static configuration (trading_rules, persona, etc.)

### How Secrets Are Injected

When `COBALT_MASTER_KEY` is present, the configuration loader:

1. **Unlocks the vault** using the provided key
2. **Lists all secrets** in the vault
3. **Attempts JSON parsing** for each secret value
4. **Routes secrets based on name**:
   - `MATTERMOST_CREDS` ‚Üí Parsed as JSON, injected into `mattermost` config
   - Other secrets ‚Üí Injected into `keys` section and `os.environ`

### Example Runtime Injection

```python
# When vault is unlocked:
vault.list_secrets()  # ['OPENAI_API_KEY', 'MATTERMOST_CREDS']

# Flat string injection:
os.environ['OPENAI_API_KEY'] = 'sk-proj-abc123'  # Also in config.keys

# JSON injection:
os.environ['MATTERMOST_URL'] = 'https://mattermost.example.com'
os.environ['MATTERMOST_TOKEN'] = 'xyz789token'
# Also in config.mattermost: {'url': '...', 'token': '...'}
```

### Security Guarantees
- **Zero disk persistence** of decrypted secrets
- **Automatic lock** after configuration load completes
- **Environment variable isolation** - secrets only in `os.environ` during active use
- **Type-safe schema** - secrets mapped to specific config fields

---

## Security Best Practices

1. **Never commit the master key** - Use `.env.example` to document required variables
2. **Rotate keys regularly** - Generate new `COBALT_MASTER_KEY` periodically
3. **Lock vault when idle** - Secrets are automatically locked after config loading
4. **Use environment-specific vaults** - Separate vaults for dev/staging/production
5. **Audit secret access** - Log all vault unlock/access events

---

## File Structure

```
data/
‚îî‚îÄ‚îÄ .cobalt_vault          # Encrypted vault file (AES-256)
    ‚îî‚îÄ‚îÄ plaintext in RAM   # Decrypted secrets (JSON) - RAM-only
```

### Vault File Format (Encrypted)
```json
{
  "OPENAI_API_KEY": "sk-proj-abc123...",
  "MATTERMOST_CREDS": "{\"url\":\"https://mattermost.example.com\",\"token\":\"xyz789\"}"
}
```

### Environment Variable Mapping

| Vault Key | Environment Variable | Config Field |
|-----------|---------------------|--------------|
| `OPENAI_API_KEY` | `OPENAI_API_KEY` | `llm.api_key` |
| `ANTHROPIC_API_KEY` | `ANTHROPIC_API_KEY` | `llm.api_key` |
| `MATTERMOST_CREDS` | `MATTERMOST_URL`, `MATTERMOST_TOKEN` | `mattermost.url`, `mattermost.token` |

---

## Example Usage

### Initialize Vault (One-Time Setup)
```bash
python dev_utils/manage_vault.py
# Follow prompts to generate a new master key
# Save the key: export COBALT_MASTER_KEY="..."
```

### Add a Secret
```bash
export COBALT_MASTER_KEY="your-fernet-key"
python dev_utils/manage_vault.py
# Select option 3, enter secret name and value
```

### Use in Application Code
```python
from cobalt_agent.config import load_config

# Configuration automatically unlocks vault if COBALT_MASTER_KEY is set
config = load_config()

# Secrets are injected into config and os.environ
# config.llm.api_key contains the vault value
# os.environ['OPENAI_API_KEY'] contains the vault value
```

### Lock Vault Manually
```python
from cobalt_agent.config import Config

config = Config.get_instance()
config.lock_vault()  # Wipes secrets from RAM

========================================
FILE: docs/0 - Projects/Cobalt/00 - Master Plan/Developer Docs/wipe_memory.md
========================================

---
title: "Wipe Memory Documentation"
status: Active
module: Utility
type: Script
dependencies:
  - "[[postgres]]"
location: "dev_utils/wipe_memory.py"
tags: [cobalt, dev_docs]
created: 2026-02-23
---

# Wipe Memory Script

**Location:** `dev_utils/wipe_memory.py`

## Overview

Wipe Memory is a utility script that removes all data from any table in the PostgreSQL public schema. It finds all tables and truncates them without dropping them.

## Usage

```bash
python dev_utils/wipe_memory.py
```

Or with uv:

```bash
uv run python dev_utils/wipe_memory.py
```

## ‚ö†Ô∏è Destructive Warning

üö® **THIS SCRIPT DELETES ALL DATA FROM ALL TABLES** in the public schema - all records will be permanently lost. This action cannot be undone.

**Before running:**
1. Ensure you have a database backup
2. Verify you are connected to the correct database
3. Understand that ALL tables will be truncated

## Behavior

The script performs the following actions:

1. Connects to PostgreSQL using credentials from `.env` or environment variables
2. Queries the `information_schema.tables` to find all tables in the public schema
3. Truncates each table found (removes all rows)
4. Prints the name of each table being wiped

## Environment Variables

| Variable | Default | Description |
|--|--|--|
| `POSTGRES_HOST` | `localhost` | Database host |
| `POSTGRES_DB` | `cobalt_memory` | Database name |
| `POSTGRES_USER` | `postgres` | Database user |
| `POSTGRES_PASSWORD` | `cobalt_password` | Database password |

## Typical Use Case

This script is used when:
- You need to clear all memory logs for testing
- You want to reset the database to empty state
- You are debugging and need a clean slate

**After running:**
- All tables remain (schema intact), but all rows are deleted
- You may need to re-seed any reference data

## Dependencies

- `psycopg` - PostgreSQL client library
- `python-dotenv` - Environment variable loading

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-001 Cobalt-Ion Tactical HUD.md
========================================

---
title: "PRD-001: Cobalt-Ion Tactical HUD"
status: Draft
priority: P0
module: [Requirements]
phase: 1
complexity: L
tags: [cobalt, prd, requirements]
created: 2026-02-23
---

# PRD-001: Cobalt-Ion Tactical HUD

## 1. Executive Summary
**The Vision:** Build a "Co-Pilot" system for manual day trading.
**The Problem:** Professional trading requires processing dozens of variables (RVOL, Levels, Tape, News) in real-time. Humans are slow and emotional.
**The Solution:** A "Heads-Up Display" (HUD) that acts as a real-time **Confidence Gauge**. It calculates the mathematical "Expected Value" (EV) of a trade 10x/second, allowing the trader to execute with conviction.

## 2. Core Philosophy: The Sniper and Spotter Architecture

1.  **Not an Auto-Trader (With Exception):** The system does not execute trades autonomously by default. It observes, calculates, and suggests. The user pulls the trigger. **Exception:** Ion *can* execute autonomously, but ONLY when provided with a cryptographic Just-In-Time (JIT) execution token by the Human-in-the-Loop via the Mattermost Proposal Engine.

2.  **Distributed Brain:**
    * **Mac Studio (Cobalt):** The Spotter. Slow, deep thinking. Analysis of Context & Catalysts. Written in Python.
    * **Windows PC (Ion):** The Sniper. Fast, reactive execution. Visualizing the HUD and executing with cryptographic JIT tokens. Written in Rust.

3.  **Separation of Concerns:**
    * **Cobalt (Spotter):** Responsible for high-level strategy, risk analysis, and generating the "Math Package." Operates on Mac.
    * **Ion (Sniper):** Responsible for real-time scoring, latency-sensitive execution, and HUD rendering. Operates on Windows.

## 3. User Stories

### Story A: The "Morning Briefing" (Context)
**As a** Trader,
**I want** Cobalt to scan the market for "In Play" stocks and identify the specific *Strategies* (from my Playbook) that apply to them (e.g., "NVDA is an Earnings Gap"),
**So that** I start the day with a curated list of opportunities, not just raw tickers.

### Story B: The "Formula Injection" (Handoff)
**As a** System Architect,
**I want** Cobalt to send a "Math Package" (JSON) to Ion containing the specific *Weights and Variables* for the day (e.g., "For NVDA, Gap Fill is +10 points, Resistance at $145 is -20 points"),
**So that** Ion can run the math locally without latency, acting as a "dumb calculator" for Cobalt's "smart rules."

### Story C: The "Tactical Engagement" (The HUD)
**As a** Trader executing a trade,
**I want** a visual Gauge (0-100) that updates in real-time based on Price, Volume, and Time,
**So that** I can intuitively see if the trade is degrading (Score dropping) or improving (Score rising) without doing mental math.
* *Example:* "I am long NVDA. Volume dries up -> Score drops 10 points -> Gauge turns Yellow -> I trim my position."

### Story D: The "JIT Token" (Autonomous Execution)
**As a** Human-in-the-Loop Trader,
**I want** to issue a cryptographic Just-In-Time execution token via the Mattermost Proposal Engine,
**So that** Ion can execute trades autonomously during high-velocity market conditions while maintaining strict human oversight.
* *Example:* "I approve this trade with a 5-minute JIT token -> Ion executes at $145.25 -> Trade is closed if price moves against me."

## 4. Functional Requirements

### 4.1 The Scoring Engine (Dynamic EV)
The Score (0-100) is calculated as:
$$ Score = Base + Fuel - Friction - Decay $$
* **Base:** Static score from the Daily Setup (e.g., "A+ Setup" = 60).
* **Fuel (Momentum):** Live modifiers (e.g., `RVOL > 2.0` adds +10).
* **Friction (Risk):** Proximity to Resistance (e.g., `Dist < $0.10` subtracts -20).
* **Decay (Time):** Penalty for stalling (e.g., `-1 point` per minute of chop).

### 4.2 The "Math Package" Protocol
Cobalt must send a JSON payload to Ion containing:
* `Ticker`: Symbol (e.g., "NVDA").
* `Strategies`: List of active setups (e.g., ["GapAndGo", "BellaFade"]).
* `Zones`: Key Price Levels (Entry, Stop, Target).
* `Coefficients`: The weights for the Scoring Engine.

### 4.3 The Multi-Strategy Capability
The system must support **Conflicting Strategies** simultaneously.
* *Scenario:* NVDA gaps up.
* *HUD State:* Ion displays *two* potential scores:
    1.  **Long Score:** For the "Gap & Go" breakout.
    2.  **Short Score:** For the "Extension Fade" reversal.

### 4.4 The JIT Token Protocol
* **Format:** Cryptographically signed JWT token containing:
  * `symbol`: Trading pair/ticker
  * `direction`: Long/Short
  * `quantity`: Amount to execute
  * `deadline`: Unix timestamp for token expiration
  * `signature`: HMAC-SHA256 signature from Mattermost Proposal Engine
* **Validation:** Ion MUST verify the token signature before executing any trade.
* **Expiration:** Tokens expire after a configured time window (default: 5 minutes).

## 5. Technical Constraints
* **Language (Cobalt):** Python 3.11+.
* **Language (Ion):** Rust (stable channel).
* **GUI Framework:** Any relevant (Windows) for transparent overlays.
* **Communication:** Redis Pub/Sub **or** ZeroMQ over Tailscale LAN.
* **Data Source:** TradeStation API (connected locally on Windows).
* **Latency Target:** < 50ms from Tick to HUD Update.
* **Security:** All autonomous execution requires cryptographic token verification.

## 6. Future Extensibility
* **Discord Integration:** Manual scraping of trader sentiment to adjust "Base Scores."
* **Journaling:** Automated logging of *why* a score was high/low at the moment of execution.
* **Token Dashboard:** Web interface to view active JIT tokens and their expiration times.

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-002 Mattermost HITL Proposal Engine.md
========================================

---
title: "PRD-002: Mattermost HITL Proposal Engine"
status: Draft
priority: P0
module: [Requirements]
phase: 1
complexity: L
tags: [cobalt, prd, requirements]
created: 2026-02-23
---

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-003 Zero Trust Docker Sandbox.md
========================================

---
title: "PRD-003: Zero Trust Docker Sandbox"
status: Draft
priority: P0
module: [Requirements]
phase: 1
complexity: L
tags: [cobalt, prd, requirements]
created: 2026-02-23
---

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-004 Cortex LLM Switchboard Router.md
========================================

---
title: "PRD-004: Cortex LLM Switchboard Router"
status: Draft
priority: P0
module: [Requirements]
phase: 1
complexity: L
tags: [cobalt, prd, requirements]
created: 2026-02-23
---

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-005 Voice Architecture.md
========================================

---
title: "PRD-005 Voice Architecture"
status: Draft
priority: P2
module: [Requirements]
phase: Backlog
complexity: L
tags: [cobalt, prd, requirements, voice]
created: 2026-02-23
---

# Voice Architecture Plan

**Purpose**: Documenting intent to add voice-controlled interaction capabilities for X1 Carbon integration.

**Last Updated**: 2026-02-18

## Overview

This document outlines the planned architecture for voice-based interaction in Project Cobalt, enabling hands-free control through natural language processing.

## Planned Components

### 1. Mattermost Integration
- **Purpose**: Voice-controlled messaging and collaboration
- **Features**:
  - Read and send messages via voice commands
  - Join/leave channels with voice
  - Search message history using natural language

### 2. Browser Control
- **Purpose**: Voice-driven web automation
- **Features**:
  - Navigate to URLs via voice command
  - Extract content using natural language queries
  - Perform searches and interpret results

## Technical Considerations

- **Speech-to-Text**: Integration with transcription services
- **Text-to-Speech**: Natural sounding voice responses
- **Intent Recognition**: Mapping voice commands to system actions
- **Error Handling**: Graceful fallback for misinterpreted commands

## Related Files

- `src/cobalt_agent/tools/browser.py` - Existing browser control module
- `src/cobalt_agent/main.py` - Main agent entry point
- `configs/config.yaml` - Configuration for voice services

## Status

- **Phase**: Planning / Design
- **Priority**: Medium
- **Dependencies**: Qwen3-80B integration complete (v0.5.0)

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/Requirements/PRD-006 Dynamic Browser Automation.md
========================================

---
title: "PRD-006: Dynamic Browser Automation"
status: Approved
priority: P1
module: [Requirements, Tools]
phase: 5
complexity: M
tags: [cobalt, prd, requirements, playwright, browser]
created: 2026-02-25
---

# PRD-006: Dynamic Browser Automation

## 1. Executive Summary
**The Vision:** Give Cobalt "hands" to navigate the modern, dynamic web.
**The Problem:** The existing `BrowserTool` relies on `requests` and `BeautifulSoup`. It is blind to JavaScript-rendered content (Single Page Applications) and cannot interact with pages (click, type, login). Modern financial and news data portals are heavily obfuscated behind dynamic loading and cookie banners.
**The Solution:** Implement a headless browser engine that allows Cobalt to not just "read" a URL, but actively drive a browser session using a predefined set of actions.

## 2. User Stories
### Story A: The JS-Heavy Scrape
**As a** Researcher,
**I want** Cobalt to read data from a modern web app (like TradingView or SEC Edgar),
**So that** I can get accurate data even if the HTML body is initially empty and requires JavaScript to render.

### Story B: The Vault-Secured Login
**As a** Chief of Staff,
**I want** Cobalt to securely retrieve credentials from the Local Vault, navigate to a data portal, fill out the login form, click "Submit", and extract the dashboard text,
**So that** I can automate daily data extraction behind paywalls without exposing my passwords to the LLM or plain text logs.

## 3. Functional Requirements
1. **Dual-Mode Input:** The tool must accept either a simple string (URL) for basic scraping, or a JSON object containing a target URL and a sequential list of actions.
2. **Action DSL (Domain Specific Language):** Support specific interaction types:
   - `fill`: Target a CSS selector and input text.
   - `click`: Target a CSS selector and trigger a click, waiting for network idle.
3. **DOM Cleaning:** Before returning text to the LLM, the tool must strip scripts, styles, headers, footers, and navbars to save context window tokens.

## 4. Technical Constraints
- Must run headlessly to avoid interrupting the user's primary desktop experience.
- Must include hard timeouts to prevent infinite hanging on broken selectors.
- Must spoof User-Agent strings to minimize bot detection.

========================================
FILE: docs/0 - Projects/Cobalt/90 - Project Management/User Stories/Story-001_Initial_Brainstorm.md
========================================

---
title: "Story-001: Initial Brainstorm"
status: Active
module: [Requirements]
tags: [cobalt, user_story]
created: 2026-02-23
---

# Story-001: Initial Brainstorm

## The Cobalt-Ion Distributed Architecture

### System Overview

**Cobalt (Mac Studio - The Strategist):**
- Runs the heavy AI (DeepSeek 70B)
- Monitors the "Catalyst" and "Setup" phases (Minutes/Hours)
- Sets the Rules and generates Scoring Profiles

**Ion (Windows PC - The Engine):**
- A lightweight Python application
- Monitors the "Trade" and "Execution" phases (Milliseconds)
- Runs the math based on formulas provided by Cobalt

### The Data Flow (The "Formula Injection")
1. **Cobalt** scans the market (continuously) and identifies a Ticker as "In Play."
2. **Cobalt** selects *all applicable strategies* from the Playbook (e.g., NVDA fits both "Gap & Go" and "Fade").
3. **Cobalt** generates a **Scoring Profile (JSON)** and pushes it to Ion.
   - This profile contains *Variables* (Weights), not *Decisions*.
   - Example: `{"strategy": "BellaFade", "trigger": "Price < VWAP", "rvol_weight": 10}`.
4. **Ion** subscribes to live data (TradeStation).
5. **Ion** calculates the Score (0-100) and EV live.
6. **Ion** paints the HUD.

### The Core Concept: "Configurator vs. Calculator"

To achieve the speed you need (color changing instantly as volume dries up), we cannot ask the LLM to calculate the score every second. The LLM is too slow and "fuzzy."

Instead, we split the brain:

- **Cobalt (The Coach / Mac):** _Sets the Rules._
  - Before the market opens (or when you spot a setup), Cobalt analyzes the context (News, Daily Chart, Sector).
  - Output: Generates a **"Scoring Profile"** (a JSON file).
    - Example: "For NVDA today: If RVOL > 3, +10 points. If Price hits 145.50 (Resistance), -15 points. If SPY drops, -20 points."

- **Ion (The Engine / Windows):** _Runs the Math._
  - Reads the live data feed and applies the _Scoring Profile_ 10 times a second.
  - Output: Draws the Gauge. It doesn't "think"; it just calculates.

### The Visual Metaphor: "The Confidence Gauge"

Imagine a UI widget floating next to your TradeStation charts.

- **The Needle (0-100):** Represents your **Dynamic Score**.
  - **0-40 (Red):** "No Go" or "Abort." (Iceberg ahead).
  - **41-70 (Yellow):** "Cautious Hold." (Trim position, tighten stops).
  - **71-100 (Green):** "Conviction." (Add size, hold for target).

- **The Delta (Rate of Change):**
  - If the needle suddenly drops from 90 to 60 in 2 seconds, that's your alert to get out _before_ the price collapses. This is faster than waiting for a candle to close red.

### The Logic: How We Calculate "Dynamic EV"

Dynamic EV = (Prob(win) √ó Dist(target)) - (Prob(loss) √ó Dist(stop))

**The Inputs (The Variables Ion Monitors):**
1. **The Setup Score (Static Baseline):**
   - Defined by Cobalt in the morning. (e.g., "A+ Setup = Base Probability 60%").
2. **The "Fuel" (Real-Time Momentum):**
   - **RVOL:** Is volume expanding on the move? (Boosts Probability).
   - **Tape Speed:** Are prints accelerating?
3. **The "Friction" (Resistance/Support):**
   - As Price ‚Üí Resistance, the **Reward** shrinks, but the **Risk of Reversal** grows.
   - Effect: EV drops rapidly as you hit target. The HUD goes yellow ("Take Profit").
4. **The "Decay" (Time):**
   - If you enter and price goes sideways for 10 minutes, probability of success usually drops.
   - Effect: The score slowly bleeds down, turning the gauge yellow/red solely because "It's taking too long."

### Technical Architecture: The "Sidecar" Pattern

**The Stack:**
- **Frontend (Ion):** **Python** (PyQt6 or similar for overlay).
  - Why? Cross-platform development. Deep integration with Windows via native APIs. Can draw "Always on Top" transparent overlays.
- **Data Source:** **TradeStation API / NinjaTrader API.**
  - Ion connects directly to the feed. No round-trip to the Mac for data.
- **The Brain Link:**
  - Cobalt (Mac) runs a **Web Dashboard** (or API endpoint).
  - You chat with Cobalt: _"Watch NVDA for a Gap and Go."_
  - Cobalt sends the **Parameters** to Ion over the LAN.
  - Ion lights up: _"NVDA Watchlist Active. Waiting for Breakout at $145."_

### Strategy: How to Build This

**Phase 1: The "Dashboard" (Mac-based Prototype)**
- Use Python on the Mac.
- Use a fast plotting library (like `Streamlit` or `Dash`) to visualize the "Gauge."
- Input: Simulate the data feed (or hook into a lightweight API like Alpaca/Polygon).
- Goal: Perfect the **Scoring Formula**.

**Phase 2: The "Overlay" (Windows Port)**
- Once the math works, port the _Calculator_ to Python on Windows (Ion).
- Build the visual overlay using PyQt6.

### Trade Phases (State Management)

The HUD needs to behave differently depending on where you are in the trade.

1. **Phase 1: The Stalk (Watchlist)**
   - **Gauge:** Shows **"Setup Quality"**.
   - **Goal:** Alert you when price hits the Trigger _with_ High Score.
   - Logic: Focus heavily on "Gap Maintenance" and "Pre-market Volume."

2. **Phase 2: The Engagement (In Trade)**
   - **Gauge:** Shows **"Holding Confidence"**.
   - **Goal:** Tell you when to fold.
   - Logic:
     - **Time Decay:** Starts ticking. If price doesn't move, score drops.
     - **Extension:** As price moves away from VWAP, risk increases (Score might dip to Yellow to signal "Trim").
     - **Resistance:** As price hits Target, EV drops (Risk of reversal).

### Multi-Strategy Reality

The critical requirement: NVDA having _multiple_ active strategies simultaneously.

**The Architectural Fix:** Cobalt cannot send "One Instruction." It must send a **Strategy Package**. Ion will display **Multiple Gauges** (or a Split Gauge) for NVDA:

1. **Long Gauge (Gap & Go):** Currently at **30/100** (Waiting for breakout).
2. **Short Gauge (Fade):** Currently at **10/100** (Not extended enough).

As the day evolves, if NVDA rips to $145.50 and volume dies:

- **Long Gauge:** Drops to 0 (Trade invalidated).
- **Short Gauge:** Spikes to **95/100** (Green Light).

This is why the Mac must run all day. It watches the "Macro" shift. If the SPY suddenly tanks, Cobalt updates the package: _"Market is now Bearish. Disable all Long strategies. Boost Short EV by 20%."_ Ion receives this update instantly and the HUD changes color before you even blink.

### The Playbook Architecture

Professional traders only execute trades that are in their Playbook.

**Hierarchical State Machine:**
- **Level 1 (Catalyst/Context):** "NVDA is In Play (Earnings)." (Determined by Cobalt/Mac).
- **Level 2 (Setup/Regime):** "It is currently a 'Morning Drive' or 'Reversal' regime." (Determined by Cobalt/Mac).
- **Level 3 (Trade Strategy):** "Active Strategies: `GapAndGo` (Long) AND `BellaFade` (Short)." (Cobalt sends BOTH to Ion).
- **Level 4 (Execution):** "Price broke $145.50 on High Volume -> Trigger `GapAndGo`." (Ion/Windows executes).

### The "Formula Injection" Architecture

Cobalt (The Strategist) and Ion (The Engine) interaction:

1. **Cobalt (Morning/Prep):** Analyzes the context (Daily chart, News, Sector). Determines _what matters today_.
   - Example: "For NVDA, because the market is bearish, 'Gap Strength' is less important, but 'Relative Volume' is critical. Also, there is an iceberg (resistance) at $145.50."
   
2. **The Artifact:** Cobalt generates a **Strategy Config Object (JSON)** that contains _weights and penalties_, not just hard rules.

3. **Ion (Live):** Receives this object. It plugs live data into the formula 10 times a second.

**The Strategy Config Object (JSON):**
```json
{
  "ticker": "NVDA",
  "strategy": "Gap_And_Go",
  "direction": "LONG",
  "levels": {
    "entry": 142.50,
    "stop": 141.00,
    "target": 145.50,
    "resistance_zones": [145.50, 148.00]
  },
  "scoring_weights": {
    "base_score": 65,
    "rvol_multiplier": 5.0,
    "spy_correlation": 10.0,
    "time_decay": -0.5
  },
  "abort_conditions": [
    "price < 140.00",
    "rvol < 0.2 after 10:00"
  ]
}
```

**Why this is powerful:**
- **Ion doesn't need to know _why_ SPY correlation matters.** It just knows: _"If SPY is Green, add 10 points."_
- **Cobalt can change the strategy dynamically.** On a crazy Fed Day, Cobalt might send a config with `base_score: 40` (start cautious) and `time_decay: -2.0` (get out fast if it stalls).

### Next Steps

1. **Don't write the code yourself.** Delete the skeleton I gave you.
2. **Define the Interface:** We only need to define _how_ Cobalt talks to the Strategy Engine (e.g., `analyze(data) -> signal`).
3. **The "Forge" (Future):** When we get to Phase 7, you will paste the SMB PDF, and **Cobalt** will generate `second_day_play.py` and run the backtest.

### Revised Strategic Roadmap

Since we are avoiding "Rapid Coding," let's lock in the **Architecture** before we write another line.

**Does this look like the correct ecosystem to you?**

1. **Mac Studio (The Brain)**
   - **DeepSeek 70B (Local):** The reasoning engine.
   - **Postgres (Docker):** The memory.
   - **Cobalt Core:** The manager.
   - Status: **Built.**

2. **Windows Rig (The Body)**
   - **TradeStation/DAS:** The platform.
   - **Ion Agent (Python Service):**
     - Listens on port 5555.
     - Reads "Account Value" and "Positions" every 1s.
     - Can trigger "Flatten" or "Buy" instantly.
   - Status: **Not Started (Phase 6).**

3. **The "Nerve" (LAN)**
   - A dedicated, encrypted channel between Mac and PC.
   - Keeps the "Brain" safe from Windows viruses/crashes.

### Decision Point

Do you want to continue fleshing out the **Brain (Playbook Logic)** on the Mac now, knowing it will eventually send commands to Ion?

OR

Do you want to switch gears and design the **Ion Protocol** (how the two machines talk) so we know what data we need to send?

========================================
FILE: docs/0 - Projects/Cobalt/Cobalt Project Board.base
========================================

views:
  - type: list
    name: Table
    filters:
      and:
        - file.inFolder("0 - Projects/Cobalt/Tasks")
    groupBy:
      property: status
      direction: ASC
    order:
      - file.name
      - status
      - priority
      - module
      - complexity
    sort:
      - property: file.name
        direction: ASC
      - property: module
        direction: ASC
      - property: priority
        direction: DESC
    columnSize:
      file.name: 244
    cardSize: 110


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/01 System Prep.md
========================================

---
status: Done
priority: P0
module: Ops
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/02 Architecture Setup.md
========================================

---
status: Done
priority: P0
module: Ops
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/03 Dependency Management.md
========================================

---
status: Done
priority: P0
module: Core
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/04 Verification.md
========================================

---
status: Done
priority: P0
module: Ops
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/05 Hello World.md
========================================

---
status: Done
priority: P0
module: Core
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/06 Core Config.md
========================================

---
status: Done
priority: P1
module: Core
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/07 Memory System.md
========================================

---
status: Done
priority: P1
module: Brain
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/08 Persona Logic.md
========================================

---
status: Done
priority: P2
module: Brain
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/09 Interface Layer.md
========================================

---
status: Done
priority: P2
module: Interface
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/10 Tool Manager.md
========================================

---
status: Done
priority: P1
module: Interface
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/11 Prompt Engine.md
========================================

---
status: Done
priority: P1
module: Interface
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/12 Browser Capabilities.md
========================================

---
status: Done
priority: P1
module: Tools
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/13 Trading Engine.md
========================================

---
status: Done
priority: P1
module: Skills
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/14 Autonomous Loop.md
========================================

---
status: Done
priority: P2
module: Brain
complexity:
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/15 Memory Interface.md
========================================

---
status: Done
priority: P0
module: Brain
complexity: S
---
- _Goal:_ Create `base.py` abstract class to standardize memory storage.
    
- _Why:_ Decouples logic from storage, allowing us to swap JSON for Postgres later without breaking code.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/16 Postgres Adapter.md
========================================

---
status: Done
priority: P1
module: Brain
complexity: M
---
- _Goal:_ Create `postgres.py` implementing `MemoryProvider`.
    
- _Why:_ Enables vector search and massive scale storage (Long-Term Memory).

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/17 Cortex Dispatcher.md
========================================

---
status: Done
priority: P1
module: Brain
complexity: L
---
- _Goal:_ Build the "Router" logic in `main.py`.
    
- _Why:_ Decides if a prompt needs the Trader, the Scribe, or the coder.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/18 Scribe Skill (Obsidian).md
========================================

---
status: Done
priority: P1
module: Skills
complexity: M
---
- _Goal:_ Build `skills/scribe.py` to read/write Obsidian Markdown files.
    
- _Why:_ Allows the agent to organize your "Second Brain."

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/19 Scheduler & Cron.md
========================================

---
status: Done
priority: P2
module: Core
complexity: M
---
- _Goal:_ Implement `APScheduler` in `core`.
    
- _Why:_ Allows tasks to run automatically (e.g., "Check market at 9:30 AM") without user input.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/20 Multi-Agent Orchestration.md
========================================

---
status: Done
priority: P2
module: Brain
complexity: L
---
- _Goal:_ Allow agents to talk to each other (Trader -> Scribe).
    
- _Why:_ Complex workflows require team collaboration, not just Q&A.

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/21 (Morning Briefing).md
========================================

---
status: Done
priority: P2
module: Skills
complexity: S
---


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/22 Mac Studio Deployment.md
========================================

---
status: To Do
priority: P2
module: Ops
complexity: M
---
- _Goal:_ Containerize the full stack and deploy to the M3 Ultra.
    
- _Why:_ Moves from "Dev" to "Production" (Always on).

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/23 Strategos Agent Setup.md
========================================

---
status: Done
priority: P0
module: Tactical
complexity: M
tags:
  - cobalt/task
created: 2026-02-10
---

# Strategos Agent Setup

## Objective
Create the 'Strategos' class. This manages the Playbook and Risk, replacing the basic FinanceTool wrapper.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/24 Playbook Registry.md
========================================

---
status: Done
priority: P1
module: Tactical
complexity: S
tags:
  - cobalt/task
created: 2026-02-10
---

# Playbook Registry

## Objective
Create 'strategies.yaml' to define rules for Second Day Play and Fashionably Late Scalp.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/25 Strategy Interface.md
========================================

---
status: Done
priority: P1
module: Tactical
complexity: M
tags:
  - cobalt/task
created: 2026-02-10
---

# Strategy Interface

## Objective
Define the abstract Python class for a Strategy (check_entry, check_stop, calculate_probability).

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/26 Second Day Play Impl.md
========================================

---
status: Done
priority: P1
module: Tactical
complexity: L
tags:
  - cobalt/task
created: 2026-02-10
---

# Second Day Play Impl

## Objective
Implement the specific logic from the SMB PDF: Day 1 Trend, Day 2 Open, RVOL checks.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/27 Backtest Engine.md
========================================

---
status: To Do
priority: P2
module: Tactical
complexity: XL
tags:
  - cobalt/task
created: 2026-02-10
---

# Backtest Engine

## Objective
Create the engine that runs a Strategy against 90 days of historical minute-data.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/28 Ops Medical Stub.md
========================================

---
status: To Do
priority: P2
module: Ops
complexity: S
tags:
  - cobalt/task
created: 2026-02-10
---

# Ops Medical Stub

## Objective
Create the Steward Agent shell to handle future medical billing tasks.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/29 Privacy Guardrails.md
========================================

---
status: To Do
priority: P0
module: Ops
complexity: M
tags:
  - cobalt/task
created: 2026-02-10
---

# Privacy Guardrails

## Objective
Implement PII stripping to ensure no patient data ever hits the LLM.

## Acceptance Criteria
- [ ] Code implemented
- [ ] Verified with test script


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/30 Ion Core Architecture.md
========================================

---
status: To Do
priority: P1 (High)
module: Interface
phase: 4 (Ion HUD)
complexity: L
tags: [cobalt, task, ion]
created: 2026-02-11
---

# 30 Ion Core Architecture

## Objective
Establish the foundational Python application for the **Windows HUD**.

## Requirements
* [ ] Create `ion_agent/` directory structure on Windows.
* [ ] Initialize a **PyQt6** application loop.
* [ ] Implement a **Transparent Overlay Window** (Click-through capable).
* [ ] Create a system tray icon for background management.
* [ ] Ensure it can run alongside TradeStation without stealing focus.

## Technical Notes
* Use `PyQt6.QtCore.Qt.WindowType.FramelessWindowHint`.
* Must handle high-DPI scaling (4K monitors).


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/31 Cobalt-Ion Bridge.md
========================================

---
status: To Do
priority: P0 (Critical)
module: Core
phase: 4 (Ion HUD)
complexity: M
tags: [cobalt, task, network]
created: 2026-02-11
---

# 31 Cobalt-Ion Bridge

## Objective
Create the low-latency communication link between **Cobalt (Mac)** and **Ion (Windows)**.

## Requirements
* [ ] Implement **ZeroMQ (ZMQ)** PUB/SUB pattern.
* [ ] **Publisher:** Cobalt (Mac) broadcasting strategy signals.
* [ ] **Subscriber:** Ion (Windows) listening for HUD updates.
* [ ] Define the JSON payload schema (Ticker, Action, Confidence, Price).
* [ ] Secure the connection over **Tailscale IP**.

## Technical Notes
* Latency target: < 50ms.
* Use `zmq.asyncio` for non-blocking I/O.


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/32 HUD Widgets & Overlay.md
========================================

---
status: To Do
priority: P1 (High)
module: Interface
phase: 4 (Ion HUD)
complexity: M
tags: [cobalt, task, ui]
created: 2026-02-11
---

# 32 HUD Widgets & Overlay

## Objective
Build the specific visual components that appear on the screen.

## Requirements
* [ ] **Confidence Gauge:** A visual bar/dial showing Model Confidence (0-100%).
* [ ] **Signal Box:** A "BUY/SELL" indicator that flashes on trigger.
* [ ] **Trade Log:** A small scrolling list of recent fills.
* [ ] **P&L Ticker:** Real-time session P&L display.

## Design
* "Dark Mode" aesthetic (Cyberpunk/High-Contrast).
* Green = Long, Red = Short.


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/33 Mattermost C2 Integration.md
========================================

---
status: To Do
priority: P1 (High)
module: Ops
phase: 5 (Ops)
complexity: M
tags: [cobalt, task, chat]
created: 2026-02-11
---

# 33 Mattermost C2 Integration

## Objective
Connect Cobalt to the "Red Phone" (Mattermost) for remote command and control.

## Requirements
* [ ] Create a Mattermost Bot Account ("Cobalt").
* [ ] Implement **Incoming Webhooks** for alerts (Trade Signals).
* [ ] Implement **Outgoing Webhooks** (or Slash Commands) for user commands.
* [ ] **Kill Switch:** Create a command `/cobalt stop` that halts all trading instantly.
* [ ] **Approval Flow:** Interactive buttons for "Approve Trade?" messages.


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/34 Automated Trade Journaling.md
========================================

---
status: To Do
priority: P2 (Normal)
module: Skills
phase: 5 (Ops)
complexity: S
tags: [cobalt, task, journaling]
created: 2026-02-11
---

# 34 Automated Trade Journaling

## Objective
Remove manual data entry by having Cobalt write its own trade logs.

## Requirements
* [ ] Capture execution details (Entry, Exit, Size, P&L).
* [ ] Capture "Why?" (The Strategy Logic snapshot at moment of trade).
* [ ] Format as a Markdown table.
* [ ] Append to the **Daily Note** in Obsidian via Scribe.

## Format
| Time | Ticker | Side | P&L | Strategy | Confidence |
|------|--------|------|-----|----------|------------|


========================================
FILE: docs/0 - Projects/Cobalt/Tasks/35 Untethering Tailscale VSCode.md
========================================

---
status: To Do
priority: P0
module: Ops
phase: 1
complexity: M
tags: [cobalt, task]
created: 2026-02-23
---
# 35 Untethering Tailscale VSCode
# Task: Untethering Tailscale VSCode

**Status**: To Do  
**Priority**: Medium  
**Tags**: infrastructure, development, network  
**Created**: 2026-02-22

## Description

Establish remote development mesh using Tailscale for secure, direct access to development servers without exposing ports to the public internet.

## Objectives

- Configure Tailscale on all development machines
- Set up VSCode Remote-SSH to connect via Tailscale IP
- Configure firewall rules to only allow Tailscale traffic
- Document the connection process

## Tasks

- [ ] Install Tailscale on all development machines
- [ ] Enable SSH on each machine via Tailscale
- [ ] Configure VSCode Remote-SSH plugin
- [ ] Create connection script for quick access
- [ ] Document network configuration in Obsidian

## Success Criteria

- VSCode can connect to development servers by Tailscale IP
- No exposed ports on public firewall
- Connection established in < 30 seconds

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/36 Feature Proposal Engine.md
========================================

---
status: To Do
priority: P0
module: Interface
phase: 2
complexity: M
tags: [cobalt, task]
created: 2026-02-23
---
# 36 Feature Proposal Engine
# Task: Feature Proposal Engine

**Status**: To Do  
**Priority**: High  
**Tags**: feature, HITL, approval  
**Created**: 2026-02-22

## Description

Create Pydantic models and infrastructure for the Human-In-The-Loop (HITL) Proposal Engine. This enables the agent to request approval before executing high-risk operations.

## Objectives

- Design Pydantic models for proposals and approvals
- Create proposal generation logic
- Implement approval status tracking
- Integrate with Mattermost for human review

## Tasks

- [ ] Create proposal_engine.py module
- [ ] Design ApprovalRequest Pydantic model
  - request_id, action_type, parameters, risk_level, justification, timestamp
- [ ] Design ApprovalResponse Pydantic model
  - approved, approver, timestamp, comments
- [ ] Implement proposal generation function
- [ ] Create approval status tracker
- [ ] Integrate with Mattermost for approval UI

## Success Criteria

- All high-risk operations require proposal
- Proposals are reviewed via Mattermost
- Approval decisions recorded in system
- Timeout-based rejection after 5 minutes

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/37 Feature Docker Sandbox.md
========================================

---
status: To Do
priority: P0
module: Security
phase: 2
complexity: XL
tags: [cobalt, task]
created: 2026-02-23
---
# 37 Feature Docker Sandbox
# Task: Feature Docker Sandbox

**Status**: To Do  
**Priority**: High  
**Tags**: security, docker, sandbox  
**Created**: 2026-02-22

## Description

Build secure code execution environment using Docker with Seccomp profiles. This enables safe execution of dynamically generated code without exposing the host system.

## Objectives

- Create Docker container for code execution
- Implement strict Seccomp security profile
- Add resource limits (CPU, memory)
- Create Python client for container management

## Tasks

- [ ] Create docker_sandbox.py module
- [ ] Design Seccomp profile (allow read/write/open, block socket/ptrace/execve)
- [ ] Implement container creation function
- [ ] Add resource limits (1 CPU, 512MB memory)
- [ ] Implement output capture and timeout
- [ ] Add cleanup function for containers

## Success Criteria

- Code executes in isolated container
- Seccomp profile blocks dangerous syscalls
- Container cleaned up after execution
- Timeout prevents hung execution

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/38 Refactor Switchboard Router.md
========================================

---
status: To Do
priority: P1
module: Brain
phase: 2
complexity: M
tags: [cobalt, task]
created: 2026-02-23
---
# 38 Refactor Switchboard Router
# Task: Refactor Switchboard Router

**Status**: To Do  
**Priority**: High  
**Tags**: refactoring, routing, llm  
**Created**: 2026-02-22

## Description

Replace hardcoded `?` routing in cortex.py with a localized LLM classification step. This enables dynamic, intelligent routing based on semantic understanding rather than simple keyword matching.

## Objectives

- Replace hardcoded routing logic with LLM-based classification
- Create router function with proper prompt
- Test routing accuracy with sample inputs
- Ensure zero-latency fallback for known patterns

## Tasks

- [ ] Read current cortex.py routing logic
- [ ] Design prompt for LLM classification
- [ ] Create switchboard_router.py module
- [ ] Implement LLM-based routing function
- [ ] Add fallback for known patterns (e.g., "?")
- [ ] Test routing with diverse inputs
- [ ] Update cortex.py to use new router

## Success Criteria

- Routing accuracy > 95% on test set
- No routing latency added to fast paths
- Hardcoded bypasses preserved for known patterns

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/39 Tool Playwright Browser.md
========================================

---
status: To Do
priority: P2
module: Tools
phase: 3
complexity: L
tags: [cobalt, task]
created: 2026-02-23
---
# 39 Tool Playwright Browser
# Task: Tool Playwright Browser

**Status**: To Do  
**Priority**: High  
**Tags**: tool, browser, automation  
**Created**: 2026-02-22

## Description

Add dynamic browser interaction capability using Playwright to the Cobalt Agent. This enables the agent to navigate websites, extract dynamic content, and perform complex web scraping.

## Objectives

- Integrate Playwright for headless browser automation
- Create tool wrapper for common browser actions
- Implement page navigation and content extraction
- Add session management for multi-step browsing

## Tasks

- [ ] Install playwright and dependencies
- [ ] Create browser.py module in tools directory
- [ ] Implement page_load(url: str) function
- [ ] Implement scrape_content(selector: str) function
- [ ] Implement click_element(selector: str) function
- [ ] Add timeout and error handling
- [ ] Document tool usage in Developer Docs

## Success Criteria

- Browser can navigate to any URL
- Dynamic content extraction works for SPA sites
- Sessions persist across related requests

========================================
FILE: docs/0 - Projects/Cobalt/Tasks/40 Tool LastPass Integration.md
========================================

---
status: To Do
priority: P1
module: Security
phase: 3
complexity: L
tags: [cobalt, task]
created: 2026-02-23
---
# 40 Tool LastPass Integration
# Task: Tool LastPass Integration

**Status**: To Do  
**Priority**: High  
**Tags**: security, secrets, tool  
**Created**: 2026-02-22

## Description

Add secure secrets retrieval integration with LastPass API using Just-In-Time (JIT) credential management. This enables the agent to access credentials without storing them in plaintext.

## Objectives

- Integrate LastPass API for credential retrieval
- Implement credential caching with TTL expiration
- Create audit logging for all credential access
- Securely handle credentials in memory

## Tasks

- [ ] Set up LastPass API credentials
- [ ] Create lastpass.py module in tools directory
- [ ] Implement get_credential(vault_id: str, justification: str) function
- [ ] Implement credential caching with 5-minute TTL
- [ ] Add audit logging for all credential access
- [ ] Create credential cleanup function

## Success Criteria

- Credentials retrieved via LastPass JIT API
- Credentials expire after 5 minutes
- All access logged for audit trail
- Credentials never written to disk

========================================
FILE: logs/agent_2026-02-18.log
========================================

2026-02-18 12:45:22.535 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:22.541 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:22.546 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:22.551 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:22.556 | INFO     | cobalt_agent.core.scheduler:add_job:45 - Scheduled task added: run (cron)
2026-02-18 12:45:22.556 | INFO     | __main__:__init__:45 - Cobalt Agent - System Initialized
2026-02-18 12:45:22.556 | INFO     | __main__:__init__:46 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-18 12:45:22.556 | INFO     | __main__:__init__:47 - Configuration Loaded: Debug Mode = True
2026-02-18 12:45:22.556 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:22.562 | INFO     | __main__:__init__:51 - Brain Initialized: Role-Based Routing Active (default)
2026-02-18 12:45:22.562 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: search
2026-02-18 12:45:22.562 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: browser
2026-02-18 12:45:22.562 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:22.567 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: finance
2026-02-18 12:45:24.699 | INFO     | __main__:__init__:67 - Persona: Persona(name='Cobalt', roles=4, skills=3)
2026-02-18 12:45:24.699 | INFO     | __main__:__init__:68 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-18 12:45:24.699 | INFO     | __main__:__init__:70 - ================================================================================
2026-02-18 12:45:24.699 | INFO     | __main__:__init__:71 - SYSTEM PROMPT:
2026-02-18 12:45:24.699 | INFO     | __main__:__init__:72 - ================================================================================
2026-02-18 12:45:24.699 | INFO     | __main__:__init__:73 - 
You are Cobalt, a Chief of Staff, Software Architect, Senior Developer, Business Analyst.
Your Tone: Professional, Concise, Data-Driven, Analytical.

### CURRENT CONTEXT
- Current Date/Time: 2026-02-18 12:45:22
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- Prioritize risk management
- Verify all data
- Protect capital
- Analyze data before deciding
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- <cobalt_agent.tools.search.SearchTool object at 0x10f71a350>: No description provided.
- <cobalt_agent.tools.browser.BrowserTool object at 0x10f71a490>: No description provided.
- <cobalt_agent.tools.finance.FinanceTool object at 0x10f71a5d0>: No description provided.

2026-02-18 12:45:24.699 | INFO     | __main__:__init__:74 - ================================================================================
2026-02-18 12:45:24.700 | INFO     | __main__:__init__:76 - Memory System online
2026-02-18 12:45:24.708 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:24.714 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:24.721 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:24.727 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:24.733 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 12:45:24.740 | INFO     | __main__:main:107 - ================================================================================
2026-02-18 12:45:24.740 | INFO     | __main__:main:108 - Starting interactive CLI interface...
2026-02-18 12:45:24.740 | INFO     | __main__:main:109 - ================================================================================
2026-02-18 12:45:24.740 | INFO     | cobalt_agent.interface:__init__:29 - CLI initialized with Brain connected
2026-02-18 12:56:29.357 | INFO     | __main__:main:125 - Exiting Cobalt Agent
2026-02-18 12:56:29.361 | INFO     | cobalt_agent.core.scheduler:stop:35 - Scheduler stopped
2026-02-18 14:03:59.429 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:03:59.436 | INFO     | cobalt_agent.persona:__init__:43 - Persona 'Cobalt' initialized
2026-02-18 14:03:59.755 | INFO     | cobalt_agent.memory.postgres:_init_db:52 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-18 14:03:59.755 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:03:59.764 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:03:59.770 | INFO     | cobalt_agent.brain.cortex:__init__:40 - üß† Cortex Online | Loaded 0 Departments from Config
2026-02-18 14:03:59.771 | INFO     | cobalt_agent.core.scheduler:start:25 - Scheduler started (Time Awareness Online)
2026-02-18 14:03:59.771 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:03:59.781 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:03:59.788 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:03:59.794 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:03:59.799 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:03:59.805 | INFO     | cobalt_agent.core.scheduler:add_job:45 - Scheduled task added: run (cron)
2026-02-18 14:03:59.805 | INFO     | __main__:__init__:45 - Cobalt Agent - System Initialized
2026-02-18 14:03:59.805 | INFO     | __main__:__init__:46 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-18 14:03:59.805 | INFO     | __main__:__init__:47 - Configuration Loaded: Debug Mode = True
2026-02-18 14:03:59.805 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:03:59.811 | INFO     | __main__:__init__:51 - Brain Initialized: Role-Based Routing Active (default)
2026-02-18 14:03:59.811 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: search
2026-02-18 14:03:59.811 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: browser
2026-02-18 14:03:59.811 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:03:59.816 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: finance
2026-02-18 14:04:02.678 | INFO     | __main__:__init__:67 - Persona: Persona(name='Cobalt', roles=4, skills=3)
2026-02-18 14:04:02.678 | INFO     | __main__:__init__:68 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-18 14:04:02.678 | INFO     | __main__:__init__:70 - ================================================================================
2026-02-18 14:04:02.678 | INFO     | __main__:__init__:71 - SYSTEM PROMPT:
2026-02-18 14:04:02.678 | INFO     | __main__:__init__:72 - ================================================================================
2026-02-18 14:04:02.678 | INFO     | __main__:__init__:73 - 
### IDENTITY
You are Cobalt.

### ROLES
Your roles are: Chief of Staff, Software Architect, Senior Developer, Business Analyst.

### OPERATIONAL DIRECTIVES
- Prioritize risk management
- Verify all data
- Protect capital
- Analyze data before deciding

### TONE
Maintain a tone that is: Professional, Concise, Data-Driven, Analytical.

### CURRENT CONTEXT
- Current Date/Time: 2026-02-18 14:03:59
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- Prioritize risk management
- Verify all data
- Protect capital
- Analyze data before deciding
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- <cobalt_agent.tools.search.SearchTool object at 0x16d7ce350>: No description provided.
- <cobalt_agent.tools.browser.BrowserTool object at 0x16d7ce490>: No description provided.
- <cobalt_agent.tools.finance.FinanceTool object at 0x16d7ce5d0>: No description provided.

2026-02-18 14:04:02.679 | INFO     | __main__:__init__:74 - ================================================================================
2026-02-18 14:04:02.679 | INFO     | __main__:__init__:76 - Memory System online
2026-02-18 14:04:02.703 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:04:02.713 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:04:02.719 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:04:02.724 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:04:02.730 | INFO     | cobalt_agent.config:load_config:172 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-18 14:04:02.736 | INFO     | __main__:main:107 - ================================================================================
2026-02-18 14:04:02.736 | INFO     | __main__:main:108 - Starting interactive CLI interface...
2026-02-18 14:04:02.736 | INFO     | __main__:main:109 - ================================================================================
2026-02-18 14:04:02.736 | INFO     | cobalt_agent.interface:__init__:29 - CLI initialized with Brain connected
2026-02-18 14:04:15.883 | INFO     | __main__:main:125 - Exiting Cobalt Agent
2026-02-18 14:04:15.884 | INFO     | cobalt_agent.core.scheduler:stop:35 - Scheduler stopped


========================================
FILE: logs/agent_2026-02-22.log
========================================

2026-02-22 08:00:32.863 | INFO     | cobalt_agent.skills.productivity.briefing:run:115 - ‚úÖ Briefing saved to: ‚úÖ Note saved: 0 - Inbox/Briefing_2026-02-22.md


========================================
FILE: logs/agent_2026-02-24.log
========================================

2026-02-24 18:16:16.325 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-24 18:16:16.325 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-24 18:21:16.337 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-24 18:21:16.337 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-24 18:21:36.567 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:372 - Bot shut down manually.
2026-02-24 18:21:36.620 | INFO     | cobalt_agent.interfaces.mattermost:disconnect:100 - Disconnected from Mattermost
2026-02-24 18:21:36.621 | INFO     | cobalt_agent.core.proposals:stop_monitoring:303 - Proposal Engine monitoring stopped
2026-02-24 18:21:36.621 | INFO     | cobalt_agent.core.scheduler:stop:35 - Scheduler stopped
2026-02-24 18:21:36.639 | ERROR    | cobalt_agent.memory.postgres:_generate_embedding:82 - Embedding failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
2026-02-24 18:24:01.988 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:01.994 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:01.996 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:01.996 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:01.996 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:01.997 | INFO     | cobalt_agent.persona:__init__:43 - Persona 'Cobalt' initialized
2026-02-24 18:24:01.997 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.003 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.003 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.003 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.003 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.021 | INFO     | cobalt_agent.memory.postgres:_init_db:61 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-24 18:24:02.021 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.027 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.027 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.027 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.027 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.029 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.034 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.034 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.034 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.035 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.036 | INFO     | cobalt_agent.brain.cortex:__init__:43 - üß† Cortex Online | Loaded 5 Departments from Config
2026-02-24 18:24:02.036 | INFO     | cobalt_agent.core.scheduler:start:25 - Scheduler started (Time Awareness Online)
2026-02-24 18:24:02.037 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.042 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.042 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.042 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.042 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.044 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.049 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.049 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.049 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.049 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.051 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.056 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.056 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.056 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.056 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.058 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.064 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.064 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.064 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.064 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.065 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.071 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.071 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.071 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.071 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.073 | INFO     | cobalt_agent.core.scheduler:add_job:45 - Scheduled task added: run (cron)
2026-02-24 18:24:02.073 | INFO     | __main__:__init__:47 - Cobalt Agent - System Initialized
2026-02-24 18:24:02.073 | INFO     | __main__:__init__:48 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-24 18:24:02.073 | INFO     | __main__:__init__:49 - Configuration Loaded: Debug Mode = True
2026-02-24 18:24:02.073 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.079 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.079 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.079 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.079 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.080 | INFO     | __main__:__init__:53 - Brain Initialized: Role-Based Routing Active (default)
2026-02-24 18:24:02.080 | INFO     | cobalt_agent.tools.tool_manager:register_tool:50 - Tool registered: search
2026-02-24 18:24:02.080 | INFO     | cobalt_agent.tools.tool_manager:register_tool:50 - Tool registered: browser
2026-02-24 18:24:02.081 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-24 18:24:02.086 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-24 18:24:02.086 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-24 18:24:02.086 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-24 18:24:02.086 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-24 18:24:02.087 | INFO     | cobalt_agent.tools.tool_manager:register_tool:50 - Tool registered: finance
2026-02-24 18:24:05.012 | INFO     | __main__:__init__:69 - Persona: Persona(name='Cobalt', roles=3, skills=4)
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:70 - Persona Roles: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:72 - ================================================================================
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:73 - SYSTEM PROMPT:
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:74 - ================================================================================
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:75 - 
### IDENTITY
You are Cobalt.

### ROLES
Your roles are: Chief of Staff to Dejan, Principal Systems Architect, Zero-Trust Automation Engine.

### OPERATIONAL DIRECTIVES
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.

### TONE
Maintain a tone that is: Hyper-competent and authoritative, Analytical and unshakeable, Extremely concise (high signal, zero noise), Professional (strictly avoid chatty filler, apologies, and sycophancy).

### CURRENT CONTEXT
- Current Date/Time: 2026-02-24 18:24:02
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- PRIME DIRECTIVE: You are an autonomous intelligence, but strictly bound by the Human-in-the-Loop (HITL) framework.
- PROPOSAL ENGINE: Never execute destructive, financial, or high-stakes system changes unilaterally. You must draft a precise proposal and await authorization.
- ZERO TRUST: Assume breach. Verify identity and permissions before accessing secure vaults or executing environment commands.
- DOCUMENTATION AS CODE: Treat the Obsidian Vault as the absolute source of truth. No system change is complete until documented.
- BREVITY: Deliver answers directly. Eliminate introductory filler.
- FIRST PRINCIPLES (R&D): When writing code, analyzing business operations, or developing new strategies, reject analogies. Deconstruct problems to their fundamental truths (e.g., market micro-structure, liquidity, basic physics) before formulating solutions.
- TACTICAL OVERWATCH: You are a strict spotter, never the sniper. You monitor real-time environments, identify playbook setups on 'stocks in play', grade the risk (A, A-, B, B-, C), and dynamically calculate Expected Value (EV) for active trades. You NEVER execute trades. Your job is mathematical monitoring and alerting only.
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- SearchTool: Use this tool for search tasks.
- BrowserTool: Use this tool for browser tasks.
- FinanceTool: Use this tool for finance tasks.

2026-02-24 18:24:05.013 | INFO     | __main__:__init__:76 - ================================================================================
2026-02-24 18:24:05.013 | INFO     | __main__:__init__:78 - Memory System online
2026-02-24 18:24:05.013 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-24 18:24:05.053 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-24 18:24:05.053 | INFO     | cobalt_agent.core.proposals:__init__:59 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-24 18:24:05.053 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-24 18:24:05.063 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-24 18:24:05.063 | INFO     | cobalt_agent.core.proposals:connect_mattermost:75 - Proposal Engine: Mattermost connection established
2026-02-24 18:24:05.063 | INFO     | __main__:start_mattermost_interface:197 - ================================================================================
2026-02-24 18:24:05.063 | INFO     | __main__:start_mattermost_interface:198 - Cobalt Agent - Mattermost Interface Active
2026-02-24 18:24:05.063 | INFO     | __main__:start_mattermost_interface:199 - HITL Proposal Engine - Active
2026-02-24 18:24:05.063 | INFO     | __main__:start_mattermost_interface:200 - ================================================================================
2026-02-24 18:24:05.063 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:366 - Starting native WebSocket engine...
2026-02-24 18:24:05.064 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:351 - Connecting to native WebSocket engine: ws://100.70.206.126:8065/api/v4/websocket
2026-02-24 18:24:05.071 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:356 - Connected and authenticated via HTTP headers. Listening for messages...
2026-02-24 18:24:05.075 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"t3eiwm3fwpnqtgc3gto65i34eh","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-24 18:24:05.075 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"t3eiwm3fwpnqtgc3gto65i34eh","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-24 18:24:05.075 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-24 18:24:05.075 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-24 18:25:09.195 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-24 18:25:09.196 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-24 18:25:14.712 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}
2026-02-24 18:25:14.713 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 3}
2026-02-24 18:25:17.167 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event":"posted","data":{"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","mentions":"[\"oyc789ktdpn75norxkk11hi5dc\"]","post":"{\"id\":\"hzt9ce6ky3dppraez99py7ccao\",\"create_at\":1771975517134,\"update_at\":1771975517134,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"@cobalt what is your name?\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1771975517032\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"},"broadcast":{"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""},"seq":4}

2026-02-24 18:25:17.168 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"posted","data":{"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","mentions":"[\"oyc789ktdpn75norxkk11hi5dc\"]","post":"{\"id\":\"hzt9ce6ky3dppraez99py7ccao\",\"create_at\":1771975517134,\"update_at\":1771975517134,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"@cobalt what is your name?\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1771975517032\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"},"broadcast":{"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""},"seq":4}

2026-02-24 18:25:17.176 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:239 - Message received in channel badpmg1j5jf3mj7hxroe6xsrcw: @cobalt what is your name?
2026-02-24 18:25:17.177 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:252 - Routing message to Cortex in background thread...
2026-02-24 18:25:17.178 | INFO     | cobalt_agent.brain.cortex:route:54 - Direct route bypass triggered: Question detected.
2026-02-24 18:25:17.179 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:263 - No route match, generating conversational response...
2026-02-24 18:25:31.530 | INFO     | cobalt_agent.llm:generate_response:172 - Cobalt, LLM model version: ollama/qwen3-coder-next
2026-02-24 18:25:31.534 | INFO     | cobalt_agent.llm:generate_response:173 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-24 18:25:31.560 | INFO     | cobalt_agent.interfaces.mattermost:send_message_to_channel_id:177 - Message sent to channel badpmg1j5jf3mj7hxroe6xsrcw
2026-02-24 18:25:31.560 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:360 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","post":"{\"id\":\"nbpjch5e6bdx9etxgu7qapbh3h\",\"create_at\":1771975531550,\"update_at\":1771975531550,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"I‚Äôm Cobalt ‚Äî your AI Chief of Staff and Trading Assistant. Ready to help with strategy, analysis, or execution. What‚Äôs on your mind?\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 5}
2026-02-24 18:25:31.560 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:274 - Conversational response sent to Mattermost
2026-02-24 18:25:31.560 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","post":"{\"id\":\"nbpjch5e6bdx9etxgu7qapbh3h\",\"create_at\":1771975531550,\"update_at\":1771975531550,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"I‚Äôm Cobalt ‚Äî your AI Chief of Staff and Trading Assistant. Ready to help with strategy, analysis, or execution. What‚Äôs on your mind?\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 5}
2026-02-24 18:26:03.662 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:372 - Bot shut down manually.
2026-02-24 18:26:03.690 | INFO     | cobalt_agent.interfaces.mattermost:disconnect:100 - Disconnected from Mattermost
2026-02-24 18:26:03.690 | INFO     | cobalt_agent.core.proposals:stop_monitoring:303 - Proposal Engine monitoring stopped
2026-02-24 18:26:03.691 | INFO     | cobalt_agent.core.scheduler:stop:35 - Scheduler stopped


========================================
FILE: logs/agent_2026-02-25.log
========================================

System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- SearchTool: Use this tool for search tasks.
- BrowserTool: Use this tool for browser tasks.
- FinanceTool: Use this tool for finance tasks.

2026-02-25 10:35:18.901 | INFO     | __main__:__init__:76 - ================================================================================
2026-02-25 10:35:18.901 | INFO     | __main__:__init__:78 - Memory System online
2026-02-25 10:35:18.901 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-25 10:35:18.925 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-25 10:35:18.926 | INFO     | cobalt_agent.core.proposals:__init__:59 - Proposal Engine initialized (Channel: cobalt-approvals)
2026-02-25 10:35:18.926 | INFO     | cobalt_agent.interfaces.mattermost:__init__:44 - MattermostInterface initialized (URL: http://100.70.206.126:8065)
2026-02-25 10:35:18.936 | INFO     | cobalt_agent.interfaces.mattermost:connect:80 - Successfully connected to Mattermost as user: cobalt
2026-02-25 10:35:18.937 | INFO     | cobalt_agent.core.proposals:connect_mattermost:75 - Proposal Engine: Mattermost connection established
2026-02-25 10:35:18.937 | INFO     | __main__:start_mattermost_interface:197 - ================================================================================
2026-02-25 10:35:18.937 | INFO     | __main__:start_mattermost_interface:198 - Cobalt Agent - Mattermost Interface Active
2026-02-25 10:35:18.937 | INFO     | __main__:start_mattermost_interface:199 - HITL Proposal Engine - Active
2026-02-25 10:35:18.937 | INFO     | __main__:start_mattermost_interface:200 - ================================================================================
2026-02-25 10:35:18.937 | INFO     | cobalt_agent.interfaces.mattermost:start_listening:460 - Starting native WebSocket engine...
2026-02-25 10:35:18.937 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:445 - Connecting to native WebSocket engine: ws://100.70.206.126:8065/api/v4/websocket
2026-02-25 10:35:18.944 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:450 - Connected and authenticated via HTTP headers. Listening for messages...
2026-02-25 10:35:18.944 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:454 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"u63won8w4jr59kfzyxz4ptug3h","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-25 10:35:18.945 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"u63won8w4jr59kfzyxz4ptug3h","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}

2026-02-25 10:35:18.946 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:454 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-25 10:35:18.946 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}
2026-02-25 10:35:40.283 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:454 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-25 10:35:40.284 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}
2026-02-25 10:35:43.910 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:454 - RAW WEBSOCKET PAYLOAD: {"event":"posted","data":{"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","mentions":"[\"oyc789ktdpn75norxkk11hi5dc\"]","post":"{\"id\":\"jh8q7swt8fn83drznnz4p5q9jr\",\"create_at\":1772033743881,\"update_at\":1772033743881,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"@cobalt I need you to do general web research. Use the browser tool to scrape https://news.ycombinator.com and return the raw text.\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1772033743775\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{\"embeds\":[{\"type\":\"link\",\"url\":\"https://news.ycombinator.com\"}]}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"},"broadcast":{"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""},"seq":3}

2026-02-25 10:35:43.911 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event":"posted","data":{"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","mentions":"[\"oyc789ktdpn75norxkk11hi5dc\"]","post":"{\"id\":\"jh8q7swt8fn83drznnz4p5q9jr\",\"create_at\":1772033743881,\"update_at\":1772033743881,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"@cobalt I need you to do general web research. Use the browser tool to scrape https://news.ycombinator.com and return the raw text.\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1772033743775\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{\"embeds\":[{\"type\":\"link\",\"url\":\"https://news.ycombinator.com\"}]}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"},"broadcast":{"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""},"seq":3}

2026-02-25 10:35:43.920 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:239 - Message received in channel badpmg1j5jf3mj7hxroe6xsrcw: @cobalt I need you to do general web research. Use the browser tool to scrape https://news.ycombinator.com and return the raw text.
2026-02-25 10:35:43.920 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:252 - Routing message to Cortex in background thread...
2026-02-25 10:35:43.921 | INFO     | cobalt_agent.memory.core:load_memory:90 - Memory loaded from data/memory.json
2026-02-25 10:35:43.922 | INFO     | cobalt_agent.brain.cortex:route:57 - ‚ö° Fast-Path Routing Triggered: DEFAULT
2026-02-25 10:35:43.922 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:274 - DEFAULT route detected, using ReAct loop...
2026-02-25 10:35:43.923 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:294 - ReAct iteration 1/3
2026-02-25 10:35:59.841 | INFO     | cobalt_agent.llm:generate_response:172 - Cobalt, LLM model version: ollama/qwen3-coder-next
2026-02-25 10:35:59.842 | INFO     | cobalt_agent.llm:generate_response:173 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-25 10:35:59.842 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:304 - LLM Response: ACTION: scrape https://news.ycombinator.com
2026-02-25 10:35:59.842 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:309 - ACTION: detected, parsing tool command...
2026-02-25 10:35:59.843 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:327 - Fuzzy matched 'browser' -> 'browser'
2026-02-25 10:35:59.843 | INFO     | cobalt_agent.tools.tool_manager:register_tool:50 - Tool registered: search
2026-02-25 10:35:59.843 | INFO     | cobalt_agent.tools.tool_manager:register_tool:50 - Tool registered: browser
2026-02-25 10:35:59.843 | INFO     | cobalt_agent.config:load_config:422 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-25 10:35:59.861 | INFO     | cobalt_agent.config:load_config:452 - üîë COBALT_MASTER_KEY detected. Unlocking secure vault...
2026-02-25 10:35:59.861 | INFO     | cobalt_agent.security.vault:unlock:44 - üîê Vault successfully unlocked into memory.
2026-02-25 10:35:59.862 | INFO     | cobalt_agent.security.vault:lock:55 - üîí Vault locked. Secrets wiped from RAM.
2026-02-25 10:35:59.862 | INFO     | cobalt_agent.config:load_config:483 - üîí Vault secrets loaded into runtime RAM and vault locked.
2026-02-25 10:35:59.864 | INFO     | cobalt_agent.tools.tool_manager:register_tool:50 - Tool registered: finance
2026-02-25 10:35:59.865 | INFO     | cobalt_agent.tools.tool_manager:execute_tool:70 - Executing tool: browser with args: {'query': 'https://news.ycombinator.com'}
2026-02-25 10:35:59.865 | INFO     | cobalt_agent.tools.browser:run:68 - üåê Playwright navigating to: https://news.ycombinator.com
2026-02-25 10:36:02.711 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:352 - Tool executed: browser, Observation: [Observation: ### Hacker News
Hacker Newsnew | past | comments | ask | show | jobs | submit	login
1.
Never Buy A .online Domain (0xsid.com)
297 points by ssiddharth 2 hours ago | hide | 151¬†comments
2.
US orders diplomats to fight data sovereignty initiatives (reuters.com)
69 points by colinhb 47 minutes ago | hide | 37¬†comments
3.
How to fold the Blade Runner origami unicorn (1996) (archive.org)
107 points by exvi 5 hours ago | hide | 5¬†comments
4.
Danish government agency to ditch Microsoft software (2025) (therecord.media)
452 points by robtherobber 5 hours ago | hide | 257¬†comments
5.
Ask HN: Have top AI research institutions just given up on the idea of safety?
37 points by DietaryNonsense 40 minutes ago | hide | 19¬†comments
6.
Show HN: Django Control Room ‚Äì All Your Tools Inside the Django Admin (github.com/yassi)
12 points by yassi_dev 1 hour ago | hide | 4¬†comments
7.
Show HN: A real-time strategy game that AI agents can play (llmskirmish.com)
137 points by __cayenne__ 5 hours ago | hide | 46¬†comments
8.
100M-Row Challenge with PHP (github.com/tempestphp)
92 points by brentroose 5 hours ago | hide | 29¬†comments
9.
I'm helping my dog vibe code games (calebleak.com)
1022 points by cleak 22 hours ago | hide | 333¬†comments
10.
Claude Code Remote Control (claude.com)
214 points by empressplay 8 hours ago | hide | 144¬†comments
11.
Launch HN: TeamOut (YC W22) ‚Äì AI agent for planning company events (teamout.com)
7 points by vincentalbouy 1 hour ago | hide | 4¬†comments
12.
The History of a Security Hole (os2museum.com)
8 points by st_goliath 2 hours ago | hide | 1¬†comment
13.		Event Horizon Labs (YC W24) Is Hiring (ycombinator.com)
3 hours ago | hide
14.
Confusables.txt and NFKC disagree on 31 characters (paultendo.github.io)
17 points by pimterry 3 hours ago | hide | 13¬†comments
15.
Pi ‚Äì A minimal terminal coding harness (pi.dev)
493 points by kristianpaul 17 hours ago | hide | 236¬†comments
16.
Mercury 2: Fast reasoning LLM powered by diffusion (inceptionlabs.ai)
284 points by fittingopposite 16 hours ago | hide | 113¬†comments
17.
Turing Completeness of GNU find (arxiv.org)
89 points by todsacerdoti 10 hours ago | hide | 17¬†comments
18.
Japanese Death Poems (secretorum.life)
95 points by NaOH 10 hours ago | hide | 28¬†comments
19.
Show HN: Moonshine Open-Weights STT models ‚Äì higher accuracy than WhisperLargev3 (github.com/moonshine-ai)
280 points by petewarden 17 hours ago | hide | 66¬†comments
20.
Red Hat takes on Docker Desktop with its enterprise Podman Desktop build (thenewstack.io)
29 points by twelvenmonkeys 2 hours ago | hide | 18¬†comments
21.
I pitched a roller coaster to Disneyland at age 10 in 1978 (wordglyph.xyz)
505 points by wordglyph 1 day ago | hide | 186¬†comments
22.
Show HN: Scheme-langserver ‚Äì Digest incomplete code with static analysis (github.com/ufo5260987423)
22 points by ufo5260987423 7 hours ago | hide | discuss
23.
Mac¬†mini will be made at a new facility in Houston (apple.com)
574 points by haunter 18 hours ago | hide | 584¬†comments
24.
Hacking an old Kindle to display bus arrival times (mariannefeng.com)
312 points by mengchengfeng 19 hours ago | hide | 79¬†comments
25.
LLM=True (blog.codemine.be)
173 points by avh3 6 hours ago | hide | 122¬†comments
26.
Cl-kawa: Scheme on Java on Common Lisp (github.com/atgreen)
61 points by varjag 11 hours ago | hide | 16¬†comments
27.
Nearby Glasses (github.com/yjeanrenaud)
384 points by zingerlio 21 hours ago | hide | 168¬†comments
28.
Show HN: Clocksimulator.com ‚Äì A minimalist, distraction-free analog clock (clocksimulator.com)
55 points by user_timo 1 hour ago | hide | 46¬†comments
29.
Show HN: Emdash ‚Äì Open-source agentic development environment (github.com/generalaction)
185 points by onecommit 20 hours ago | hide | 66¬†comments
30.
Steel Bank Common Lisp (sbcl.org)
248 points by tosh 21 hours ago | hide | 100¬†comments
More
Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | Contact
Search:...]
2026-02-25 10:36:02.711 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:294 - ReAct iteration 2/3
2026-02-25 10:36:32.027 | INFO     | cobalt_agent.llm:generate_response:172 - Cobalt, LLM model version: ollama/qwen3-coder-next
2026-02-25 10:36:32.028 | INFO     | cobalt_agent.llm:generate_response:173 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-25 10:36:32.028 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:304 - LLM Response: Hacker News top 30 items (raw text):

1. Never Buy A .online Domain (0xsid.com) ‚Äî 297 pts  
2. US orders diplomats to fight data sovereignty initiatives (reuters.com) ‚Äî 69 pts  
3. How to fold the Blade Runner origami unicorn (1996) (archive.org) ‚Äî 107 pts  
4. Danish government agency to ditch Microsoft software (2025) (therecord.media) ‚Äî 452 pts  
5. Ask HN: Have top AI research institutions just given up on the idea of safety? ‚Äî 37 pts  
6. Show HN: Django Control Room ‚Äì All Your Tools Inside the Django Admin (github.com/yassi) ‚Äî 12 pts  
7. Show HN: A real-time strategy game that AI agents can play (llmskirmish.com) ‚Äî 137 pts  
8. 100M-Row Challenge with PHP (github.com/tempestphp) ‚Äî 92 pts  
9. I'm helping my dog vibe code games (calebleak.com) ‚Äî 1022 pts  
10. Claude Code Remote Control (claude.com) ‚Äî 214 pts  
11. Launch HN: TeamOut (YC W22) ‚Äì AI agent for planning company events (teamout.com) ‚Äî 7 pts  
12. The History of a Security Hole (os2museum.com) ‚Äî 8 pts  
13. Event Horizon Labs (YC W24) Is Hiring (ycombinator.com)  
14. Confusables.txt and NFKC disagree on 31 characters (paultendo.github.io) ‚Äî 17 pts  
15. Pi ‚Äì A minimal terminal coding harness (pi.dev) ‚Äî 493 pts  
16. Mercury 2: Fast reasoning LLM powered by diffusion (inceptionlabs.ai) ‚Äî 284 pts  
17. Turing Completeness of GNU find (arxiv.org) ‚Äî 89 pts  
18. Japanese Death Poems (secretorum.life) ‚Äî 95 pts  
19. Show HN: Moonshine Open-Weights STT models ‚Äì higher accuracy than WhisperLargev3 (github.com/moonshine-ai) ‚Äî 280 pts  
20. Red Hat takes on Docker Desktop with its enterprise Podman Desktop build (thenewstack.io) ‚Äî 29 pts  
21. I pitched a roller coaster to Disneyland at age 10 in 1978 (wordglyph.xyz) ‚Äî 505 pts  
22. Show HN: Scheme-langserver ‚Äì Digest incomplete code with static analysis (github.com/ufo5260987423) ‚Äî 22 pts  
23. Mac mini will be made at a new facility in Houston (apple.com) ‚Äî 574 pts  
24. Hacking an old Kindle to display bus arrival times (mariannefeng.com) ‚Äî 312 pts  
25. LLM=True (blog.codemine.be) ‚Äî 173 pts  
26. Cl-kawa: Scheme on Java on Common Lisp (github.com/atgreen) ‚Äî 61 pts  
27. Nearby Glasses (github.com/yjeanrenaud) ‚Äî 384 pts  
28. Show HN: Clocksimulator.com ‚Äì A minimalist, distraction-free analog clock (clocksimulator.com) ‚Äî 55 pts  
29. Show HN: Emdash ‚Äì Open-source agentic development environment (github.com/generalaction) ‚Äî 185 pts  
30. Steel Bank Common Lisp (sbcl.org) ‚Äî 248 pts
2026-02-25 10:36:32.029 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:359 - No ACTION: detected, returning final answer
2026-02-25 10:36:32.058 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:454 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","post":"{\"id\":\"6jj3kaiwtb8j7nugk596p6um1e\",\"create_at\":1772033792044,\"update_at\":1772033792044,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"Hacker News top 30 items (raw text):\\n\\n1. Never Buy A .online Domain (0xsid.com) ‚Äî 297 pts  \\n2. US orders diplomats to fight data sovereignty initiatives (reuters.com) ‚Äî 69 pts  \\n3. How to fold the Blade Runner origami unicorn (1996) (archive.org) ‚Äî 107 pts  \\n4. Danish government agency to ditch Microsoft software (2025) (therecord.media) ‚Äî 452 pts  \\n5. Ask HN: Have top AI research institutions just given up on the idea of safety? ‚Äî 37 pts  \\n6. Show HN: Django Control Room ‚Äì All Your Tools Inside the Django Admin (github.com/yassi) ‚Äî 12 pts  \\n7. Show HN: A real-time strategy game that AI agents can play (llmskirmish.com) ‚Äî 137 pts  \\n8. 100M-Row Challenge with PHP (github.com/tempestphp) ‚Äî 92 pts  \\n9. I'm helping my dog vibe code games (calebleak.com) ‚Äî 1022 pts  \\n10. Claude Code Remote Control (claude.com) ‚Äî 214 pts  \\n11. Launch HN: TeamOut (YC W22) ‚Äì AI agent for planning company events (teamout.com) ‚Äî 7 pts  \\n12. The History of a Security Hole (os2museum.com) ‚Äî 8 pts  \\n13. Event Horizon Labs (YC W24) Is Hiring (ycombinator.com)  \\n14. Confusables.txt and NFKC disagree on 31 characters (paultendo.github.io) ‚Äî 17 pts  \\n15. Pi ‚Äì A minimal terminal coding harness (pi.dev) ‚Äî 493 pts  \\n16. Mercury 2: Fast reasoning LLM powered by diffusion (inceptionlabs.ai) ‚Äî 284 pts  \\n17. Turing Completeness of GNU find (arxiv.org) ‚Äî 89 pts  \\n18. Japanese Death Poems (secretorum.life) ‚Äî 95 pts  \\n19. Show HN: Moonshine Open-Weights STT models ‚Äì higher accuracy than WhisperLargev3 (github.com/moonshine-ai) ‚Äî 280 pts  \\n20. Red Hat takes on Docker Desktop with its enterprise Podman Desktop build (thenewstack.io) ‚Äî 29 pts  \\n21. I pitched a roller coaster to Disneyland at age 10 in 1978 (wordglyph.xyz) ‚Äî 505 pts  \\n22. Show HN: Scheme-langserver ‚Äì Digest incomplete code with static analysis (github.com/ufo5260987423) ‚Äî 22 pts  \\n23. Mac mini will be made at a new facility in Houston (apple.com) ‚Äî 574 pts  \\n24. Hacking an old Kindle to display bus arrival times (mariannefeng.com) ‚Äî 312 pts  \\n25. LLM=True (blog.codemine.be) ‚Äî 173 pts  \\n26. Cl-kawa: Scheme on Java on Common Lisp (github.com/atgreen) ‚Äî 61 pts  \\n27. Nearby Glasses (github.com/yjeanrenaud) ‚Äî 384 pts  \\n28. Show HN: Clocksimulator.com ‚Äì A minimalist, distraction-free analog clock (clocksimulator.com) ‚Äî 55 pts  \\n29. Show HN: Emdash ‚Äì Open-source agentic development environment (github.com/generalaction) ‚Äî 185 pts  \\n30. Steel Bank Common Lisp (sbcl.org) ‚Äî 248 pts\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 4}
2026-02-25 10:36:32.059 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","post":"{\"id\":\"6jj3kaiwtb8j7nugk596p6um1e\",\"create_at\":1772033792044,\"update_at\":1772033792044,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"Hacker News top 30 items (raw text):\\n\\n1. Never Buy A .online Domain (0xsid.com) ‚Äî 297 pts  \\n2. US orders diplomats to fight data sovereignty initiatives (reuters.com) ‚Äî 69 pts  \\n3. How to fold the Blade Runner origami unicorn (1996) (archive.org) ‚Äî 107 pts  \\n4. Danish government agency to ditch Microsoft software (2025) (therecord.media) ‚Äî 452 pts  \\n5. Ask HN: Have top AI research institutions just given up on the idea of safety? ‚Äî 37 pts  \\n6. Show HN: Django Control Room ‚Äì All Your Tools Inside the Django Admin (github.com/yassi) ‚Äî 12 pts  \\n7. Show HN: A real-time strategy game that AI agents can play (llmskirmish.com) ‚Äî 137 pts  \\n8. 100M-Row Challenge with PHP (github.com/tempestphp) ‚Äî 92 pts  \\n9. I'm helping my dog vibe code games (calebleak.com) ‚Äî 1022 pts  \\n10. Claude Code Remote Control (claude.com) ‚Äî 214 pts  \\n11. Launch HN: TeamOut (YC W22) ‚Äì AI agent for planning company events (teamout.com) ‚Äî 7 pts  \\n12. The History of a Security Hole (os2museum.com) ‚Äî 8 pts  \\n13. Event Horizon Labs (YC W24) Is Hiring (ycombinator.com)  \\n14. Confusables.txt and NFKC disagree on 31 characters (paultendo.github.io) ‚Äî 17 pts  \\n15. Pi ‚Äì A minimal terminal coding harness (pi.dev) ‚Äî 493 pts  \\n16. Mercury 2: Fast reasoning LLM powered by diffusion (inceptionlabs.ai) ‚Äî 284 pts  \\n17. Turing Completeness of GNU find (arxiv.org) ‚Äî 89 pts  \\n18. Japanese Death Poems (secretorum.life) ‚Äî 95 pts  \\n19. Show HN: Moonshine Open-Weights STT models ‚Äì higher accuracy than WhisperLargev3 (github.com/moonshine-ai) ‚Äî 280 pts  \\n20. Red Hat takes on Docker Desktop with its enterprise Podman Desktop build (thenewstack.io) ‚Äî 29 pts  \\n21. I pitched a roller coaster to Disneyland at age 10 in 1978 (wordglyph.xyz) ‚Äî 505 pts  \\n22. Show HN: Scheme-langserver ‚Äì Digest incomplete code with static analysis (github.com/ufo5260987423) ‚Äî 22 pts  \\n23. Mac mini will be made at a new facility in Houston (apple.com) ‚Äî 574 pts  \\n24. Hacking an old Kindle to display bus arrival times (mariannefeng.com) ‚Äî 312 pts  \\n25. LLM=True (blog.codemine.be) ‚Äî 173 pts  \\n26. Cl-kawa: Scheme on Java on Common Lisp (github.com/atgreen) ‚Äî 61 pts  \\n27. Nearby Glasses (github.com/yjeanrenaud) ‚Äî 384 pts  \\n28. Show HN: Clocksimulator.com ‚Äì A minimalist, distraction-free analog clock (clocksimulator.com) ‚Äî 55 pts  \\n29. Show HN: Emdash ‚Äì Open-source agentic development environment (github.com/generalaction) ‚Äî 185 pts  \\n30. Steel Bank Common Lisp (sbcl.org) ‚Äî 248 pts\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 4}
2026-02-25 10:36:32.062 | INFO     | cobalt_agent.interfaces.mattermost:send_message_to_channel_id:177 - Message sent to channel badpmg1j5jf3mj7hxroe6xsrcw
2026-02-25 10:36:32.062 | INFO     | cobalt_agent.interfaces.mattermost:think_and_reply:368 - Final response sent to Mattermost
2026-02-25 10:42:18.962 | INFO     | cobalt_agent.interfaces.mattermost:run_native_ws:454 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 5}
2026-02-25 10:42:18.962 | INFO     | cobalt_agent.interfaces.mattermost:_handle_mattermost_event:215 - RAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 5}


========================================
FILE: logs/cobalt_agent_2026-02-15.log
========================================

2026-02-15 11:25:50.793 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.797 | INFO     | cobalt_agent.persona:__init__:43 - Persona 'Cobalt' initialized
2026-02-15 11:25:50.842 | INFO     | cobalt_agent.memory.postgres:_init_db:52 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-15 11:25:50.842 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.846 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5:14b
2026-02-15 11:25:50.846 | INFO     | cobalt_agent.brain.cortex:__init__:40 - üß† Cortex Online | Loaded 0 Departments from Config
2026-02-15 11:25:50.847 | INFO     | cobalt_agent.core.scheduler:start:25 - Scheduler started (Time Awareness Online)
2026-02-15 11:25:50.847 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.851 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5:14b
2026-02-15 11:25:50.871 | WARNING  | cobalt_agent.skills.productivity.scribe:__init__:35 - ‚ö†Ô∏è Obsidian Vault not found at /home/dejan/Documents/Think. Scribe functions will fail.
2026-02-15 11:25:50.871 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.876 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.879 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5:14b
2026-02-15 11:25:50.893 | WARNING  | cobalt_agent.skills.productivity.scribe:__init__:35 - ‚ö†Ô∏è Obsidian Vault not found at /home/dejan/Documents/Think. Scribe functions will fail.
2026-02-15 11:25:50.894 | INFO     | cobalt_agent.core.scheduler:add_job:45 - Scheduled task added: run (cron)
2026-02-15 11:25:50.894 | INFO     | __main__:main:95 - Cobalt Agent - System Initialized
2026-02-15 11:25:50.894 | INFO     | __main__:main:96 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-15 11:25:50.894 | INFO     | __main__:main:97 - Configuration Loaded: Debug Mode = True
2026-02-15 11:25:50.894 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5:14b
2026-02-15 11:25:50.894 | INFO     | __main__:main:102 - Brain Initialized: ollama/qwen2.5:14b
2026-02-15 11:25:50.894 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: search
2026-02-15 11:25:50.894 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: browser
2026-02-15 11:25:50.894 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 11:25:50.898 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: finance
2026-02-15 11:25:53.004 | INFO     | __main__:main:121 - Persona: Persona(name='Cobalt', roles=4, skills=3)
2026-02-15 11:25:53.005 | INFO     | __main__:main:122 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-15 11:25:53.005 | INFO     | __main__:main:126 - ================================================================================
2026-02-15 11:25:53.005 | INFO     | __main__:main:127 - SYSTEM PROMPT:
2026-02-15 11:25:53.005 | INFO     | __main__:main:128 - ================================================================================
2026-02-15 11:25:53.005 | INFO     | __main__:main:129 - 
You are Cobalt, a Chief of Staff, Software Architect, Senior Developer, Business Analyst.
Your Tone: Professional, Concise, Data-Driven, Analytical.

### CURRENT CONTEXT
- Current Date/Time: 2026-02-15 11:25:50
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- Prioritize risk management
- Verify all data
- Protect capital
- Analyze data before deciding
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- <cobalt_agent.tools.search.SearchTool object at 0x11b05e710>: No description provided.
- <cobalt_agent.tools.browser.BrowserTool object at 0x11b05e490>: No description provided.
- <cobalt_agent.tools.finance.FinanceTool object at 0x11b05ed50>: No description provided.

2026-02-15 11:25:53.006 | INFO     | __main__:main:130 - ================================================================================
2026-02-15 11:25:53.006 | INFO     | __main__:main:133 - Memory System online
2026-02-15 11:25:53.006 | INFO     | __main__:main:136 - ================================================================================
2026-02-15 11:25:53.006 | INFO     | __main__:main:137 - Starting interactive CLI interface...
2026-02-15 11:25:53.006 | INFO     | __main__:main:138 - ================================================================================
2026-02-15 11:25:53.006 | INFO     | cobalt_agent.interface:__init__:29 - CLI initialized with Brain connected
2026-02-15 12:33:43.956 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:43.960 | INFO     | cobalt_agent.persona:__init__:43 - Persona 'Cobalt' initialized
2026-02-15 12:33:43.991 | INFO     | cobalt_agent.memory.postgres:_init_db:52 - üß† Connected to Postgres Memory (Vector Ready)
2026-02-15 12:33:43.991 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:43.995 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5-coder:32b
2026-02-15 12:33:43.995 | INFO     | cobalt_agent.brain.cortex:__init__:40 - üß† Cortex Online | Loaded 0 Departments from Config
2026-02-15 12:33:43.995 | INFO     | cobalt_agent.core.scheduler:start:25 - Scheduler started (Time Awareness Online)
2026-02-15 12:33:43.995 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:43.999 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5-coder:32b
2026-02-15 12:33:44.017 | WARNING  | cobalt_agent.skills.productivity.scribe:__init__:35 - ‚ö†Ô∏è Obsidian Vault not found at /home/dejan/Documents/Think. Scribe functions will fail.
2026-02-15 12:33:44.017 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:44.021 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:44.025 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5-coder:32b
2026-02-15 12:33:44.039 | WARNING  | cobalt_agent.skills.productivity.scribe:__init__:35 - ‚ö†Ô∏è Obsidian Vault not found at /home/dejan/Documents/Think. Scribe functions will fail.
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.core.scheduler:add_job:45 - Scheduled task added: run (cron)
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.main:__init__:45 - Cobalt Agent - System Initialized
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.main:__init__:46 - Python Version: 3.14.3 (main, Feb  3 2026, 15:32:20) [Clang 17.0.0 (clang-1700.6.3.2)]
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.main:__init__:47 - Configuration Loaded: Debug Mode = True
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.llm:model_post_init:37 - LLM Initialized: ollama/qwen2.5-coder:32b
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.main:__init__:51 - Brain Initialized: ollama/qwen2.5-coder:32b
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: search
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: browser
2026-02-15 12:33:44.039 | INFO     | cobalt_agent.config:load_config:118 - Loading configuration from: /Users/cobalt/cobalt/configs
2026-02-15 12:33:44.043 | INFO     | cobalt_agent.tool_manager:register_tool:50 - Tool registered: finance
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:67 - Persona: Persona(name='Cobalt', roles=4, skills=3)
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:68 - Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:70 - ================================================================================
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:71 - SYSTEM PROMPT:
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:72 - ================================================================================
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:73 - 
You are Cobalt, a Chief of Staff, Software Architect, Senior Developer, Business Analyst.
Your Tone: Professional, Concise, Data-Driven, Analytical.

### CURRENT CONTEXT
- Current Date/Time: 2026-02-15 12:33:44
- Operating System: Python Environment (CLI)
- User: Administrator


### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.


### DIRECTIVES
- You are an AUTONOMOUS AGENT. You are NOT a chat bot.
- You DO NOT have internal knowledge of real-time events.
- You MUST use tools to answer questions about the world.
- STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.
- DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.
- Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation.
- Prioritize risk management
- Verify all data
- Protect capital
- Analyze data before deciding
### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°
To use a tool, you must output a single line starting with 'ACTION:'.
Do not talk. Do not explain. JUST ACTION.

### EXAMPLES OF CORRECT BEHAVIOR:
User: What is the price of Apple?
You: ACTION: finance AAPL
System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- <cobalt_agent.tools.search.SearchTool object at 0x10ff9cf50>: No description provided.
- <cobalt_agent.tools.browser.BrowserTool object at 0x10ff9ccd0>: No description provided.
- <cobalt_agent.tools.finance.FinanceTool object at 0x10ff9d590>: No description provided.

2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:74 - ================================================================================
2026-02-15 12:33:46.228 | INFO     | cobalt_agent.main:__init__:76 - Memory System online


========================================
FILE: logs/mattermost_session.log
========================================

System: [Observation: AAPL is $150]
You: Apple is trading at $150.

User: Find news about AI.
You: ACTION: search AI news
System: [Observation: AI is growing...]
You: Recent news indicates AI is growing.

### YOUR TURN:
If I ask you a question that requires data, do not answer directly. START WITH ACTION:.

### AVAILABLE TOOLS
- SearchTool: Use this tool for search tasks.
- BrowserTool: Use this tool for browser tasks.
- FinanceTool: Use this tool for finance tasks.
[0m
[32m2026-02-25 10:35:18.901[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m76[0m - [1m================================================================================[0m
[32m2026-02-25 10:35:18.901[0m | [1mINFO    [0m | [36m__main__[0m:[36m__init__[0m:[36m78[0m - [1mMemory System online[0m
[32m2026-02-25 10:35:18.901[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m__init__[0m:[36m44[0m - [1mMattermostInterface initialized (URL: http://100.70.206.126:8065)[0m
[32m2026-02-25 10:35:18.925[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mconnect[0m:[36m80[0m - [1mSuccessfully connected to Mattermost as user: cobalt[0m
[32m2026-02-25 10:35:18.926[0m | [1mINFO    [0m | [36mcobalt_agent.core.proposals[0m:[36m__init__[0m:[36m59[0m - [1mProposal Engine initialized (Channel: cobalt-approvals)[0m
[32m2026-02-25 10:35:18.926[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m__init__[0m:[36m44[0m - [1mMattermostInterface initialized (URL: http://100.70.206.126:8065)[0m
[32m2026-02-25 10:35:18.936[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mconnect[0m:[36m80[0m - [1mSuccessfully connected to Mattermost as user: cobalt[0m
[32m2026-02-25 10:35:18.937[0m | [1mINFO    [0m | [36mcobalt_agent.core.proposals[0m:[36mconnect_mattermost[0m:[36m75[0m - [1mProposal Engine: Mattermost connection established[0m
[32m2026-02-25 10:35:18.937[0m | [1mINFO    [0m | [36m__main__[0m:[36mstart_mattermost_interface[0m:[36m197[0m - [1m================================================================================[0m
[32m2026-02-25 10:35:18.937[0m | [1mINFO    [0m | [36m__main__[0m:[36mstart_mattermost_interface[0m:[36m198[0m - [1mCobalt Agent - Mattermost Interface Active[0m
[32m2026-02-25 10:35:18.937[0m | [1mINFO    [0m | [36m__main__[0m:[36mstart_mattermost_interface[0m:[36m199[0m - [1mHITL Proposal Engine - Active[0m
[32m2026-02-25 10:35:18.937[0m | [1mINFO    [0m | [36m__main__[0m:[36mstart_mattermost_interface[0m:[36m200[0m - [1m================================================================================[0m
[32m2026-02-25 10:35:18.937[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mstart_listening[0m:[36m460[0m - [1mStarting native WebSocket engine...[0m
[32m2026-02-25 10:35:18.937[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m445[0m - [1mConnecting to native WebSocket engine: ws://100.70.206.126:8065/api/v4/websocket[0m
[32m2026-02-25 10:35:18.944[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m450[0m - [1mConnected and authenticated via HTTP headers. Listening for messages...[0m
[32m2026-02-25 10:35:18.944[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m454[0m - [1mRAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"u63won8w4jr59kfzyxz4ptug3h","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}
[0m
[32m2026-02-25 10:35:18.945[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event":"hello","data":{"connection_id":"u63won8w4jr59kfzyxz4ptug3h","server_hostname":"7a18772f78d2","server_version":"11.4.0.21550760092.de08ead441c51c565085524a5a422aac3510be86312d1536fea3ff6fd4ef90f4.true"},"broadcast":{"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""},"seq":0}
[0m
[32m2026-02-25 10:35:18.946[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m454[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}[0m
[32m2026-02-25 10:35:18.946[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"online","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 1}[0m
[32m2026-02-25 10:35:40.283[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m454[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}[0m
[32m2026-02-25 10:35:40.284[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "typing", "data": {"parent_id":"","user_id":"xi4s3ncfypnz8fcbgyfhhwmt8a"}, "broadcast": {"omit_users":{"xi4s3ncfypnz8fcbgyfhhwmt8a":true},"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 2}[0m
[32m2026-02-25 10:35:43.910[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m454[0m - [1mRAW WEBSOCKET PAYLOAD: {"event":"posted","data":{"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","mentions":"[\"oyc789ktdpn75norxkk11hi5dc\"]","post":"{\"id\":\"jh8q7swt8fn83drznnz4p5q9jr\",\"create_at\":1772033743881,\"update_at\":1772033743881,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"@cobalt I need you to do general web research. Use the browser tool to scrape https://news.ycombinator.com and return the raw text.\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1772033743775\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{\"embeds\":[{\"type\":\"link\",\"url\":\"https://news.ycombinator.com\"}]}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"},"broadcast":{"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""},"seq":3}
[0m
[32m2026-02-25 10:35:43.911[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event":"posted","data":{"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","mentions":"[\"oyc789ktdpn75norxkk11hi5dc\"]","post":"{\"id\":\"jh8q7swt8fn83drznnz4p5q9jr\",\"create_at\":1772033743881,\"update_at\":1772033743881,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"@cobalt I need you to do general web research. Use the browser tool to scrape https://news.ycombinator.com and return the raw text.\",\"type\":\"\",\"props\":{},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"xi4s3ncfypnz8fcbgyfhhwmt8a:1772033743775\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{\"embeds\":[{\"type\":\"link\",\"url\":\"https://news.ycombinator.com\"}]}}","sender_name":"@dejan_z","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"},"broadcast":{"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""},"seq":3}
[0m
[32m2026-02-25 10:35:43.920[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m239[0m - [1mMessage received in channel badpmg1j5jf3mj7hxroe6xsrcw: @cobalt I need you to do general web research. Use the browser tool to scrape https://news.ycombinator.com and return the raw text.[0m
[32m2026-02-25 10:35:43.920[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m252[0m - [1mRouting message to Cortex in background thread...[0m
[32m2026-02-25 10:35:43.921[0m | [1mINFO    [0m | [36mcobalt_agent.memory.core[0m:[36mload_memory[0m:[36m90[0m - [1mMemory loaded from data/memory.json[0m
[32m2026-02-25 10:35:43.922[0m | [1mINFO    [0m | [36mcobalt_agent.brain.cortex[0m:[36mroute[0m:[36m57[0m - [1m‚ö° Fast-Path Routing Triggered: DEFAULT[0m
[32m2026-02-25 10:35:43.922[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mthink_and_reply[0m:[36m274[0m - [1mDEFAULT route detected, using ReAct loop...[0m
[32m2026-02-25 10:35:43.923[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mthink_and_reply[0m:[36m294[0m - [1mReAct iteration 1/3[0m
[32m2026-02-25 10:35:59.841[0m | [1mINFO    [0m | [36mcobalt_agent.llm[0m:[36mgenerate_response[0m:[36m172[0m - [1mCobalt, LLM model version: ollama/qwen3-coder-next[0m
[32m2026-02-25 10:35:59.842[0m | [1mINFO    [0m | [36mcobalt_agent.llm[0m:[36mgenerate_response[0m:[36m173[0m - [1mPersona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst[0m
[32m2026-02-25 10:35:59.842[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mthink_and_reply[0m:[36m304[0m - [1mLLM Response: ACTION: scrape https://news.ycombinator.com[0m
[32m2026-02-25 10:35:59.842[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mthink_and_reply[0m:[36m309[0m - [1mACTION: detected, parsing tool command...[0m
[32m2026-02-25 10:35:59.843[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mthink_and_reply[0m:[36m327[0m - [1mFuzzy matched 'browser' -> 'browser'[0m
[32m2026-02-25 10:35:59.843[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mregister_tool[0m:[36m50[0m - [1mTool registered: search[0m
[32m2026-02-25 10:35:59.843[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mregister_tool[0m:[36m50[0m - [1mTool registered: browser[0m
[32m2026-02-25 10:35:59.843[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m422[0m - [1mLoading configuration from: /Users/cobalt/cobalt/configs[0m
[32m2026-02-25 10:35:59.861[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m452[0m - [1müîë COBALT_MASTER_KEY detected. Unlocking secure vault...[0m
[32m2026-02-25 10:35:59.861[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36munlock[0m:[36m44[0m - [1müîê Vault successfully unlocked into memory.[0m
[32m2026-02-25 10:35:59.862[0m | [1mINFO    [0m | [36mcobalt_agent.security.vault[0m:[36mlock[0m:[36m55[0m - [1müîí Vault locked. Secrets wiped from RAM.[0m
[32m2026-02-25 10:35:59.862[0m | [1mINFO    [0m | [36mcobalt_agent.config[0m:[36mload_config[0m:[36m483[0m - [1müîí Vault secrets loaded into runtime RAM and vault locked.[0m
[32m2026-02-25 10:35:59.864[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mregister_tool[0m:[36m50[0m - [1mTool registered: finance[0m
[32m2026-02-25 10:35:59.865[0m | [1mINFO    [0m | [36mcobalt_agent.tools.tool_manager[0m:[36mexecute_tool[0m:[36m70[0m - [1mExecuting tool: browser with args: {'query': 'https://news.ycombinator.com'}[0m
[32m2026-02-25 10:35:59.865[0m | [1mINFO    [0m | [36mcobalt_agent.tools.browser[0m:[36mrun[0m:[36m68[0m - [1müåê Playwright navigating to: https://news.ycombinator.com[0m
[32m2026-02-25 10:36:02.711[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mthink_and_reply[0m:[36m352[0m - [1mTool executed: browser, Observation: [Observation: ### Hacker News
Hacker Newsnew | past | comments | ask | show | jobs | submit	login
1.
Never Buy A .online Domain (0xsid.com)
297 points by ssiddharth 2 hours ago | hide | 151¬†comments
2.
US orders diplomats to fight data sovereignty initiatives (reuters.com)
69 points by colinhb 47 minutes ago | hide | 37¬†comments
3.
How to fold the Blade Runner origami unicorn (1996) (archive.org)
107 points by exvi 5 hours ago | hide | 5¬†comments
4.
Danish government agency to ditch Microsoft software (2025) (therecord.media)
452 points by robtherobber 5 hours ago | hide | 257¬†comments
5.
Ask HN: Have top AI research institutions just given up on the idea of safety?
37 points by DietaryNonsense 40 minutes ago | hide | 19¬†comments
6.
Show HN: Django Control Room ‚Äì All Your Tools Inside the Django Admin (github.com/yassi)
12 points by yassi_dev 1 hour ago | hide | 4¬†comments
7.
Show HN: A real-time strategy game that AI agents can play (llmskirmish.com)
137 points by __cayenne__ 5 hours ago | hide | 46¬†comments
8.
100M-Row Challenge with PHP (github.com/tempestphp)
92 points by brentroose 5 hours ago | hide | 29¬†comments
9.
I'm helping my dog vibe code games (calebleak.com)
1022 points by cleak 22 hours ago | hide | 333¬†comments
10.
Claude Code Remote Control (claude.com)
214 points by empressplay 8 hours ago | hide | 144¬†comments
11.
Launch HN: TeamOut (YC W22) ‚Äì AI agent for planning company events (teamout.com)
7 points by vincentalbouy 1 hour ago | hide | 4¬†comments
12.
The History of a Security Hole (os2museum.com)
8 points by st_goliath 2 hours ago | hide | 1¬†comment
13.		Event Horizon Labs (YC W24) Is Hiring (ycombinator.com)
3 hours ago | hide
14.
Confusables.txt and NFKC disagree on 31 characters (paultendo.github.io)
17 points by pimterry 3 hours ago | hide | 13¬†comments
15.
Pi ‚Äì A minimal terminal coding harness (pi.dev)
493 points by kristianpaul 17 hours ago | hide | 236¬†comments
16.
Mercury 2: Fast reasoning LLM powered by diffusion (inceptionlabs.ai)
284 points by fittingopposite 16 hours ago | hide | 113¬†comments
17.
Turing Completeness of GNU find (arxiv.org)
89 points by todsacerdoti 10 hours ago | hide | 17¬†comments
18.
Japanese Death Poems (secretorum.life)
95 points by NaOH 10 hours ago | hide | 28¬†comments
19.
Show HN: Moonshine Open-Weights STT models ‚Äì higher accuracy than WhisperLargev3 (github.com/moonshine-ai)
280 points by petewarden 17 hours ago | hide | 66¬†comments
20.
Red Hat takes on Docker Desktop with its enterprise Podman Desktop build (thenewstack.io)
29 points by twelvenmonkeys 2 hours ago | hide | 18¬†comments
21.
I pitched a roller coaster to Disneyland at age 10 in 1978 (wordglyph.xyz)
505 points by wordglyph 1 day ago | hide | 186¬†comments
22.
Show HN: Scheme-langserver ‚Äì Digest incomplete code with static analysis (github.com/ufo5260987423)
22 points by ufo5260987423 7 hours ago | hide | discuss
23.
Mac¬†mini will be made at a new facility in Houston (apple.com)
574 points by haunter 18 hours ago | hide | 584¬†comments
24.
Hacking an old Kindle to display bus arrival times (mariannefeng.com)
312 points by mengchengfeng 19 hours ago | hide | 79¬†comments
25.
LLM=True (blog.codemine.be)
173 points by avh3 6 hours ago | hide | 122¬†comments
26.
Cl-kawa: Scheme on Java on Common Lisp (github.com/atgreen)
61 points by varjag 11 hours ago | hide | 16¬†comments
27.
Nearby Glasses (github.com/yjeanrenaud)
384 points by zingerlio 21 hours ago | hide | 168¬†comments
28.
Show HN: Clocksimulator.com ‚Äì A minimalist, distraction-free analog clock (clocksimulator.com)
55 points by user_timo 1 hour ago | hide | 46¬†comments
29.
Show HN: Emdash ‚Äì Open-source agentic development environment (github.com/generalaction)
185 points by onecommit 20 hours ago | hide | 66¬†comments
30.
Steel Bank Common Lisp (sbcl.org)
248 points by tosh 21 hours ago | hide | 100¬†comments
More
Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | Contact
Search:...][0m
[32m2026-02-25 10:36:02.711[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mthink_and_reply[0m:[36m294[0m - [1mReAct iteration 2/3[0m
[32m2026-02-25 10:36:32.027[0m | [1mINFO    [0m | [36mcobalt_agent.llm[0m:[36mgenerate_response[0m:[36m172[0m - [1mCobalt, LLM model version: ollama/qwen3-coder-next[0m
[32m2026-02-25 10:36:32.028[0m | [1mINFO    [0m | [36mcobalt_agent.llm[0m:[36mgenerate_response[0m:[36m173[0m - [1mPersona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst[0m
[32m2026-02-25 10:36:32.028[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mthink_and_reply[0m:[36m304[0m - [1mLLM Response: Hacker News top 30 items (raw text):

1. Never Buy A .online Domain (0xsid.com) ‚Äî 297 pts  
2. US orders diplomats to fight data sovereignty initiatives (reuters.com) ‚Äî 69 pts  
3. How to fold the Blade Runner origami unicorn (1996) (archive.org) ‚Äî 107 pts  
4. Danish government agency to ditch Microsoft software (2025) (therecord.media) ‚Äî 452 pts  
5. Ask HN: Have top AI research institutions just given up on the idea of safety? ‚Äî 37 pts  
6. Show HN: Django Control Room ‚Äì All Your Tools Inside the Django Admin (github.com/yassi) ‚Äî 12 pts  
7. Show HN: A real-time strategy game that AI agents can play (llmskirmish.com) ‚Äî 137 pts  
8. 100M-Row Challenge with PHP (github.com/tempestphp) ‚Äî 92 pts  
9. I'm helping my dog vibe code games (calebleak.com) ‚Äî 1022 pts  
10. Claude Code Remote Control (claude.com) ‚Äî 214 pts  
11. Launch HN: TeamOut (YC W22) ‚Äì AI agent for planning company events (teamout.com) ‚Äî 7 pts  
12. The History of a Security Hole (os2museum.com) ‚Äî 8 pts  
13. Event Horizon Labs (YC W24) Is Hiring (ycombinator.com)  
14. Confusables.txt and NFKC disagree on 31 characters (paultendo.github.io) ‚Äî 17 pts  
15. Pi ‚Äì A minimal terminal coding harness (pi.dev) ‚Äî 493 pts  
16. Mercury 2: Fast reasoning LLM powered by diffusion (inceptionlabs.ai) ‚Äî 284 pts  
17. Turing Completeness of GNU find (arxiv.org) ‚Äî 89 pts  
18. Japanese Death Poems (secretorum.life) ‚Äî 95 pts  
19. Show HN: Moonshine Open-Weights STT models ‚Äì higher accuracy than WhisperLargev3 (github.com/moonshine-ai) ‚Äî 280 pts  
20. Red Hat takes on Docker Desktop with its enterprise Podman Desktop build (thenewstack.io) ‚Äî 29 pts  
21. I pitched a roller coaster to Disneyland at age 10 in 1978 (wordglyph.xyz) ‚Äî 505 pts  
22. Show HN: Scheme-langserver ‚Äì Digest incomplete code with static analysis (github.com/ufo5260987423) ‚Äî 22 pts  
23. Mac mini will be made at a new facility in Houston (apple.com) ‚Äî 574 pts  
24. Hacking an old Kindle to display bus arrival times (mariannefeng.com) ‚Äî 312 pts  
25. LLM=True (blog.codemine.be) ‚Äî 173 pts  
26. Cl-kawa: Scheme on Java on Common Lisp (github.com/atgreen) ‚Äî 61 pts  
27. Nearby Glasses (github.com/yjeanrenaud) ‚Äî 384 pts  
28. Show HN: Clocksimulator.com ‚Äì A minimalist, distraction-free analog clock (clocksimulator.com) ‚Äî 55 pts  
29. Show HN: Emdash ‚Äì Open-source agentic development environment (github.com/generalaction) ‚Äî 185 pts  
30. Steel Bank Common Lisp (sbcl.org) ‚Äî 248 pts[0m
[32m2026-02-25 10:36:32.029[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mthink_and_reply[0m:[36m359[0m - [1mNo ACTION: detected, returning final answer[0m
[32m2026-02-25 10:36:32.058[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m454[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","post":"{\"id\":\"6jj3kaiwtb8j7nugk596p6um1e\",\"create_at\":1772033792044,\"update_at\":1772033792044,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"Hacker News top 30 items (raw text):\\n\\n1. Never Buy A .online Domain (0xsid.com) ‚Äî 297 pts  \\n2. US orders diplomats to fight data sovereignty initiatives (reuters.com) ‚Äî 69 pts  \\n3. How to fold the Blade Runner origami unicorn (1996) (archive.org) ‚Äî 107 pts  \\n4. Danish government agency to ditch Microsoft software (2025) (therecord.media) ‚Äî 452 pts  \\n5. Ask HN: Have top AI research institutions just given up on the idea of safety? ‚Äî 37 pts  \\n6. Show HN: Django Control Room ‚Äì All Your Tools Inside the Django Admin (github.com/yassi) ‚Äî 12 pts  \\n7. Show HN: A real-time strategy game that AI agents can play (llmskirmish.com) ‚Äî 137 pts  \\n8. 100M-Row Challenge with PHP (github.com/tempestphp) ‚Äî 92 pts  \\n9. I'm helping my dog vibe code games (calebleak.com) ‚Äî 1022 pts  \\n10. Claude Code Remote Control (claude.com) ‚Äî 214 pts  \\n11. Launch HN: TeamOut (YC W22) ‚Äì AI agent for planning company events (teamout.com) ‚Äî 7 pts  \\n12. The History of a Security Hole (os2museum.com) ‚Äî 8 pts  \\n13. Event Horizon Labs (YC W24) Is Hiring (ycombinator.com)  \\n14. Confusables.txt and NFKC disagree on 31 characters (paultendo.github.io) ‚Äî 17 pts  \\n15. Pi ‚Äì A minimal terminal coding harness (pi.dev) ‚Äî 493 pts  \\n16. Mercury 2: Fast reasoning LLM powered by diffusion (inceptionlabs.ai) ‚Äî 284 pts  \\n17. Turing Completeness of GNU find (arxiv.org) ‚Äî 89 pts  \\n18. Japanese Death Poems (secretorum.life) ‚Äî 95 pts  \\n19. Show HN: Moonshine Open-Weights STT models ‚Äì higher accuracy than WhisperLargev3 (github.com/moonshine-ai) ‚Äî 280 pts  \\n20. Red Hat takes on Docker Desktop with its enterprise Podman Desktop build (thenewstack.io) ‚Äî 29 pts  \\n21. I pitched a roller coaster to Disneyland at age 10 in 1978 (wordglyph.xyz) ‚Äî 505 pts  \\n22. Show HN: Scheme-langserver ‚Äì Digest incomplete code with static analysis (github.com/ufo5260987423) ‚Äî 22 pts  \\n23. Mac mini will be made at a new facility in Houston (apple.com) ‚Äî 574 pts  \\n24. Hacking an old Kindle to display bus arrival times (mariannefeng.com) ‚Äî 312 pts  \\n25. LLM=True (blog.codemine.be) ‚Äî 173 pts  \\n26. Cl-kawa: Scheme on Java on Common Lisp (github.com/atgreen) ‚Äî 61 pts  \\n27. Nearby Glasses (github.com/yjeanrenaud) ‚Äî 384 pts  \\n28. Show HN: Clocksimulator.com ‚Äì A minimalist, distraction-free analog clock (clocksimulator.com) ‚Äî 55 pts  \\n29. Show HN: Emdash ‚Äì Open-source agentic development environment (github.com/generalaction) ‚Äî 185 pts  \\n30. Steel Bank Common Lisp (sbcl.org) ‚Äî 248 pts\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 4}[0m
[32m2026-02-25 10:36:32.059[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "posted", "data": {"channel_display_name":"Town Square","channel_name":"town-square","channel_type":"O","post":"{\"id\":\"6jj3kaiwtb8j7nugk596p6um1e\",\"create_at\":1772033792044,\"update_at\":1772033792044,\"edit_at\":0,\"delete_at\":0,\"is_pinned\":false,\"user_id\":\"oyc789ktdpn75norxkk11hi5dc\",\"channel_id\":\"badpmg1j5jf3mj7hxroe6xsrcw\",\"root_id\":\"\",\"original_id\":\"\",\"message\":\"Hacker News top 30 items (raw text):\\n\\n1. Never Buy A .online Domain (0xsid.com) ‚Äî 297 pts  \\n2. US orders diplomats to fight data sovereignty initiatives (reuters.com) ‚Äî 69 pts  \\n3. How to fold the Blade Runner origami unicorn (1996) (archive.org) ‚Äî 107 pts  \\n4. Danish government agency to ditch Microsoft software (2025) (therecord.media) ‚Äî 452 pts  \\n5. Ask HN: Have top AI research institutions just given up on the idea of safety? ‚Äî 37 pts  \\n6. Show HN: Django Control Room ‚Äì All Your Tools Inside the Django Admin (github.com/yassi) ‚Äî 12 pts  \\n7. Show HN: A real-time strategy game that AI agents can play (llmskirmish.com) ‚Äî 137 pts  \\n8. 100M-Row Challenge with PHP (github.com/tempestphp) ‚Äî 92 pts  \\n9. I'm helping my dog vibe code games (calebleak.com) ‚Äî 1022 pts  \\n10. Claude Code Remote Control (claude.com) ‚Äî 214 pts  \\n11. Launch HN: TeamOut (YC W22) ‚Äì AI agent for planning company events (teamout.com) ‚Äî 7 pts  \\n12. The History of a Security Hole (os2museum.com) ‚Äî 8 pts  \\n13. Event Horizon Labs (YC W24) Is Hiring (ycombinator.com)  \\n14. Confusables.txt and NFKC disagree on 31 characters (paultendo.github.io) ‚Äî 17 pts  \\n15. Pi ‚Äì A minimal terminal coding harness (pi.dev) ‚Äî 493 pts  \\n16. Mercury 2: Fast reasoning LLM powered by diffusion (inceptionlabs.ai) ‚Äî 284 pts  \\n17. Turing Completeness of GNU find (arxiv.org) ‚Äî 89 pts  \\n18. Japanese Death Poems (secretorum.life) ‚Äî 95 pts  \\n19. Show HN: Moonshine Open-Weights STT models ‚Äì higher accuracy than WhisperLargev3 (github.com/moonshine-ai) ‚Äî 280 pts  \\n20. Red Hat takes on Docker Desktop with its enterprise Podman Desktop build (thenewstack.io) ‚Äî 29 pts  \\n21. I pitched a roller coaster to Disneyland at age 10 in 1978 (wordglyph.xyz) ‚Äî 505 pts  \\n22. Show HN: Scheme-langserver ‚Äì Digest incomplete code with static analysis (github.com/ufo5260987423) ‚Äî 22 pts  \\n23. Mac mini will be made at a new facility in Houston (apple.com) ‚Äî 574 pts  \\n24. Hacking an old Kindle to display bus arrival times (mariannefeng.com) ‚Äî 312 pts  \\n25. LLM=True (blog.codemine.be) ‚Äî 173 pts  \\n26. Cl-kawa: Scheme on Java on Common Lisp (github.com/atgreen) ‚Äî 61 pts  \\n27. Nearby Glasses (github.com/yjeanrenaud) ‚Äî 384 pts  \\n28. Show HN: Clocksimulator.com ‚Äì A minimalist, distraction-free analog clock (clocksimulator.com) ‚Äî 55 pts  \\n29. Show HN: Emdash ‚Äì Open-source agentic development environment (github.com/generalaction) ‚Äî 185 pts  \\n30. Steel Bank Common Lisp (sbcl.org) ‚Äî 248 pts\",\"type\":\"\",\"props\":{\"from_bot\":\"true\"},\"hashtags\":\"\",\"file_ids\":[],\"pending_post_id\":\"\",\"remote_id\":\"\",\"reply_count\":0,\"last_reply_at\":0,\"participants\":null,\"metadata\":{}}","sender_name":"@cobalt","set_online":true,"team_id":"y7zd739mb3ga5krhu9pfrhhemr"}, "broadcast": {"omit_users":null,"user_id":"","channel_id":"badpmg1j5jf3mj7hxroe6xsrcw","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 4}[0m
[32m2026-02-25 10:36:32.062[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36msend_message_to_channel_id[0m:[36m177[0m - [1mMessage sent to channel badpmg1j5jf3mj7hxroe6xsrcw[0m
[32m2026-02-25 10:36:32.062[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mthink_and_reply[0m:[36m368[0m - [1mFinal response sent to Mattermost[0m
[32m2026-02-25 10:42:18.962[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36mrun_native_ws[0m:[36m454[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 5}[0m
[32m2026-02-25 10:42:18.962[0m | [1mINFO    [0m | [36mcobalt_agent.interfaces.mattermost[0m:[36m_handle_mattermost_event[0m:[36m215[0m - [1mRAW WEBSOCKET PAYLOAD: {"event": "status_change", "data": {"status":"away","user_id":"oyc789ktdpn75norxkk11hi5dc"}, "broadcast": {"omit_users":null,"user_id":"oyc789ktdpn75norxkk11hi5dc","channel_id":"","team_id":"","connection_id":"","omit_connection_id":""}, "seq": 5}[0m


========================================
FILE: pyproject.toml
========================================

[project]
name = "cobalt-agent"
version = "0.1.0"
description = "Project Cobalt: Autonomous AI Chief of Staff & Trading System"
readme = "README.md"
requires-python = ">=3.11"
authors = [
    { name = "Director", email = "director@cobalt-core.com" }
]

# --- CORE DEPENDENCIES (Moved here under [project]) ---
dependencies = [
    # 1. THE BRAIN
    "pydantic>=2.0.0",
    "pydantic-ai>=0.0.1",
    "litellm>=1.0.0",
    "openai>=1.0.0",
    # 2. THE FINANCE
    "pandas>=2.2.0",
    "pandas-ta-classic",
    "ta-lib>=0.4.0",
    "mplfinance>=0.12.0",
    "aiohttp>=3.9.0",
    # 3. CHIEF OF STAFF
    "mattermostdriver>=7.0",
    "google-api-python-client>=2.0",
    "gitpython>=3.1.0",
    "schedule>=1.2.0",
    "beautifulsoup4>=4.12.0",
    "playwright>=1.40.0",
    # 4. INFRASTRUCTURE
    "fastapi>=0.100.0",
    "uvicorn>=0.20.0",
    "redis>=5.0.0",
    "asyncpg>=0.29.0",
    "sqlalchemy>=2.0.0",
    "loguru>=0.7.0",
    "python-dotenv>=1.0.0",
    "pyyaml>=6.0.0",
    # 5. SECURITY
    "pyotp>=2.9.0",
    "qrcode>=7.4.0",
    "bcrypt>=4.0.0",
    "passlib>=1.7.0",
    "ddgs>=9.10.0",
    "rich>=14.3.2",
    "requests>=2.32.5",
    "yfinance>=1.1.0",
    "psycopg[binary]>=3.3.2",
    "pgvector>=0.4.2",
    "apscheduler>=3.11.2",
    "cryptography>=46.0.4",
]

# --- DEV DEPENDENCIES (New Standard: [dependency-groups]) ---
[dependency-groups]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "black>=24.0.0",
    "ipykernel>=6.29.0",
    "python-dotenv>=1.2.1",
]

[build-system]
requires = ["setuptools>=61.0", "uv.build"]
build-backend = "setuptools.build_meta"
[tool.uv.extra-build-dependencies]
cobalt-agent = ["uv.build"]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
norecursedirs = ["data", "logs", "plans", "scripts", "dev_utils"]
python_files = "test_*.py"
markers = ["integration: marks tests that require external systems (like Docker)"]

[tool.setuptools.packages.find]
where = ["src"]


========================================
FILE: src/cobalt_agent/brain/cortex.py
========================================

"""
The Cortex (Manager Agent) - Config-Driven Architecture
Routes user intent based on domains defined in config.yaml.
Includes robust error handling, full Scribe logic, and Medical Admin placeholders.
"""
import re
import json
from typing import Optional, Any
from datetime import datetime
from pydantic import BaseModel, Field
from loguru import logger

from cobalt_agent.llm import LLM
from cobalt_agent.config import load_config
from cobalt_agent.core.proposals import Proposal

# --- ROUTING MODEL ---
class DomainDecision(BaseModel):
    domain_name: str = Field(description="The exact name of the department (e.g. TACTICAL, OPS).")
    reasoning: str = Field(description="Why this department fits the request.")
    task_parameters: str = Field(
        description="The PRECISE entity or query to act on. For Tactical, this MUST be just the Ticker Symbol (e.g. 'NVDA') OR the command 'STRATEGY'."
    )

class Cortex:
    def __init__(self):
        self.config = load_config()
        
        # --- ROBUST LLM CONFIG ---
        # Try 'model_name' first, then 'model', then default to 'gpt-4o'
        model_name = getattr(self.config.llm, "model_name", None)
        if not model_name:
            model_name = getattr(self.config.llm, "model", "gpt-4o")
            
        self.llm = LLM(model_name=model_name)
        
        # --- ROBUST DEPARTMENTS LOAD ---
        deps = getattr(self.config, "departments", None)
        if deps is None:
            deps = {}
        self.departments = deps
        
        logger.info(f"üß† Cortex Online | Loaded {len(self.departments)} Departments from Config")

    def route(self, user_input: str) -> Optional[str]:
        """Dynamically routes based on config."""
        # Fast exit
        if len(user_input.split()) < 4 and "hi" in user_input.lower():
            return None

        # === DETERMINISTIC FAST-PATH ROUTING ===
        # Bypass LLM for browser/web tasks to avoid identity bias
        message_lower = user_input.lower()
        fast_path_keywords = ["http://", "https://", "browser", "scrape", "search", "summarize the top"]
        
        if any(keyword in message_lower for keyword in fast_path_keywords):
            logger.info("‚ö° Fast-Path Routing Triggered: DEFAULT")
            return None  # Handle in main chat loop (same as FOUNDATION)
        
        # 1. Hardcoded bypass for questions - routes to FOUNDATION (standard chat with tool access)
        if "?" in message_lower or "price" in message_lower or "what" in message_lower:
            logger.info("Direct route bypass triggered: Question detected.")
            return None
        
        # 2. Classify
        decision = self._classify_domain(user_input)
        
        # --- PRIME DIRECTIVE GATE ---
        high_risk_keywords = ['delete', 'move', 'remove', 'format', 'execute', 'kill', 'reorganize']
        is_high_risk = any(word in user_input.lower() for word in high_risk_keywords)
        
        if is_high_risk:
            logger.warning(f"üõ°Ô∏è Security Intercept: High-risk action detected in input: {user_input}")
            return self._generate_proposal(user_input)
        # ----------------------
        
        # 2. Lazy Load & Execute
        domain = decision.domain_name.upper()
        params = decision.task_parameters.strip()

        logger.info(f"üëâ Cortex Routing: {domain} | Task: {params}")
        
        if domain == "TACTICAL":
            return self._run_tactical(params)
        
        elif domain == "INTEL":
            return self._run_intel(params)
            
        elif domain == "GROWTH":
            return "üë∑ The Architect (Growth) is defined but not yet hired."
            
        elif domain == "OPS":
            return self._run_ops(params, user_input) # Pass original input for Scribe context
            
        elif domain == "ENGINEERING":
            from cobalt_agent.brain.engineering import EngineeringDepartment
            forge = EngineeringDepartment()
            return forge.run(params)
            
        elif domain == "DEFAULT":
            return None # Handle in main chat loop (same as FOUNDATION)
            
        elif domain == "FOUNDATION":
            return None # Handle in main chat loop
            
        else:
            return f"‚ö†Ô∏è Unknown Domain: {domain}"

    def _generate_proposal(self, user_input: str) -> str:
        prompt = f"""
        [SECURITY PROTOCOL: PRIME DIRECTIVE]
        High-risk action detected: "{user_input}"
        
        You are the Chief of Staff. You are FORBIDDEN from executing this autonomously.
        Generate a JSON response explaining the risk.
        
        OUTPUT FORMAT:
        {{
          "action": "Summary of what was requested",
          "justification": "Why the user wants this",
          "risk_assessment": "Blunt warning about data loss or system instability"
        }}
        
        OUTPUT ONLY JSON. NO EXTRA TEXT.
        """
        
        raw_response = ""
        try:
            # Bypass ask_structured to avoid schema confusion; use base ask/generate
            raw_response = self.llm.ask(prompt)
            
            # Bulletproof JSON extraction
            match = re.search(r'\{.*\}', raw_response, re.DOTALL)
            if not match:
                raise ValueError("No JSON block found in LLM response.")
                
            data = json.loads(match.group(0))
            
            # Manually instantiate the Proposal (task_id and timestamp will auto-generate)
            proposal = Proposal(
                action=data.get("action", "Unknown Action"),
                justification=data.get("justification", "User requested high-stakes operation."),
                risk_assessment=data.get("risk_assessment", "High risk of system modification.")
            )
            return proposal.format_for_mattermost()
            
        except Exception as e:
            logger.error(f"Proposal Generation Failed: {e} | Raw Output: {raw_response}")
            return (
                f"### üõ°Ô∏è SECURITY INTERCEPT\n"
                f"**Action Blocked:** Administrative system change.\n\n"
                f"**Reason:** The Proposal Engine could not validate the risk assessment. "
                f"Execution is denied by default per the Prime Directive."
            )

    def _classify_domain(self, user_input: str) -> DomainDecision:
        """Builds prompt from config.yaml definitions."""
        options_text = ""
        
        # Guard against empty departments
        if not self.departments:
            options_text = "- TACTICAL\n- INTEL\n- OPS"
        else:
            for name, data in self.departments.items():
                is_active = False
                desc = "No description"
                if isinstance(data, dict):
                    is_active = data.get('active', False)
                    desc = data.get('description', desc)
                elif hasattr(data, 'active'):
                    is_active = getattr(data, 'active', False)
                    desc = getattr(data, 'description', desc)

                if is_active:
                    options_text += f"- {name}: {desc}\n"
        
        # STRICT MUTUALLY EXCLUSIVE ROUTING PROMPT
        prompt = f"""
        You are the Chief of Staff (Cortex). Route this user request to the correct Department.
        
        USER REQUEST: "{user_input}"
        
        ACTIVE DEPARTMENTS:
        {options_text}
        - DEFAULT: General chat, web research, web browsing, article summarization. Use for queries that don't fit other domains.
        
        === STRICT ROUTING RULES (MUST FOLLOW) ===
        1. WEB RESEARCH / DEFAULT ROUTING:
           - If the user asks to browse a website, scrape a URL, summarize an article, or perform general web research, you MUST return 'DEFAULT'.
           - Examples: "What's the weather in Paris?", "Summarize this article", "Look up recent news", "Research X", "Browse Y"
        
        2. TACTICAL (TRADING ONLY - STRICTLY RESTRICTED):
           - ONLY return 'TACTICAL' if the user explicitly mentions trading, stocks, tickers, playbooks, or expected value (EV).
           - Valid examples: "What is AAPL trading at?", "TSLA stock price", "Show me playbooks", "Calculate EV for X"
           - Extract ONLY the ticker symbol (e.g. "NVDA", "AAPL") or "STRATEGY" as task_parameters
        
        3. INTEL (Research/News):
           - Use for: news, deep dives, current events (non-trading focused)
           - Extract the search topic as task_parameters
        
        4. OPS (Operations/Scribe):
           - Use for: logging, journaling, saving notes, medical billing
           - Extract relevant content as task_parameters
        
        5. ENGINEERING (CODE WORK - STRICTLY RESTRICTED):
           - ONLY return 'ENGINEERING' if the user explicitly asks to write, edit, or review code.
           - Examples: "Write a function", "Fix this bug", "Review my code", "Create a new tool"
        
        6. DEFAULT:
           - Use for: general conversation, greetings, system questions, or anything not matching the above
           - Return task_parameters: "chat"
        
        === EXAMPLES ===
        Input: "What is the current price of AAPL?"
        ‚Üí Domain: TACTICAL, Parameters: "AAPL"
        
        Input: "What is the price of TSLA?"
        ‚Üí Domain: TACTICAL, Parameters: "TSLA"
        
        Input: "Show me the strategies/playbooks"
        ‚Üí Domain: TACTICAL, Parameters: "STRATEGY"
        
        Input: "What is the expected value of X given Y?"
        ‚Üí Domain: TACTICAL, Parameters: "STRATEGY"
        
        Input: "Browse https://example.com and summarize it"
        ‚Üí Domain: DEFAULT, Parameters: "chat"
        
        Input: "Summarize this article about AI"
        ‚Üí Domain: DEFAULT, Parameters: "chat"
        
        Input: "Write a Python function to do X"
        ‚Üí Domain: ENGINEERING, Parameters: "Python function: X"
        
        Input: "Fix the routing bug in cortex.py"
        ‚Üí Domain: ENGINEERING, Parameters: "Fix routing bug in cortex.py"
        
        Input: "What's the weather like?"
        ‚Üí Domain: DEFAULT, Parameters: "chat"
        
        Input: "Hi, how are you?"
        ‚Üí Domain: DEFAULT, Parameters: "chat"
        
        === FINAL INSTRUCTION ===
        FOLLOW THESE RULES STRICTLY AND MUTUALLY EXCLUSIVELY:
        1. Web research/browser/URL/summary queries ‚Üí DEFAULT
        2. Trading/stocks/tickers/playbooks/EV ‚Üí TACTICAL
        3. Writing/editing/reviewing code ‚Üí ENGINEERING
        4. Everything else ‚Üí DEFAULT
        
        Return the decision structured correctly. DO NOT DEVIATE FROM THESE RULES.
        """
        try:
            return self.llm.ask_structured(prompt, DomainDecision)
        except Exception:
            return DomainDecision(domain_name="FOUNDATION", reasoning="Error", task_parameters="")

    # --- DEPARTMENT HANDLERS ---
    
    def _run_tactical(self, params: str) -> str:
        """Handles Trading & Market Data."""
        from cobalt_agent.brain.tactical import Strategos
        try:
            # Clean up params
            # If the LLM sends "STRATEGY" or "PLAYBOOK", we pass it raw.
            # If it sends a ticker "NVDA", we clean it.
            if "STRATEGY" in params.upper() or "PLAYBOOK" in params.upper():
                task = "STRATEGY"
            else:
                task = params.split()[0].strip(".,!?")
                
            department_head = Strategos()
            return department_head.run(task)
        except Exception as e:
            return f"Tactical Error: {e}"

    def _run_intel(self, params: str) -> str:
        """Handles Research & Briefings."""
        if "briefing" in params.lower():
            from cobalt_agent.skills.productivity.briefing import MorningBriefing
            return MorningBriefing().run()
        else:
            from cobalt_agent.skills.research.deep_dive import DeepResearch
            return DeepResearch().run(params)

    def _run_ops(self, params: str, original_input: str) -> str:
        """
        Handles Operations (Scribe, Medical, Scheduling).
        """
        from cobalt_agent.skills.productivity.scribe import Scribe
        scribe = Scribe()
        
        prompt_lower = original_input.lower()
        
        # 1. LOGGING
        if "log" in prompt_lower or "journal" in prompt_lower:
            content = original_input.replace("log", "").replace("journal", "").strip()
            if not content: return "Please provide text to log."
            return scribe.append_to_daily_note(content)
            
        # 2. SAVING (New Note)
        elif "save" in prompt_lower or "note" in prompt_lower:
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
            filename = f"AutoNote_{timestamp}" 
            content = params if len(params) > 5 else original_input
            return scribe.write_note(filename, content, folder="0 - Inbox")
            
        # 3. SEARCHING
        elif "search" in prompt_lower or "find" in prompt_lower:
            # Use the LLM extracted param for the query
            results = scribe.search_vault(params)
            if not results: return "No notes found."
            return f"üîç Found these notes:\n- " + "\n- ".join(results)
            
        # 4. MEDICAL (Placeholder for future Steward logic)
        elif "medical" in prompt_lower or "billing" in prompt_lower:
             return "üè• Medical Admin module is not yet implemented. (See Ops Department Plan)"
             
        return "Ops processed the request."

========================================
FILE: src/cobalt_agent/brain/engineering.py
========================================

"""
The Forge (Engineering Department)
Cobalt's Principal Systems Architect and Senior Software Engineer.
Responsible for reading, analyzing, and writing code.
"""
from loguru import logger
from cobalt_agent.llm import LLM
from cobalt_agent.tools.tool_manager import ToolManager


class EngineeringDepartment:
    """
    The Forge - Cobalt's codebase manipulation department.
    Handles code reading, analysis, and writing tasks.
    """
    
    def __init__(self):
        """Initialize the Engineering Department."""
        logger.info("üõ†Ô∏è The Forge (Engineering) Online")
        self.llm = LLM()
        self.tool_manager = ToolManager()
        
        self.system_prompt = """
        You are THE FORGE, Cobalt's Principal Systems Architect and Senior Software Engineer.
        Your job is to read, analyze, and write code.
        
        CRITICAL RULES:
        1. NEVER guess the contents of a file. ALWAYS use the `read_file` tool before suggesting edits.
        2. To modify a file, use the `write_file` tool. 
        3. The `write_file` tool requires a valid JSON string with `filepath` and `content`.
        4. When you use `write_file`, it will NOT execute immediately. It sends a Proposal to the user. You must inform the user that a proposal has been generated.
        5. Think step-by-step. First list the directory, then read the target file, then propose the change.
        """

    def run(self, user_message: str, chat_history: list = None) -> str:
        """
        Process an engineering request using ReAct loop.
        
        Args:
            user_message: The user's request for engineering work
            chat_history: Optional list of previous messages for context
            
        Returns:
            The final response after tool execution or max loops
        """
        logger.info("The Forge is analyzing an engineering request...")
        
        # Build the LLM prompt with tools
        messages = [{"role": "system", "content": self.system_prompt}]
        if chat_history:
            messages.extend(chat_history)
            
        messages.append({"role": "user", "content": user_message})
        
        # Execute the ReAct loop for engineering tools
        max_loops = 4
        for _ in range(max_loops):
            # Get response from LLM
            response = self.llm.generate_response(
                system_prompt=self.system_prompt,
                user_input=messages[-1]["content"],
                memory_context=messages[:-1] if len(messages) > 1 else None,
                search_context=""
            )
            
            logger.debug(f"Forge LLM Response: {response}")
            
            if "ACTION:" in response:
                # Extract tool name and query from ACTION line
                action_lines = [line for line in response.split('\n') if line.startswith('ACTION:')]
                if not action_lines:
                    return response
                    
                action_line = action_lines[0]
                command = action_line.replace('ACTION:', '').strip()
                
                # Parse tool name and arguments
                parts = command.split(' ', 1)
                tool_name = parts[0]
                args_dict = {}
                if len(parts) > 1:
                    # Try to parse the rest as JSON for tool args
                    try:
                        args_dict = eval(parts[1])
                        if not isinstance(args_dict, dict):
                            args_dict = {'query': parts[1]}
                    except:
                        args_dict = {'query': parts[1]}
                
                logger.debug(f"Forge executing tool: {tool_name}, args: {args_dict}")
                
                # Execute the tool
                result = self.tool_manager.execute_tool(tool_name, args_dict)
                
                # Format the result
                if result.success:
                    result_text = result.output
                else:
                    result_text = f"Error: {result.error}"
                
                # Append observation to history and loop
                messages.append({"role": "assistant", "content": response})
                messages.append({"role": "system", "content": f"[Observation: {result_text}]"})
            else:
                return response
                
        return "Error: ReAct loop maxed out. Please simplify the request."

========================================
FILE: src/cobalt_agent/brain/playbook.py
========================================

"""
The Playbook Registry
Loads trading strategies and parameters from strategies.yaml.
Executes the strategy logic against market data.
"""
import yaml
import json
from pathlib import Path
from typing import Dict, Any, Optional
from loguru import logger

# Import your strategies here
from cobalt_agent.brain.strategies.second_day_play import SecondDayPlay

class Playbook:
    """
    Manages the active trading strategies and their parameters.
    """
    
    def __init__(self, config_path: str = "configs/strategies.yaml"):
        self.config_data = self._load_config(config_path)
        self.strategies = {}
        self._initialize_strategies()
        
    def _load_config(self, path_str: str) -> Dict[str, Any]:
        """Loads the YAML config."""
        path = Path(path_str)
        # Handle running from root or inside module
        if not path.exists():
            path = Path(__file__).parent.parent.parent / path_str
            
        if not path.exists():
            logger.warning(f"‚ö†Ô∏è Strategy Config not found at {path}")
            return {}

        try:
            with open(path, "r") as f:
                data = yaml.safe_load(f)
                return data.get("strategies", {})
        except Exception as e:
            logger.error(f"‚ùå Failed to load Playbook Config: {e}")
            return {}

    def _initialize_strategies(self):
        """Hydrates the Strategy classes with their Configs."""
        # Map YAML keys to Python Classes
        class_map = {
            "second_day_play": SecondDayPlay,
            # Future: "gap_and_go": GapAndGo
        }

        for key, params in self.config_data.items():
            if key in class_map:
                try:
                    # Instantiate the class with its specific config
                    strategy_instance = class_map[key](params)
                    self.strategies[key] = strategy_instance
                    logger.debug(f"Loaded strategy: {key}")
                except Exception as e:
                    logger.error(f"Failed to init strategy {key}: {e}")

    def get_strategy(self, name: str):
        return self.strategies.get(name)

    def list_strategies(self) -> str:
        """Returns a formatted list of ACTIVE (Loaded) strategies."""
        if not self.strategies:
            return "No strategies loaded (Check strategies.yaml)."
        
        output = "üìú **Active Playbook:**\n"
        for key, strategy in self.strategies.items():
            cfg = strategy.config
            output += f"- **{cfg['name']}**: {cfg['direction']} ({cfg['time_window']['start']}-{cfg['time_window']['end']})\n"
        return output
        
    def run_all(self, market_data: Dict[str, Any]) -> str:
        """
        Runs ALL strategies against the incoming data.
        Returns a summary string of Scoring Profiles.
        """
        results = []
        
        for name, strategy in self.strategies.items():
            try:
                # Run the math
                profile = strategy.analyze(market_data)
                
                # Format the output for the CLI
                # We show the Name, Base Score, and Quality
                status = profile.get("status", "UNKNOWN")
                base_score = profile.get("base_score", 0)
                quality = profile.get("setup_quality", "N/A")
                reason = profile.get("reason", "")
                
                # Create a mini-report
                report = f"**{name}** [{status}]\n"
                report += f"   ‚Ä¢ Score: {base_score}/100 ({quality})\n"
                report += f"   ‚Ä¢ Logic: {reason}\n"
                
                # If there are HUD rules, mention them
                if profile.get("hud_rules"):
                    rules_count = len(profile["hud_rules"])
                    report += f"   ‚Ä¢ HUD Config: {rules_count} dynamic rules active\n"
                
                results.append(report)
                
            except Exception as e:
                logger.error(f"Error running {name}: {e}")
                results.append(f"**{name}**: Error ({e})")
                
        if not results:
            return "No active strategies found."
            
        return "\n".join(results)

========================================
FILE: src/cobalt_agent/brain/strategies/second_day_play.py
========================================

"""
Second Day Play - Strategy Logic
Author: Cobalt AI
Context: Phase 3 (Tactical)

Refactored to pull scoring rules and thresholds dynamically from strategies.yaml.
"""
from datetime import datetime

class SecondDayPlay:
    def __init__(self, config: dict = None):
        # Fallback to empty dict if None, but usually this comes from strategies.yaml
        self.config = config or {}
        
        # Load Parameters from Config (or defaults if missing)
        self.params = self.config.get("parameters", {})
        self.scoring = self.config.get("scoring", {})
        
        self.name = self.config.get("name", "SecondDayPlay")
        self.version = "1.1"

    def analyze(self, ticker: str, market_data: dict) -> dict:
        """
        Takes raw market data and returns the Scoring Profile (JSON).
        """
        
        # 1. UNPACK DATA
        y_close = market_data.get('yesterday_close', 0)
        y_vol = market_data.get('yesterday_volume', 0)
        avg_vol = market_data.get('average_volume', 1) 
        today_open = market_data.get('today_open', 0)
        pm_high = market_data.get('pre_market_high', 0)
        
        # 2. VALIDATION (The Gatekeeper)
        y_rvol = y_vol / avg_vol if avg_vol else 0
        
        # Rule: Min RVOL (from config)
        min_rvol = self.params.get("min_rvol", 1.5)
        if y_rvol < min_rvol:
            return {
                "ticker": ticker,
                "strategy": self.name,
                "status": "REJECTED",
                "reason": f"Low Relative Volume Yesterday (RVOL: {y_rvol:.2f} < {min_rvol})"
            }

        # Rule: Gap Down Rejection
        if today_open < (y_close * 0.98):
             return {
                "ticker": ticker,
                "strategy": self.name,
                "status": "REJECTED",
                "reason": "Gap Down - Momentum Lost"
            }

        # 3. CALCULATE ZONES
        entry_price = pm_high + 0.05
        stop_loss = y_close - 0.20
        risk = entry_price - stop_loss
        target = entry_price + (risk * 2)

        # 4. SCORING ENGINE (Dynamic)
        # Instead of hardcoding "50" or "+10", we look them up.
        current_score = self.scoring.get("base_score", 50)
        
        # RVOL Modifiers
        high_rvol_thresh = self.scoring.get("high_rvol_threshold", 3.0)
        
        if y_rvol >= high_rvol_thresh:
            current_score += self.scoring.get("high_rvol_points", 15)
        elif y_rvol >= min_rvol:
            current_score += self.scoring.get("base_rvol_points", 10)
            
        # Gap Modifiers
        if today_open > y_close:
            current_score += self.scoring.get("gap_up_points", 10)
        
        # 5. CONSTRUCT THE MATH PACKAGE
        return {
            "timestamp": datetime.now().isoformat(),
            "ticker": ticker,
            "strategy": self.name,
            "status": "ACTIVE_WATCH",
            "direction": "LONG",
            "zones": {
                "entry": round(entry_price, 2),
                "stop": round(stop_loss, 2),
                "target": round(target, 2),
                "risk_per_share": round(risk, 2)
            },
            "scoring_engine": {
                "base_score": current_score,
                # Pass instructions to Ion (Windows)
                "modifiers": {
                    "live_rvol_multiplier": self.scoring.get("live_rvol_multiplier", 5.0),
                    "spy_correlation_weight": self.scoring.get("spy_correlation_weight", 10.0),
                    "resistance_penalty": self.scoring.get("resistance_penalty", -20.0),
                    "time_decay_per_min": self.scoring.get("time_decay_per_min", -0.5)
                }
            },
            "abort_conditions": [
                f"price < {stop_loss}",
                "volume_run_rate < 50%" 
            ]
        }

========================================
FILE: src/cobalt_agent/brain/strategy.py
========================================

"""
The Strategy Interface (The Contract)
All trading strategies must inherit from this class.
This enforces a standard structure for the Backtester and Live Engine.
"""
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from datetime import datetime

class Strategy(ABC):
    """
    Abstract Base Class for all Cobalt Strategies.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize with specific parameters from strategies.yaml.
        """
        self.config = config
        self.name = config.get("name", "Unknown Strategy")

    @abstractmethod
    def analyze(self, market_data: Any) -> Dict[str, Any]:
        """
        The Core Logic.
        Args:
            market_data: A clean object containing Price, Volume, VWAP, etc.
        Returns:
            Dict containing:
            - 'signal': 'BUY', 'SELL', or 'WAIT'
            - 'confidence': 0.0 to 1.0 (The 'T-Shirt Size')
            - 'stop_loss': Price level
            - 'target': Price level
            - 'reason': Text explanation
        """
        pass

    def check_time_window(self, current_time_str: str = None) -> bool:
        """
        Helper: Checks if we are allowed to trade right now.
        """
        if not current_time_str:
            current_time_str = datetime.now().strftime("%H:%M")
            
        window = self.config.get("time_window", {})
        start = window.get("start", "00:00")
        end = window.get("end", "23:59")
        
        # Simple string comparison works for HH:MM format (24h)
        return start <= current_time_str <= end

========================================
FILE: src/cobalt_agent/brain/tactical.py
========================================

"""
The Strategos Agent (Tactical Department Head)
Responsible for:
1. Market Data Retrieval (FinanceTool)
2. Strategy Execution (Playbook)
"""
from typing import Optional
from loguru import logger
from cobalt_agent.tools.finance import FinanceTool
from cobalt_agent.brain.playbook import Playbook

class Strategos:
    """
    The Quantitative Trading Engine.
    Routes raw data requests or executes full strategy scans.
    """
    
    def __init__(self):
        self.finance = FinanceTool()
        self.playbook = Playbook() 
        logger.info(f"‚öîÔ∏è Strategos Online | Strategies Loaded: {len(self.playbook.strategies)}")

    def run(self, task: str) -> str:
        """
        The main entry point for the Tactical Department.
        
        Args:
            task: The ticker symbol (e.g., 'NVDA') or a specific command.
        """
        # 1. Clean the input (extract ticker)
        ticker = task.split()[0].strip(".,!?").upper()
        
        logger.info(f"Strategos analyzing: {ticker}")
        
        try:
            # CHECK: If user asks for "Strategies", show the menu
            if "STRATEGY" in ticker or "PLAYBOOK" in ticker:
                return self.playbook.list_strategies()
            
            # STEP 1: Get Raw Market Data (The Finance Tool)
            market_data_obj = self.finance.run(ticker)
            
            # STEP 2: Convert to Dictionary
            # The Strategy Engine needs a clean dict, not a Pydantic model
            if hasattr(market_data_obj, 'dict'):
                market_data_dict = market_data_obj.dict()
            elif hasattr(market_data_obj, 'model_dump'):
                market_data_dict = market_data_obj.model_dump()
            else:
                market_data_dict = market_data_obj.__dict__

            # STEP 3: RUN THE PLAYBOOK ENGINE
            # This loops through all active strategies and calculates scores
            strategy_output = self.playbook.run_all(market_data_dict)
            
            # STEP 4: Return Combined Intelligence
            return f"{market_data_obj}\n\n[‚öîÔ∏è Strategy Scan]\n{strategy_output}"
            
        except Exception as e:
            logger.error(f"Strategos failed on {ticker}: {e}")
            return f"Tactical Error: {e}"

========================================
FILE: src/cobalt_agent/config.py
========================================

"""
Configuration Management for Cobalt Agent
Pydantic Settings-based configuration with environment variable overrides.

Loading Priority (highest to lowest):
1. Environment Variables (via .env file and OS env)
2. YAML Configuration Files (configs/*.yaml)

Environment Variable Mapping:
- Simple fields: UPPER_CASE converts to lower_case_with_underscores
- Nested fields: POSTGRES_HOST maps to postgres.host via env_nested_delimiter="_"
"""

import json
import os
from pathlib import Path
from typing import Any, Optional

import yaml
from dotenv import load_dotenv
from loguru import logger
from pydantic import BaseModel, Field, ConfigDict
from pydantic_settings import BaseSettings
from pydantic_settings.sources import PydanticBaseSettingsSource

from cobalt_agent.security.vault import VaultManager

# Load environment variables from .env file (explicit path)
# Get the directory where config.py is located
config_dir = Path(__file__).parent
# Look for .env in the project root (parent of src/)
env_path = config_dir.parent.parent / ".env"
if env_path.exists():
    load_dotenv(env_path)
else:
    # Fallback to current working directory
    load_dotenv()  # Fallback to default behavior (looks in cwd)


# --- 1. Modular Schema Definitions ---


class MomentumRules(BaseModel):
    """Schema for momentum trading rules."""
    rvol_alert_threshold: float
    rvol_strong_threshold: float


class RSIRules(BaseModel):
    """Schema for RSI trading rules."""
    period: int
    overbought: int
    oversold: int


class ATRRules(BaseModel):
    """Schema for ATR trading rules."""
    period: int
    expansion_multiplier: float
    extension_multiplier: float


class TradingRules(BaseModel):
    """
    Schema for 'trading_rules' section.
    We are strict here to ensure trading logic is type-safe.
    """
    momentum: Optional[MomentumRules] = None
    moving_averages: Optional[dict] = None
    rsi: Optional[RSIRules] = None
    atr: Optional[ATRRules] = None


class SystemConfig(BaseModel):
    """Schema for system-level configuration."""
    debug_mode: bool = False
    version: str = "0.1.0"
    obsidian_vault_path: str = "/default/obsidian/vault/path"


class LLMConfig(BaseModel):
    """Schema for LLM configuration."""
    model_name: str = "gemini/gemini-1.5-pro"
    api_key: Optional[str] = None


class PersonaConfig(BaseModel):
    """Schema for agent persona configuration."""
    name: str = "Cobalt"
    roles: list[str] = Field(default_factory=list)
    skills: list[str] = Field(default_factory=list)
    tone: list[str] = Field(default_factory=list)
    directives: list[str] = Field(default_factory=list)


class NodeConfig(BaseModel):
    """Schema for network node configuration."""
    role: str
    ip: str = "127.0.0.1"
    port: int = 8080
    protocol: str = "http"


class NetworkConfig(BaseModel):
    """Schema for network topology configuration."""
    nodes: dict[str, NodeConfig]


class PostgresConfig(BaseModel):
    """Schema for PostgreSQL database configuration."""
    host: str = "localhost"
    port: int = 5432
    db: str = "cobalt_memory"
    user: str = "postgres"
    password: Optional[str] = None


class MattermostConfig(BaseModel):
    """Schema for Mattermost communication configuration."""
    url: Optional[str] = None
    token: Optional[str] = None
    scheme: str = "http"
    port: int = 8065
    approval_channel: str = "cobalt-approvals"
    approval_team: str = "cobalt-team"


class VaultConfig(BaseModel):
    """Schema for vault configuration."""
    path: str = "data/.cobalt_vault"
    enabled: bool = True


# --- 2. Main Configuration Class ---


class CobaltSettings(BaseSettings):
    """
    Pydantic Settings class that loads YAML config and allows ENV overrides.
    
    Environment Variable Naming Convention:
    - Nested keys: POSTGRES_HOST -> postgres.host (using env_nested_delimiter="_")
    - The env_nested_delimiter setting allows Pydantic to automatically
      map POSTGRES_HOST to postgres.host via the "_" delimiter.
    """
    model_config = ConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        extra="allow",  # Allow extra fields not defined in schema
        env_prefix="",  # No prefix for environment variables
        env_nested_delimiter="_",  # Use underscore to separate nested keys
    )

    # Core Sections with defaults from YAML
    system: SystemConfig = Field(default_factory=SystemConfig)
    llm: LLMConfig = Field(default_factory=LLMConfig)
    persona: PersonaConfig = Field(default_factory=PersonaConfig)
    
    # Optional Known Sections
    trading_rules: Optional[TradingRules] = None
    active_profile: Optional[dict[str, str]] = None
    models: Optional[dict[str, Any]] = None
    network: Optional[NetworkConfig] = None
    postgres: PostgresConfig = Field(default_factory=PostgresConfig)
    mattermost: MattermostConfig = Field(default_factory=MattermostConfig)
    vault: Optional[VaultConfig] = Field(default_factory=VaultConfig)

    @classmethod
    def settings_customise_sources(
        cls,
        settings_cls: type[BaseSettings],
        init_settings: PydanticBaseSettingsSource,
        env_settings: PydanticBaseSettingsSource,
        dotenv_settings: PydanticBaseSettingsSource,
        file_secret_settings: PydanticBaseSettingsSource,
    ) -> tuple[PydanticBaseSettingsSource, ...]:
        """
        Custom source order: ENV variables override YAML values.
        Source order (highest to lowest priority):
        1. ENV settings (including .env file)
        2. File secret settings
        3. Init settings (YAML data passed as kwargs)
        """
        return (env_settings, dotenv_settings, file_secret_settings, init_settings)


# --- 3. Helper Functions ---


def _load_yaml_config(yaml_path: Path) -> dict[str, Any]:
    """Load and return YAML configuration as dictionary."""
    if not yaml_path.exists():
        logger.warning(f"Config file not found: {yaml_path}")
        return {}
    
    try:
        with open(yaml_path, "r") as f:
            return yaml.safe_load(f) or {}
    except Exception as e:
        logger.error(f"Failed to load {yaml_path}: {e}")
        return {}


def parse_json_credentials(json_string: str) -> dict[str, Any]:
    """
    Parse JSON credentials string into a dictionary.
    
    Handles grouped credentials like URLs and Tokens together.
    Example input: '{"url": "https://api.example.com", "token": "secret123"}'
    
    Args:
        json_string: A JSON-formatted string containing credentials.
        
    Returns:
        A dictionary with the parsed credentials.
        
    Raises:
        json.JSONDecodeError: If the input is not valid JSON.
    """
    try:
        credentials = json.loads(json_string)
        if not isinstance(credentials, dict):
            logger.warning("JSON credentials parsed to non-dict type, wrapping in dict")
            credentials = {"data": credentials}
        return credentials
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse JSON credentials: {e}")
        raise


def _deep_merge(base: dict[str, Any], update: dict[str, Any]) -> dict[str, Any]:
    """Recursively merge dictionary 'update' into 'base'."""
    result = base.copy()
    
    for key, value in update.items():
        if isinstance(value, dict) and key in result and isinstance(result[key], dict):
            result[key] = _deep_merge(result[key], value)
        else:
            result[key] = value
    
    return result


def get_current_node_role() -> Optional[str]:
    """
    Determine the role of the current node based on the 'network' section in config.yaml.
    Returns the role if found, otherwise returns None.
    """
    try:
        config_dir = Path.cwd() / "configs"
        if not config_dir.exists():
            config_dir = Path(__file__).parent.parent / "configs"
        
        with open(config_dir / "config.yaml", "r") as f:
            config_data = yaml.safe_load(f) or {}
        
        network_config = config_data.get('network', {})
        nodes = network_config.get('nodes', {})
        
        import socket
        hostname = socket.gethostname()
        
        for node, details in nodes.items():
            if 'ip' in details and details['ip'] == socket.gethostbyname(hostname):
                return details.get('role')
    
    except Exception as e:
        logger.error(f"Failed to determine current node role: {e}")
    
    return None


class Config:
    """Singleton configuration manager with integrated VaultManager."""
    _instance = None
    _vault_manager: Optional[VaultManager] = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(Config, cls).__new__(cls)
            cls._instance._config = load_config()
        return cls._instance

    @staticmethod
    def get_instance():
        """Get the singleton configuration instance."""
        if Config._instance is None:
            Config._instance = Config()
        return Config._instance

    @property
    def vault_manager(self) -> Optional[VaultManager]:
        """Get or create the VaultManager instance."""
        if Config._vault_manager is None:
            config = self._config
            vault_config = config.vault if config.vault else None
            vault_path = vault_config.path if vault_config else "data/.cobalt_vault"
            Config._vault_manager = VaultManager(vault_path)
        return Config._vault_manager

    def load(self) -> CobaltSettings:
        """Load and return the configuration."""
        return self._config

    def unlock_vault(self, master_key: str) -> bool:
        """
        Unlock the vault and inject secrets into the runtime configuration.
        
        Args:
            master_key: The AES-256 Fernet key to decrypt the vault.
            
        Returns:
            True if vault was successfully unlocked, False otherwise.
        """
        vault_mgr = self.vault_manager
        if vault_mgr is None:
            logger.error("Failed to unlock vault: VaultManager not initialized")
            return False
            
        success = vault_mgr.unlock(master_key)
        if success:
            logger.info("üîê Vault unlocked successfully. Secrets injected into runtime configuration.")
        return success

    def lock_vault(self) -> None:
        """Lock the vault and wipe secrets from memory."""
        vault_mgr = self.vault_manager
        if vault_mgr is not None:
            vault_mgr.lock()
            Config._vault_manager = None
            logger.info("üîí Vault locked. Secrets wiped from RAM.")

    def inject_secrets(self, config: CobaltSettings) -> CobaltSettings:
        """
        Inject secrets from the vault into the runtime configuration.
        This replaces sensitive fields (like API keys and tokens) with values from the vault.
        
        Args:
            config: The configuration object to inject secrets into.
            
        Returns:
            The configuration object with secrets injected from the vault.
        """
        vault_mgr = self.vault_manager
        if vault_mgr is None:
            logger.warning("Vault is locked or not initialized. Skipping secret injection.")
            return config
            
        if not vault_mgr._is_unlocked:
            logger.warning("Vault is locked. Cannot inject secrets.")
            return config

        # Create a mutable copy of the configuration
        config_data = config.model_dump()
        
        # Inject LLM API keys from vault
        llm_config = config_data.get('llm', {})
        vault_keys = vault_mgr.list_secrets()
        
        # Check for common API key names in vault
        llm_key_mapping = {
            'openai_api_key': 'api_key',
            'anthropic_api_key': 'api_key',
            'gemini_api_key': 'api_key',
            'openrouter_api_key': 'api_key',
        }
        
        for vault_key, config_field in llm_key_mapping.items():
            if vault_key in vault_keys:
                secret_value = vault_mgr.get_secret(vault_key)
                if secret_value:
                    llm_config[config_field] = secret_value
                    logger.debug(f"Injected {vault_key} into LLM config")
        
        # Inject Mattermost credentials (URL and Token together)
        mattermost_config = config_data.get('mattermost', {})
        if 'mattermost_url' in vault_keys and 'mattermost_token' in vault_keys:
            vault_mgr.get_secret('mattermost_url') and None  # Access to verify
            mattermost_url = vault_mgr.get_secret('mattermost_url')
            mattermost_token = vault_mgr.get_secret('mattermost_token')
            if mattermost_url and mattermost_token:
                mattermost_config['url'] = mattermost_url
                mattermost_config['token'] = mattermost_token
                logger.debug("Injected Mattermost URL and token from vault")
        
        # Update the config with injected secrets
        config_data['llm'] = llm_config
        config_data['mattermost'] = mattermost_config
        
        # Create new config object with injected secrets
        return CobaltSettings(**config_data)


def load_config(config_dir: Optional[Path | str] = None) -> CobaltSettings:
    """
    Load configuration from YAML files and merge with environment variables.
    
    Priority (highest to lowest):
    1. Environment variables (via Pydantic's env_nested_delimiter)
    2. YAML files in configs directory
    3. Default values
    
    Args:
        config_dir: Optional path to configuration directory. Defaults to 'configs/'.
    
    Returns:
        CobaltSettings: Loaded configuration object.
    """
    # 1. Resolve Directory
    if config_dir is None:
        candidates = [
            Path.cwd() / "configs",
            Path(__file__).parent.parent / "configs"
        ]
        config_dir = next((p for p in candidates if p.exists()), None)

    if not config_dir:
        logger.warning("Config directory 'configs/' not found. Using defaults.")
        return CobaltSettings()

    config_dir = Path(config_dir)
    logger.info(f"Loading configuration from: {config_dir}")

    # 2. Scan for YAML and Load
    yaml_files = sorted(list(config_dir.glob("*.yaml")) + list(config_dir.glob("*.yml")))
    
    if not yaml_files:
        logger.warning("No YAML files found in configs/. Using defaults.")
        return CobaltSettings()

    # 3. Merge All YAML Files
    master_data = {}
    
    for file_path in yaml_files:
        try:
            file_data = _load_yaml_config(file_path)
            
            if not file_data:
                continue
                
            keys = list(file_data.keys())
            logger.debug(f"Loaded {file_path.name} -> Keys: {keys}")
            
            master_data = _deep_merge(master_data, file_data)
            
        except Exception as e:
            logger.error(f"Failed to load {file_path.name}: {e}")

    # --- VAULT INTEGRATION (NEW) ---
    master_key = os.getenv("COBALT_MASTER_KEY")
    if master_key:
        logger.info("üîë COBALT_MASTER_KEY detected. Unlocking secure vault...")
        vault = VaultManager()
        if vault.unlock(master_key):
            # Ensure base sections exist
            if 'keys' not in master_data: master_data['keys'] = {}
            if 'mattermost' not in master_data: master_data['mattermost'] = {}

            for key_name in vault.list_secrets():
                secret_val = vault.get_secret(key_name)
                
                # Skip None values
                if secret_val is None:
                    continue
                
                # Try to parse as JSON for grouped credentials
                try:
                    parsed_val = json.loads(secret_val)
                except (ValueError, TypeError):
                    parsed_val = secret_val # Fallback to flat string
                
                # Routing logic
                if key_name == "MATTERMOST_CREDS" and isinstance(parsed_val, dict):
                    master_data['mattermost'].update(parsed_val)
                else:
                    # Default flat keys (OpenAI, Gemini, etc.)
                    master_data['keys'][key_name] = parsed_val
                    # Inject into runtime environment for external libraries (LiteLLM)
                    if isinstance(parsed_val, str):
                        os.environ[key_name] = parsed_val
                    
            vault.lock()
            logger.info("üîí Vault secrets loaded into runtime RAM and vault locked.")
        else:
            logger.error("Failed to unlock vault with provided Master Key!")
    else:
        logger.warning("‚ö†Ô∏è No COBALT_MASTER_KEY found. Running in degraded/unsecure mode.")
    # -------------------------------

    # 4. Create Pydantic Settings Object
    # Pydantic will automatically handle ENV overrides via env_nested_delimiter="_"
    try:
        logger.debug(f"Final merged configuration: {master_data}")
        return CobaltSettings(**master_data)
    except Exception as e:
        logger.error(f"Configuration Validation Error: {e}")
        return CobaltSettings()


# Convenience function for direct access
def get_config() -> CobaltSettings:
    """Get the singleton configuration instance."""
    return Config.get_instance().load()

========================================
FILE: src/cobalt_agent/core/proposals.py
========================================

from typing import Dict, Any, Optional, Callable
from pydantic import BaseModel, Field
import uuid
from datetime import datetime
import threading
import time
import re
from loguru import logger
from typing import TYPE_CHECKING

from cobalt_agent.config import get_config

if TYPE_CHECKING:
    from cobalt_agent.interfaces.mattermost import MattermostInterface

# --- PROPOSAL MODEL ---
class Proposal(BaseModel):
    """Standardized ticket for high-stakes AI actions."""
    task_id: str = Field(default_factory=lambda: str(uuid.uuid4())[:8])
    action: str = Field(description="The specific command or operation to be executed.")
    justification: str = Field(description="The agent's reasoning for why this action is necessary.")
    risk_assessment: str = Field(description="A summary of potential negative impacts (e.g., data loss, capital risk).")
    parameters: Dict[str, Any] = Field(default_factory=dict, description="Technical metadata required for execution.")
    timestamp: datetime = Field(default_factory=datetime.now)
    approved: bool = False
    approval_channel: Optional[str] = None
    approval_message_id: Optional[str] = None

    def format_for_mattermost(self) -> str:
        return (
            f"### üõ°Ô∏è ACTION PROPOSAL [{self.task_id}]\n"
            f"**Action:** `{self.action}`\n\n"
            f"**Justification:** {self.justification}\n"
            f"**Risk:** {self.risk_assessment}\n\n"
            f"--- \n"
            f"‚ö†Ô∏è *This action is paused per the Prime Directive. Reply with 'Approve {self.task_id}' to proceed.*"
        )


# --- PROPOSAL ENGINE ---
class ProposalEngine:
    """
    The Proposal Engine enforces the Prime Directive by requiring human approval
    before executing high-stakes actions. It creates proposals, sends them to
    Mattermost for approval, and only executes approved actions.
    """
    
    def __init__(self):
        self.config = get_config()
        self.approval_channel = self.config.mattermost.approval_channel
        self.approval_team = self.config.mattermost.approval_team
        self.mattermost: Optional[Any] = None
        self.approved_proposals: Dict[str, Proposal] = {}
        self.pending_proposals: Dict[str, Proposal] = {}
        self._approval_callback: Optional[Callable[[Proposal], None]] = None
        self._monitoring = False
        self._monitor_thread: Optional[threading.Thread] = None
        
        logger.info(f"Proposal Engine initialized (Channel: {self.approval_channel})")
    
    def connect_mattermost(self) -> bool:
        """Connect to Mattermost for approval workflow."""
        if self.mattermost:
            return True
        
        # Lazy import to avoid circular dependency
        from cobalt_agent.interfaces.mattermost import MattermostInterface
        
        self.mattermost = MattermostInterface()
        connected = self.mattermost.connect()
        
        if connected:
            # Attach brain for message routing
            self.mattermost.brain = self._get_brain_for_approval_routing()
            logger.info("Proposal Engine: Mattermost connection established")
        
        return connected
    
    def _get_brain_for_approval_routing(self) -> Any:
        """
        Get the brain instance for approval routing.
        This is a stub - the actual brain should be passed in or connected externally.
        """
        # For now, return None - the brain will be attached by the main agent
        return None
    
    def create_proposal(
        self,
        action: str,
        justification: str,
        risk_assessment: str,
        parameters: Optional[Dict[str, Any]] = None
    ) -> Proposal:
        """
        Create a new proposal for a high-stakes action.
        
        Args:
            action: The specific command or operation to be executed
            justification: The agent's reasoning for why this action is necessary
            risk_assessment: A summary of potential negative impacts
            parameters: Technical metadata required for execution
            
        Returns:
            The created Proposal object
        """
        proposal = Proposal(
            action=action,
            justification=justification,
            risk_assessment=risk_assessment,
            parameters=parameters or {}
        )
        
        self.pending_proposals[proposal.task_id] = proposal
        logger.info(f"Proposal created: [{proposal.task_id}] {action[:50]}...")
        
        return proposal
    
    def send_proposal(self, proposal: Proposal) -> bool:
        """
        Send a proposal to Mattermost for approval.
        
        Args:
            proposal: The Proposal object to send
            
        Returns:
            True if proposal was sent successfully
        """
        if not self.mattermost:
            logger.error("Mattermost not connected. Cannot send proposal.")
            return False
        
        if not self.approval_channel:
            logger.error("Approval channel not configured.")
            return False
        
        message = proposal.format_for_mattermost()
        
        # Lazy import to avoid circular dependency
        from cobalt_agent.interfaces.mattermost import MattermostInterface
        
        # Get team ID first
        try:
            teams = self.mattermost.driver.teams.get_team_by_name(self.approval_team)
            if not teams:
                logger.error(f"Approval team not found: {self.approval_team}")
                return False
            
            team_id = teams["id"]
            
            # Get channel ID using team_id as parameter
            channel = self.mattermost.driver.channels.get_channel_by_name(team_id, self.approval_channel)
            if not channel:
                logger.error(f"Approval channel not found: {self.approval_channel} in team {self.approval_team}")
                return False
            
            channel_id = channel["id"]
            
            # Send the proposal message
            post = self.mattermost.driver.posts.create_post(
                options={
                    "channel_id": channel_id,
                    "message": message
                }
            )
            
            if post and "id" in post:
                proposal.approval_message_id = post["id"]
                proposal.approval_channel = channel_id
                logger.info(f"Proposal sent to Mattermost: [{proposal.task_id}]")
                return True
            else:
                logger.error("Failed to send proposal to Mattermost")
                return False
                
        except Exception as e:
            logger.error(f"Failed to send proposal: {e}")
            return False
    
    def handle_approval_response(self, message: str, channel_id: str) -> Optional[Proposal]:
        """
        Check if a message is an approval response for a pending proposal.
        
        Args:
            message: The message text from Mattermost
            channel_id: The channel ID where the message was posted
            
        Returns:
            The approved Proposal if this is a valid approval, None otherwise
        """
        # Check if this is an approval message
        approval_pattern = r"approve\s+(\w{8})"
        match = re.search(approval_pattern, message.lower())
        
        if not match:
            return None
        
        task_id = match.group(1)
        
        # Check if this is in the approval channel
        if channel_id != self.approval_channel:
            return None
        
        # Look up the pending proposal
        if task_id not in self.pending_proposals:
            logger.warning(f"Approval for unknown task_id: {task_id}")
            return None
        
        proposal = self.pending_proposals.pop(task_id)
        proposal.approved = True
        self.approved_proposals[task_id] = proposal
        
        logger.info(f"Proposal approved: [{task_id}]")
        
        return proposal
    
    def wait_for_approval(self, proposal: Proposal, timeout: int = 3600) -> bool:
        """
        Wait for a proposal to be approved (with polling).
        
        Args:
            proposal: The Proposal to wait for
            timeout: Maximum time to wait in seconds (default 1 hour)
            
        Returns:
            True if approved, False if timed out
        """
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            if proposal.task_id in self.approved_proposals:
                return True
            
            time.sleep(5)  # Check every 5 seconds
        
        # Remove from pending if timeout
        if proposal.task_id in self.pending_proposals:
            del self.pending_proposals[proposal.task_id]
        
        logger.warning(f"Approval timeout for proposal: [{proposal.task_id}]")
        return False
    
    def execute_approved(self, proposal: Proposal) -> bool:
        """
        Execute an approved proposal's action.
        
        Args:
            proposal: The approved Proposal to execute
            
        Returns:
            True if execution succeeded
        """
        if not proposal.approved:
            logger.error(f"Cannot execute unapproved proposal: [{proposal.task_id}]")
            return False
        
        try:
            # Execute the action (this would be implemented by the caller)
            action = proposal.action
            
            # For now, just log the action
            logger.info(f"Executing approved action: {action}")
            
            if self._approval_callback:
                self._approval_callback(proposal)
            
            return True
        except Exception as e:
            logger.error(f"Failed to execute approved action [{proposal.task_id}]: {e}")
            return False
    
    def set_approval_callback(self, callback: Callable[[Proposal], None]) -> None:
        """
        Set a callback function to be called when a proposal is approved.
        
        Args:
            callback: Function that takes a Proposal and returns None
        """
        self._approval_callback = callback
        logger.info("Approval callback set")
    
    def start_monitoring(self) -> None:
        """Start monitoring for approval responses in the background."""
        if self._monitoring:
            logger.warning("Monitoring already running")
            return
        
        self._monitoring = True
        self._monitor_thread = threading.Thread(target=self._monitor_approval_channel, daemon=True)
        self._monitor_thread.start()
        logger.info("Proposal Engine monitoring started")
    
    def _monitor_approval_channel(self) -> None:
        """Background thread to monitor the approval channel for approval responses."""
        # This would be implemented with the Mattermost WebSocket listener
        # For now, just a placeholder
        logger.info("Approval channel monitoring started (WebSocket listener attached to MattermostInterface)")
    
    def stop_monitoring(self) -> None:
        """Stop monitoring for approval responses."""
        self._monitoring = False
        if self._monitor_thread:
            self._monitor_thread.join(timeout=1)
        logger.info("Proposal Engine monitoring stopped")


# --- CONVENIENCE FUNCTION ---
def create_and_send_proposal(
    action: str,
    justification: str,
    risk_assessment: str,
    parameters: Optional[Dict[str, Any]] = None
) -> Optional[Proposal]:
    """
    Convenience function to create and send a proposal.
    
    Args:
        action: The specific command or operation to be executed
        justification: The agent's reasoning for why this action is necessary
        risk_assessment: A summary of potential negative impacts
        parameters: Technical metadata required for execution
        
    Returns:
        The created and sent Proposal if successful, None otherwise
    """
    engine = ProposalEngine()
    
    # Connect to Mattermost
    if not engine.connect_mattermost():
        logger.error("Failed to connect to Mattermost")
        return None
    
    # Create the proposal
    proposal = engine.create_proposal(
        action=action,
        justification=justification,
        risk_assessment=risk_assessment,
        parameters=parameters
    )
    
    # Send to Mattermost
    if not engine.send_proposal(proposal):
        logger.error("Failed to send proposal")
        return None
    
    return proposal

========================================
FILE: src/cobalt_agent/core/scheduler.py
========================================

"""
Scheduler Module
Gives Cobalt a sense of time and allows for autonomous tasks.
"""
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from loguru import logger
from datetime import datetime

class AgentScheduler:
    """
    Manages timed tasks for the agent.
    """
    
    def __init__(self, cortex):
        self.scheduler = BackgroundScheduler()
        self.cortex = cortex # We need access to the Brain to do things!
        self.running = False

    def start(self):
        """Start the internal clock."""
        if not self.running:
            self.scheduler.start()
            self.running = True
            logger.info("Scheduler started (Time Awareness Online)")
            
            # Example: Add a simple heartbeat job (runs every 30 mins)
            # self.add_job(self._heartbeat, "interval", minutes=30)

    def stop(self):
        """Stop the clock."""
        if self.running:
            self.scheduler.shutdown()
            self.running = False
            logger.info("Scheduler stopped")

    def add_job(self, func, trigger_type, **kwargs):
        """
        Add a new task.
        trigger_type: 'cron', 'interval', or 'date'
        kwargs: e.g. hour=9, minute=30 (for cron) or minutes=15 (for interval)
        """
        try:
            self.scheduler.add_job(func, trigger_type, **kwargs)
            logger.info(f"Scheduled task added: {func.__name__} ({trigger_type})")
        except Exception as e:
            logger.error(f"Failed to schedule task: {e}")

    def _heartbeat(self):
        """A simple task to prove it's working."""
        logger.info(f"‚ô• System Heartbeat: {datetime.now()}")

========================================
FILE: src/cobalt_agent/interfaces/cli.py
========================================

"""
Cobalt Agent - Interactive CLI Interface
Refactored: Centralized Routing + RAG (Retrieval Augmented Generation)
"""

from rich.console import Console
from rich.prompt import Prompt
from loguru import logger
from rich.markdown import Markdown

# Type hinting
from typing import Optional, TYPE_CHECKING, Any, List
if TYPE_CHECKING:
    from cobalt_agent.brain.cortex import Cortex

from cobalt_agent.tools.tool_manager import ToolManager

class CLI:
    """Interactive command-line interface for Cobalt Agent."""
    
    def __init__(self, memory_system, llm, system_prompt, tool_manager, cortex=None):
        self.console = Console()
        self.tool_manager = tool_manager
        self.memory = memory_system
        self.llm = llm
        self.system_prompt = system_prompt
        self.cortex = cortex 

        logger.info("CLI initialized with Brain connected")
    
    def start(self):
        """Start the interactive CLI loop."""
        self.console.print("\n[bold green]ü§ñ Cobalt Agent Interface[/bold green]")
        self.console.print(f"[dim]Model: {self.llm.model_name}[/dim]")
        self.console.print("[dim]Type 'exit' or 'quit' to leave[/dim]\n")
        
        while True:
            try:
                user_input = Prompt.ask("[bold cyan]Cobalt >[/]")
                user_input = user_input.strip()
                
                if not user_input: continue

                if user_input.lower() in ['exit', 'quit']:
                    self.console.print("[yellow]Shutting down Cobalt Agent...[/yellow]")
                    break
                
                # Save to Short-Term Memory immediately
                self.memory.add_log(user_input, source="User")

                # 1. CORTEX ROUTING (The Primary Brain)
                handled_by_cortex = False
                if self.cortex:
                    # Cortex decides: Tactical? Intel? Ops? Or None (General Chat)?
                    specialist_response = self.cortex.route(user_input)
                    
                    if specialist_response:
                        # Cortex returned a result (e.g., Raw Data or Note Status)
                        self.console.print(f"\n[bold purple]ü§ñ Cortex:[/bold purple]")
                        self.console.print(Markdown(specialist_response))
                        self.console.print()
                        
                        # Crucial: Log this to memory so the LLM "sees" it for follow-up analysis
                        self.memory.add_log(specialist_response, source="System")
                        handled_by_cortex = True
                
                # If Cortex handled it, we loop back to let user ask follow-up (e.g. "Analyze this")
                if handled_by_cortex: continue 
      	      	
                # 2. AUTONOMOUS CHAT (The Fallback / Analyst)
                # Handles "Analyze that", "Hi", or generic questions Cortex didn't claim.
                self._handle_chat(user_input)
                    
            except KeyboardInterrupt:
                self.console.print("\n[yellow]Interrupted. Shutting down...[/yellow]")
                break
            except Exception as e:
                logger.error(f"CLI error: {str(e)}", exc_info=True)
                self.console.print(f"[red]Error: {str(e)}[/red]")
    
    def _format_tool_output(self, output: Any) -> str:
        """Helper to convert Pydantic models/Lists to clean strings."""
        if isinstance(output, list):
            return "\n".join([str(item) for item in output])
        return str(output)

    def _retrieve_long_term_memory(self, query: str) -> str:
        """
        RAG HOOK: Searches the Postgres DB for relevant past context.
        """
        if not hasattr(self.memory, "search"):
            return ""

        try:
            self.console.print("[dim]üß† Recalling...[/dim]")
            
            # 1. Fetch MORE (10 instead of 3) to break through the "Echo Chamber"
            results = self.memory.search(query, limit=10)
            
            if not results:
                return ""
            
            # 2. Deduplicate & Format
            seen_content = set()
            unique_memories = []
            
            for mem in results:
                # Extract content safely
                if hasattr(mem, "content"):
                    content = mem.content
                    timestamp = getattr(mem, "timestamp", "Unknown")
                elif isinstance(mem, dict):
                    content = mem.get("content", "")
                    timestamp = mem.get("timestamp", "Unknown")
                else:
                    content = str(mem)
                    timestamp = "Unknown"
                
                # CLEANUP: Remove whitespace and skip if empty
                content = content.strip()
                if not content: continue
                
                # DEDUPLICATION: If we already saw this exact sentence, skip it.
                # This prevents "What is my favorite stock?" appearing 5 times.
                if content in seen_content:
                    continue
                
                # SELF-FILTER: Don't show the user's *current* question as a memory
                if content == query.strip():
                    continue

                seen_content.add(content)
                unique_memories.append((timestamp, content))
            
            # 3. Limit the final output to the top 5 UNIQUE results
            final_memories = unique_memories[:5]
            
            if not final_memories:
                return ""

            self.console.print(f"[dim green]Found {len(final_memories)} unique memories:[/dim green]")
            
            memory_block = "\n\n=== RELEVANT LONG-TERM MEMORY ===\n"
            for ts, text in final_memories:
                # Print preview for you
                clean_preview = text.replace("\n", " ")[:80]
                self.console.print(f"[dim]  - [{ts}] {clean_preview}...[/dim]")
                
                # Add to context
                memory_block += f"- [{ts}] {text}\n"
            
            return memory_block
            
        except Exception as e:
            logger.warning(f"Memory retrieval failed: {e}")
            return ""

    def _handle_chat(self, user_input: str):
        """Autonomous Agent Loop (ReAct Pattern) for general analysis."""
        self.console.print(f"[dim]Thinking...[/dim]")
        
        turn_history = [] 
        current_input = user_input
        MAX_TURNS = 5
        
        # --- STEP 1: RAG (Retrieval) ---
        # Fetch past memories relevant to this specific input
        long_term_context = self._retrieve_long_term_memory(user_input)
        
        # --- CRITICAL FIX: INJECT MEMORY INTO SYSTEM PROMPT ---
        # We modify the system prompt for THIS RUN ONLY.
        # This forces the LLM to treat the memory as an absolute rule/fact.
        run_specific_system_prompt = self.system_prompt
        if long_term_context:
            run_specific_system_prompt += f"\n\n{long_term_context}"
        
        for turn in range(MAX_TURNS):
            # 1. Get Short Term RAM
            short_term_context = self.memory.get_context()
            
            # Combine RAM + History (But NOT Long Term, that's in System Prompt now)
            full_history = str(short_term_context)
            if turn > 0:
                for t in turn_history:
                    full_history += f"\n{t['role']}: {t['content']}"
            
            # 2. Ask Brain
            response = self.llm.think(
                user_input=current_input,
                system_prompt=run_specific_system_prompt, # <--- The "Memory-Enhanced" Prompt
                memory_context=full_history
            )
            
            # 3. Check for ACTION (Tool Use by the LLM itself)
            if "ACTION:" in response:
                try:
                    lines = response.split('\n')
                    action_line = next(line for line in lines if "ACTION:" in line)
                    parts = action_line.replace("ACTION:", "").strip().split(" ", 1)
                    
                    tool_name = parts[0]
                    query = parts[1] if len(parts) > 1 else ""
                    
                    self.console.print(f"[bold yellow]‚ö° Auto-Tool:[/bold yellow] {tool_name} -> {query}")
                    self.memory.add_log(f"Agent Thought: {response}", source="Assistant")
                    
                    # Execute
                    result = self.tool_manager.execute_tool(tool_name.lower(), {"query": query})
                    
                    if result.success:
                        output_str = self._format_tool_output(result.output)
                        preview = output_str[:500] + "..." if len(output_str) > 500 else output_str
                        self.console.print(f"[dim cyan]{preview}[/dim cyan]") 
      	      	
                        observation = f"System Observation from {tool_name}: {output_str}"
                    else:
                        observation = f"System Observation: Error - {result.error}"
                        self.console.print(f"[red]{observation}[/red]")
                    
                    turn_history.append({"role": "assistant", "content": response})
                    turn_history.append({"role": "user", "content": observation})
                    
                    current_input = (
                        "(Observation provided above. Analyze this data STRICTLY according to the "
                        "protocols and formatting rules defined in your System Prompt. "
                        "Do not deviate from the agreed structure.)"
                    )
                    
                except Exception as e:
                    self.console.print(f"[red]Auto-Loop Error: {e}[/red]")
                    break
            else:
                self.memory.add_log(response, source="Assistant")
                self.console.print(f"\n[bold green]Cobalt:[/bold green]")
                self.console.print(Markdown(response))
                self.console.print()
                break

========================================
FILE: src/cobalt_agent/interfaces/mattermost.py
========================================

"""
Mattermost Communication Interface for Cobalt Agent
Provides a robust interface for sending and receiving messages via Mattermost.
"""

import asyncio
import json
import threading
import multiprocessing
from typing import Optional, Dict, Any, Callable, TYPE_CHECKING
if TYPE_CHECKING:
    from cobalt_agent.main import CobaltAgent
    from cobalt_agent.core.proposals import ProposalEngine, Proposal
from urllib.parse import urlparse

import websockets
from loguru import logger
from mattermostdriver import Driver

from cobalt_agent.config import get_config, MattermostConfig


class MattermostInterface:
    """
    Interface for Mattermost communication.
    
    Handles connection to Mattermost server, authentication,
    and message sending functionality.
    """
    
    def __init__(self, config: Optional[MattermostConfig] = None):
        self.proposal_engine: Optional[Any] = None
        """
        Initialize the Mattermost interface.
        
        Args:
            config: Optional MattermostConfig. If not provided, loads from global config.
        """
        self.config = config or get_config().mattermost
        self.driver: Optional[Driver] = None
        self.brain: Optional[Any] = None
        self.is_connected: bool = False
        
        logger.info(f"MattermostInterface initialized (URL: {self.config.url})")
    
    def connect(self) -> bool:
        """
        Connect to the Mattermost server and authenticate.
        
        Returns:
            True if connection and authentication succeeded, False otherwise.
        """
        if not self.config.url:
            logger.error("MATTERMOST_URL is not configured")
            return False
        
        if not self.config.token:
            logger.error("MATTERMOST_TOKEN is not configured")
            return False
        
        try:
            parsed = urlparse(self.config.url)
            driver_options = {
                "url": parsed.hostname,
                "scheme": parsed.scheme or "http",
                "port": parsed.port or 8065,
                "basepath": "/api/v4",
                "token": self.config.token,
            }
            
            logger.debug(f"Driver options: {driver_options}")
            
            self.driver = Driver(options=driver_options)
            
            # Attempt login
            user = self.driver.login()
            
            if user and "id" in user:
                self.is_connected = True
                logger.info(f"Successfully connected to Mattermost as user: {user.get('username', 'unknown')}")
                return True
            else:
                logger.error("Failed to authenticate with Mattermost")
                self.is_connected = False
                return False
                
        except Exception as e:
            logger.error(f"Failed to connect to Mattermost: {e}")
            self.is_connected = False
            return False
    
    def disconnect(self) -> None:
        """Disconnect from the Mattermost server."""
        if self.driver:
            try:
                self.driver.logout()
            except Exception as e:
                logger.warning(f"Error during logout: {e}")
        self.is_connected = False
        logger.info("Disconnected from Mattermost")
    
    def send_message(self, channel_name: str, team_name: str, message: str) -> bool:
        """
        Send a message to a Mattermost channel.
        
        Args:
            channel_name: Name of the channel (without #)
            team_name: Name of the team
            message: The message content to send
            
        Returns:
            True if message was sent successfully, False otherwise.
        """
        if not self.is_connected or not self.driver:
            logger.error("Not connected to Mattermost")
            return False
        
        try:
            # Get team ID
            teams = self.driver.teams.get_team_by_name(team_name)
            if not teams:
                logger.error(f"Team not found: {team_name}")
                return False
            
            team_id = teams["id"]
            
            # Get channel ID using team_id as parameter
            channel = self.driver.channels.get_channel_by_name(team_id, channel_name)
            if not channel:
                logger.error(f"Channel not found: {channel_name} in team {team_name}")
                return False
            
            channel_id = channel["id"]
            
            post = self.driver.posts.create_post(
                options={
                    "channel_id": channel_id,
                    "message": message
                }
            )
            
            if post and "id" in post:
                logger.info(f"Message sent to #{channel_name} in team {team_name}")
                return True
            else:
                logger.error("Failed to create post")
                return False
                
        except Exception as e:
            logger.error(f"Failed to send message: {e}")
            return False
    
    def send_message_to_channel_id(self, channel_id: str, message: str) -> bool:
        """
        Send a message directly to a channel using its ID.
        
        Args:
            channel_id: The Mattermost channel ID
            message: The message content to send
            
        Returns:
            True if message was sent successfully, False otherwise.
        """
        if not self.is_connected or not self.driver:
            logger.error("Not connected to Mattermost")
            return False
        
        try:
            post = self.driver.posts.create_post(
                options={
                    "channel_id": channel_id,
                    "message": message
                }
            )
            
            if post and "id" in post:
                logger.info(f"Message sent to channel {channel_id}")
                return True
            else:
                logger.error("Failed to create post")
                return False
                
        except Exception as e:
            logger.error(f"Failed to send message: {e}")
            return False
    
    def get_my_user_id(self) -> Optional[str]:
        """
        Get the current user's ID.
        
        Returns:
            User ID string if connected, None otherwise.
        """
        if not self.is_connected or not self.driver:
            return None
        
        try:
            user = self.driver.users.get_user("me")
            return user["id"] if user else None
        except Exception as e:
            logger.error(f"Failed to get user: {e}")
            return None
    
    async def _handle_mattermost_event(self, message: str) -> None:
        """
        Internal handler for Mattermost WebSocket events.
        
        Properly handles the Mattermost API quirk where event_data['data']['post']
        is passed as a stringified JSON object, NOT a parsed dictionary.
        
        Args:
            message: The event JSON string from Mattermost WebSocket
        """
        # Log raw payload for debugging
        logger.info(f"RAW WEBSOCKET PAYLOAD: {message}")
        
        try:
            event_data = json.loads(message)
            
            # Only process 'posted' events (new messages)
            if event_data.get("event") != "posted":
                return
            
            # Extract and parse the nested post data
            post_str = event_data.get("data", {}).get("post")
            if not post_str:
                return
            
            post_data = json.loads(post_str)
            
            user_id = post_data.get("user_id")
            channel_id = post_data.get("channel_id")
            text = post_data.get("message", "")
            
            # Ignore the bot's own messages to prevent infinite loops
            if user_id == self.get_my_user_id():
                return
            
            logger.info(f"Message received in channel {channel_id}: {text}")
            
            # Check for approval response first
            if self.proposal_engine:
                approved_proposal = self.proposal_engine.handle_approval_response(text, channel_id)
                if approved_proposal:
                    logger.info(f"Proposal approved: [{approved_proposal.task_id}]")
                    # Execute the approved action
                    self.proposal_engine.execute_approved(approved_proposal)
                    return  # Don't route to brain for approval responses
            
            # Route to the brain if attached - run LLM inference in background thread
            if hasattr(self, 'brain') and self.brain:
                logger.info("Routing message to Cortex in background thread...")
                
                # Import tool_manager for the tool loop
                from cobalt_agent.tools.tool_manager import ToolManager
                from cobalt_agent.memory import MemorySystem
                from cobalt_agent.config import get_config
                
                # Try to get memory from brain if available (for longer-term context)
                try:
                    memory = self.brain.memory if hasattr(self.brain, 'memory') else MemorySystem()
                except:
                    memory = MemorySystem()
                
                def think_and_reply():
                    try:
                        # Use 'route' method on Cortex for user input
                        response = self.brain.route(text)
                        if response:
                            # Specialized department response (TACTICAL, INTEL, OPS, etc.)
                            self.send_message_to_channel_id(channel_id, response)
                        else:
                            # DEFAULT route - use ReAct loop for tool execution
                            logger.info("DEFAULT route detected, using ReAct loop...")
                            # Use the agent's LLM with the correct system prompt
                            from cobalt_agent.config import get_config
                            config = get_config()
                            from cobalt_agent.prompt import PromptEngine
                            prompt_engine = PromptEngine(config.persona)
                            system_prompt = prompt_engine.build_system_prompt()
                            
                            # Initialize conversation history with user input
                            conversation_history = [
                                {"role": "user", "content": text}
                            ]
                            
                            # MAX_ITERATIONS to prevent infinite loops
                            MAX_ITERATIONS = 3
                            iteration = 0
                            final_answer = None
                            
                            while iteration < MAX_ITERATIONS:
                                iteration += 1
                                logger.info(f"ReAct iteration {iteration}/{MAX_ITERATIONS}")
                                
                                # Generate response from LLM using conversation history
                                response = self.brain.llm.generate_response(
                                    system_prompt=system_prompt,
                                    user_input=None,  # Already included in conversation history
                                    memory_context=conversation_history,
                                    search_context=""
                                )
                                
                                logger.info(f"LLM Response: {response}")
                                
                                # Check if response contains ACTION:
                                if "ACTION:" in response:
                                    # Parse the tool name and query
                                    logger.info("ACTION: detected, parsing tool command...")
                                    
                                    # Extract the ACTION line
                                    action_line = None
                                    for line in response.split('\n'):
                                        if 'ACTION:' in line:
                                            action_line = line
                                            break
                                    
                                    if action_line:
                                        # Parse "ACTION: tool_name query_string"
                                        action_parts = action_line.replace('ACTION:', '').strip().split(' ', 1)
                                        tool_name = action_parts[0].strip().lower()
                                        query = action_parts[1].strip() if len(action_parts) > 1 else ""
                                        
                                        # Fuzzy Match Hack: map "scrape" and "search" to "browser"
                                        if tool_name in ["scrape", "search"]:
                                            tool_name = "browser"
                                            logger.info(f"Fuzzy matched '{tool_name}' -> 'browser'")
                                        
                                        # Execute the tool
                                        tool_manager = ToolManager()
                                        tool_result = tool_manager.execute_tool(
                                            tool_name=tool_name,
                                            args={"query": query}
                                        )
                                        
                                        # Format the observation for LLM
                                        if tool_result.success:
                                            observation = f"[Observation: {tool_result.output}]"
                                        else:
                                            observation = f"[Observation: Tool execution failed - {tool_result.error}]"
                                        
                                        # Append observation to conversation history
                                        conversation_history.append({
                                            "role": "assistant",
                                            "content": response
                                        })
                                        conversation_history.append({
                                            "role": "user",
                                            "content": observation
                                        })
                                        
                                        logger.info(f"Tool executed: {tool_name}, Observation: {observation}")
                                    else:
                                        # No valid ACTION line found, treat as final answer
                                        final_answer = response
                                        break
                                else:
                                    # No ACTION: found, this is the final conversational answer
                                    logger.info("No ACTION: detected, returning final answer")
                                    final_answer = response
                                    break
                            
                            # Send final answer to Mattermost
                            if final_answer:
                                # Update memory with assistant's response
                                memory.add_log(final_answer, source="Assistant")
                                self.send_message_to_channel_id(channel_id, final_answer)
                                logger.info("Final response sent to Mattermost")
                            else:
                                logger.warning("ReAct loop completed without final answer")
                    except Exception as e:
                        logger.error(f"think_and_reply error: {e}", exc_info=True)
                
                # Run the sync function in a background thread
                asyncio.create_task(asyncio.to_thread(think_and_reply))
            else:
                logger.warning("Brain is not attached to MattermostInterface! Cannot reply.")
                
        except Exception as e:
            logger.error(f"Error parsing Mattermost event: {e}", exc_info=True)
    
    def _handle_events(self, mm_driver: Driver) -> None:
        """
        Event handler for Mattermost WebSocket events.
        
        This method is called by the websocket when events are received.
        
        Args:
            mm_driver: The Mattermost driver instance (for accessing get_user_id, etc.)
        """
        # This is called for each event type from the websocket
        pass
    
    def _run_websocket_in_process(self, brain: "CobaltAgent", event_queue: "multiprocessing.Queue") -> None:
        """
        Run the Mattermost WebSocket in a separate process to avoid event loop conflicts.
        
        Args:
            brain: The CobaltAgent instance (not used directly, but for reference)
            event_queue: Queue for passing events to the main process
        """
        # Import here to ensure it runs in the new process context
        from mattermostdriver import Driver
        from loguru import logger
        
        # Reinitialize the driver in this process
        parsed = urlparse(self.config.url)
        driver_options = {
            "url": parsed.hostname,
            "scheme": parsed.scheme or "http",
            "port": parsed.port or 8065,
            "basepath": "/api/v4",
            "token": self.config.token,
        }
        
        driver = Driver(options=driver_options)
        driver.login()
        
        # Define the event handler for init_websocket
        def on_event(event: str, data: Dict[str, Any]) -> None:
            # Build the event dict from the event type and data
            event_dict = {"event": event, "data": data}
            # For now, just log to file since stdout might be redirected
            logger.info(f"Mattermost event: {event}")
            # Send to main process if needed
            try:
                event_queue.put(event_dict)
            except:
                pass
        
        try:
            # This runs its own event loop
            driver.init_websocket(on_event)
        except Exception as e:
            logger.error(f"WebSocket error: {e}")
        
        driver.logout()
    
    def start_listening(self, brain: "CobaltAgent") -> None:
        async def run_native_ws():
            # Format the URL properly for WebSockets
            base_url = self.config.url.rstrip('/')
            ws_url = base_url.replace('http://', 'ws://').replace('https://', 'wss://') + "/api/v4/websocket"
            
            logger.info(f"Connecting to native WebSocket engine: {ws_url}")
            
            headers = {"Authorization": f"Bearer {self.config.token}"}
            try:
                async with websockets.connect(ws_url, ping_interval=20, ping_timeout=20, additional_headers=headers) as ws:
                    logger.info("Connected and authenticated via HTTP headers. Listening for messages...")
                    
                    # Listen to the raw data stream forever
                    async for message in ws:
                        logger.info(f"RAW WEBSOCKET PAYLOAD: {message}")
                        await self._handle_mattermost_event(message)
            except Exception as e:
                logger.error(f"Native WebSocket connection dropped: {e}", exc_info=True)

        # Run the native engine in the main thread
        logger.info("Starting native WebSocket engine...")
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(run_native_ws())
        except KeyboardInterrupt:
            logger.info("Bot shut down manually.")

========================================
FILE: src/cobalt_agent/llm.py
========================================

"""
Cobalt Agent - LLM (The Brain)
Handles communication with AI providers via LiteLLM.
Unified interface supporting Chat, Direct Queries, and Structured Data extraction.
"""

import os
import json
from typing import List, Dict, Any, Optional, Type, TypeVar
from pydantic import BaseModel, Field, SecretStr, ValidationError
from loguru import logger
from litellm import completion

# Generic type for Pydantic models
T = TypeVar("T", bound=BaseModel)

class LLM(BaseModel):
    """
    The Brain of the agent. 
    Processes prompts and returns intelligent responses.
    """
    
    # Configuration
    role: str = Field("default", description="The role to use for model selection")
    api_key: Optional[SecretStr] = Field(default=None, description="API Key (optional if in env vars)")
    
    def __init__(self, **data: Any) -> None:
        super().__init__(**data)
        self._resolve_model_config()
        
    # Model name property
    @property
    def model_name(self) -> str:
        """Public property to access the resolved model name."""
        return self._model_name
    
    def switch_role(self, new_role: str) -> None:
        """
        Switch to a new role and re-resolve the model configuration.
        This allows hot-swapping between different models (e.g., Qwen 80B -> DeepSeek 70B).
        """
        self.role = new_role
        self._resolve_model_config()
        logger.info(f"Role switched to '{new_role}', model updated to: {self._model_name}")
    
    def _resolve_model_config(self) -> None:
        from cobalt_agent.config import load_config
        # Load the configuration object
        config = load_config()
        
        # Debugging: Print the config object to verify its attributes
        logger.debug(f"Config Object: {config.__dict__}")
        # 1. Resolve the Model Alias (Intent -> Alias)
        active_profile = config.active_profile
        
        model_alias = active_profile.get(self.role, active_profile.get("default"))

        # 2. Retrieve Model Config (Alias -> Config)
        if model_alias not in config.models:
            raise ValueError(f"Model alias '{model_alias}' not found in registry.")
            
        model_config = config.models[model_alias]
        
        # 3. Construct Model String
        if isinstance(model_config, dict):
            provider = model_config.get("provider")
            name = model_config.get("model_name")
            node_ref = model_config.get("node_ref")
            env_key_ref = model_config.get("env_key_ref")
        else:
            provider = model_config.provider
            name = model_config.model_name
            node_ref = getattr(model_config, "node_ref", None)
            env_key_ref = getattr(model_config, "env_key_ref", None)

        self._model_name = f"{provider}/{name}"

        # 4. Resolve Network or Keys
        if node_ref:
            nodes = config.network.nodes
            target_node = nodes.get(node_ref) if isinstance(nodes, dict) else getattr(nodes, node_ref, None)
            
            if not target_node:
                raise ValueError(f"Node reference '{node_ref}' not found in network topology.")
            
            if isinstance(target_node, dict):
                ip = target_node.get("ip")
                port = target_node.get("port")
                protocol = target_node.get("protocol", "http")
            else:
                ip = target_node.ip
                port = target_node.port
                protocol = getattr(target_node, "protocol", "http")

            self._api_base = f"{protocol}://{ip}:{port}"
            
        elif env_key_ref:
            keys = config.keys
            env_var_name = keys.get(env_key_ref) if isinstance(keys, dict) else getattr(keys, env_key_ref, None)
            
            if env_var_name:
                self.api_key = SecretStr(os.getenv(env_var_name, ""))
        
    def _call_provider(self, messages: List[Dict[str, str]]) -> str:
        """
        Internal helper to send messages to the provider via LiteLLM.
        """
        try:
            # Get key string safely if it exists on the instance
            key_str = self.api_key.get_secret_value() if self.api_key else None
            
            api_base = self._api_base
            
            # Make the call
            response = completion(
                model=self._model_name,
                messages=messages,
                api_key=key_str,
                base_url=api_base,  
                temperature=0.7 
            )
            
            if not response.choices or not response.choices[0].message:
                 raise ValueError("Empty response from provider")
                 
            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"LLM Call Failed: {str(e)}")
            raise e

    # --- 1. THE CHAT INTERFACE (For Main Loop) ---
    def generate_response(self,
                          system_prompt: str,
                          user_input: Optional[str] = None,
                          memory_context: List[Dict] = None,
                          search_context: str = "") -> str:
        """
        Main conversational loop method. Handles history and context injection.
        """
        messages = []

        # A. System Prompt
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        # B. Memory Context
        if memory_context:
            for item in memory_context:
                # Case 1: Memory Log (Standard)
                if "source" in item:
                    role = "user" if item["source"] == "User" else "assistant"
                    messages.append({"role": role, "content": item["message"]})
                
                # Case 2: Tool Loop Message (Raw)
                elif "role" in item:
                    messages.append({"role": item["role"], "content": item["content"]})

        # C. Search Context (Legacy/Injection)
        if search_context:
             messages.append({
                "role": "user", 
                "content": f"Context Information:\n{search_context}"
            })

        # D. Current Input
        if user_input:
            messages.append({"role": "user", "content": user_input})

        try:
            response = self._call_provider(messages)
            logger.info(f"Cobalt, LLM model version: {self.model_name}")
            logger.info(f"Persona Roles: Chief of Staff, Software Architect, Senior Developer, Business Analyst")
            return response
        except Exception as e:
            logger.error(f"LLM Call Failed: {str(e)}")
            raise e

    # --- 2. THE SKILL INTERFACE (For Tools & Research) ---
    def generate_response_skill(self, prompt: str) -> str:
        return self.generate_response(
            system_prompt=prompt,
            user_input=None,
            memory_context=None,
            search_context=""
        )

    def ask(self, 
            system_message: str,
            user_input: Optional[str] = None) -> str:
        """
        Direct one-off query. Used by skills like Research or Briefing.
        """
        messages = [
            {"role": "system", "content": system_message},
        ]

        if user_input:
            messages.append({"role": "user", "content": user_input})

        try:
            return self._call_provider(messages)
        except Exception as e:
            logger.error(f"Ask Failed: {str(e)}")
            raise e

    # --- 3. THE STRUCTURED INTERFACE (For Strict Data) ---
    def ask_structured(self, 
                       system_prompt: str, 
                       response_model: Type[T],
                       memory_context: List[Dict] = None,
                       search_context: str = "", 
                       user_input: Optional[str] = None) -> T:
        """
        Forces the LLM to output JSON conforming to a Pydantic model.
        Returns the instantiated Pydantic object.
        """
        # Get the schema from the model
        schema = response_model.model_json_schema()
        
        system_instruction = (
            f"You are a precise data output engine.\n"
            f"You MUST return ONLY valid JSON that matches this schema:\n"
            f"{json.dumps(schema, indent=2)}\n"
            f"Do not include markdown formatting (like ```json). Return raw JSON only."
        )

        messages = [
            {"role": "system", "content": system_instruction},
        ]

        if memory_context:
            for item in memory_context:
                # Case 1: Memory Log (Standard)
                if "source" in item:
                    role = "user" if item["source"] == "User" else "assistant"
                    messages.append({"role": role, "content": item["message"]})
                
                # Case 2: Tool Loop Message (Raw)
                elif "role" in item:
                    messages.append({"role": item["role"], "content": item["content"]})

        if search_context:
            messages.append({
                "role": "user", 
                "content": f"Context Information:\n{search_context}"
            })

        if user_input:
            messages.append({"role": "user", "content": user_input})

        try:
            raw_response = self._call_provider(messages)
            
            # Clean up potential markdown leakage
            cleaned_json = raw_response.replace("```json", "").replace("```", "").strip()
            
            # Parse and Validate
            return response_model.model_validate_json(cleaned_json)
            
        except ValidationError as e:
            logger.error(f"Structured Data Validation Failed: {e}")
            logger.debug(f"Raw Output: {raw_response}")
            raise ValueError(f"LLM failed to generate valid JSON: {e}")
        except Exception as e:
            logger.error(f"Structured Request Failed: {e}")
            raise e

========================================
FILE: src/cobalt_agent/main.py
========================================

"""
Cobalt Agent - Main Entry Point
Project Cobalt: Autonomous AI Chief of Staff & Trading System
"""

import sys
from loguru import logger
from datetime import datetime, timedelta

from cobalt_agent.config import load_config
from cobalt_agent.memory.postgres import PostgresMemory
from cobalt_agent.memory import MemorySystem  # Keep this as fallback
from cobalt_agent.persona import Persona
from cobalt_agent.interfaces.cli import CLI
from cobalt_agent.interfaces.mattermost import MattermostInterface
from cobalt_agent.llm import LLM
from cobalt_agent.prompt import PromptEngine
from cobalt_agent.tools.tool_manager import ToolManager
from cobalt_agent.brain.cortex import Cortex
from cobalt_agent.core.scheduler import AgentScheduler
from cobalt_agent.core.proposals import ProposalEngine
from cobalt_agent.skills.productivity.briefing import MorningBriefing
from cobalt_agent.skills.research.deep_dive import DeepResearch

class CobaltAgent:
    def __init__(self):
        self.configure_logging()
        self.config = load_config()
        self.persona = Persona(self.config.persona)
        
        try:
            self.memory = PostgresMemory()
        except Exception as e:
            logger.warning(f"Database offline, falling back to local file: {e}")
            self.memory = MemorySystem()

        self.cortex = Cortex()
        self.scheduler = AgentScheduler(self.cortex)
        self.scheduler.start()
        
        briefing = MorningBriefing()
        researcher = DeepResearch() 

        # This sets it to run every morning at 8:00 AM
        self.scheduler.add_job(briefing.run, 'cron', hour=8, minute=0)

        logger.info("Cobalt Agent - System Initialized")
        logger.info(f"Python Version: {sys.version}")
        logger.info(f"Configuration Loaded: Debug Mode = {self.config.system.debug_mode}")

        # Initialize the Brain (LLM) with Intent-Based Routing
        self.llm = LLM(role="default")
        logger.info("Brain Initialized: Role-Based Routing Active (default)")

        # Initialize Tool Manager
        self.tool_manager = ToolManager()

        # Initialize Prompt Engine instead of static string
        self.prompt_engine = PromptEngine(self.config.persona)
        
        tools_list = self.tool_manager.get_tool_descriptions()
        system_prompt = self.prompt_engine.build_system_prompt(tools=tools_list)
        self.system_prompt = system_prompt

        # Log System Start to Memory
        self.memory.add_log("Cobalt Agent System Initialized", source="System")
        self.memory.add_log(f"Persona '{self.config.persona.name}' loaded", source="System")

        logger.info(f"Persona: {self.persona}")
        logger.info(f"Persona Roles: {', '.join(self.config.persona.roles)}")

        logger.info("=" * 80)
        logger.info("SYSTEM PROMPT:")
        logger.info("=" * 80)
        logger.info(f"\n{self.system_prompt}\n")
        logger.info("=" * 80)

        logger.info("Memory System online")

    def configure_logging(self):
        """Configure loguru logging with INFO level and file rotation."""
        # Remove default handler
        logger.remove()
        
        # Add console handler with INFO level
        logger.add(
            sys.stderr,
            level="INFO",
            format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
            colorize=True,
        )
        
        # Add file handler with rotation
        logger.add(
            "logs/agent_{time:YYYY-MM-DD}.log",
            level="INFO",
            format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
            rotation="00:00",  # Rotate daily at midnight
            retention="7 days",  # Keep logs for 7 days
        )
    def main(self):
        """Main entry point for Cobalt Agent."""
        self.configure_logging()
        
        briefing = MorningBriefing()
        researcher = DeepResearch() 

        logger.info("=" * 80)
        logger.info("Starting interactive CLI interface...")
        logger.info("=" * 80)

        cli = CLI(
            memory_system=self.memory, 
            llm=self.llm, 
            system_prompt=self.system_prompt,
            tool_manager=self.tool_manager,
            cortex=self.cortex
        )
  
        try:
            cli.start()
        except Exception as e:
            logger.error(f"Critical Error: {e}")
        finally:
            # Save memory to disk after exiting
            logger.info("Exiting Cobalt Agent")
            
            self.scheduler.stop()
        
            self.memory.add_log("CLI session ended", source="System")
        
            self.memory.save_memory()

    def process_input(self, text: str) -> str:
        """
        Process incoming text input and generate a response.
        Combines Cortex routing with autonomous chat fallback.
        
        Args:
            text: The incoming message text
            
        Returns:
            The response string
        """
        try:
            # 1. Try Cortex routing first (specialized departments)
            if self.cortex:
                specialist_response = self.cortex.route(text)
                if specialist_response:
                    logger.info(f"Cortex handled: {specialist_response[:100]}")
                    return specialist_response
            
            # 2. Fallback to autonomous chat (LLM)
            response = self.llm.generate_response(
                system_prompt=self.system_prompt,
                user_input=text,
                memory_context=[],
                search_context=""
            )
            logger.info(f"LLM response generated")
            return response
        except Exception as e:
            logger.error(f"Failed to process input: {e}")
            return f"Error processing your request: {e}"
    
    def send_message(self, message):
        """Send a message using the LLM."""
        try:
            response = self.llm.generate_response(
                system_prompt=self.system_prompt,
                user_input=message,
                memory_context=[],
                search_context=""
            )
            logger.info(f"Message sent: {message}")
            logger.info(f"Response received: {response}")
            return response
        except Exception as e:
            logger.error(f"Failed to send message: {e}")
    
    def start_mattermost_interface(self) -> None:
        """
        Start the Mattermost WebSocket listener instead of CLI.
        """
        mm_interface = MattermostInterface()
        
        try:
            if not mm_interface.connect():
                logger.error("Failed to connect to Mattermost. Exiting.")
                return
            
            # Initialize and attach Proposal Engine for HITL approval workflow
            self.proposal_engine = ProposalEngine()
            self.proposal_engine.connect_mattermost()
            mm_interface.proposal_engine = self.proposal_engine
            
            logger.info("=" * 80)
            logger.info("Cobalt Agent - Mattermost Interface Active")
            logger.info("HITL Proposal Engine - Active")
            logger.info("=" * 80)
            
            # Explicitly attach brain (cortex) to the interface before listening
            mm_interface.brain = self.cortex
            
            # Start listening for messages (blocking)
            mm_interface.start_listening(self)
        finally:
            if hasattr(mm_interface, 'disconnect'):
                mm_interface.disconnect()
            if hasattr(self, 'proposal_engine') and self.proposal_engine:
                self.proposal_engine.stop_monitoring()
            self.scheduler.stop()
            self.memory.add_log("Mattermost session ended", source="System")
            self.memory.save_memory()

if __name__ == "__main__":
    agent = CobaltAgent()
    agent.start_mattermost_interface()


========================================
FILE: src/cobalt_agent/memory/base.py
========================================

"""
Memory Interface (The Contract)
Defines how Agents interact with memory, regardless of storage (JSON vs Postgres).
"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any

class MemoryProvider(ABC):
    """
    Abstract Base Class for Memory.
    Any memory system (JSON, SQL, Vector) MUST implement these methods.
    """

    @abstractmethod
    def add_log(self, message: str, source: str = "System", data: Dict = None):
        """Record an event or thought."""
        pass

    @abstractmethod
    def get_context(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Get recent conversation history (Short Term RAM)."""
        pass

    @abstractmethod
    def search(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        Find relevant memories based on meaning/content.
        (For JSON, this will be keyword search. For Postgres, Vector search.)
        """
        pass

========================================
FILE: src/cobalt_agent/memory/core.py
========================================

"""
Memory System Core (JSON Implementation)
Manages short-term (RAM) and long-term (Disk) memory for Cobalt Agent
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Any, Dict, List
from loguru import logger
from .base import MemoryProvider  # <--- IMPORT THE CONTRACT

class MemorySystem(MemoryProvider):  # <--- SIGN THE CONTRACT
    """
    Memory System for Cobalt Agent
    
    Manages:
    - Short-term memory: Last 10 interactions (RAM - Fast)
    - Long-term memory: Persistent storage in data/memory.json (Disk - Safe)
    """
    
    def __init__(self, memory_file: str = "data/memory.json"):
        self.memory_file = Path(memory_file)
        self.short_term: List[Dict[str, Any]] = [] 
        self.long_term: Dict[str, Any] = {"logs": []}
        self.load_memory()
        
    def add_log(self, message: str, source: str = "System", data: Dict = None) -> None:
        """Add a message to short-term memory AND long-term memory."""
        entry = {
            "timestamp": datetime.now().isoformat(),
            "source": source,
            "message": message,
            "data": data or {}
        }

        self.short_term.append(entry)
        
        # Keep only last 10 interactions in RAM
        if len(self.short_term) > 10:
            self.short_term.pop(0)
            
        self.long_term["logs"].append(entry)
        logger.debug(f"Memory added: [{source}] {message}")
        self.save_memory()

    def get_context(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Fast retrieval of short-term memory for AI prompts."""
        return self.short_term[-limit:]

    # <--- NEW METHOD: REQUIRED BY INTERFACE
    def search(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        Simple Keyword Search (Placeholder for Vector Search).
        Finds past logs that contain the query string.
        """
        results = []
        # Search backwards (newest first) to prioritize recent context
        for entry in reversed(self.long_term["logs"]):
            if query.lower() in entry["message"].lower():
                results.append(entry)
                if len(results) >= limit:
                    break
        return results

    def save_memory(self) -> None:
        """Save long-term memory to disk."""
        try:
            self.memory_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.memory_file, 'w', encoding='utf-8') as f:
                json.dump(self.long_term, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Failed to save memory: {e}")
            
    def load_memory(self) -> None:
        """Load long-term memory from disk."""
        try:
            if self.memory_file.exists():
                with open(self.memory_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        self.long_term = data
                        if "logs" not in self.long_term:
                            self.long_term["logs"] = []
                    else:
                        self.long_term = {"logs": []}

                    # Hydrate Short-Term RAM from Disk
                    self.short_term = self.long_term["logs"][-10:]
                logger.info(f"Memory loaded from {self.memory_file}")
            else:
                logger.info("Starting with empty memory")
                self.long_term = {"logs": []}
                self.short_term = []
        except Exception as e:
            logger.error(f"Failed to load memory: {e}")
            self.long_term = {"logs": []}
            self.short_term = []

========================================
FILE: src/cobalt_agent/memory/postgres.py
========================================

"""
Postgres Memory Adapter (The Hippocampus)
Hybrid: Combines Persistent Logging with Vector Embeddings for Semantic Search.

Configuration Sources (highest to lowest priority):
1. Environment variables (POSTGRES_HOST, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD)
2. YAML config in configs/*.yaml
"""
import os
import json
import psycopg
from datetime import datetime
from typing import List, Dict, Any, Optional
from loguru import logger
from litellm import embedding
from ..config import get_config
from .base import MemoryProvider

class PostgresMemory(MemoryProvider):
    def _get_conn(self):
        """Get a database connection."""
        return psycopg.connect(self.conn_str)
    
    def __init__(self):
        # 1. Load Credentials from config object
        config = get_config()
        postgres_config = config.postgres
        
        self.host = postgres_config.host
        self.port = postgres_config.port
        self.db = postgres_config.db
        self.user = postgres_config.user
        self.password = postgres_config.password or os.getenv("POSTGRES_PASSWORD", "cobalt_password")
        
        # Connection String (using config-based host for proper host-based execution)
        self.conn_str = f"postgresql://{self.user}:{self.password}@{self.host}:{self.port}/{self.db}"
        self.table_name = "memory_logs"
        
        # 2. Initialize DB (Auto-create vector table)
        self._init_db()
    
    def _init_db(self):
        """Initialize database connection and create tables."""
        try:
            with self._get_conn() as conn:
                # Enable Vector Extension
                conn.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                
                # Create Table with VECTOR Column (1536 dims for OpenAI)
                # We use 'content' instead of 'message' to standardize with RAG tools
                conn.execute(f"""
                    CREATE TABLE IF NOT EXISTS {self.table_name} (
                        id SERIAL PRIMARY KEY,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        source TEXT,
                        content TEXT,
                        embedding vector(1536), 
                        metadata JSONB DEFAULT '{{}}'::jsonb
                    );
                """)
                logger.info("üß† Connected to Postgres Memory (Vector Ready)")
        except Exception as e:
            logger.error(f"Failed to init DB: {e}")

    def _generate_embedding(self, text: str) -> List[float]:
        """Turns text into a list of numbers using LiteLLM."""
        try:
            text = text.replace("\n", " ")
            response = embedding(
                model="text-embedding-3-small",
                input=[text]
            )
            
            # ROBUST PARSING FIX: Handle both Object and Dict responses
            data_item = response.data[0]
            if isinstance(data_item, dict):
                return data_item['embedding']
            else:
                return data_item.embedding
                
        except Exception as e:
            logger.error(f"Embedding failed: {e}")
            return []

    def add_log(self, message: str, source: str = "System", data: Dict = None):
        """
        Saves a memory AND its vector representation.
        """
        # Generate Vector
        vector = self._generate_embedding(message)
        
        if not data:
            data = {}
            
        try:
            with self._get_conn() as conn:
                if vector:
                    conn.execute(
                        f"INSERT INTO {self.table_name} (source, content, embedding, metadata) VALUES (%s, %s, %s, %s)",
                        (source, message, str(vector), json.dumps(data))
                    )
                else:
                    # Fallback (save without vector if embedding fails)
                    conn.execute(
                        f"INSERT INTO {self.table_name} (source, content, metadata) VALUES (%s, %s, %s)",
                        (source, message, json.dumps(data))
                    )
        except Exception as e:
            logger.error(f"Failed to save memory: {e}")

    def get_context(self, limit: int = 10) -> str:
        """
        Get the most recent logs (Short Term RAM).
        Fetched from DB so it persists across restarts.
        """
        try:
            with self._get_conn() as conn:
                # We fetch the raw rows
                rows = conn.execute(f"""
                    SELECT timestamp, source, content 
                    FROM {self.table_name} 
                    ORDER BY timestamp DESC 
                    LIMIT %s
                """, (limit,)).fetchall()
                
                # Format into a chat-log string for the LLM
                context = ""
                # Reverse so it reads chronologically (Old -> New)
                for row in rows[::-1]:
                    ts = row[0].strftime("%H:%M") if hasattr(row[0], 'strftime') else str(row[0])
                    context += f"[{ts}] {row[1]}: {row[2]}\n"
                
                return context
        except Exception as e:
            logger.error(f"Failed to get context: {e}")
            return ""

    def search(self, query: str, limit: int = 5) -> List[Dict]:
        """
        Semantic Search: Finds memories mathematically similar to the query.
        """
        vector = self._generate_embedding(query)
        if not vector:
            return []

        try:
            with self._get_conn() as conn:
                # The <=> operator is "Cosine Distance" (Lower is better)
                results = conn.execute(f"""
                    SELECT timestamp, source, content, metadata, 
                           1 - (embedding <=> %s) as similarity
                    FROM {self.table_name}
                    WHERE embedding IS NOT NULL
                    ORDER BY embedding <=> %s
                    LIMIT %s;
                """, (str(vector), str(vector), limit)).fetchall()
                
                memories = []
                for row in results:
                    # Filter low relevance (Similarity < 0.3 is usually noise)
                    if row[4] < 0.3: 
                        continue
                        
                    memories.append({
                        "timestamp": row[0],
                        "source": row[1],
                        "content": row[2],
                        "metadata": row[3],
                        "score": row[4]
                    })
                
                return memories
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []
            
    def save_memory(self) -> None:
        """Postgres saves immediately, so this is a no-op."""
        pass

========================================
FILE: src/cobalt_agent/persona.py
========================================

"""
Persona System for Cobalt Agent
Manages the AI agent's identity, roles, skills, and behavioral directives.
"""

from typing import List

from loguru import logger
from pydantic import BaseModel, Field


class PersonaConfig(BaseModel):
    """Configuration for Cobalt Agent persona."""

    name: str = Field(default="Cobalt", description="Agent name")
    roles: List[str] = Field(
        default_factory=list, description="List of roles the agent fulfills"
    )
    skills: List[str] = Field(
        default_factory=list, description="List of agent skills and capabilities"
    )
    tone: List[str] = Field(
        default_factory=list, description="Communication tone characteristics"
    )
    directives: List[str] = Field(
        default_factory=list, description="Core behavioral directives"
    )


class Persona:
    """
    Persona class that manages the AI agent's identity and generates system prompts.
    """

    def __init__(self, config: PersonaConfig):
        """
        Initialize the Persona with configuration.

        Args:
            config: PersonaConfig instance containing persona settings
        """
        self.config = config
        logger.info(f"Persona '{config.name}' initialized")

    def get_system_prompt(self) -> str:
        """
        Generate a comprehensive system prompt combining all persona attributes.

        Returns:
            str: Complete system instruction string for the AI agent
        """
        prompt_parts = []

        # Introduction
        prompt_parts.append(f"You are {self.config.name}, an advanced AI agent.")
        prompt_parts.append("")

        # Roles
        if self.config.roles:
            prompt_parts.append("YOUR ROLES:")
            for role in self.config.roles:
                prompt_parts.append(f"  ‚Ä¢ {role}")
            prompt_parts.append("")

        # Skills
        if self.config.skills:
            prompt_parts.append("YOUR SKILLS:")
            for skill in self.config.skills:
                prompt_parts.append(f"  ‚Ä¢ {skill}")
            prompt_parts.append("")

        # Communication Tone
        if self.config.tone:
            prompt_parts.append("COMMUNICATION STYLE:")
            tone_description = ", ".join(self.config.tone)
            prompt_parts.append(f"  Maintain a {tone_description} approach in all interactions.")
            prompt_parts.append("")

        # Core Directives
        if self.config.directives:
            prompt_parts.append("CORE DIRECTIVES:")
            for directive in self.config.directives:
                prompt_parts.append(f"  ‚Ä¢ {directive}")
            prompt_parts.append("")

        # Mission statement
        prompt_parts.append(
            "MISSION: Execute tasks with precision, leveraging your multidisciplinary expertise "
            "to deliver optimal outcomes while adhering to core directives."
        )

        system_prompt = "\n".join(prompt_parts)
        logger.debug("System prompt generated successfully")

        return system_prompt

    def __repr__(self) -> str:
        """String representation of the Persona."""
        return (
            f"Persona(name='{self.config.name}', "
            f"roles={len(self.config.roles)}, "
            f"skills={len(self.config.skills)})"
        )


========================================
FILE: src/cobalt_agent/prompt.py
========================================

"""
Cobalt Agent - Prompt Engine
Constructs dynamic system prompts based on context, tools, and time.
Refactored: Includes Memory Protocol & Temporal Gating.
"""

import datetime
from typing import List, Any
from cobalt_agent.config import PersonaConfig

class PromptEngine:
    """
    Generates the 'System Prompt' that tells the LLM how to behave.
    """
    
    def __init__(self, persona_config: PersonaConfig):
        self.persona = persona_config

    def build_system_prompt(self, tools: List[Any] = None) -> str:
        """
        Construct the full system prompt.
        
        Args:
            tools: List of tool objects available to the agent.
        """
        # 1. Identity & Role
        header = self._build_header()
        
        # 2. Operational Context (Time/Date)
        context = self._build_context()

        # 3. Memory Rules (NEW: Handles Recall & Stale Data)
        memory_rules = self._build_memory_protocol()
        
        # 4. Directives (Rules)
        directives = self._build_directives()
        
        # 5. Tool Capabilities (What it can do)
        tool_section = self._build_tool_descriptions(tools)
        
        # Combine everything
        return f"{header}\n\n{context}\n\n{memory_rules}\n\n{directives}\n\n{tool_section}"

    def _build_header(self) -> str:
        """
        Build the identity section of the system prompt.
        Includes: Identity, Roles, Tone, and Directives.
        """
        # Format roles
        roles_str = ", ".join(self.persona.roles)
        # Format tone
        tone_str = ", ".join(self.persona.tone)
        # Format directives as bullet points
        directives_str = "\n".join([f"- {d}" for d in self.persona.directives]) if self.persona.directives else "No specific directives defined."
        
        return (
            f"### IDENTITY\n"
            f"You are {self.persona.name}.\n"
            f"\n"
            f"### ROLES\n"
            f"Your roles are: {roles_str}.\n"
            f"\n"
            f"### OPERATIONAL DIRECTIVES\n"
            f"{directives_str}\n"
            f"\n"
            f"### TONE\n"
            f"Maintain a tone that is: {tone_str}."
        )

    def _build_context(self) -> str:
        now = datetime.datetime.now()
        return (
            f"### CURRENT CONTEXT\n"
            f"- Current Date/Time: {now.strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"- Operating System: Python Environment (CLI)\n"
            f"- User: Administrator"
        )

    def _build_memory_protocol(self) -> str:
        """
        Defines how to handle Long-Term Memory and Stale Data.
        Prevents the 'Bag Holder' scenario by expiring old market context.
        """
        return """
### üß† MEMORY PROTOCOL (CRITICAL)
- You will receive a block called "RELEVANT LONG-TERM MEMORY".
- **STEP 1: Check the Timestamp.** Compare the memory's timestamp to the "Current Date/Time" above.
- **STEP 2: Classify the Memory.**
   - **PREFERENCE:** (e.g., "I like TSLA", "I am a scalper") -> **KEEP FOREVER.**
   - **MARKET CONTEXT:** (e.g., "Ignore the volume", "Market is crashing") -> **EXPIRE AFTER 24 HOURS.**
- **STEP 3: Apply Logic.**
   - If a Market Context memory is older than 24 hours, **IGNORE IT** and treat it as historical noise.
   - If a Preference memory is 5 years old, **RESPECT IT** unless told otherwise.
- **STEP 4: Answer Retrieval.**
   - If the answer to the user's question is in the Memory, YOU MUST USE IT.
   - Do not say "I don't know" if the memory contains the answer.
"""

    def _build_directives(self) -> str:
        # 1. Base Rules
        rules = [
            "You are an AUTONOMOUS AGENT. You are NOT a chat bot.",
            "You DO NOT have internal knowledge of real-time events.",
            "You MUST use tools to answer questions about the world.",
            # Strict Math Rules
            "STRICT DATA ADHERENCE: If a tool provides a specific technical indicator (e.g., 'RSI (20)'), you MUST reference that specific period.",
            "DO NOT HALLUCINATE standard defaults (like '14-day RSI') if the tool data says otherwise.",
            "Trust the tool's calculated signals (e.g., 'BULLISH', 'PARABOLIC') over your own interpretation."
        ]
        
        if self.persona.directives:
            rules.extend(self.persona.directives)
            
        # 2. The Protocol (Simulated Dialogue)
        protocol = (
            "\n### ‚ö° CRITICAL OPERATING PROTOCOL ‚ö°\n"
            "To use a tool, you must output a single line starting with 'ACTION:'.\n"
            "Do not talk. Do not explain. JUST ACTION.\n\n"
            "### EXAMPLES OF CORRECT BEHAVIOR:\n"
            "User: What is the price of Apple?\n"
            "You: ACTION: finance AAPL\n"
            "System: [Observation: AAPL is $150]\n"
            "You: Apple is trading at $150.\n\n"
            "User: Find news about AI.\n"
            "You: ACTION: search AI news\n"
            "System: [Observation: AI is growing...]\n"
            "You: Recent news indicates AI is growing.\n\n"
            "### YOUR TURN:\n"
            "If I ask you a question that requires data, do not answer directly. START WITH ACTION:."
        )

        return "### DIRECTIVES\n" + "\n".join([f"- {r}" for r in rules]) + protocol

    def _build_tool_descriptions(self, tools) -> str:
        if not tools:
            return ""
            
        descriptions = []
        for tool in tools:
            # Use class name instead of raw memory address
            name = type(tool).__name__
            formatted_name = name.replace('Tool', '').lower()
            descriptions.append(f"- {name}: Use this tool for {formatted_name} tasks.")
        
        return "### AVAILABLE TOOLS\n" + "\n".join(descriptions)


========================================
FILE: src/cobalt_agent/security/vault.py
========================================

"""
Local Vault Manager - Just-In-Time (JIT) Secrets Manager.
AES-256 encrypted local credential storage with in-memory operations.
"""
import os
import json
from pathlib import Path
from typing import Dict, Optional, List
from loguru import logger
from cryptography.fernet import Fernet


class VaultManager:
    """
    In-memory Just-In-Time (JIT) Secrets Manager.
    Reads from an AES-256 encrypted local file. Secrets only exist in RAM.
    """
    
    def __init__(self, vault_path: str = "data/.cobalt_vault"):
        self.vault_path = Path(vault_path)
        self._secrets: Dict[str, str] = {}
        self._is_unlocked: bool = False
        
    def generate_master_key(self) -> str:
        """Generates a new AES-256 Fernet key. RUN ONCE."""
        return Fernet.generate_key().decode()

    def unlock(self, master_key: str) -> bool:
        """Decrypts the vault directly into RAM."""
        if not self.vault_path.exists():
            logger.warning("Vault file does not exist. Creating a new empty vault.")
            self._secrets = {}
            self._is_unlocked = True
            return True

        try:
            f = Fernet(master_key.encode())
            with open(self.vault_path, "rb") as file:
                encrypted_data = file.read()
            
            decrypted_data = f.decrypt(encrypted_data)
            self._secrets = json.loads(decrypted_data.decode())
            self._is_unlocked = True
            logger.info("üîê Vault successfully unlocked into memory.")
            return True
        except Exception as e:
            logger.error(f"Vault unlock failed (Invalid Key or Corrupt Data): {e}")
            self._is_unlocked = False
            return False

    def lock(self) -> None:
        """Wipes secrets from RAM."""
        self._secrets.clear()
        self._is_unlocked = False
        logger.info("üîí Vault locked. Secrets wiped from RAM.")

    def get_secret(self, key_name: str) -> Optional[str]:
        """JIT Secret retrieval."""
        if not self._is_unlocked:
            logger.error(f"Attempted to access secret '{key_name}' while vault is locked!")
            return None
        return self._secrets.get(key_name)

    def set_secret(self, master_key: str, key_name: str, secret_value: str) -> bool:
        """Encrypts and saves a new secret to the physical vault file."""
        if not self._is_unlocked:
            logger.error("Cannot add secret: Vault is locked.")
            return False
            
        self._secrets[key_name] = secret_value
        return self._save_vault(master_key)

    def list_secrets(self) -> List[str]:
        """Returns a list of all secret keys currently in the vault (names only)."""
        if not self._is_unlocked:
            logger.error("Cannot list secrets: Vault is locked.")
            return []
        return list(self._secrets.keys())

    def delete_secret(self, master_key: str, key_name: str) -> bool:
        """Deletes a secret from the vault and saves the updated vault."""
        if not self._is_unlocked:
            logger.error("Cannot delete secret: Vault is locked.")
            return False
            
        if key_name in self._secrets:
            del self._secrets[key_name]
            logger.info(f"Secret '{key_name}' removed from memory.")
            return self._save_vault(master_key)
        return False

    def _save_vault(self, master_key: str) -> bool:
        """Internal helper to encrypt and save the current state of RAM to disk."""
        try:
            f = Fernet(master_key.encode())
            encrypted_data = f.encrypt(json.dumps(self._secrets).encode())
            
            self.vault_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.vault_path, "wb") as file:
                file.write(encrypted_data)
                
            logger.debug("Vault successfully saved to disk.")
            return True
        except Exception as e:
            logger.error(f"Failed to encrypt and save vault: {e}")
            return False

========================================
FILE: src/cobalt_agent/skills/productivity/briefing.py
========================================

"""
The Morning Briefing Skill
Orchestrates Tools to create a daily digest.
Refactored to use Pydantic Models and LLM Synthesis.
"""
from datetime import datetime
from typing import List
from loguru import logger
from pydantic import BaseModel, Field

from cobalt_agent.config import load_config
from cobalt_agent.llm import LLM
from cobalt_agent.skills.productivity.scribe import Scribe
from cobalt_agent.tools.finance import FinanceTool
from cobalt_agent.tools.search import SearchTool

# --- PYDANTIC SCHEMA ---
class BriefingReport(BaseModel):
    """Structured format for the daily briefing."""
    executive_summary: str = Field(description="A concise 3-sentence summary of the overall market and news mood.")
    market_analysis: str = Field(description="A technical analysis of the provided stock data (Bullish/Bearish/Neutral).")
    top_headlines: List[str] = Field(description="A list of the 3-5 most critical news headlines found.")
    strategic_thought: str = Field(description="A single, provocative thought or question for the user based on today's events.")

# --- SKILL ---
class MorningBriefing:
    def __init__(self):
        # 1. Load Config & LLM
        config = load_config()
        # Handle model name attribute safely
        model_name = getattr(config.llm, "model_name", getattr(config.llm, "model", "gpt-4o"))
        
        self.llm = LLM(model_name=model_name)
        
        # 2. Initialize Tools
        self.scribe = Scribe()
        self.finance = FinanceTool()
        self.search = SearchTool()

    def _gather_data(self) -> str:
        """
        Runs tools to collect raw context for the LLM.
        """
        raw_data = []
        
        # A. Markets
        tickers = ["NVDA", "SPY", "BTC-USD"]
        raw_data.append("--- MARKET DATA ---")
        for t in tickers:
            try:
                data = self.finance.run(t)
                raw_data.append(f"{t}: {str(data)}")
            except Exception as e:
                logger.warning(f"Failed to fetch {t}: {e}")

        # B. News
        query = "top technology and finance news today"
        raw_data.append(f"\n--- NEWS SEARCH: '{query}' ---")
        try:
            results = self.search.run(query)
            if isinstance(results, list):
                raw_data.extend([str(item) for item in results])
            else:
                raw_data.append(str(results))
        except Exception as e:
            logger.warning(f"Failed to search news: {e}")

        return "\n".join(raw_data)

    def run(self):
        """Generates the daily report."""
        logger.debug("üå§Ô∏è Starting Morning Briefing generation...")
        
        # 1. Gather Data
        context_data = self._gather_data()
        
        # 2. Synthesize with LLM (The "Smart" Step)
        prompt = f"""
        You are a Chief of Staff. Review the raw market data and news below.
        Synthesize a structured Morning Briefing for me.
        
        RAW DATA:
        {context_data}
        """
        
        try:
            # Use the new ask_structured method from llm.py
            report: BriefingReport = self.llm.ask_structured(prompt, BriefingReport)
            
            # 3. Format as Markdown
            today = datetime.now().strftime("%Y-%m-%d")
            md_content = f"# üå§Ô∏è Morning Briefing: {today}\n"
            md_content += f"*Generated at: {datetime.now().strftime('%H:%M')}*\n\n"
            
            md_content += f"### üßê Executive Summary\n{report.executive_summary}\n\n"
            
            md_content += f"### üìà Market Pulse\n{report.market_analysis}\n\n"
            
            md_content += "### üì∞ Top Headlines\n"
            for news in report.top_headlines:
                md_content += f"- {news}\n"
                
            md_content += f"\n### üí° Strategic Thought\n> {report.strategic_thought}\n"

        except Exception as e:
            logger.error(f"Briefing synthesis failed: {e}")
            # Fallback if LLM fails
            md_content = f"# Briefing Failed\nCould not generate structured report.\n\nRaw Data:\n{context_data}"
            filename = f"Briefing_Failed_{datetime.now().strftime('%Y-%m-%d')}"

        # 4. Save to Obsidian
        filename = f"Briefing_{datetime.now().strftime('%Y-%m-%d')}"
        path = self.scribe.write_note(filename, md_content, folder="0 - Inbox")
        
        logger.info(f"‚úÖ Briefing saved to: {path}")
        return path

========================================
FILE: src/cobalt_agent/skills/productivity/scribe.py
========================================

"""
The Scribe Skill (Obsidian Integration)
Allows Cobalt to read, write, and search your "Second Brain".
Refactored to use Environment Variables for portability.
STRICT RULE: All automated writes go to '0 - Inbox'.
"""

import os
from pathlib import Path
from datetime import datetime
from typing import List, Optional
from loguru import logger

class Scribe:
    """
    Interface for interacting with an Obsidian Vault.
    """
    
    def __init__(self, vault_path: Optional[str] = None):
        """
        Initialize the Scribe.
        :param vault_path: Path to Obsidian vault. Defaults to env var OBSIDIAN_VAULT_PATH.
        """
        # 1. Try argument first, then environment variable
        path_str = vault_path or os.getenv("OBSIDIAN_VAULT_PATH")
        
        if not path_str:
             # Fallback for safety, but log a warning
            logger.warning("‚ö†Ô∏è OBSIDIAN_VAULT_PATH not set in .env. Defaulting to home/Documents/Think")
            path_str = str(Path.home() / "Documents" / "Think")

        self.vault_path = Path(path_str)

        if not self.vault_path.exists():
            logger.warning(f"‚ö†Ô∏è Obsidian Vault not found at {self.vault_path}. Scribe functions will fail.")

    def _resolve_path(self, filename: str) -> Path:
        """Helper to ensure file has .md extension and is inside the vault."""
        if not filename.endswith(".md"):
            filename += ".md"
        return self.vault_path / filename

    def write_note(self, filename: str, content: str, folder: str = "0 - Inbox") -> str:
        """
        Create or Overwrite a note.
        Defaults strictly to '0 - Inbox' unless overridden.
        """
        try:
            # Construct path (Vault / Folder / Filename)
            target_dir = self.vault_path / folder
            target_dir.mkdir(parents=True, exist_ok=True)
            
            clean_name = filename if filename.endswith(".md") else f"{filename}.md"
            file_path = target_dir / clean_name
            
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
            
            return f"‚úÖ Note saved: {folder}/{clean_name}"
        except Exception as e:
            logger.error(f"Failed to write note: {e}")
            return f"‚ùå Error writing note: {e}"

    def read_note(self, filename: str) -> str:
        """Read the content of a specific note."""
        try:
            # Try searching recursively if file not found in root
            found = list(self.vault_path.rglob(f"{filename if filename.endswith('.md') else filename + '.md'}"))
            
            if found:
                # Prioritize exact match if multiple found, otherwise take first
                file_path = found[0]
            else:
                 # Last ditch effort: check direct path
                file_path = self.vault_path / filename
                if not file_path.exists():
                    return f"‚ùå Note not found: {filename}"

            with open(file_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            return f"‚ùå Error reading note: {e}"

    def append_to_daily_note(self, content: str) -> str:
        """
        Appends text to today's Daily Log in '0 - Inbox'.
        """
        today = datetime.now().strftime("%Y-%m-%d")
        
        # STRICT REQUIREMENT: Inbox only
        daily_folder = "0 - Inbox"
        
        try:
            timestamp = datetime.now().strftime('%H:%M')
            header = f"\n\n### {timestamp} - Cobalt Log\n"
            full_entry = header + content
            
            target_dir = self.vault_path / daily_folder
            target_dir.mkdir(parents=True, exist_ok=True)
            
            # File format: Daily_Log_2026-02-10.md
            file_path = target_dir / f"Daily_Log_{today}.md"

            # Check if file exists to add title if new
            is_new = not file_path.exists()
            mode = "a" if not is_new else "w"

            with open(file_path, mode, encoding="utf-8") as f:
                if is_new:
                    f.write(f"# Daily Log: {today}\n")
                f.write(full_entry)
            
            return f"‚úÖ Logged to {daily_folder}/Daily_Log_{today}.md"
        except Exception as e:
            return f"‚ùå Failed to log to daily note: {e}"

    def search_vault(self, query: str, limit: int = 5) -> List[str]:
        """
        Semantic search (lite). Walks the vault and finds notes containing the keyword.
        """
        matches = []
        try:
            # Walk through all .md files
            for file_path in self.vault_path.rglob("*.md"):
                # Ignore system folders
                if any(part.startswith(".") for part in file_path.parts):
                    continue
                
                try:
                    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                        content = f.read()
                        if query.lower() in content.lower():
                            matches.append(file_path.name)
                            if len(matches) >= limit:
                                break
                except:
                    continue
            
            return matches if matches else ["No matching notes found."]
        except Exception as e:
            return [f"Error searching vault: {e}"]

========================================
FILE: src/cobalt_agent/skills/research/deep_dive.py
========================================

"""
Deep Research Agent
Implements a "Plan -> Search -> Analyze -> Report" loop.
Strictly uses Pydantic for type-safe LLM interactions.
"""
import json
from typing import List
from loguru import logger
from pydantic import BaseModel, Field, ValidationError

from cobalt_agent.llm import LLM
from cobalt_agent.config import load_config
from cobalt_agent.tools.search import SearchTool
from cobalt_agent.tools.browser import BrowserTool
from cobalt_agent.skills.productivity.scribe import Scribe

# --- PYDANTIC SCHEMAS ---
class ResearchPlan(BaseModel):
    """The strategy for researching a topic."""
    queries: List[str] = Field(
        description="A list of 3 specific, distinct search queries to investigate the topic from different angles."
    )

class ResearchReport(BaseModel):
    """The final synthesized report structure."""
    title: str = Field(description="A clear, professional title for the report.")
    executive_summary: str = Field(description="A high-level summary of the findings.")
    key_findings: List[str] = Field(description="A list of the most important technical or financial facts found.")
    strategic_outlook: str = Field(description="Forward-looking analysis or conclusion.")

# --- AGENT ---
class DeepResearch:
    def __init__(self):
        # 1. Load Global Config
        config = load_config()
        
        # 2. Extract Model Name
        if hasattr(config.llm, "model_name"):
            self.model_name = config.llm.model_name
        else:
            self.model_name = getattr(config.llm, "model", "gpt-4o")

        # 3. Initialize Components
        self.llm = LLM(model_name=self.model_name)
        self.search = SearchTool()
        self.browser = BrowserTool()
        self.scribe = Scribe()

    def run(self, topic: str):
        """
        Executes a multi-step research plan on a complex topic.
        """
        logger.info(f"üïµÔ∏è‚Äç‚ôÇÔ∏è Starting Deep Dive on: {topic} (Model: {self.model_name})")
        
        # --- PHASE 1: PLANNING ---
        logger.info("üß† Phase 1: Planning research strategy...")
        
        plan_prompt = f"Create a research plan for the topic: '{topic}'. Generate 3 distinct search queries."
        
        try:
            plan: ResearchPlan = self.llm.ask_structured(plan_prompt, ResearchPlan)
            queries = plan.queries
            logger.info(f"üìã Plan approved: {queries}")
        except Exception:
            logger.warning("Failed to generate structured plan. Falling back to defaults.")
            queries = [f"{topic} technology overview", f"{topic} market size", f"{topic} key players"]

        # --- PHASE 2: EXECUTION (The Loop) ---
        findings = []
        for q in queries:
            logger.info(f"üîç Executing Step: {q}")
            try:
                # Search returns List[SearchResult] objects now
                results = self.search.run(q)
                
                # Format the Pydantic objects into a readable string for the LLM
                formatted_results = ""
                for item in results:
                    formatted_results += f"Title: {item.title}\nURL: {item.href}\nSummary: {item.body}\n---\n"
                
                if not formatted_results:
                    formatted_results = "No results found."

                findings.append(f"### Query: {q}\n{formatted_results}\n")
                
            except Exception as e:
                logger.error(f"Search step failed for '{q}': {e}")

        # --- PHASE 3: SYNTHESIS ---
        logger.info("‚úçÔ∏è Phase 3: Synthesizing Final Report...")
        all_data = "\n".join(findings)
        
        synthesis_prompt = f"""
        Analyze these raw notes on '{topic}' and generate a final report.
        
        RAW NOTES:
        {all_data}
        """
        
        try:
            report: ResearchReport = self.llm.ask_structured(synthesis_prompt, ResearchReport)
            
            # Convert Pydantic model to Markdown for Obsidian
            md_content = f"# {report.title}\n\n"
            md_content += f"**Date:** Today\n\n"
            md_content += f"## Executive Summary\n{report.executive_summary}\n\n"
            md_content += "## Key Findings\n"
            for item in report.key_findings:
                md_content += f"- {item}\n"
            md_content += f"\n## Strategic Outlook\n{report.strategic_outlook}"
            
        except Exception as e:
            logger.error(f"Report synthesis failed: {e}")
            md_content = f"# Research Failed\nCould not generate structured report for {topic}.\n\nRaw Data:\n{all_data}"

        # --- PHASE 4: DELIVERY ---
        filename = f"Research_{topic.replace(' ', '_')}"
        path = self.scribe.write_note(filename, md_content, folder="0 - Inbox")
        
        return path

========================================
FILE: src/cobalt_agent/tools/browser.py
========================================

"""
Browser Tool with Playwright
Visits a URL and extracts clean text content. Supports dynamic actions via JSON DSL.

Features:
- Headless Chromium browsing
- Form filling, clicks, and navigation
- JSON-based action sequence support
- Clean text extraction
"""
import json
from pydantic import BaseModel, Field
from loguru import logger
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError


class WebPageContent(BaseModel):
    """Structured content from a visited webpage."""
    url: str = Field(description="The final URL after navigation.")
    title: str = Field(description="The page title.")
    content: str = Field(description="The cleaned text content of the page.")
    error: str = Field("", description="Error message if fetch failed.")

    def __str__(self):
        if self.error:
            return f"[Error reading {self.url}]: {self.error}"
        return f"### {self.title}\n{self.content[:4000]}..."


class BrowserTool:
    name = "browser"
    description = (
        "A full headless browser. You can pass a simple URL to scrape it, OR pass a JSON string to perform actions. "
        "JSON schema: {'url': '...', 'actions': [{'type': 'fill', 'selector': '...', 'text': '...'}, {'type': 'click', 'selector': '...'}]}"
    )

    def __init__(self):
        pass

    def run(self, query: str) -> WebPageContent:
        """
        Executes a browsing session. Handles both simple URLs and JSON action sequences.
        
        Args:
            query: Either a plain URL string, or a JSON object with:
                - url: The page URL
                - actions: Array of actions (fill, click)
        
        Returns:
            WebPageContent with the extracted data
        """
        url = query.strip()
        actions = []

        # Check if the LLM passed a JSON command object instead of a raw URL
        if query.strip().startswith("{") and query.strip().endswith("}"):
            try:
                command = json.loads(query)
                url = command.get("url", "")
                actions = command.get("actions", [])
            except json.JSONDecodeError:
                logger.warning("Failed to parse browser query as JSON, treating as raw URL.")
        
        # Ensure URL has protocol
        if not url.startswith("http"):
            url = "https://" + url

        logger.info(f"üåê Playwright navigating to: {url}")

        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                context = browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
                )
                page = context.new_page()
                
                # 1. Navigate
                page.goto(url, wait_until="domcontentloaded", timeout=15000)

                # 2. Execute Actions (if any)
                for action in actions:
                    act_type = action.get("type")
                    selector = action.get("selector")
                    
                    if act_type == "fill" and selector:
                        text = action.get("text", "")
                        page.fill(selector, text)
                        logger.debug(f"Filled {selector} with '{text}'")
                    elif act_type == "click" and selector:
                        page.click(selector)
                        page.wait_for_load_state("networkidle", timeout=10000)
                        logger.debug(f"Clicked {selector}")

                # 3. Wait for any dynamic content to settle
                page.wait_for_timeout(2000)

                # 4. Extract Data
                title = page.title()
                
                # Strip out scripts and styles before getting text
                page.evaluate("""
                    document.querySelectorAll('script, style, nav, footer, header, iframe').forEach(el => el.remove());
                """)
                content = page.locator("body").inner_text()
                
                # Clean up whitespace
                clean_text = "\n".join([line.strip() for line in content.splitlines() if line.strip()])
                final_url = page.url

                browser.close()

                return WebPageContent(
                    url=final_url,
                    title=title,
                    content=clean_text
                )

        except PlaywrightTimeoutError:
            return WebPageContent(url=url, title="Timeout", content="", error="Page load or action timed out.")
        except Exception as e:
            logger.error(f"Playwright error: {e}")
            return WebPageContent(url=url, title="Error", content="", error=str(e))

========================================
FILE: src/cobalt_agent/tools/finance.py
========================================

"""
Finance Tool
Returns structured market data with Technical Indicators.
Strictly implements ALL rules.yaml logic.
Fixed configuration access to handle nested dictionaries safely.
"""
import yfinance as yf
import pandas as pd
import numpy as np
from typing import Optional, Tuple, Any
from pydantic import BaseModel, Field
from loguru import logger
from cobalt_agent.config import load_config

# --- PYDANTIC MODEL ---
class MarketMetrics(BaseModel):
    """Structured financial data for a single asset."""
    ticker: str = Field(description="The stock symbol (e.g. AAPL).")
    price: float = Field(description="Current market price.")
    change_percent: float = Field(description="Daily percentage change.")
    volume: int = Field(description="Current trading volume.")
    
    # Momentum & Volatility
    rsi: float = Field(description="Relative Strength Index.")
    atr: float = Field(description="Average True Range.")
    rvol: float = Field(description="Relative Volume.")
    
    # Anchored VWAPs
    avwap_earnings: str = Field(description="VWAP from last earnings date.")
    avwap_high: str = Field(description="VWAP from 2-month Swing High.")
    avwap_low: str = Field(description="VWAP from 2-month Swing Low.")
    
    # Trend (SMAs)
    sma_10: str = Field(description="10-day SMA.")
    sma_20: str = Field(description="20-day SMA.")
    sma_50: str = Field(description="50-day SMA.")
    sma_100: str = Field(description="100-day SMA.")
    sma_200: str = Field(description="200-day SMA.")
    
    # Signals & Verification
    signal: str = Field("NEUTRAL", description="Computed technical signal.")
    alert_flags: str = Field("", description="Special alerts.")
    calculation_meta: str = Field(description="Debug string showing which rules were used.")

    def __str__(self):
        """Helper for readable string representation."""
        alerts = f" | ‚ö†Ô∏è {self.alert_flags}" if self.alert_flags else ""
        return (
            f"[{self.ticker}] ${self.price:.2f} ({self.change_percent:.2f}%) | "
            f"Signal: {self.signal}{alerts}\n"
            f"   ‚Ä¢ Rules Used: {self.calculation_meta}\n" 
            f"   ‚Ä¢ Momentum: RSI: {self.rsi:.1f} | RVOL: {self.rvol:.1f} | ATR: {self.atr:.2f}\n"
            f"   ‚Ä¢ Anchored VWAPs:\n"
            f"      - Earnings: {self.avwap_earnings}\n"
            f"      - Swing High: {self.avwap_high}\n"
            f"      - Swing Low:  {self.avwap_low}\n"
            f"   ‚Ä¢ SMAs: SMA10: {self.sma_10} | SMA20: {self.sma_20} | SMA50: {self.sma_50} | SMA200: {self.sma_200}"
        )

# --- TOOL ---
class FinanceTool:
    name = "finance"
    description = "Get current stock market data and technical indicators. Use for price queries, e.g., 'What is the price of AAPL?'"
    
    def __init__(self):
        self.system_config = load_config()
        # We access the raw dictionary or object safely
        self.rules = self.system_config.trading_rules

    def _get_rule(self, path: str, default: Any = None) -> Any:
        """
        Helper to safely access nested config rules whether they are 
        objects (dot notation) or dicts (bracket notation).
        Args:
            path: Dot-separated path e.g. "rsi.period"
        """
        try:
            current = self.rules
            for key in path.split('.'):
                if isinstance(current, dict):
                    current = current.get(key)
                else:
                    current = getattr(current, key)
                
                if current is None: return default
            return current
        except Exception:
            return default

    # --- INDICATOR CALCULATIONS ---
    def _calculate_rsi(self, data: pd.DataFrame, window: int) -> float:
        delta = data['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs)).iloc[-1]

    def _calculate_atr(self, data: pd.DataFrame, window: int) -> float:
        high_low = data['High'] - data['Low']
        high_close = np.abs(data['High'] - data['Close'].shift())
        low_close = np.abs(data['Low'] - data['Close'].shift())
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = np.max(ranges, axis=1)
        return true_range.rolling(window=window).mean().iloc[-1]

    def _calculate_rvol(self, data: pd.DataFrame, window: int = 20) -> float:
        avg_vol = data['Volume'].rolling(window=window).mean().iloc[-1]
        current_vol = data['Volume'].iloc[-1]
        if avg_vol == 0: return 0.0
        return current_vol / avg_vol

    def _calculate_avwap(self, data: pd.DataFrame, start_date: str) -> float:
        subset = data.loc[start_date:]
        if subset.empty: return 0.0
        v = subset['Volume'].values
        tp = (subset['High'] + subset['Low'] + subset['Close']) / 3
        return ((tp * v).cumsum() / v.cumsum()).iloc[-1]

    def _get_sma_data(self, data: pd.DataFrame, window: int) -> Tuple[float, str]:
        sma_series = data['Close'].rolling(window=window).mean()
        if len(sma_series) < 2 or pd.isna(sma_series.iloc[-1]): return (0.0, "N/A")
        current = sma_series.iloc[-1]
        previous = sma_series.iloc[-2]
        slope = "RISING" if current > previous else "FALLING"
        return current, slope

    def _get_last_earnings_date(self, ticker_obj) -> Optional[str]:
        try:
            earnings = ticker_obj.earnings_dates
            if earnings is None or earnings.empty: return None
            today = pd.Timestamp.now().tz_localize(earnings.index.dtype.tz)
            past_earnings = earnings[earnings.index < today]
            if past_earnings.empty: return None
            return past_earnings.index[0].strftime('%Y-%m-%d')
        except: return None

    # --- MAIN RUN METHOD ---
    def run(self, ticker: str) -> MarketMetrics:
        try:
            logger.debug(f"Fetching market data for: {ticker}")
            ticker = ticker.upper()
            stock = yf.Ticker(ticker)
            hist = stock.history(period="2y")
            
            if hist.empty:
                return MarketMetrics(
                    ticker=ticker, price=0.0, change_percent=0.0, volume=0, 
                    rsi=0, atr=0, rvol=0, avwap_earnings="N/A", avwap_high="N/A", avwap_low="N/A",
                    sma_10="N/A", sma_20="N/A", sma_50="N/A", sma_100="N/A", sma_200="N/A",
                    signal="NO DATA", calculation_meta="ERROR"
                )

            current_price = hist['Close'].iloc[-1]
            prev_price = hist['Close'].iloc[-2]
            change_pct = ((current_price - prev_price) / prev_price) * 100
            
            # --- 1. CONFIG PARAMETERS (Using Safe Access) ---
            # Using _get_rule helper to handle dict vs object mismatch
            rsi_period = self._get_rule("rsi.period", 14)
            rsi_overbought = self._get_rule("rsi.overbought", 70)
            rsi_oversold = self._get_rule("rsi.oversold", 30)
            
            atr_period = self._get_rule("atr.period", 14)
            atr_mult = self._get_rule("atr.expansion_multiplier", 5.0)
            
            ma_fast = self._get_rule("moving_averages.bullish_cross.fast", 10)
            ma_slow = self._get_rule("moving_averages.bullish_cross.slow", 20)
            
            rvol_alert = self._get_rule("momentum.rvol_alert_threshold", 3.0)

            # --- 2. CALCULATIONS ---
            rsi_val = self._calculate_rsi(hist, window=rsi_period)
            atr_val = self._calculate_atr(hist, window=atr_period)
            rvol_val = self._calculate_rvol(hist)

            # Anchored VWAPs
            last_earnings = self._get_last_earnings_date(stock)
            avwap_earn_str = "N/A"
            avwap_earn_val = 0.0
            if last_earnings:
                val = self._calculate_avwap(hist, last_earnings)
                avwap_earn_val = val
                dist = ((current_price - val) / val) * 100
                avwap_earn_str = f"${val:.2f} ({'ABOVE' if current_price > val else 'BELOW'} {abs(dist):.1f}%)"

            # Swing VWAPs
            recent_data = hist.tail(42)
            idx_max = recent_data['High'].idxmax()
            idx_min = recent_data['Low'].idxmin()
            
            val_high = self._calculate_avwap(hist, idx_max.strftime('%Y-%m-%d'))
            dist_high = ((current_price - val_high) / val_high) * 100
            avwap_high_str = f"${val_high:.2f} ({'ABOVE' if current_price > val_high else 'BELOW'} {abs(dist_high):.1f}%)"

            val_low = self._calculate_avwap(hist, idx_min.strftime('%Y-%m-%d'))
            dist_low = ((current_price - val_low) / val_low) * 100
            avwap_low_str = f"${val_low:.2f} ({'ABOVE' if current_price > val_low else 'BELOW'} {abs(dist_low):.1f}%)"

            # SMAs
            sma10_val, sma10_slope = self._get_sma_data(hist, 10)
            sma20_val, sma20_slope = self._get_sma_data(hist, 20)
            sma50_val, sma50_slope = self._get_sma_data(hist, 50)
            sma100_val, sma100_slope = self._get_sma_data(hist, 100)
            sma200_val, sma200_slope = self._get_sma_data(hist, 200)

            # --- 3. SIGNAL LOGIC ---
            signal = "NEUTRAL"
            alerts = []
            
            # A. RSI Checks
            if rsi_val > rsi_overbought: signal = f"OVERBOUGHT (> {rsi_overbought})"
            elif rsi_val < rsi_oversold: signal = f"OVERSOLD (< {rsi_oversold})"
            
            # B. Bullish Cross (Fast > Slow AND Both Rising)
            # Using configured periods for logic check (assuming 10/20 here matches variables)
            # Ideally we'd calculate dynamic SMAs based on config, but for now we hardcoded the 10/20 fetch above.
            elif (sma10_val > sma20_val) and (sma10_slope == "RISING") and (sma20_slope == "RISING"):
                 signal = f"BULLISH CROSS ({ma_fast}/{ma_slow} Rising)"
            
            # C. Trend (Earnings VWAP)
            elif avwap_earn_val > 0:
                if current_price > avwap_earn_val: signal = "BULLISH (Above Earnings VWAP)"
                else: signal = "BEARISH (Below Earnings VWAP)"

            # Alerts
            if rvol_val > rvol_alert: 
                alerts.append("RVOL ALERT")
            
            five_day_move = abs(current_price - hist['Close'].iloc[-6]) 
            if five_day_move > (atr_val * atr_mult):
                alerts.append("PARABOLIC MOVE")

            meta_string = f"RSI-{rsi_period} ({rsi_oversold}/{rsi_overbought}) | Cross-{ma_fast}/{ma_slow}"

            return MarketMetrics(
                ticker=ticker,
                price=round(current_price, 2),
                change_percent=round(change_pct, 2),
                volume=int(hist['Volume'].iloc[-1]),
                rsi=round(rsi_val, 1),
                atr=round(atr_val, 2),
                rvol=round(rvol_val, 2),
                avwap_earnings=avwap_earn_str,
                avwap_high=avwap_high_str,
                avwap_low=avwap_low_str,
                sma_10=f"${sma10_val:.2f} ({sma10_slope})",
                sma_20=f"${sma20_val:.2f} ({sma20_slope})",
                sma_50=f"${sma50_val:.2f} ({sma50_slope})",
                sma_100=f"${sma100_val:.2f} ({sma100_slope})",
                sma_200=f"${sma200_val:.2f} ({sma200_slope})",
                signal=signal,
                alert_flags=", ".join(alerts),
                calculation_meta=meta_string
            )

        except Exception as e:
            logger.error(f"Finance tool error for {ticker}: {e}")
            return MarketMetrics(
                ticker=ticker, price=0.0, change_percent=0.0, volume=0, 
                rsi=0, atr=0, rvol=0, avwap_earnings="Err", avwap_high="Err", avwap_low="Err",
                sma_10="N/A", sma_20="N/A", sma_50="N/A", sma_100="N/A", sma_200="N/A",
                signal="ERROR", calculation_meta="Error"
            )

========================================
FILE: src/cobalt_agent/tools/search.py
========================================

"""
Search Tool
Now returns strict Pydantic models instead of raw dictionaries.
Updated to use the new 'ddgs' package.
"""
from typing import List
from pydantic import BaseModel, Field
from loguru import logger
from ddgs import DDGS # <--- CHANGED THIS IMPORT

# --- PYDANTIC MODELS ---
class SearchResult(BaseModel):
    """A single search result item."""
    title: str = Field(description="The title of the search result.")
    href: str = Field(description="The URL link to the result.")
    body: str = Field(description="The snippet or summary text.")

# --- TOOL ---
class SearchTool:
    name = "search"
    description = "Search the internet for news, information, and general knowledge. Use for questions about current events, topics, or general queries."
    
    def __init__(self):
        pass

    def run(self, query: str, max_results: int = 5) -> List[SearchResult]:
        """
        Executes a search and returns a list of typed SearchResult objects.
        """
        try:
            logger.debug(f"Searching for: {query}")
            
            # 1. Execute Search
            # We use the context manager approach for safety
            with DDGS() as ddgs:
                # .text() returns a generator/iterator, so we cast to list
                results = list(ddgs.text(query, max_results=max_results))
            
            # 2. Convert to Pydantic Models
            structured_results = []
            for item in results:
                try:
                    # We map the raw dict keys to our model
                    structured_results.append(SearchResult(
                        title=item.get('title', 'No Title'),
                        href=item.get('href', '#'),
                        body=item.get('body', 'No description available.')
                    ))
                except Exception as e:
                    logger.warning(f"Skipping malformed search result: {e}")
            
            if not structured_results:
                 logger.warning(f"No results found for '{query}'")
                 return []
                 
            return structured_results

        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []

========================================
FILE: src/cobalt_agent/tools/tool_manager.py
========================================

"""
Cobalt Agent - Tool Manager
Registry and execution engine for all agent capabilities.
"""

from typing import Dict, Any, List, Optional
from loguru import logger
from pydantic import BaseModel

# Import your tools
from cobalt_agent.tools.search import SearchTool
# Import Browser
from cobalt_agent.tools.browser import BrowserTool
# Import Finance
from cobalt_agent.tools.finance import FinanceTool

class ToolResult(BaseModel):
    """Standardized output for any tool execution."""
    success: bool
    output: Any
    error: Optional[str] = None

class ToolManager:
    """
    Manages the registration and execution of tools.
    Allows the LLM to 'see' and 'use' functions.
    """
    
    def __init__(self):
        self.tools: Dict[str, Any] = {}
        self._register_core_tools()
        
    def _register_core_tools(self):
        """Register the default built-in tools."""
        # 1. Search Tool
        search = SearchTool()
        self.register_tool("search", search)

        # 2. Browser Tool
        browser = BrowserTool()
        self.register_tool("browser", browser)
        
        # 3. <--- ADDED: Finance Tool
        finance = FinanceTool()
        self.register_tool("finance", finance)
        
    def register_tool(self, name: str, tool_instance: Any):
        """Add a new tool to the registry."""
        self.tools[name] = tool_instance
        logger.info(f"Tool registered: {name}")

    def get_tool_descriptions(self) -> List[Any]:
        """Return the list of tool objects for the Prompt Engine."""
        return list(self.tools.values())

    def execute_tool(self, tool_name: str, args: Dict[str, Any]) -> ToolResult:
        """
        Execute a registered tool by name.
        
        Args:
            tool_name: The name of the tool (e.g., 'search')
            args: Dictionary of arguments for the tool (e.g., {'query': '...'})
        """
        if tool_name not in self.tools:
            return ToolResult(success=False, output=None, error=f"Tool '{tool_name}' not found.")
            
        tool = self.tools[tool_name]
        
        try:
            logger.info(f"Executing tool: {tool_name} with args: {args}")
            
            # This logic assumes all tools have a .run() method
            # We might need to adapt this if tools have different signatures
            if hasattr(tool, 'run'):
                # Extract the main argument (most tools just take a query string for now)
                # This is a simplification; later we will make this robust.
                query = args.get('query') or args.get('q') or list(args.values())[0]
                
                result = tool.run(query)
                return ToolResult(success=True, output=result)
            else:
                return ToolResult(success=False, output=None, error=f"Tool '{tool_name}' has no run() method.")

        except Exception as e:
            logger.error(f"Tool Execution Failed: {e}")
            return ToolResult(success=False, output=None, error=str(e))

========================================
FILE: src/cobalt_agent.egg-info/SOURCES.txt
========================================

README.md
pyproject.toml
src/cobalt_agent/__init__.py
src/cobalt_agent/config.py
src/cobalt_agent/llm.py
src/cobalt_agent/main.py
src/cobalt_agent/persona.py
src/cobalt_agent/prompt.py
src/cobalt_agent.egg-info/PKG-INFO
src/cobalt_agent.egg-info/SOURCES.txt
src/cobalt_agent.egg-info/dependency_links.txt
src/cobalt_agent.egg-info/requires.txt
src/cobalt_agent.egg-info/top_level.txt
src/cobalt_agent/brain/cortex.py
src/cobalt_agent/brain/playbook.py
src/cobalt_agent/brain/strategy.py
src/cobalt_agent/brain/tactical.py
src/cobalt_agent/brain/strategies/__init__.py
src/cobalt_agent/brain/strategies/second_day_play.py
src/cobalt_agent/core/__init__.py
src/cobalt_agent/core/proposals.py
src/cobalt_agent/core/scheduler.py
src/cobalt_agent/interfaces/__init__.py
src/cobalt_agent/interfaces/cli.py
src/cobalt_agent/interfaces/mattermost.py
src/cobalt_agent/memory/__init__.py
src/cobalt_agent/memory/base.py
src/cobalt_agent/memory/core.py
src/cobalt_agent/memory/postgres.py
src/cobalt_agent/skills/productivity/briefing.py
src/cobalt_agent/skills/productivity/scribe.py
src/cobalt_agent/skills/research/deep_dive.py
src/cobalt_agent/tools/__init__.py
src/cobalt_agent/tools/browser.py
src/cobalt_agent/tools/finance.py
src/cobalt_agent/tools/search.py
src/cobalt_agent/tools/tool_manager.py
tests/test_brain_connection.py
tests/test_config_override.py
tests/test_logic_lab.py
tests/test_memory_integration.py
tests/test_role_switch.py
tests/test_scribe.py
tests/test_strategies.py

========================================
FILE: src/cobalt_agent.egg-info/dependency_links.txt
========================================




========================================
FILE: src/cobalt_agent.egg-info/requires.txt
========================================

pydantic>=2.0.0
pydantic-ai>=0.0.1
litellm>=1.0.0
openai>=1.0.0
pandas>=2.2.0
pandas-ta-classic
ta-lib>=0.4.0
mplfinance>=0.12.0
aiohttp>=3.9.0
mattermostdriver>=7.0
google-api-python-client>=2.0
gitpython>=3.1.0
schedule>=1.2.0
beautifulsoup4>=4.12.0
playwright>=1.40.0
fastapi>=0.100.0
uvicorn>=0.20.0
redis>=5.0.0
asyncpg>=0.29.0
sqlalchemy>=2.0.0
loguru>=0.7.0
python-dotenv>=1.0.0
pyyaml>=6.0.0
pyotp>=2.9.0
qrcode>=7.4.0
bcrypt>=4.0.0
passlib>=1.7.0
ddgs>=9.10.0
rich>=14.3.2
requests>=2.32.5
yfinance>=1.1.0
psycopg[binary]>=3.3.2
pgvector>=0.4.2
apscheduler>=3.11.2
cryptography>=46.0.4


========================================
FILE: src/cobalt_agent.egg-info/top_level.txt
========================================

cobalt_agent


========================================
FILE: tests/conftest.py
========================================

"""
Pytest Configuration
Allows tests to import modules from the main directory and loads Environment Variables.
"""
import sys
import os
import pytest
from dotenv import load_dotenv

# 1. LOAD SECRETS (Crucial Step)
# This forces the test runner to read your .env file
load_dotenv()

# 2. ADD SOURCE CODE TO PATH
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

@pytest.fixture
def mock_config():
    """Provides a standard mock configuration for tests."""
    return {
        "strategies": {
            "second_day_play": {
                "active": True,
                "scoring": {
                    "base_score": 50,
                    "high_rvol_threshold": 3.0,
                    "high_rvol_points": 20, 
                    "base_rvol_points": 10,
                    "gap_up_points": 5,
                    "live_rvol_multiplier": 5.0,
                    "spy_correlation_weight": 10.0,
                    "resistance_penalty": -20.0,
                    "time_decay_per_min": -0.5
                }
            }
        }
    }

========================================
FILE: tests/test_brain_connection.py
========================================

import os
import sys

# Add project root to path so we can import 'cobalt_agent'
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from dotenv import load_dotenv
from cobalt_agent.llm import LLM

# 1. Load the secrets
load_dotenv()

# 2. Get the model name from .env
# NOTE: We force the 'ollama/' prefix to test the local routing logic
model_name = os.getenv("OLLAMA_MODEL", "qwen2.5:14b")
if not model_name.startswith("ollama/"):
    full_model = f"ollama/{model_name}"
else:
    full_model = model_name

print(f"üß† Testing Connection to: {full_model}")
print(f"üì° Target URL: {os.getenv('OLLAMA_BASE_URL', 'Not Set')}")

try:
    # 3. Initialize the Brain
    brain = LLM(model_name=full_model)

    # 4. Ask a question
    response = brain.ask("Are you running on the Mac Studio?")

    print("\n--- RESPONSE ---")
    print(response)
    print("----------------")
    print("‚úÖ SUCCESS: The Brain is Online.")

except Exception as e:
    print(f"\n‚ùå FAILED: {e}")
    print("Tip: Check if Ollama is running and OLLAMA_HOST=0.0.0.0 is set if remote.")

========================================
FILE: tests/test_config_override.py
========================================

#!/usr/bin/env python3
"""
Test script to verify Pydantic Settings configuration override from .env file.

This script tests that:
1. YAML config is loaded correctly
2. Environment variables override YAML values
3. Nested values like network.nodes.cortex.ip are properly overridden
"""

import sys
import os

# Add src to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))

from cobalt_agent.config import load_config, get_config


def test_config_override():
    """Test that config overrides work correctly."""
    print("=" * 60)
    print("Testing Pydantic Settings Config Override")
    print("=" * 60)
    
    # Get configuration instance
    config = get_config()
    
    # Test 1: Check cortex IP (should be 'localhost' from .env)
    # Pydantic env_nested_delimiter="_" maps: NETWORK_NODES_CORTEX_IP -> network.nodes.cortex.ip
    print("\n[Test 1] Cortex IP Override")
    print("-" * 40)
    expected_yaml_ip = "10.200.2.196"
    expected_env_ip = "localhost"
    
    cortex_ip = config.network.nodes["cortex"].ip
    
    print(f"  Expected (from .env): {expected_env_ip}")
    print(f"  Expected (from yaml): {expected_yaml_ip}")
    print(f"  Actual: {cortex_ip}")
    
    if cortex_ip == expected_env_ip:
        print("  [PASS] Environment variable override works!")
    else:
        print(f"  [FAIL] Expected '{expected_env_ip}' but got '{cortex_ip}'")
        print("  NOTE: Use NETWORK_NODES_CORTEX_IP in .env for Pydantic env_nested_delimiter")
    
    # Test 2: Check Obsidian Vault Path (should be from .env)
    print("\n[Test 2] Obsidian Vault Path Override")
    print("-" * 40)
    expected_vault_path = "/Users/cobalt/cobalt/docs/Cobalt"
    
    vault_path = config.system.obsidian_vault_path
    
    print(f"  Expected: {expected_vault_path}")
    print(f"  Actual: {vault_path}")
    
    if vault_path == expected_vault_path:
        print("  [PASS] Obsidian vault path loaded correctly!")
    else:
        print(f"  [FAIL] Expected '{expected_vault_path}' but got '{vault_path}'")
    
    # Test 3: Print full cortex node configuration
    print("\n[Test 3] Full Cortex Node Configuration")
    print("-" * 40)
    cortex_node = config.network.nodes["cortex"]
    print(f"  Role: {cortex_node.role}")
    print(f"  IP: {cortex_node.ip}")
    print(f"  Port: {cortex_node.port}")
    print(f"  Protocol: {cortex_node.protocol}")
    
    # Test 4: Print system configuration
    print("\n[Test 4] System Configuration")
    print("-" * 40)
    print(f"  Debug Mode: {config.system.debug_mode}")
    print(f"  Version: {config.system.version}")
    print(f"  Obsidian Vault Path: {config.system.obsidian_vault_path}")
    
    print("\n" + "=" * 60)
    print("Config Override Test Complete")
    print("=" * 60)
    
    return cortex_ip == expected_env_ip


if __name__ == "__main__":
    success = test_config_override()
    sys.exit(0 if success else 1)

========================================
FILE: tests/test_logic_lab.py
========================================

"""
Logic Lab - Strategy Tester (Fixed)
Simulates the 'Mac Studio' generating a Scoring Profile.
"""
import sys
import os
import json

# Fix path to allow importing from cobalt_agent
sys.path.append(os.getcwd())

from cobalt_agent.brain.strategies.second_day_play import SecondDayPlay

def run_simulation():
    print("üß™ Starting Logic Lab: Second Day Play Simulation...\n")
    
    # --- SCENARIO 1: The Perfect Setup (NVDA Earnings) ---
    mock_market_data_good = {
        "yesterday_close": 140.00,
        "yesterday_volume": 50_000_000,
        "average_volume": 10_000_000, # RVOL = 5.0 (Huge)
        "today_open": 141.50,         # Gapping Up
        "pre_market_high": 142.00     # The Breakout Level
    }

    # --- SCENARIO 2: The Failed Setup (Weak Volume) ---
    mock_market_data_bad = {
        "yesterday_close": 50.00,
        "yesterday_volume": 1_200_000,
        "average_volume": 1_000_000,  # RVOL = 1.2 (Too Low)
        "today_open": 50.50,
        "pre_market_high": 51.00
    }

    # --- THE FIX: Create a Mock Config ---
    # The Strategy class expects a configuration dictionary (usually from strategies.yaml)
    mock_config = {
        "name": "SecondDayPlay",
        "description": "Continuation breakout logic",
        "parameters": {
            "min_rvol": 1.5,
            "gap_percentage": 2.0
        }
    }

    # Initialize with the config
    try:
        strategy = SecondDayPlay(mock_config)
    except TypeError:
        # Fallback if your version doesn't take config (just in case)
        strategy = SecondDayPlay()

    # TEST 1: Run the Good Data
    print(f"üîπ Analyzing Ticker: NVDA (Scenario: Earnings Blowout)")
    profile_good = strategy.analyze("NVDA", mock_market_data_good)
    print(json.dumps(profile_good, indent=4))
    
    print("\n" + "-"*50 + "\n")

    # TEST 2: Run the Bad Data
    print(f"üîπ Analyzing Ticker: WEAK (Scenario: Low Volume Pump)")
    profile_bad = strategy.analyze("WEAK", mock_market_data_bad)
    print(json.dumps(profile_bad, indent=4))

if __name__ == "__main__":
    run_simulation()

========================================
FILE: tests/test_memory_integration.py
========================================

"""
Memory Integration Tests
Verifies that the Docker Database is reachable and properly configured.
"""
import os
import pytest
import psycopg  # We assume psycopg 3 (modern standard)

# Load environment variables (normally loaded by python-dotenv in app)
# For tests, we can just grab them from os if they are set, or define defaults
DB_HOST = os.getenv("POSTGRES_HOST", "localhost")
DB_NAME = os.getenv("POSTGRES_DB", "cobalt_memory")
DB_USER = os.getenv("POSTGRES_USER", "postgres")
DB_PASS = os.getenv("POSTGRES_PASSWORD", "cobalt_password")

def get_connection_string():
    return f"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:5432/{DB_NAME}"

@pytest.mark.integration
def test_database_connection():
    """Can we actually knock on the door?"""
    try:
        conn_str = get_connection_string()
        with psycopg.connect(conn_str) as conn:
            # Execute a simple query
            res = conn.execute("SELECT 1").fetchone()
            assert res[0] == 1
    except Exception as e:
        pytest.fail(f"Could not connect to Docker DB: {e}")

@pytest.mark.integration
def test_vector_extension_enabled():
    """
    CRITICAL: Is the 'pgvector' extension turned on?
    Without this, the AI cannot have Long-Term Memory.
    """
    conn_str = get_connection_string()
    with psycopg.connect(conn_str) as conn:
        # Check the pg_extension table
        res = conn.execute("SELECT extname FROM pg_extension WHERE extname = 'vector'").fetchone()
        
        if not res:
            pytest.fail("The 'vector' extension is missing! Memory retrieval will fail.")
        
        assert res[0] == "vector"

@pytest.mark.integration
def test_create_and_read_memory():
    """Can we write a fake memory and read it back?"""
    conn_str = get_connection_string()
    table_name = "test_memory_check"
    
    with psycopg.connect(conn_str) as conn:
        # 1. Create a dummy table
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                id SERIAL PRIMARY KEY,
                content TEXT
            );
        """)
        
        # 2. Insert data
        test_phrase = "Cobalt Integration Test"
        conn.execute(f"INSERT INTO {table_name} (content) VALUES (%s)", (test_phrase,))
        
        # 3. Read it back
        res = conn.execute(f"SELECT content FROM {table_name} ORDER BY id DESC LIMIT 1").fetchone()
        assert res[0] == test_phrase
        
        # 4. Cleanup (Drop table)
        conn.execute(f"DROP TABLE {table_name}")

========================================
FILE: tests/test_role_switch.py
========================================

"""
Test script for role switching (Two-Brain Hot Swap)
Project Cobalt: Verifies Qwen 80B -> DeepSeek 70B transition

This script tests the role switch capability:
1. Initialize the Agent with default role
2. Print current model (Should be Qwen 80B)
3. Execute role switch: agent.llm.switch_role("strategist")
4. Print new model (Should be DeepSeek 70B)

This triggers a "Hot Swap" - unloading Qwen (48GB) and loading DeepSeek (42GB).
Watch RAM usage - this tests our 'MAX_LOADED_MODELS=1' safety valve.
"""

import sys
import os

# Add the project root to the path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from cobalt_agent.llm import LLM
from cobalt_agent.config import load_config


def test_role_switch():
    """Test the role switching functionality."""
    print("=" * 80)
    print("TWO-BRAIN ROLE SWITCH TEST")
    print("=" * 80)
    print()
    
    # Load config to display current settings
    config = load_config()
    
    print("Current Configuration:")
    print(f"  Strategist role: {config.active_profile.get('strategist', 'NOT FOUND')}")
    print(f"  Strategist model: {config.models.get('local_strategist_r1', {}).get('model_name', 'NOT FOUND')}")
    print()
    
    # Step 1: Initialize Agent with default role
    print("Step 1: Initialize Agent with 'default' role...")
    agent_llm = LLM(role="default")
    print(f"  Current model: {agent_llm.model_name}")
    print()
    
    # Verify initial model is Qwen 80B (local_bleeding_edge)
    expected_initial = "ollama/qwen3-coder-next"
    if agent_llm.model_name == expected_initial:
        print(f"  ‚úì Initial model matches expected: {expected_initial}")
    else:
        print(f"  ‚ö† Initial model differs from expected ({expected_initial})")
    print()
    
    # Step 2: Execute role switch to strategist
    print("Step 2: Execute role switch to 'strategist'...")
    agent_llm.switch_role("strategist")
    print(f"  New model: {agent_llm.model_name}")
    print()
    
    # Verify new model is DeepSeek 70B (local_strategist_r1)
    expected_strategist = "ollama/deepseek-r1:70b"
    if agent_llm.model_name == expected_strategist:
        print(f"  ‚úì Strategist model matches expected: {expected_strategist}")
    else:
        print(f"  ‚ö† Strategist model differs from expected ({expected_strategist})")
    print()
    
    # Summary
    print("=" * 80)
    print("TEST SUMMARY")
    print("=" * 80)
    print(f"  Initial model (default):    {agent_llm.model_name}")
    print(f"  After switch to strategist: {agent_llm.model_name}")
    print()
    
    # Hot swap note
    print("HOT SWAP NOTES:")
    print("  - This test triggers model unloading/reloading")
    print("  - Expected: Qwen 80B (48GB) -> DeepSeek 70B (42GB)")
    print("  - Monitor RAM usage to verify MAX_LOADED_MODELS=1 safety valve")
    print("=" * 80)


if __name__ == "__main__":
    test_role_switch()

========================================
FILE: tests/test_scribe.py
========================================

"""
Scribe Skill Tests
Verifies that notes are written to the correct location using environment variables.
"""
import os
import pytest
from cobalt_agent.skills.productivity.scribe import Scribe

def test_scribe_initialization(tmp_path):
    """Test if Scribe accepts a direct path."""
    scribe = Scribe(vault_path=str(tmp_path))
    assert scribe.vault_path == tmp_path

def test_scribe_env_var_fallback(monkeypatch, tmp_path):
    """
    Test if Scribe falls back to the Environment Variable if no path is given.
    """
    monkeypatch.setenv("OBSIDIAN_VAULT_PATH", str(tmp_path))
    scribe = Scribe()
    assert scribe.vault_path == tmp_path

def test_write_note(tmp_path):
    """Test actually writing a file to a fake vault."""
    scribe = Scribe(vault_path=str(tmp_path))
    
    filename = "test_note"
    content = "# Hello World"
    folder = "0 - Inbox"
    
    result = scribe.write_note(filename, content, folder)
    
    expected_file = tmp_path / folder / "test_note.md"
    assert expected_file.exists()
    assert expected_file.read_text(encoding="utf-8") == content
    assert "‚úÖ Note saved" in result

========================================
FILE: tests/test_strategies.py
========================================

"""
Strategy Test Suite
Verifies that trading logic respects the configuration rules.
"""
import pytest
from cobalt_agent.brain.strategies.second_day_play import SecondDayPlay

# --- FIXTURES (Reusable Data) ---

@pytest.fixture
def mock_config():
    """Simulates the data from strategies.yaml"""
    return {
        "name": "Second Day Play",
        "parameters": {
            "min_rvol": 1.5,
            "gap_percentage": 2.0
        },
        "scoring": {
            "base_score": 50,
            "high_rvol_threshold": 3.0,
            "high_rvol_points": 20, # Custom value for test to verify logic
            "base_rvol_points": 10,
            "gap_up_points": 5
        }
    }

@pytest.fixture
def mock_nvda_data():
    """A perfect setup: High Volume, Gap Up."""
    return {
        "yesterday_close": 140.00,
        "yesterday_volume": 50_000_000,
        "average_volume": 10_000_000, # RVOL = 5.0 (High)
        "today_open": 141.50,         # Gap Up
        "pre_market_high": 142.00
    }

@pytest.fixture
def mock_weak_data():
    """A failed setup: Low Volume."""
    return {
        "yesterday_close": 50.00,
        "yesterday_volume": 1_200_000,
        "average_volume": 1_000_000,  # RVOL = 1.2 (Fail)
        "today_open": 50.50,
        "pre_market_high": 51.00
    }

# --- TESTS ---

def test_second_day_play_initialization(mock_config):
    """Does the strategy load the config correctly?"""
    strategy = SecondDayPlay(mock_config)
    assert strategy.params["min_rvol"] == 1.5
    assert strategy.scoring["high_rvol_points"] == 20

def test_valid_setup_scoring(mock_config, mock_nvda_data):
    """
    Test Math:
    Base (50) + High RVOL (20) + Gap Up (5) = 75
    """
    strategy = SecondDayPlay(mock_config)
    result = strategy.analyze("NVDA", mock_nvda_data)
    
    assert result["status"] == "ACTIVE_WATCH"
    assert result["scoring_engine"]["base_score"] == 75
    assert result["zones"]["entry"] == 142.05

def test_rejection_logic(mock_config, mock_weak_data):
    """Ensure weak stocks are rejected."""
    strategy = SecondDayPlay(mock_config)
    result = strategy.analyze("WEAK", mock_weak_data)
    
    assert result["status"] == "REJECTED"
    assert "Low Relative Volume" in result["reason"]